[
  {
    "doc_id": "10000326",
    "abstract_original": "The teaching of programming is a critical topic in our society. Given the Science and Technology initiatives, these topics are considered in different training cycles: primary, secondary and higher education. In the case of higher education, students must cultivate fundamental concepts for developing computer applications, which contribute to not only the knowledge of programming languages but also open guidelines for computational thinking. In previous research, we evaluated a set of platforms under a usability lens; on this occasion, we compare these results and their impact on the learning outcomes. We evaluated three experimental groups that used video game platforms to achieve their learning outcomes. Additionally, we will synthesize the literature regarding new paradigms of programming education under immersive environments.",
    "abstract_processed": "teach program critic topic societi given scienc technolog initi topic consid differ train cycl primari secondari higher educ case higher educ student must cultiv fundament concept develop comput applic contribut knowledg program languag also open guidelin comput think previou research evalu set platform usabl len occas compar result impact learn outcom evalu three experiment group use video game platform achiev learn outcom addit synthes literatur regard new paradigm program educ immers environ"
  },
  {
    "doc_id": "10003332",
    "abstract_original": "A pattern classifier named Hash-based Associative Memory-like Pattern Classifier (HAPC) based on hashing technique, associative memory, and human deep-thinking logic is proposed in this paper to solve pattern classification problems without complicated mathematical computation. In the hashing layer of the designed system, one of the similarity-preserve hashing is used to convert the input samples to hashed data which dramatically reduces the dimensionality of the data but keeps the similarity information. In the clustering layer, hashed samples are divided into different clusters, which can be considered a feature extraction process based on the similarity of the hash value. In the associate memory layer, each cluster will be trained as an associate memory to store the hashed data stably. In the logical layer, Bayesian inference is used to perform the decision-making process to classify the testing sample without complicated mathematical computation. In the simulation, we are able to achieve a good result, especially on small numbers of training data.",
    "abstract_processed": "pattern classifi name hash base associ memori like pattern classifi hapc base hash techniqu associ memori human deep think logic propos paper solv pattern classif problem without complic mathemat comput hash layer design system one similar preserv hash use convert input sampl hash data dramat reduc dimension data keep similar inform cluster layer hash sampl divid differ cluster consid featur extract process base similar hash valu associ memori layer cluster train associ memori store hash data stabli logic layer bayesian infer use perform decis make process classifi test sampl without complic mathemat comput simul abl achiev good result especi small number train data"
  },
  {
    "doc_id": "10003911",
    "abstract_original": "Brain-computer interface (BCI) is a promising technology that controls computers or machines using brain signals. With this technology, people with various disabilities, such as neural paralysis, and spinal cord injury can control electric devices or express their intention by thinking. However, previous BCI studies have a limitation that they can predict only one type of intention. To use the BCI system in daily life, the BCI user should be able to achieve various tasks such as moving, text typing, and arm movements. In this paper, we propose a multi-functional BCI method that can predict various intentions simultaneously. To classify multiple intentions, we proposed two prediction models using Neural Networks (NN) and Convolutional Neural Networks (CNN) models. To evaluate the proposed BCI system, the classification accuracy of the model was measured and compared using steady state visually evoked potential (SSVEP), sensory motor rhythm (SMR), and both of them (Multiple Intention). The average prediction accuracies were 22.46% in NN, 55.86% in CNN. These results indicate that the proposed multi-functional BCI can predict multiple intentions. It also means that users of the proposed BCI system can control various electric devices simultaneously.",
    "abstract_processed": "brain comput interfac bci promis technolog control comput machin use brain signal technolog peopl variou disabl neural paralysi spinal cord injuri control electr devic express intent think howev previou bci studi limit predict one type intent use bci system daili life bci user abl achiev variou task move text type arm movement paper propos multi function bci method predict variou intent simultan classifi multipl intent propos two predict model use neural network nn convolut neural network cnn model evalu propos bci system classif accuraci model measur compar use steadi state visual evok potenti ssvep sensori motor rhythm smr multipl intent averag predict accuraci nn cnn result indic propos multi function bci predict multipl intent also mean user propos bci system control variou electr devic simultan"
  },
  {
    "doc_id": "10004399",
    "abstract_original": "An increasing number of tools have been created to assist students in learning mathematics. Robots have been regarded as an especially powerful tool to help students master mathematics since students can simultaneously learn mathematics, programming, robotic control, and computational thinking. Although a number of educational robots and curricula have been developed, some of them do not comply with math standards, so they are primarily suitable for after-school programs, camps, or workshops. Students might not be able to focus on learning mathematics now that writing a program might be difficult for them due to debugging. In this paper, mathematics curricula that meet math standards are developed with a block-based programming platform, Roboblocky. Linkbots are utilized as robots in the curricula to teach and learn mathematics in school settings. Students learn mathematics by observing the motions of robots in simulations or on real mats. Most students improved greatly in mathematics after using the curricula. It is expected that the curricula based on Roboblocky will continue to be improved to enable more middle and high school students to be successful in learning mathematics.",
    "abstract_processed": "increas number tool creat assist student learn mathemat robot regard especi power tool help student master mathemat sinc student simultan learn mathemat program robot control comput think although number educ robot curricula develop compli math standard primarili suitabl school program camp workshop student might abl focu learn mathemat write program might difficult due debug paper mathemat curricula meet math standard develop block base program platform roboblocki linkbot util robot curricula teach learn mathemat school set student learn mathemat observ motion robot simul real mat student improv greatli mathemat use curricula expect curricula base roboblocki continu improv enabl middl high school student success learn mathemat"
  },
  {
    "doc_id": "10005170",
    "abstract_original": "As computing becomes more powerful and extends the reach of those who wield it, the imperative grows for computing professionals to make ethical decisions regarding the use of that power. We propose the concept of abstracted power to help computer science students understand how technology may distance them perceptually from consequences of their actions. Specifically, we identify technological intermediation and computational thinking as two factors in computer science that contribute to this distancing. To counter the abstraction of power, we argue for increased emotional engagement in computer science ethics education, to encourage students to feel as well as think regarding the potential impacts of their power on others. We suggest four concrete pedagogical approaches to enable this emotional engagement in computer science ethics curriculum, and we share highlights of student reactions to the material.",
    "abstract_processed": "comput becom power extend reach wield imper grow comput profession make ethic decis regard use power propos concept abstract power help comput scienc student understand technolog may distanc perceptu consequ action specif identifi technolog intermedi comput think two factor comput scienc contribut distanc counter abstract power argu increas emot engag comput scienc ethic educ encourag student feel well think regard potenti impact power other suggest four concret pedagog approach enabl emot engag comput scienc ethic curriculum share highlight student reaction materi"
  },
  {
    "doc_id": "10005436",
    "abstract_original": "The migration of traditional deployment to clouds has driven the need for a more robust security model, the Zero-Trust model. The application of zero-trust principles addresses known security issues such as lateral movement attacks but adds extra identity management complexity. In addition, to cover a broader range of attacks, one must think of strategies to protect data, code, and credentials in such applications. Confidential computing aims to fulfill this goal. Nevertheless, confidential computing is even more complex to implement than Zero-Trust. In this work, we combine the Zero-Trust model with confidential computing by leveraging the SPIFFE standard through its reference implementation (SPIRE), and Intel SGX through the SCONE framework, to seamlessly supply software identities to confidential microservices. Furthermore, we also protected the whole identity-provisioning stack with Intel SGX and assessed the performance overhead. We believe this combination not only improves the security of SPIFFE deployments but also leverages SPIFFE to facilitate the integration between confidential computing components and native applications.",
    "abstract_processed": "migrat tradit deploy cloud driven need robust secur model zero trust model applic zero trust principl address known secur issu later movement attack add extra ident manag complex addit cover broader rang attack one must think strategi protect data code credenti applic confidenti comput aim fulfil goal nevertheless confidenti comput even complex implement zero trust work combin zero trust model confidenti comput leverag spiff standard refer implement spire intel sgx scone framework seamlessli suppli softwar ident confidenti microservic furthermor also protect whole ident provis stack intel sgx assess perform overhead believ combin improv secur spiff deploy also leverag spiff facilit integr confidenti comput compon nativ applic"
  },
  {
    "doc_id": "10007773",
    "abstract_original": "Open-source research software plays a central role in accelerating advances in science and engineering. Its increasing significance, however, incentivizes malicious actors to attack that software and compromise the systems on which it runs, undermining the free and open exchange of trustworthy research codes. In the world of conventional software development, there has been a shift towards integrating security as early as possible in the development process to guard against malicious activity. Given the potential risks at hand, developers of research software must consider how to do the same across the research software lifecycle. This editorial argues for the need to unite diverse forms of expertise in scientific computing and software security to address these challenges and outlines a roadmap for future work in this space.",
    "abstract_processed": "open sourc research softwar play central role acceler advanc scienc engin increas signific howev incentiv malici actor attack softwar compromis system run undermin free open exchang trustworthi research code world convent softwar develop shift toward integr secur earli possibl develop process guard malici activ given potenti risk hand develop research softwar must consid across research softwar lifecycl editori argu need unit divers form expertis scientif comput softwar secur address challeng outlin roadmap futur work space"
  },
  {
    "doc_id": "10008928",
    "abstract_original": "Power, accountability, and responsibility for facial recognition technology require us to think carefully and methodically about the ethically significant interests of stakeholders. We suggest two simple models to help guide appropriate analysis when concerns arise.",
    "abstract_processed": "power account respons facial recognit technolog requir us think care method ethic signific interest stakehold suggest two simpl model help guid appropri analysi concern aris"
  },
  {
    "doc_id": "10009523",
    "abstract_original": "A lot of people are scared of cancer since it’s so deadly. However, if caught and treated early, cancer has a high chance of being cured. The ability of computer-assisted diagnosis to serve as a primary screening test for many illnesses, including cancer, has contributed to its rise in popularity in recent years. Deep learning is an artificial intelligence technology that gives computers intelligence by programming them to think like people. In this study, we explore the feasibility of training a deep neural network to provide such a prediction for breast cancer. Information is taken from a UCI-supplied dataset on breast cancer in Wisconsin. Over fitting is prevented by the early halting mechanism and the dropout layers in the neural network model, which together allow for an F1 score of more than 97.",
    "abstract_processed": "lot peopl scare cancer sinc it’ deadli howev caught treat earli cancer high chanc cure abil comput assist diagnosi serv primari screen test mani ill includ cancer contribut rise popular recent year deep learn artifici intellig technolog give comput intellig program think like peopl studi explor feasibl train deep neural network provid predict breast cancer inform taken uci suppli dataset breast cancer wisconsin fit prevent earli halt mechan dropout layer neural network model togeth allow f score"
  },
  {
    "doc_id": "10009551",
    "abstract_original": "Small, medium, and big organizations get several advantages from cloud computing, but it also presents obstacles. Whether a firm is in the financial, technology, or engineering sector, a cloud component might be beneficial. Though there are numerous obstacles associated with cloud computing, experts think that the benefits outweigh the drawbacks. The issues will be addressed when more research in the field of cloud computing is conducted. Cloud services are provided by a number of significant companies, including Amazon Web Services, Microsoft Azure, and Google Cloud Platform, among others. Among them, AWS (Amazon Web Services) is one of the fine cloud service providers that comprises several features, including the AWS EC2 (Elastic Compute Cloud) which is one of the widely used by many organizations. Amazon's Elastic Compute Cloud Web service delivers highly adjustable processing capacity throughout the cloud, allowing developers to construct applications with incredible scalability. Using EC2 (Elastic Compute Cloud) by using the proposed deployment method can be more effort saver for any IT development and deployment team for any organization. There should be an easy deployment method that auto-configures EC2 Instance. The aim of this research paper is to showcase the current deployment and service models provided by Amazon Web Services EC2 and present the proposed solution in order to the existing scenario. Furthermore, its advantages are also present so that it becomes easier to select the most appropriate one for deployment and research development.",
    "abstract_processed": "small medium big organ get sever advantag cloud comput also present obstacl whether firm financi technolog engin sector cloud compon might benefici though numer obstacl associ cloud comput expert think benefit outweigh drawback issu address research field cloud comput conduct cloud servic provid number signific compani includ amazon web servic microsoft azur googl cloud platform among other among aw amazon web servic one fine cloud servic provid compris sever featur includ aw ec elast comput cloud one wide use mani organ amazon elast comput cloud web servic deliv highli adjust process capac throughout cloud allow develop construct applic incred scalabl use ec elast comput cloud use propos deploy method effort saver develop deploy team organ easi deploy method auto configur ec instanc aim research paper showcas current deploy servic model provid amazon web servic ec present propos solut order exist scenario furthermor advantag also present becom easier select appropri one deploy research develop"
  },
  {
    "doc_id": "10010318",
    "abstract_original": "The development of social media in the form of websites and android applications should be appreciated. The background of this research is the stage to develop the software needed to know the age range. The objective thing to observe is through the visitor’s face on the web or application. The purpose is to avoid false information and get the proper process flow. The Technology used is deep learning for facial image recognition. The methods use Convolutional Neural Network with residuals because the advantage is using multi-branch layers but having a stable training process. The use of augmentation is needed to increase the variety of facial recognition image positions and to overcome unbalanced classes. The dataset used consists of seven categories, namely Children, Youth, Early Workers, Middle Ages, Pre-Retirement, Retirement, and Old People, which Bappenas regulate. Each folder contains about 1157 images with a total data of 8,105 images. The training process results can obtain a model with an average accuracy of 99.08% and a computational training time of about three hundred minutes. The model’s accuracy is 99.08%, with MSE 0.0037, RMSE 0.0610, and MAE 0.0037. Testing time is about 2 seconds.",
    "abstract_processed": "develop social media form websit android applic appreci background research stage develop softwar need know age rang object thing observ visitor’ face web applic purpos avoid fals inform get proper process flow technolog use deep learn facial imag recognit method use convolut neural network residu advantag use multi branch layer stabl train process use augment need increas varieti facial recognit imag posit overcom unbalanc class dataset use consist seven categori name children youth earli worker middl age pre retir retir old peopl bappena regul folder contain imag total data imag train process result obtain model averag accuraci comput train time three hundr minut model’ accuraci mse rmse mae test time second"
  },
  {
    "doc_id": "10013327",
    "abstract_original": "For current Internet is confronted with some defects such as structural rigidity, single function, and protocol-independent, the functions, performance and efficiency of the Internet were promoted from the perspective of the data plane, it proposes to support computing definable programmable data based on the full-dimensional defined polymorphic smart network. It uses in-network calculations to offload network functions to programmable network elements (programmable switches) to improve operational efficiency and flexibility. This article first uses the protocol-independent P4 language to realize the definable forwarding of the data plane; on this basis, a new forwarding model is designed, adding calculation functions that are not originally supported by P4, and the calculation is definable; finally, DES encryption is used as the calculation Function verification, and think and discuss the experimental process.",
    "abstract_processed": "current internet confront defect structur rigid singl function protocol independ function perform effici internet promot perspect data plane propos support comput defin programm data base full dimension defin polymorph smart network use network calcul offload network function programm network element programm switch improv oper effici flexibl articl first use protocol independ p languag realiz defin forward data plane basi new forward model design ad calcul function origin support p calcul defin final de encrypt use calcul function verif think discuss experiment process"
  },
  {
    "doc_id": "10013387",
    "abstract_original": "The educational challenges of society permeated by digital technologies are aimed at developing skills to identify and solve environment problems. In this context, computational thinking (CT) emerges as a set of skills to be developed from an early age, which requires the empowerment of programming and demands the use of technological tools. The purpose of this article is to present the design and implementation process of a computer tool for CT evaluation, as well as its validation with a sample of elementary school students from a public institution in Colombia. The methodology focuses on the phases of the SCRUM development process. The results show that women perceive less difficulty in understanding the activities to be solved. It is possible to obtain a web application type software taking into account the evaluated characteristics of the tools used for CT teaching, covering most of these, and with special emphasis on some such as the content in Spanish, instructional model, management of the course, learning activities, monitoring, feedback and gamification.",
    "abstract_processed": "educ challeng societi permeat digit technolog aim develop skill identifi solv environ problem context comput think ct emerg set skill develop earli age requir empower program demand use technolog tool purpos articl present design implement process comput tool ct evalu well valid sampl elementari school student public institut colombia methodolog focus phase scrum develop process result show women perceiv less difficulti understand activ solv possibl obtain web applic type softwar take account evalu characterist tool use ct teach cover special emphasi content spanish instruct model manag cours learn activ monitor feedback gamif"
  },
  {
    "doc_id": "10013445",
    "abstract_original": "In the article, the authors propose technological projects to develop computational thinking following the four problem-solving phases: understanding the problem, making the plan, executing the plan, and reviewing the solution. This study was based on a quantitative approach; the participants were 37 engineering students who had just entered university; also, the Pearson correlation statistical test was used to assess the relationship between computational thinking and problem- resolve. The activities of the technological projects have been developed using technological resources, such as the Arduino board, the mBlock software, and electronic sensors. It has been shown that following the problem-solving method based on the four phases contributes to the development of computational thinking skills in engineering students who have recently entered university.",
    "abstract_processed": "articl author propos technolog project develop comput think follow four problem solv phase understand problem make plan execut plan review solut studi base quantit approach particip engin student enter univers also pearson correl statist test use assess relationship comput think problem resolv activ technolog project develop use technolog resourc arduino board mblock softwar electron sensor shown follow problem solv method base four phase contribut develop comput think skill engin student recent enter univers"
  },
  {
    "doc_id": "10013462",
    "abstract_original": "Computational Thinking is one of the fundamental skills of the 21st century and will be a necessary part of all future work, so it is essential that children learn it in school. One way to work on Computational Thinking is through data visualization. This paper presents the motivation, design and implementation of a platform called AlfaDatizando, through which it is possible to work with data visualization activities to promote the skill of Computational Thinking in Digital Humanities. AlfaDatizando allows the creation, resolution, and feedback of data visualization activities without the need to use another platform. It also allows sharing didactic sequences and data sources with the educational community registered in the platform. AlfaDatizando is still in an early stage of development.",
    "abstract_processed": "comput think one fundament skill st centuri necessari part futur work essenti children learn school one way work comput think data visual paper present motiv design implement platform call alfadatizando possibl work data visual activ promot skill comput think digit human alfadatizando allow creation resolut feedback data visual activ without need use anoth platform also allow share didact sequenc data sourc educ commun regist platform alfadatizando still earli stage develop"
  },
  {
    "doc_id": "10013660",
    "abstract_original": "With the rapid development of autonomous driving technology, a variety of high-performance end-to-end driving models (E2EDMs) are being proposed. In order to understand the computational methods of E2EDMs, pixel-level explanations methods are used to obtain the explanations of the E2EDMs. However, little attention has been paid to the excellence of the explanations of E2EDMs. Therefore, in order to build trustworthy E2EDMs, we focus on improving the persuasibility of the explanations of E2EDMs. We propose an object-level explanation method (main approach) for E2EDMs, which masks the objects in the image and then treats the change in the prediction result as the importance of the objects, then we explain the E2EDM by the importance of each object. To further validate the effectiveness of object-level explanations, we propose another approach (validation approach), which trains E2EDMs with object information as input and generates the importance of objects using general explanation methods. Both approaches generate object-level explanations, in order to compare these object-level explanations with traditional pixel-level explanations, we propose experimental methods to measure the persuasibility of explanations of E2EDMs through a subjective and objective method. The subjective method evaluates persuasibility based on the extent to which participants think the importance of features indicated by the explanations is correct. The objective method evaluates the persuasibility based on the human annotation similarity between provided with only the important part of images and provided with the complete images. The experimental results show that the object-level explanations are more persuasive than the traditional pixel-level explanations.",
    "abstract_processed": "rapid develop autonom drive technolog varieti high perform end end drive model e edm propos order understand comput method e edm pixel level explan method use obtain explan e edm howev littl attent paid excel explan e edm therefor order build trustworthi e edm focu improv persuas explan e edm propos object level explan method main approach e edm mask object imag treat chang predict result import object explain e edm import object valid effect object level explan propos anoth approach valid approach train e edm object inform input gener import object use gener explan method approach gener object level explan order compar object level explan tradit pixel level explan propos experiment method measur persuas explan e edm subject object method subject method evalu persuas base extent particip think import featur indic explan correct object method evalu persuas base human annot similar provid import part imag provid complet imag experiment result show object level explan persuas tradit pixel level explan"
  },
  {
    "doc_id": "10014030",
    "abstract_original": "Many senior citizens stay in a hospital, or they are moved into sheltered accommodation. When they live apart from their family, there is a risk of them suffering from serious disturbance in mental ability including delirium due to stress [1] [2]. Their family can visit hospital or sheltered accomodation and meet senior citizens so as to reduce their stress and prevent them from suffering serious disturbance. However they might not be able to do so due to epidemics. They can communicate with their family as in the case of life when they live in same house by making constant video calls instead of visit. However, they may feel uncomfortable with constant shooting. We feel a need of the system that they can communicate without feeling uncomfortable even if senior citizens live apart from their family. When we came to think of the place where the families lived in comfortably, the living room came to our mind. Family live freely in the living room, spending much of their time without a strong connection each other. But a person can start a conversation at any time by talking to another person, and the conversation will end naturally without clear termination signal. For this reason, we have proposed “Virtual living room system” [3] that had these feature and reproduced a real living room. We made an experimental system in order to verify the validity of the system and conducted experiments that we had subjects live while using it. In the experiment, we confirm the usefulness of the system. However, we also confirm two problems through the opinions of participants. One is the lack of presence. The system displays an icon on the screen that represents the the information of whether person that lives away from the user is in a certain room or not. The icon is not related to the user, so it may not have made the users feel that they live in the same place. The other is the difficulty of setting up for using the system. Setting up this system is not easy for people who are not very familiar with computer operation. The system will actually be used in a hospital or nursing home. Therefore the staff work in would have to set up the system and help the user use it. They may be unfamiliar with computer operation and probably cannot set up the system and use it by theirselves. In this paper, we propose an improved system based on photos that is created in view of the problem and the actual users.",
    "abstract_processed": "mani senior citizen stay hospit move shelter accommod live apart famili risk suffer seriou disturb mental abil includ delirium due stress famili visit hospit shelter accomod meet senior citizen reduc stress prevent suffer seriou disturb howev might abl due epidem commun famili case life live hous make constant video call instead visit howev may feel uncomfort constant shoot feel need system commun without feel uncomfort even senior citizen live apart famili came think place famili live comfort live room came mind famili live freeli live room spend much time without strong connect person start convers time talk anoth person convers end natur without clear termin signal reason propos “virtual live room system” featur reproduc real live room made experiment system order verifi valid system conduct experi subject live use experi confirm use system howev also confirm two problem opinion particip one lack presenc system display icon screen repres inform whether person live away user certain room icon relat user may made user feel live place difficulti set use system set system easi peopl familiar comput oper system actual use hospit nurs home therefor staff work would set system help user use may unfamiliar comput oper probabl cannot set system use theirselv paper propos improv system base photo creat view problem actual user"
  },
  {
    "doc_id": "10016193",
    "abstract_original": "The number of network attacks is increasing at an unprecedented speed, and online phishing is the most common form of network attacks and the most close to our life. In order to enable users to better understand what kind of online phishing they have suffered, and enable scholars and researchers to more quickly customize detection for different types of online phishing detection. We need an in-depth summary of the existing types of online phishing and various detection methods. This paper classifies and summarizes all kinds of phishing, mainly introduces six kinds of phishing, including E-mail phishing and search engine phishing. For phishing detection methods, this paper also summarizes and classifies existing and widely used detection methods into seven categories such as list-based heuristic machine learning, and introduces them in detail. Then the paper analyzes the big data frontier technology and detection channel direction of assisted anomaly detection, and divides it into stream processing technology, Hadoop DPI parsing keyword recognition, web crawler recognition, etc. Finally the paper discusses and thinks deeply about the methods and techniques mentioned above as well as the current situation of phishing detection, and puts forward some forward-looking suggestions on the interpretation of data processing model selection and general detection architecture.",
    "abstract_processed": "number network attack increas unpreced speed onlin phish common form network attack close life order enabl user better understand kind onlin phish suffer enabl scholar research quickli custom detect differ type onlin phish detect need depth summari exist type onlin phish variou detect method paper classifi summar kind phish mainli introduc six kind phish includ e mail phish search engin phish phish detect method paper also summar classifi exist wide use detect method seven categori list base heurist machin learn introduc detail paper analyz big data frontier technolog detect channel direct assist anomali detect divid stream process technolog hadoop dpi pars keyword recognit web crawler recognit etc final paper discuss think deepli method techniqu mention well current situat phish detect put forward forward look suggest interpret data process model select gener detect architectur"
  },
  {
    "doc_id": "10018542",
    "abstract_original": "The three-way decision theory provides a three-way philosophical thinking to solve problems, and the regret theory quantifies the risk preferences of decision makers under different psychological behaviors. On the one hand, the combination of these two theories makes models more practical by considering the psychological behaviors of decision makers. On the other hand, we can effectively combine the advantages of the three-way decision theory with the regret theory to highlight the interpretability of decision-making processes. In this article, we propose a novel approximate estimation method for incomplete utility values via the regret theory and establish a wide sense of a three-way decision model on incomplete multiscale decision information systems. First, the degree of consistency for each scale is measured via using the dependence degree, then the optimal subsystem is selected by evaluating the scale selection cost. Furthermore, the incomplete multiscale evaluation information is transformed into triangular fuzzy numbers via linguistic term sets. Second, in light of fuzzy evaluation values and tradeoff factors, an estimation method for incomplete fuzzy subsystems is constructed, which can be used to calculate the utility difference and regret-rejoicing values for pairwise comparisons. Finally, from the perspective of human cognition, the tripartition and the corresponding decision rules are built by the tolerance degree, and the ranking of objects is calculated by the relative closeness degree. Additionally, multiaspect comparative and experimental analyses are performed by extensive experiments, and the feasibility, validity, and stability of the constructed model are shown by parametric analyses.",
    "abstract_processed": "three way decis theori provid three way philosoph think solv problem regret theori quantifi risk prefer decis maker differ psycholog behavior one hand combin two theori make model practic consid psycholog behavior decis maker hand effect combin advantag three way decis theori regret theori highlight interpret decis make process articl propos novel approxim estim method incomplet util valu via regret theori establish wide sens three way decis model incomplet multiscal decis inform system first degre consist scale measur via use depend degre optim subsystem select evalu scale select cost furthermor incomplet multiscal evalu inform transform triangular fuzzi number via linguist term set second light fuzzi evalu valu tradeoff factor estim method incomplet fuzzi subsystem construct use calcul util differ regret rejoic valu pairwis comparison final perspect human cognit tripartit correspond decis rule built toler degre rank object calcul rel close degre addit multiaspect compar experiment analys perform extens experi feasibl valid stabil construct model shown parametr analys"
  },
  {
    "doc_id": "10019495",
    "abstract_original": "The massively increasing data in computing world inspires the R&D of novel memory-centric computing architectures and devices. In this work, we propose a novel analog CIM technique for GEMM using 3D NOR Flash devices to support general-purpose matrix multiplication. Our analysis indicates that it’s very robust to use “billions” of memory cells with modest 4-level and large-spacing analog Icell to produce good accuracy and reliability, contrary to the past thinking to pursue many levels in each memory cell that inevitably suffers accuracy loss. We estimate that a 2.7Gb 3D NOR GEMM can provide a high-performance (frame/sec>300) image recognition inference of ResNet-50 on ImageNet dataset, using a simple flexible controller chip with 1MB SRAM without the need of massive ALU and external DRAM. The accuracy can maintain ~85% for Cifar-10 (by VGG7), and ~90% for ImageNet Top-5 (by ResNet-50) under good device control. This 3D NOR GEMM enjoys much lower system cost and flexibility than a complicated SOC. We also propose an operation and design method of “Cosine Similarity” computing using the 3D NOR. We can use a ternary similarity search algorithm with positive and negative inputs and weights to perform high-dimension feature vector (such as 512 for face recognition with FaceNet on VGGFace2 dataset) similarity computing in a high-parallelism CIM design (512 WL inputs, 1024 BL’s, at Tread=100ns). High-accuracy search (~97.8%, almost identical to 98% of software computing) and high internal search bandwidth (~5Tb/s per chip) are achieved. This in-Flash search accelerator is potential to enable new hardware-aware search algorithms in big data retrieval applications.",
    "abstract_processed": "massiv increas data comput world inspir r novel memori centric comput architectur devic work propos novel analog cim techniqu gemm use flash devic support gener purpos matrix multipl analysi indic it’ robust use “billions” memori cell modest level larg space analog icel produc good accuraci reliabl contrari past think pursu mani level memori cell inevit suffer accuraci loss estim gb gemm provid high perform frame sec imag recognit infer resnet imagenet dataset use simpl flexibl control chip mb sram without need massiv alu extern dram accuraci maintain cifar vgg imagenet top resnet good devic control gemm enjoy much lower system cost flexibl complic soc also propos oper design method “cosin similarity” comput use use ternari similar search algorithm posit neg input weight perform high dimens featur vector face recognit facenet vggface dataset similar comput high parallel cim design wl input bl’ tread ns high accuraci search almost ident softwar comput high intern search bandwidth tb per chip achiev flash search acceler potenti enabl new hardwar awar search algorithm big data retriev applic"
  },
  {
    "doc_id": "10020957",
    "abstract_original": "Reparative description of collections is a growing element of diversity, equity, and inclusion efforts at cultural heritage institutions. However, the scale and complexity of the work can be overwhelming in practice. I demonstrate that computational methodologies and data analytics can be used to kickstart the planning stage for reparative description of archival finding aids. I discuss auditing and analyzing finding aids at the University of Chicago Library’s Hanna Holborn Gray Special Collections Research Center for potentially problematic language utilizing Python, Trifacta, Tableau, and Neo4j. I describe insights gained by treating finding aids as data, and I share recommendations for structuring reparative description work in a logical and attainable way.",
    "abstract_processed": "repar descript collect grow element divers equiti inclus effort cultur heritag institut howev scale complex work overwhelm practic demonstr comput methodolog data analyt use kickstart plan stage repar descript archiv find aid discuss audit analyz find aid univers chicago library’ hanna holborn gray special collect research center potenti problemat languag util python trifacta tableau neo j describ insight gain treat find aid data share recommend structur repar descript work logic attain way"
  },
  {
    "doc_id": "10021019",
    "abstract_original": "This paper discusses the use of Computational Thinking (CT) in Archival Educators’ instruction towards enhancing the training and professional development of the library and archival workforce to meet the needs of their communities, and enhancing digital collection management and access to information and resources through retrospective and born-digital content. Four educators share their teaching strategies aimed at modernizing the way digital LIS and computational education are conducted. Their goal is to create an active and engaged community of future archival practitioners, ready to tackle the digital records and archives future.",
    "abstract_processed": "paper discuss use comput think ct archiv educators’ instruct toward enhanc train profession develop librari archiv workforc meet need commun enhanc digit collect manag access inform resourc retrospect born digit content four educ share teach strategi aim modern way digit li comput educ conduct goal creat activ engag commun futur archiv practition readi tackl digit record archiv futur"
  },
  {
    "doc_id": "10024282",
    "abstract_original": "Processing-in-memory (PIM) has attracted attention to overcome the memory bandwidth limitation, especially for computing memory-intensive DNN applications. Most PIM approaches use the CPU’s memory requests to deliver instructions and operands to the PIM engines, making a core busy and incurring unnecessary data transfer, thus, resulting in significant offloading overhead. DMA can resolve the issue by transferring a high volume of successive data without intervening CPU and polluting the memory hierarchy, thus perfectly fitting the PIM concept. However, the small computing resources of DRAM-based PIM devices allow us to transfer only small amounts of data at one DMA transaction and require a large number of descriptors, thus still incurring significant offloading overhead. This paper introduces PIM Instruction Set Architecture (ISA) using a DMA descriptor called PISA-DMA to express a PIM opcode and operand in a single descriptor. Our ISA makes PIM programming intuitive by thinking of committing one PIM instruction as completing one DMA transaction and representing a sequence of PIM instructions using the DMA descriptor list. Also, PISA-DMA minimizes the offloading overhead while guaranteeing compatibility with commercial platforms. Our PISA-DMA eliminates the opcode offloading overhead and achieves 1.25x, 1.31x, and 1.29x speedup over the baseline PIM at the sequence length of 128 with the BERT, RoBERTa, and GPT-2 models, respectively, in ONNX runtime with real machines. Also, we study how our proposed PISA affects performance in compiler optimization and show that the operator fusion of matrix-matrix multiplication and element-wise addition achieved 1.04x speedup, a similar performance gain using conventional ISAs.",
    "abstract_processed": "process memori pim attract attent overcom memori bandwidth limit especi comput memori intens dnn applic pim approach use cpu’ memori request deliv instruct operand pim engin make core busi incur unnecessari data transfer thu result signific offload overhead dma resolv issu transfer high volum success data without interven cpu pollut memori hierarchi thu perfectli fit pim concept howev small comput resourc dram base pim devic allow us transfer small amount data one dma transact requir larg number descriptor thu still incur signific offload overhead paper introduc pim instruct set architectur isa use dma descriptor call pisa dma express pim opcod operand singl descriptor isa make pim program intuit think commit one pim instruct complet one dma transact repres sequenc pim instruct use dma descriptor list also pisa dma minim offload overhead guarante compat commerci platform pisa dma elimin opcod offload overhead achiev x x x speedup baselin pim sequenc length bert roberta gpt model respect onnx runtim real machin also studi propos pisa affect perform compil optim show oper fusion matrix matrix multipl element wise addit achiev x speedup similar perform gain use convent isa"
  },
  {
    "doc_id": "10024444",
    "abstract_original": "Affective interaction with virtual humans can enhance the quality of user experience in virtual reality. It takes place through various considerations such as emotional representation in their behavioral patterns, facial expressions, head pose, body stance, and so on. Deciding on the emotional state of a virtual human at a moment, however, is still a challenge. Computational models of emotion, stemming from appraisal theories, are suggested for modeling emotion in virtual agents. Despite their competence in extracting emotion from appraisal values, they are poorly defined in describing how to assess appraisal values within a sense-think-act behavior model. Motivated by this lack of empirical knowledge on the appraisal stage, in this preliminary work, we propose a framework to bridge the gap between a computational model of emotion and a behavior model of virtual humans. To this end, we use a need-based, goal- oriented, autonomous behavior model to generate salient stimuli for eliciting emotions. Our simulation of a case study suggests that the proposed framework can produce sensible emotional states that conform to the essential principles of appraisal-based emotion theories.",
    "abstract_processed": "affect interact virtual human enhanc qualiti user experi virtual realiti take place variou consider emot represent behavior pattern facial express head pose bodi stanc decid emot state virtual human moment howev still challeng comput model emot stem apprais theori suggest model emot virtual agent despit compet extract emot apprais valu poorli defin describ assess apprais valu within sens think act behavior model motiv lack empir knowledg apprais stage preliminari work propos framework bridg gap comput model emot behavior model virtual human end use need base goal orient autonom behavior model gener salient stimuli elicit emot simul case studi suggest propos framework produc sensibl emot state conform essenti principl apprais base emot theori"
  },
  {
    "doc_id": "10024468",
    "abstract_original": "Many conflicts emanate from failure to understand others’ perspectives. Computationally supported roleplaying games have the potential to promote successful perspective taking. When implemented with the affordances of virtual reality, nuances of embodied communication in roleplaying can be more robustly modeled. In this paper, we describe the design and development of a roleplaying game aimed at simulating ingroup-outgroup biases with the goal of supporting positive perspective taking in virtual reality: On the Plane. The game presents players with a simulation of air travel experience, from airport security screening to in-flight events. On the Plane affords the ability to experience the simulation as different characters, supporting both ingroup and outgroup perspectives. We describe how the game is structured to simulate and challenge ingroupoutgroup biases within the context of xenophobia and lay out our plans for future research using On the Plane to promote positive perspective transformation (e.g., challenging one’s own ill-founded preconceptions).",
    "abstract_processed": "mani conflict eman failur understand others’ perspect comput support roleplay game potenti promot success perspect take implement afford virtual realiti nuanc embodi commun roleplay robustli model paper describ design develop roleplay game aim simul ingroup outgroup bias goal support posit perspect take virtual realiti plane game present player simul air travel experi airport secur screen flight event plane afford abil experi simul differ charact support ingroup outgroup perspect describ game structur simul challeng ingroupoutgroup bias within context xenophobia lay plan futur research use plane promot posit perspect transform e g challeng one’ ill found preconcept"
  },
  {
    "doc_id": "10025038",
    "abstract_original": "This study reports a pre-college initiative that aims to integrate computational thinking (CT) in an integrated STEM learning environment in community centers' after-school programs for upper-level elementary school students. The initiative takes a collaborative approach that engages a range of stakeholders including higher institution's STEM educational researchers and disciplinary experts, a school district, three community centers and their satellite campus that serve Title I schools, and both in-service and pre-service teachers to develop and implement an integrated “STEM + CT” curriculum. The design and development of the integrated STEM+CT curriculum was guided by project-based learning (PBL) that engages students in sustained project-based activities and requires students to apply multiple STEM content knowledge and skills to solve a problem, in after-school programs where they enjoy large blocks of dedicated time to learn and practice CT and STEM. The implementation of the curriculum was led by in-service teachers in community centers' after-school programs who serve as facilitators and learners, and bring a depth of pedagogical knowledge, and who also benefit from such sustained interactions. This collaborative initiative brings relevant stakeholders together and helps build a researcher-practitioner partnership that aims to design, study, improve, and scale innovations in teaching and learning, which facilities the solving of a shared challenge of educational practice - how to integrate CT in K-12 STEM learning? - in this study. Lessons learned from the collaborative process are also discussed.",
    "abstract_processed": "studi report pre colleg initi aim integr comput think ct integr stem learn environ commun center school program upper level elementari school student initi take collabor approach engag rang stakehold includ higher institut stem educ research disciplinari expert school district three commun center satellit campu serv titl school servic pre servic teacher develop implement integr “stem ct” curriculum design develop integr stem ct curriculum guid project base learn pbl engag student sustain project base activ requir student appli multipl stem content knowledg skill solv problem school program enjoy larg block dedic time learn practic ct stem implement curriculum led servic teacher commun center school program serv facilit learner bring depth pedagog knowledg also benefit sustain interact collabor initi bring relev stakehold togeth help build research practition partnership aim design studi improv scale innov teach learn facil solv share challeng educ practic integr ct k stem learn studi lesson learn collabor process also discuss"
  },
  {
    "doc_id": "10025068",
    "abstract_original": "K-12 computer science education has challenges related to content and to teacher expertise and comfort. This is further made difficult with inconsistent standards and teacher preparation from state-to-state. We describe a K-12 Computer Science Teaching certificate program, located at Montclair State University, aimed at providing current teachers in northern New Jersey with enhanced understanding of computer science concepts, capabilities, and skills, plus scaffolding of equitable and inclusive teacher practices for applied CS pedagogy. We discuss a brief history of the field, our curriculum and approach and then our first graduating cohort’s experiences and challenges. Finally, we discuss our future work.",
    "abstract_processed": "k comput scienc educ challeng relat content teacher expertis comfort made difficult inconsist standard teacher prepar state state describ k comput scienc teach certif program locat montclair state univers aim provid current teacher northern new jersey enhanc understand comput scienc concept capabl skill plu scaffold equit inclus teacher practic appli cs pedagogi discuss brief histori field curriculum approach first graduat cohort’ experi challeng final discuss futur work"
  },
  {
    "doc_id": "10025227",
    "abstract_original": "Computational thinking (CT) has been integrated into K-12 curricula globally, and coding has been the main vehicle in CT education. While great effort has been made in exploring cognitive effect of coding, limited has been done in attitudinal aspects. To bridge this gap, this study validated the existing Elementary Student Coding Attitudes Survey (ESCAS) in Chinese context and use the scale to explore how students perceived coding. Also, the association between coding attitude and CT performance was investigated. A total of 217 elementary students were involved. Psychometric qualities of ESCAS (Chinese) were examined, and the effect of coding attitudes on CT cognitive performance was analyzed with linear regression. Results showed that ESCAS (Chinese) was a valid and reliable attitudinal scale, and coding interest could predict CT performance. Future directions for the study were discussed.",
    "abstract_processed": "comput think ct integr k curricula global code main vehicl ct educ great effort made explor cognit effect code limit done attitudin aspect bridg gap studi valid exist elementari student code attitud survey esca chines context use scale explor student perceiv code also associ code attitud ct perform investig total elementari student involv psychometr qualiti esca chines examin effect code attitud ct cognit perform analyz linear regress result show esca chines valid reliabl attitudin scale code interest could predict ct perform futur direct studi discuss"
  },
  {
    "doc_id": "10027220",
    "abstract_original": "This article illustrates the online education platform technology of contemporary education and students' learning mode change and influence, and the technology to promote the development of derivatives of hybrid teaching concept, both at home and abroad present situation and existing problems, and through to the medical profession and carried on the thorough analysis of the characteristics of computer courses, through the strong support of the online education platform technology, In the teaching goal, curriculum resource development, to build hybrid curriculum implementation, formative assessment established medical college computer basic course reform model depth fusion, practice and summary and online education platform technology plays an indispensable role in hybrid teaching, online depth fusion teaching reform and innovation of teaching mode, It stimulates students' learning enthusiasm, steadily improves the degree of knowledge transfer, and promotes the improvement of talent training quality in medical higher education, which has important practical significance for the development of higher education.",
    "abstract_processed": "articl illustr onlin educ platform technolog contemporari educ student learn mode chang influenc technolog promot develop deriv hybrid teach concept home abroad present situat exist problem medic profess carri thorough analysi characterist comput cours strong support onlin educ platform technolog teach goal curriculum resourc develop build hybrid curriculum implement form assess establish medic colleg comput basic cours reform model depth fusion practic summari onlin educ platform technolog play indispens role hybrid teach onlin depth fusion teach reform innov teach mode stimul student learn enthusiasm steadili improv degre knowledg transfer promot improv talent train qualiti medic higher educ import practic signific develop higher educ"
  },
  {
    "doc_id": "10027252",
    "abstract_original": "In recent years, artificial intelligence technology is booming, and artificial intelligence technology has become a research hotspot in academic circles. The author uses CiteSpace to conduct citation analysis on the research literature of knowledge map in the field of artificial intelligence. Through LLR cluster analysis, it is known that most of the research topics focus on basic theoretical research, method research and application research. This paper analyzes the proportion of artificial intelligence in various industries by using SPSS technology, and forecasts the trend of the scale of China’s artificial intelligence market. On the basis of adhering to the principle of people-oriented and the unity of truth principle and value principle, we should overcome the problems caused by man-machine relationship and promote the harmonious coexistence of artificial intelligence and human intelligence.",
    "abstract_processed": "recent year artifici intellig technolog boom artifici intellig technolog becom research hotspot academ circl author use citespac conduct citat analysi research literatur knowledg map field artifici intellig llr cluster analysi known research topic focu basic theoret research method research applic research paper analyz proport artifici intellig variou industri use spss technolog forecast trend scale china’ artifici intellig market basi adher principl peopl orient uniti truth principl valu principl overcom problem caus man machin relationship promot harmoni coexist artifici intellig human intellig"
  },
  {
    "doc_id": "10027409",
    "abstract_original": "With the continuous development of big data and artificial intelligence, big data and intelligence in the traditional field will be inevitable. At present, the combination of artificial intelligence and the education industry is becoming a hot spot in artificial intelligence applications. This research explores the research hotspots of artificial intelligence in education, using Bloom’s educational goal classification method to divide learning effects into cognitive learning effects, emotional learning effects, and skill-behavior learning effects, and analyze the effects of artificial intelligence on student learning. Through the in-depth integration of artificial intelligence and education, cultivate students’ human-computer collaboration ability, promote education reform, strengthen the research of artificial intelligence education learning content, and strengthen artificial intelligence theoretical innovation and practical innovation to enhance the learning effect.",
    "abstract_processed": "continu develop big data artifici intellig big data intellig tradit field inevit present combin artifici intellig educ industri becom hot spot artifici intellig applic research explor research hotspot artifici intellig educ use bloom’ educ goal classif method divid learn effect cognit learn effect emot learn effect skill behavior learn effect analyz effect artifici intellig student learn depth integr artifici intellig educ cultiv students’ human comput collabor abil promot educ reform strengthen research artifici intellig educ learn content strengthen artifici intellig theoret innov practic innov enhanc learn effect"
  },
  {
    "doc_id": "10027412",
    "abstract_original": "Computational thinking is the process sequence of solving problems and behaves a method of systematic solving problems. Computational thinking is essentially a view of systematic information processing process. In essence, developing the computational thinking of middle school students is to improve their problem-solving ability and the corresponding practical accomplishment. The instructional activity design based on six links of problem solving can well meet the need of cultivating students’ computational thinking. The instructional mode of systematic problem solving in middle school can improve students’ learning effects and satisfaction, and promote students’ computational thinking ability significantly. The method of systematic information processing process can be trained.",
    "abstract_processed": "comput think process sequenc solv problem behav method systemat solv problem comput think essenti view systemat inform process process essenc develop comput think middl school student improv problem solv abil correspond practic accomplish instruct activ design base six link problem solv well meet need cultiv students’ comput think instruct mode systemat problem solv middl school improv students’ learn effect satisfact promot students’ comput think abil significantli method systemat inform process process train"
  },
  {
    "doc_id": "10029394",
    "abstract_original": "Design is a creative, complex, and iterative process. Although a variety of AI models for supporting design has been developed, there is little research on providing a seamless flow across multiple AI models, as well as the inspiration evolution within the process. We present an integrated AI-based Creativity Support Tool(AI-CST) that systematically integrates multiple AI models and contains a novel Inpiration Evolver to facilitate collaboration between designers and AI models. A between-subject sneaker-design experiment comparing our integrated AI-CST and non-integrated AI-CST shows that our AI-CST can significantly improve designers’ performance. Different using preferences and evolution styles have been discovered by the Inspiration Evolver, which inspires further study on the adaptation of the integrated AI-CST.",
    "abstract_processed": "design creativ complex iter process although varieti ai model support design develop littl research provid seamless flow across multipl ai model well inspir evolut within process present integr ai base creativ support tool ai cst systemat integr multipl ai model contain novel inpir evolv facilit collabor design ai model subject sneaker design experi compar integr ai cst non integr ai cst show ai cst significantli improv designers’ perform differ use prefer evolut style discov inspir evolv inspir studi adapt integr ai cst"
  },
  {
    "doc_id": "10031762",
    "abstract_original": "With the development of corpus linguistics and the improvement of computer performance, the effect of machine translation is getting better and better, and has been widely used. However, the existing automatic machine translation technology is far from being completely practical. As a feasible alternative to automatic machine translation technology, computer-aided translation technology has been greatly developed, and a feasible mode of computer-aided translation is interactive machine translation technology. Therefore, this paper proposes a Human-Computer Interaction Algorithm(HCIA) and designs an English machine translation system(MTS). Based on the research and analysis of the existing interactive machine translation technology, a human-computer interactive English machine translation algorithm model is proposed; The experimental test and analysis of the English MTS proposed in this paper show that the translation system designed in this paper reduces the translator’s thinking time and cognitive burden, does not need to spend too much time and energy on the correct translation recognition, and improves the translation efficiency.",
    "abstract_processed": "develop corpu linguist improv comput perform effect machin translat get better better wide use howev exist automat machin translat technolog far complet practic feasibl altern automat machin translat technolog comput aid translat technolog greatli develop feasibl mode comput aid translat interact machin translat technolog therefor paper propos human comput interact algorithm hcia design english machin translat system mt base research analysi exist interact machin translat technolog human comput interact english machin translat algorithm model propos experiment test analysi english mt propos paper show translat system design paper reduc translator’ think time cognit burden need spend much time energi correct translat recognit improv translat effici"
  },
  {
    "doc_id": "10033178",
    "abstract_original": "This paper presents a comprehensive model of smart and collaborative last mile supply networks. Facing a multitude of challenges such as economic pressure, demographic change, and environmental demands, urban last mile supply networks are increasingly strained. Various solutions and strategies such as the integration of novel technologies and collaborative approaches are discussed in the literature and tested in case studies. The application of artificial intelligence for supply networks holds potential for future urban logistics optimization and is thus considered a relevant research avenue. A design science approach comprising system dynamics-based modeling is chosen due to last mile networks' inherent complexity. Systems thinking has proven to be useful in urban logistics and smart city research contexts as it enables researchers and practitioners to achieve a more holistic perspective. The proposed model contributes to a better understanding of last mile network complexity as well as the underlying interdependencies.",
    "abstract_processed": "paper present comprehens model smart collabor last mile suppli network face multitud challeng econom pressur demograph chang environment demand urban last mile suppli network increasingli strain variou solut strategi integr novel technolog collabor approach discuss literatur test case studi applic artifici intellig suppli network hold potenti futur urban logist optim thu consid relev research avenu design scienc approach compris system dynam base model chosen due last mile network inher complex system think proven use urban logist smart citi research context enabl research practition achiev holist perspect propos model contribut better understand last mile network complex well underli interdepend"
  },
  {
    "doc_id": "10033266",
    "abstract_original": "The design and development of smart products and services with data science enabled solutions forms a core topic of the current trend of digitalisation in industry. Enabling skilled staff, employees, and students to use data science in their daily work routine of designing such products and services is a key concern of higher education institutions, including universities, company workshop providers and in further education. The scope and usage scenario of this paper is to assess software modules ('tools') for integrated data and analytics as service (DAaaS). The tools are usually driven by machine learning, may be deployed in cloud infrastructures, and are specifically targeted at particular needs of the industrial manufacturing, production, or supply chain sector. The paper describes existing theories and previous work, namely methods used in didactics, work done for visually designing and using machine learning algorithms (no-code /low-code tools), as well as combinations of these two topics. For tools available on the market, an extended assessment of their suitability for a set of learning scenarios and personas is discussed.",
    "abstract_processed": "design develop smart product servic data scienc enabl solut form core topic current trend digitalis industri enabl skill staff employe student use data scienc daili work routin design product servic key concern higher educ institut includ univers compani workshop provid educ scope usag scenario paper assess softwar modul tool integr data analyt servic daaa tool usual driven machin learn may deploy cloud infrastructur specif target particular need industri manufactur product suppli chain sector paper describ exist theori previou work name method use didact work done visual design use machin learn algorithm code low code tool well combin two topic tool avail market extend assess suitabl set learn scenario persona discuss"
  },
  {
    "doc_id": "10036693",
    "abstract_original": "Information technology changes people's way of working, learning and thinking at an amazing speed, which will inevitably lead to comprehensive reform and development in the education field. The epidemic situation of COVID-19 makes online teaching the main teaching mode of “teaching without stopping and learning without stopping”. The application of modern education technology based on “Chaoxing Platform+Tencent Meeting” in teaching process is explored. Based on teaching environment, interactive teaching mode construction, teaching management and evaluation, the teaching design is carried out in combination with the actual characteristics of each teaching link. The application of virtual simulation modern educational technology in the course Circuit Analysis is studied, and the convenience and the intuitiveness brought by virtual simulation technical resources and interactive platform are given full play, and the virtual simulation technology can effectively solve the obscure circuit analysis problem in theoretical teaching. The aim of teaching model reform has been achieved.",
    "abstract_processed": "inform technolog chang peopl way work learn think amaz speed inevit lead comprehens reform develop educ field epidem situat covid make onlin teach main teach mode “teach without stop learn without stopping” applic modern educ technolog base “chaox platform tencent meeting” teach process explor base teach environ interact teach mode construct teach manag evalu teach design carri combin actual characterist teach link applic virtual simul modern educ technolog cours circuit analysi studi conveni intuit brought virtual simul technic resourc interact platform given full play virtual simul technolog effect solv obscur circuit analysi problem theoret teach aim teach model reform achiev"
  },
  {
    "doc_id": "10036735",
    "abstract_original": "The impact of new technology on higher vocational education(HVE) has attracted the attention of many domestic scholars. The current direction of education informatization research is mostly smart classrooms. Therefore, schools will inevitably promote education informatization through the use of smart classrooms, and smart classrooms with classroom teaching(CT), teacher-student activities, and Internet + education will also become the core. This article uses experimental analysis and questionnaire survey methods to experiment on the design and application of the intelligent CT model of deep learning in HVE, compare and analyze the learning effects of the experimental and control classes of computer professional courses, and investigate and analyze their attitudes to the application of the intelligent classroom model. The experimental survey results show that the outstanding students in the experimental class has more students than that in the control class, and the learning effect is better than the traditional mode in the smart CT mode of deep learning, and most students in the experimental class prefer the use of the smart classroom mode. It can be concluded that it is necessary to study the design and application of the intelligent CT model of deep learning in HVE. In the intelligent classroom teaching system, data mining, K-means algorithm and MapReduce framework are comprehensively applied. By analyzing various behavioral data of students in school, the potential value behind these data is mined, so as to improve the construction of intelligent classroom and promote the improvement of higher vocational education.",
    "abstract_processed": "impact new technolog higher vocat educ hve attract attent mani domest scholar current direct educ informat research mostli smart classroom therefor school inevit promot educ informat use smart classroom smart classroom classroom teach ct teacher student activ internet educ also becom core articl use experiment analysi questionnair survey method experi design applic intellig ct model deep learn hve compar analyz learn effect experiment control class comput profession cours investig analyz attitud applic intellig classroom model experiment survey result show outstand student experiment class student control class learn effect better tradit mode smart ct mode deep learn student experiment class prefer use smart classroom mode conclud necessari studi design applic intellig ct model deep learn hve intellig classroom teach system data mine k mean algorithm mapreduc framework comprehens appli analyz variou behavior data student school potenti valu behind data mine improv construct intellig classroom promot improv higher vocat educ"
  },
  {
    "doc_id": "10036800",
    "abstract_original": "Big data is relative to data in the general sense. It refers to such a data collection: the amount of data is growing so fast that it is impossible to collect, process, store and store data within a certain period of time with conventional data tools. Calculated data set. The era of big data has changed people's social life and way of thinking. In the field of education, it has also promoted the reform of teaching mode, especially the teaching of foreign languages. At the same time, it also brings challenges and new ideas to Japanese grammar teaching.",
    "abstract_processed": "big data rel data gener sens refer data collect amount data grow fast imposs collect process store store data within certain period time convent data tool calcul data set era big data chang peopl social life way think field educ also promot reform teach mode especi teach foreign languag time also bring challeng new idea japanes grammar teach"
  },
  {
    "doc_id": "10038656",
    "abstract_original": "John Clark was inventor of the Eureka machine to generate hexameter Latin verse. He labored for 13 years from 1832 to implement the device that could compose at random over 26 million different lines of well-formed verse. This article proposes that Clark should be regarded as an early cognitive scientist. Clark described his machine as an illustration of a theory of “kaleidoscopic evolution” whereby the Latin verse is “conceived in the mind of the machine” then mechanically produced and displayed. We describe the background to automated generation of verse, the design and mechanics of Eureka, its reception in London in 1845 and its place in the history of language generation by machine. The article interprets Clark's theory of kaleidoscopic evolution in terms of modern cognitive science. It suggests that Clark has not been given the recognition he deserves as a pioneer of computational creativity.",
    "abstract_processed": "john clark inventor eureka machin gener hexamet latin vers labor year implement devic could compos random million differ line well form vers articl propos clark regard earli cognit scientist clark describ machin illustr theori “kaleidoscop evolution” wherebi latin vers “conceiv mind machine” mechan produc display describ background autom gener vers design mechan eureka recept london place histori languag gener machin articl interpret clark theori kaleidoscop evolut term modern cognit scienc suggest clark given recognit deserv pioneer comput creativ"
  },
  {
    "doc_id": "10039663",
    "abstract_original": "The application of “programming education” has become one of the future technological trends, and students with design backgrounds should also grasp this important development. In this study, the “AgilePoint NX” program course was established, and computational thinking was introduced into the course to guide students, through the image flow and low-code learning process, to carry out structured thinking and question speculation, and complete task exercises. This aims to teach design students to learn programming and computational thinking through a cloud-based low-code development platform with image processes and interdisciplinary learning processes. We conduct a comprehensive analysis and evaluate the learning effect through classroom learning observation, simple questionnaire survey, imagination scale, and other methods. Finally, the study found that in interdisciplinary programming learning, different factors lead to low learning effects of programming courses for design background students, resulting in different degrees of learning pain points and learning experiences. The power of imagination test is a tentative exploration of this research, but for the low-code development platform with fewer measurement data and biased towards procedural thinking, only predictive exploration has no significant data to show the specific impact on the programming learning process, only As a reference for interdisciplinary study.",
    "abstract_processed": "applic “program education” becom one futur technolog trend student design background also grasp import develop studi “agilepoint nx” program cours establish comput think introduc cours guid student imag flow low code learn process carri structur think question specul complet task exercis aim teach design student learn program comput think cloud base low code develop platform imag process interdisciplinari learn process conduct comprehens analysi evalu learn effect classroom learn observ simpl questionnair survey imagin scale method final studi found interdisciplinari program learn differ factor lead low learn effect program cours design background student result differ degre learn pain point learn experi power imagin test tent explor research low code develop platform fewer measur data bias toward procedur think predict explor signific data show specif impact program learn process refer interdisciplinari studi"
  },
  {
    "doc_id": "10040274",
    "abstract_original": "Alzheimer's disease is one of the commonly occurring disease in which the common cause of dementia called as memory loss will happen resiliently and damage the brain activity. It also produces cognitive abilities and serious impact of interference with the day today life. Disease contains 60% to 80% of dementia cases in the early stages are predicted and further actions are initiated to alert the patient behaviour from abnormal activity. The direct impact of Alzheimer's disease (AD) interfere with the regular activity and make complexity in making decisions, thinking capability, problem solving and speaking. The evaluation of artificial intelligence (AI) created numerous ways of analysing strategies, helpful for making the early prediction. In spite of image processing technology, Machine learning models are created to analyse the disease features, symptoms, Chronic records to perform AD detection. The role of deep learning algorithm incorporated with image processing, deep feature extraction, and deep feature fusion enhances the scope of research in AD analysis. Further the benefit of deep learning algorithm to provide search detection mechanism. The presented study discusses various criteria of AD detection and tabulated the findings.",
    "abstract_processed": "alzheim diseas one commonli occur diseas common caus dementia call memori loss happen resili damag brain activ also produc cognit abil seriou impact interfer day today life diseas contain dementia case earli stage predict action initi alert patient behaviour abnorm activ direct impact alzheim diseas ad interfer regular activ make complex make decis think capabl problem solv speak evalu artifici intellig ai creat numer way analys strategi help make earli predict spite imag process technolog machin learn model creat analys diseas featur symptom chronic record perform ad detect role deep learn algorithm incorpor imag process deep featur extract deep featur fusion enhanc scope research ad analysi benefit deep learn algorithm provid search detect mechan present studi discuss variou criteria ad detect tabul find"
  },
  {
    "doc_id": "10040291",
    "abstract_original": "“India's agriculture is its lifeline.” The production of agriculture depends on fertilisers. One of the main issues that farmers face is a lack of information regarding the necessary fertiliser amounts. Farmers think that when fertiliser use rises, production rises as well. This, however, is untrue since the soil just uses what it need and leaves the remainder behind. Overuse results in leaching, a decrease in the natural fertility of the soil, and other problems. A solution is to make it possible for farmers to test their soil and use fertilisers in accordance with the needs of the soil at a reasonable cost. This study describes the development of a low-cost soil nutrient detection method using pre-made capsules. Here, it is possible to do three different nutritional tests for sodium, potassium, and phosphorus. In this experiment, three test tubes are used, and after adding varied amounts of dirt and water to each, the mixture is stirred for 15 minutes. After then, the tube starts to change colour. A colour sensor is used in this instance, and it recognises the colour shift in the test tubes and compares it to the information previously known about the colour deficit. The farmer is advised of the shortage and how much fertiliser is necessary to make up for it once the sensor data is analysed using Arduino.",
    "abstract_processed": "“india agricultur lifelin ” product agricultur depend fertilis one main issu farmer face lack inform regard necessari fertilis amount farmer think fertilis use rise product rise well howev untru sinc soil use need leav remaind behind overus result leach decreas natur fertil soil problem solut make possibl farmer test soil use fertilis accord need soil reason cost studi describ develop low cost soil nutrient detect method use pre made capsul possibl three differ nutrit test sodium potassium phosphoru experi three test tube use ad vari amount dirt water mixtur stir minut tube start chang colour colour sensor use instanc recognis colour shift test tube compar inform previous known colour deficit farmer advis shortag much fertilis necessari make sensor data analys use arduino"
  },
  {
    "doc_id": "10040358",
    "abstract_original": "Alzheimer's disease progress over several years, it slowly ruins memories and thinking ability, and eventually the capacity to carry out daily tasks, leading to full-time care. The brain shrinks and loses brain cells as a result of Alzheimer's disease. While the condition can strike at any age, most patients with Alzheimer's disease are over 65.. Alzheimer patients mostly have Symptoms like memory loss, disorientation and problems with thinking ability but vary from person to person. Although genetics, environment, and lifestyle are the most likely causes of this illness, other experts think there may be multiple causes. The term “dementia” refers to brain illnesses that impair thinking, memory, and behaviour. The most typical cause of dementia is Alzheimer's disease. Patients with Alzheimer's disease typically struggle to speak clearly, identify relatives and friends, and recognise items. They can also become angry, restless, and frustrated. As Alzheimer's disease progresses, physical issues like weakness, loss of balance, and impaired bladder and bowel control appear. In this study paper, we will introduce a convolutional neural network (CNN), which is a machine learning technique, to recognise Alzheimer's disease. On the input image, image segmentation is carried out. CNN is a group of artificial neural networks that provides a more scalable approach to image classification and identification of patterns in images. Convolution is a mathematical procedure that CNN employs in place of matrix multiplication at one layer. CNN are different from other neural networks by their exceptional performance with audio, image or speech signal inputs. CNN algorithm take an input image, assign priority to different aspects for an image to find difference between images. CNN Captures Spatial and Temporal dependencies of an image using application of relevant filters.",
    "abstract_processed": "alzheim diseas progress sever year slowli ruin memori think abil eventu capac carri daili task lead full time care brain shrink lose brain cell result alzheim diseas condit strike age patient alzheim diseas alzheim patient mostli symptom like memori loss disorient problem think abil vari person person although genet environ lifestyl like caus ill expert think may multipl caus term “dementia” refer brain ill impair think memori behaviour typic caus dementia alzheim diseas patient alzheim diseas typic struggl speak clearli identifi rel friend recognis item also becom angri restless frustrat alzheim diseas progress physic issu like weak loss balanc impair bladder bowel control appear studi paper introduc convolut neural network cnn machin learn techniqu recognis alzheim diseas input imag imag segment carri cnn group artifici neural network provid scalabl approach imag classif identif pattern imag convolut mathemat procedur cnn employ place matrix multipl one layer cnn differ neural network except perform audio imag speech signal input cnn algorithm take input imag assign prioriti differ aspect imag find differ imag cnn captur spatial tempor depend imag use applic relev filter"
  },
  {
    "doc_id": "10040412",
    "abstract_original": "Twitter, a social networking platform allows users to convey their ideas. on a wide range of topics, including politics, sports, the stock market, and entertainment. It has a big influence on how people think. A bot on Twitter sends spam messages. As a result, detecting bots aids in spam detection. In this paper, the detection of twitter bots using Deep Learning methods is addressed. At present, the used models aren't updated with latest datasets and have reduced accuracy and some aren't multilingual. A final classifier, Bot-DenseNet, is built on a dense neural network on combining additional metadata with text encodings. Existing methods consider metadata information or along with some semantic features of text in encoding the user account. It will be trained and then verified using extensive data sets collected from Kaggle and twitter API. Subsequently, comparison between the performance of the Bot-DenseNet and Bag-of-Words model is also analyzed.",
    "abstract_processed": "twitter social network platform allow user convey idea wide rang topic includ polit sport stock market entertain big influenc peopl think bot twitter send spam messag result detect bot aid spam detect paper detect twitter bot use deep learn method address present use model updat latest dataset reduc accuraci multilingu final classifi bot densenet built dens neural network combin addit metadata text encod exist method consid metadata inform along semant featur text encod user account train verifi use extens data set collect kaggl twitter api subsequ comparison perform bot densenet bag word model also analyz"
  },
  {
    "doc_id": "10040422",
    "abstract_original": "Alzheimer's disease (AD) is a kind of Dementia. It affects the brain functions, thinking ability and creates memory loss. Each stage of AD is worsening the symptoms and also affects the patient's daily activities. The current diagnosis AD detection process is not providing an accurate report for the early stages of AD. Therefore, accurate Alzheimer detection is an open challenge for the researchers. In this research, a deep learning model is introduced to improve Alzheimer's stage diagnosis. The Hybrid deep model is designed to detect abnormal changes in brain (Magnetic Resonance Imaging) MRI scans. It utilizes the multi-class log loss (MCLL) function as the objective function to reduce the error rate in detecting AD stages. The MCLL approach computes the variations in actual and detected AD stages of each biomarkers features of input MRI images to identify loss rate. It helps to reduce the loss rate in AD stages detection. Moreover, the Hybrid deep learning model for Alzheimer stages detection (HDLMASD)system analysis the images deeply to provide accurate biomarkers detection with the help of all essential biomarkers processing steps. The efficiency of the Alzheimer stages diagnosis system is evaluated with various evaluation metrics. Finally, a comparative analysis is made with multiple present diagnosis systems to verify the performance of the AD detection system. The performance analysis proves that the AD stages diagnosis approach accuracy rate is improved up to 0.47% and the prediction error rate reduced up to 0.49% than comparison approaches.",
    "abstract_processed": "alzheim diseas ad kind dementia affect brain function think abil creat memori loss stage ad worsen symptom also affect patient daili activ current diagnosi ad detect process provid accur report earli stage ad therefor accur alzheim detect open challeng research research deep learn model introduc improv alzheim stage diagnosi hybrid deep model design detect abnorm chang brain magnet reson imag mri scan util multi class log loss mcll function object function reduc error rate detect ad stage mcll approach comput variat actual detect ad stage biomark featur input mri imag identifi loss rate help reduc loss rate ad stage detect moreov hybrid deep learn model alzheim stage detect hdlmasd system analysi imag deepli provid accur biomark detect help essenti biomark process step effici alzheim stage diagnosi system evalu variou evalu metric final compar analysi made multipl present diagnosi system verifi perform ad detect system perform analysi prove ad stage diagnosi approach accuraci rate improv predict error rate reduc comparison approach"
  },
  {
    "doc_id": "10040862",
    "abstract_original": "This document presents the results of the development of a learning program on computational thinking through programming challenges with robots oriented to early childhood. The methodological approach used was quantitative, using a quasi-experimental design, taking pretest/posttest measures, with experimental and control groups. The sample of participating students was 46. They belonged to a group of first grade of primary education, aged between 6 and 7 years, in a Spanish educational center. The learning of computational thinking was measured through the following dimensions: algorithmic thinking-sequences, abstraction-patterns and debugging. The learning activities used were an adaptation of the activities proposed in the “TangibleK” robotics curriculum. The results generated show positive effects in relation to the level of achievement reached by the students in the proposed challenges; in other words, there is a significant effect on the mastery of skills related to computational thinking. Differences were found between the pretest and posttest measures of the experimental group. Those of the latter group were statistically significant and higher than those of the control group. Therefore, we can statistically attribute the mastery of computational thinking skills to the participation in the training activities.",
    "abstract_processed": "document present result develop learn program comput think program challeng robot orient earli childhood methodolog approach use quantit use quasi experiment design take pretest posttest measur experiment control group sampl particip student belong group first grade primari educ age year spanish educ center learn comput think measur follow dimens algorithm think sequenc abstract pattern debug learn activ use adapt activ propos “tangiblek” robot curriculum result gener show posit effect relat level achiev reach student propos challeng word signific effect masteri skill relat comput think differ found pretest posttest measur experiment group latter group statist signific higher control group therefor statist attribut masteri comput think skill particip train activ"
  },
  {
    "doc_id": "10041572",
    "abstract_original": "This paper presents an interactive software tool developed to be used in an entry level course of control system. This software tool is open-source and it was programmed using Python3 language. It was created with the purpose of offering students an alternative software tool with a low computational cost. It was made thinking in providing a great user experience to the students when they are learning about process dynamics and closed-loop system behavior based on proportional-integral and derivative controllers. In particular, the real-time simulation mode, provides to the user an interactive way to understand the meaning of each parameter in classical second order process models or in PID controllers and, hence it could become in a useful tool in careers as electrical engineering.",
    "abstract_processed": "paper present interact softwar tool develop use entri level cours control system softwar tool open sourc program use python languag creat purpos offer student altern softwar tool low comput cost made think provid great user experi student learn process dynam close loop system behavior base proport integr deriv control particular real time simul mode provid user interact way understand mean paramet classic second order process model pid control henc could becom use tool career electr engin"
  },
  {
    "doc_id": "10042116",
    "abstract_original": "The expansion of artificial intelligence (AI) into our lives and livelihoods makes it clear that we must develop AI to be ethical and trustworthy. We propose Wasabi, a novel conceptual model for trustworthy AI based on an adaptation of the well-known ability–benevolence–integrity model of trust to trustworthiness.",
    "abstract_processed": "expans artifici intellig ai live livelihood make clear must develop ai ethic trustworthi propos wasabi novel conceptu model trustworthi ai base adapt well known ability–benevolence–integr model trust trustworthi"
  },
  {
    "doc_id": "10043302",
    "abstract_original": "Compared with combat in other fields, ground combat has the characteristics of complex environment, fierce confrontation and difficult coordination. The inherent shortcomings of artificial intelligence in understanding, interpretability and controllability restrict the development speed of unmanned ground combat. In order to give full play to the advantages of artificial intelligence, overcome deficiencies and promote the development of ground unmanned combat, this paper starts from the advantages of man-machine hybrid intelligence, Combined with OODA(Observatio, Orientation, Decision, Action) ring theory, this paper analyzes the application and prospect of man-machine hybrid intelligence in ground unmanned combat, and finally briefly analyzes the key technologies that should be grasped in the development of man-machine hybrid intelligence, hoping to provide inspiration and reference for the research of ground unmanned combat.",
    "abstract_processed": "compar combat field ground combat characterist complex environ fierc confront difficult coordin inher shortcom artifici intellig understand interpret control restrict develop speed unman ground combat order give full play advantag artifici intellig overcom defici promot develop ground unman combat paper start advantag man machin hybrid intellig combin ooda observatio orient decis action ring theori paper analyz applic prospect man machin hybrid intellig ground unman combat final briefli analyz key technolog grasp develop man machin hybrid intellig hope provid inspir refer research ground unman combat"
  },
  {
    "doc_id": "10046490",
    "abstract_original": "Cloud computing has arisen as a correlative response to deal with the troubles stood up to in figuring. While dispensed computing lets in us to greater deal extra with time/delay-delicate IoT functions (e.g., wise frameworks and ill-disposed climate), there is a scope of practical difficulties. For instance, the asset-compelled nature of mist hubs and heterogeneity of IoT occupations entangle endeavors to proficiently timetable errands. In this manner, to greater clean out time/delay-delicate unique IoE demands, the creators contribute by using imparting a sharp layer between IoE devices and haze hubs to contain a speedy and versatile learning-based mission planning strategy. We cautiously think about the exhibition of the proposed procedure the utilization of reproduction, as pleasantly as its accuracy the use of formal confirmation. The difference discoveries are promising, each in expressions of solidarity utilization and Quality of Service (QoS).",
    "abstract_processed": "cloud comput arisen correl respons deal troubl stood figur dispens comput let us greater deal extra time delay delic iot function e g wise framework ill dispos climat scope practic difficulti instanc asset compel natur mist hub heterogen iot occup entangl endeavor profici timet errand manner greater clean time delay delic uniqu ioe demand creator contribut use impart sharp layer ioe devic haze hub contain speedi versatil learn base mission plan strategi cautious think exhibit propos procedur util reproduct pleasantli accuraci use formal confirm differ discoveri promis express solidar util qualiti servic qo"
  },
  {
    "doc_id": "10046557",
    "abstract_original": "Now with the current state of power engineering, the idea of a microgrid (MG) is widely accepted because of how quickly energy electronics are being made. People are also becoming more interested in direct current (DC) MGs because DC delivery schemes have benefits like less damage and quick alignment of energy loading resources. With the rise of distributed output, a DCMG with many fonts is an important area to investigate. In this DCMG with many sources, the goal is to offer voltage help and strong value division. The control technique includes a thorough analysis of the \"state-of-the-art\" control procedures in DCMGs. This is important because it makes sure that MG's power and performance are always the same. In this section, the main and secondary control mechanisms in the DCMG hierarchy are explained. In particular, the main ways to control internal loop and droop control are looked at. The secondary regulation is a solution that is centralized, spread out, and independent.",
    "abstract_processed": "current state power engin idea microgrid mg wide accept quickli energi electron made peopl also becom interest direct current dc mg dc deliveri scheme benefit like less damag quick align energi load resourc rise distribut output dcmg mani font import area investig dcmg mani sourc goal offer voltag help strong valu divis control techniqu includ thorough analysi state art control procedur dcmg import make sure mg power perform alway section main secondari control mechan dcmg hierarchi explain particular main way control intern loop droop control look secondari regul solut central spread independ"
  },
  {
    "doc_id": "10046729",
    "abstract_original": "Credit card fraud, although not directly impacting banks, does have repercussions for the financial sector as a whole. Criminals pose a significant threat to safety since they are continually thinking up new methods to commit these types of fraud. Early detection of fraudulent behavior is therefore vital to retain customer trust and defend the firm. Since lawful transactions far outnumber fraudulent transactions, which typically make up less than 1% of all transactions, addressing the class imbalance issue in the data presents a significant challenge for developing fraud detection algorithms. It is challenging to identify a positive example (fraudulent case), and this challenge increases as more data is gathered, leading to a lower proportion of positive examples. Because of this, research is very important. Models for making predictions were trained in this study utilizing a variety of sampling strategies, including the ANN, GBM, and the RF. Models used SMOTE, RUS, DBSMOTE, and SMOTE plus ENS were all examples of Synthetic Minority Over-Sampling Technique (SMOTEENN). This research suggests that SMOTE-based sampling techniques will provide positive results. The highest recall (0.81) was achieved by the SMOTE sampling method when a DRF classifier was used. It was determined that this classifier has an accuracy score of 0.87. The Stacked Ensembling algorithm was accomplished using altogether of collected data, and its average performance was 0.78, making it the clear winner. As a fraud detection model, the Stacked Ensemble has performed well in most sampling operations.",
    "abstract_processed": "credit card fraud although directli impact bank repercuss financi sector whole crimin pose signific threat safeti sinc continu think new method commit type fraud earli detect fraudul behavior therefor vital retain custom trust defend firm sinc law transact far outnumb fraudul transact typic make less transact address class imbal issu data present signific challeng develop fraud detect algorithm challeng identifi posit exampl fraudul case challeng increas data gather lead lower proport posit exampl research import model make predict train studi util varieti sampl strategi includ ann gbm rf model use smote ru dbsmote smote plu en exampl synthet minor sampl techniqu smoteenn research suggest smote base sampl techniqu provid posit result highest recal achiev smote sampl method drf classifi use determin classifi accuraci score stack ensembl algorithm accomplish use altogeth collect data averag perform make clear winner fraud detect model stack ensembl perform well sampl oper"
  },
  {
    "doc_id": "10050074",
    "abstract_original": "This study uses a physical programming course to explore the development of children’s multiple intelligences. The process includes the design of teaching objectives, course design, course implementation and evaluation of effectiveness. A graphic multiple intelligences test scale was designed to measure children’s multiple intelligences. The study was conducted as a controlled experiment and the implementation of the courses showed that the physical programming coursess had a significant effect on the development of children’s natural observation, visual-spatial and mathematical-logical intelligences compared to the traditional courses.",
    "abstract_processed": "studi use physic program cours explor develop children’ multipl intellig process includ design teach object cours design cours implement evalu effect graphic multipl intellig test scale design measur children’ multipl intellig studi conduct control experi implement cours show physic program coursess signific effect develop children’ natur observ visual spatial mathemat logic intellig compar tradit cours"
  },
  {
    "doc_id": "10050860",
    "abstract_original": "Growing electricity demand, the deployment of renewable energy sources and the widespread use of smart home appliances provide new opportunities for home energy management systems (HEMSs), which can be defined as systems that improve the overall energy production and consumption of residential buildings by controlling and scheduling the use of household equipment. By saving energy, reducing residential electricity costs, optimizing the utilization rate and reliability of utility companies’ power systems, and reducing air pollution for society, HEMSs lead to an enhancement in the socioeconomic development of low-carbon economies. This review aims to systematically analyze and summarize the development trends and challenges of HEMSs in recent years. This paper reviews the development history of the HEMS architecture and discusses the characteristics of several major communication technologies in the current HEMS infrastructure. In addition, the common objectives and constraints related to scheduling optimization are classified, and several optimization methods in the literature, including various intelligent algorithms, have been introduced, compared, and critically analyzed. Furthermore, experimental studies and challenges in the real world are also summarized and recommendations are given. This paper reveals the trend from simple to complex in the architecture and functionality of HEMSs, discusses the challenges for future improvements in modeling and scheduling, and shows the development of various modeling and scheduling methods. Based on this review, researchers can gain a comprehensive understanding of current research trends in HEMSs and open up ideas for developing new modeling and scheduling approaches by gaining insight into the trade-offs between optimum solutions and computational complexity.",
    "abstract_processed": "grow electr demand deploy renew energi sourc widespread use smart home applianc provid new opportun home energi manag system hemss defin system improv overal energi product consumpt residenti build control schedul use household equip save energi reduc residenti electr cost optim util rate reliabl util companies’ power system reduc air pollut societi hemss lead enhanc socioeconom develop low carbon economi review aim systemat analyz summar develop trend challeng hemss recent year paper review develop histori hem architectur discuss characterist sever major commun technolog current hem infrastructur addit common object constraint relat schedul optim classifi sever optim method literatur includ variou intellig algorithm introduc compar critic analyz furthermor experiment studi challeng real world also summar recommend given paper reveal trend simpl complex architectur function hemss discuss challeng futur improv model schedul show develop variou model schedul method base review research gain comprehens understand current research trend hemss open idea develop new model schedul approach gain insight trade off optimum solut comput complex"
  },
  {
    "doc_id": "10053182",
    "abstract_original": "Epilepsy is considered as one of the most dangerous and fatal neurological disorder for the patient suffering from it. It affects the particular areas of the brain, due to which patient has seizures. Epilepsy is often referred to as ‘mirgi’ in the Hindi language. The purpose of the paper is to identify and understand the prediction of the seizures that occur due to neurological disorder called Epilepsy. Epilepsy can be explained as the disorder of central nervous system, which results in abnormal activities inside the brain. The impacts of this disorder come out as seizures, and patient behaves in a weird manner. Sometimes the patient can even lose the track of consciousness and sensations, the power of thinking and reacting is also affected. When seen during Electroencephalogram, the brain wave patterns which are observed appear to be different and abnormal. It is one of the difficult diseases to be diagnosed. In this project, we have tried to find out the result as whether the patient is having an epileptic seizure or not, using machine learning models, like KNN, logistic regression and naïve bayes. The Output label column of the dataset has the value whether patient is having (1) or not having (0) a seizure. In this paper, we have preprocessed the dataset and calculated the accuracies of the models on both training and testing datasets. Dataset is extracted from GitHub and the coding is performed in python programming language. Python libraries like seaborn, matplotlib, pandas, numpyetc are used in the pre-processing of the model. We have later on come to the result as out of the three models that we have used which one gives the best results, with the help of AUC value.",
    "abstract_processed": "epilepsi consid one danger fatal neurolog disord patient suffer affect particular area brain due patient seizur epilepsi often refer ‘mirgi’ hindi languag purpos paper identifi understand predict seizur occur due neurolog disord call epilepsi epilepsi explain disord central nervou system result abnorm activ insid brain impact disord come seizur patient behav weird manner sometim patient even lose track conscious sensat power think react also affect seen electroencephalogram brain wave pattern observ appear differ abnorm one difficult diseas diagnos project tri find result whether patient epilept seizur use machin learn model like knn logist regress naïv bay output label column dataset valu whether patient seizur paper preprocess dataset calcul accuraci model train test dataset dataset extract github code perform python program languag python librari like seaborn matplotlib panda numpyetc use pre process model later come result three model use one give best result help auc valu"
  },
  {
    "doc_id": "10053425",
    "abstract_original": "Suicide is a very critical and important issue in modern society. Suicide is the third-leading cause of death for college and high school students. Social media allows students in the digital environment to share their suicidal ideas and thoughts with others. Accurate and early detection and prevention of suicidal ideation in students can save the students' lives. To identify the risk factor for suicidal attempts, a suitable method of analysing the suicidal behaviour of students using their sentiment text posted on social media can be used. This paper presents an optimized Dragonfly algorithm (DFA) using a Deep Belief Network (DBN) for the automatic detection of suicidal ideation in students. In our CyberHelp Solution, the proposed DFA-based DBN model analyses student social media data, predicts suicidal behavior, and treats students appropriately. The sentiment analysis performs automated categorization of online messages and makes accurate predictions of the student’s suicidal behaviors. The dragonfly heuristic optimization algorithm is used for tuning the hyperparameter in the deep belief network. The proposed DFA-DBN technique has been implemented to predict suicidal ideation in students with a higher accuracy of 95.5% compared with other classification models.",
    "abstract_processed": "suicid critic import issu modern societi suicid third lead caus death colleg high school student social media allow student digit environ share suicid idea thought other accur earli detect prevent suicid ideat student save student live identifi risk factor suicid attempt suitabl method analys suicid behaviour student use sentiment text post social media use paper present optim dragonfli algorithm dfa use deep belief network dbn automat detect suicid ideat student cyberhelp solut propos dfa base dbn model analys student social media data predict suicid behavior treat student appropri sentiment analysi perform autom categor onlin messag make accur predict student’ suicid behavior dragonfli heurist optim algorithm use tune hyperparamet deep belief network propos dfa dbn techniqu implement predict suicid ideat student higher accuraci compar classif model"
  },
  {
    "doc_id": "10054028",
    "abstract_original": "Data mining approaches have proven to be successful in improving learners’ interaction with educational computer games. Despite the potential of predictive modelling in providing timely adaptive learning and gameplay experience, there is a lack of research on the early prediction of learners’ performance in educational games. In this research, we propose an early predictive modelling approach, called GameEPM, to estimate learners’ final scores in an educational game for promoting computational thinking. Specifically, the GameEPM approach models the sequence of learners’ actions and then uses a limited sequence of the actions to predict the final score of the game for each learner. The findings from our initial trials show that our approach can accurately and robustly estimate the learners’ performance at the early stages of the game. Using less than 50% of learners’ action sequences, the cross-validated deep learning model achieves a squared correlation higher than 0.8 with a relative error of less than 8%, outperforming a range of regression models like linear regression, random forest, neural networks, and support vector machines. An additional experiment showed that the validated deep learning model can also achieve high performance while tested on an independent game dataset, showing its applicability and robustness in real-world cases. Comparing the results with traditional machine learning methods revealed that, in the validation and application phases, up to 0.30 and 0.35 R2 gain is achieved in favor of the deep learning model, respectively. Finally, we found that while the lengths of action sequences influence the predictive power of the traditional machine learning methods, this effect is not substantial in the deep learning model.",
    "abstract_processed": "data mine approach proven success improv learners’ interact educ comput game despit potenti predict model provid time adapt learn gameplay experi lack research earli predict learners’ perform educ game research propos earli predict model approach call gameepm estim learners’ final score educ game promot comput think specif gameepm approach model sequenc learners’ action use limit sequenc action predict final score game learner find initi trial show approach accur robustli estim learners’ perform earli stage game use less learners’ action sequenc cross valid deep learn model achiev squar correl higher rel error less outperform rang regress model like linear regress random forest neural network support vector machin addit experi show valid deep learn model also achiev high perform test independ game dataset show applic robust real world case compar result tradit machin learn method reveal valid applic phase r gain achiev favor deep learn model respect final found length action sequenc influenc predict power tradit machin learn method effect substanti deep learn model"
  },
  {
    "doc_id": "10054368",
    "abstract_original": "The rise of the Industrial Revolution 4.0 and the increasing reliance on the digital economy drive the need for a new set of skills, especially in robotics learning, that includes computational thinking (CT) and adversarial thinking (AT) for the young generation. The need for CT-related skills includes various fields, such as robotics, engineering, computer science, mathematics, music, arts, and humanities. Therefore, adopting robotic learning with CT and AT can enhance learning skills over the conventional learning model. This paper presents a systematic literature review on CT and AT practices in robotics learning to improve educational methods. This study conducts a systematic literature review from four databases: ACM, Scopus, IEEE Xplore, and ScienceDirect. Sixty-five studies in robotics learning to increase CT and AT skills were analyzed by applying the inclusion and exclusion criteria. The study’s findings show that CT and AT are significant in training students to engage in robotics learning activities. These considerations will lead to strengthening their skill and critical thinking. The study also suggests that integrating these skills can prepare teachers for critical thinking and boost student learning. The findings suggest that CT and AT can directly adopt digital adversarial learning skills to improve overall robotics learning activities. For future studies, the difference in learning ages related to robotics activities with CT and AT applications can be studied to deeply comprehend the effectiveness of CT and AT applications.",
    "abstract_processed": "rise industri revolut increas relianc digit economi drive need new set skill especi robot learn includ comput think ct adversari think young gener need ct relat skill includ variou field robot engin comput scienc mathemat music art human therefor adopt robot learn ct enhanc learn skill convent learn model paper present systemat literatur review ct practic robot learn improv educ method studi conduct systemat literatur review four databas acm scopu ieee xplore sciencedirect sixti five studi robot learn increas ct skill analyz appli inclus exclus criteria study’ find show ct signific train student engag robot learn activ consider lead strengthen skill critic think studi also suggest integr skill prepar teacher critic think boost student learn find suggest ct directli adopt digit adversari learn skill improv overal robot learn activ futur studi differ learn age relat robot activ ct applic studi deepli comprehend effect ct applic"
  },
  {
    "doc_id": "1005573",
    "abstract_original": "Kohonen's self organizing maps (SOM) is a kind of neural network that the algorithm learns the feature of input data thorough unsupervised and competitive neighborhood learning. SOM is mapped from a high dimensional space onto a two dimensional space, so it can visualize the high-dimensional information to the map. In the SOM's learning algorithm, there are many factors to aggravate the computational load and a competition to be declared the winner. We think it is a major factor at the beginning of learning process that SOM's map is changing dynamically and widely and the learning dynamics depends on the distance of each input data. Thus we suppose that, by adjusting the data order, the competition must be reduced and the learning convergence must become faster. In this paper, we discuss the \"efficient learning by data order adjustment\", and compare it with the conventional method. We achieved a maximum 9% improvement.",
    "abstract_processed": "kohonen self organ map som kind neural network algorithm learn featur input data thorough unsupervis competit neighborhood learn som map high dimension space onto two dimension space visual high dimension inform map som learn algorithm mani factor aggrav comput load competit declar winner think major factor begin learn process som map chang dynam wide learn dynam depend distanc input data thu suppos adjust data order competit must reduc learn converg must becom faster paper discuss effici learn data order adjust compar convent method achiev maximum improv"
  },
  {
    "doc_id": "10057228",
    "abstract_original": "Digital human in cyberspace can help provide humanized services in specific applications, such as question & answer systems, recommender systems, chatter robots, and intelligent assistants. While most researches focus on behavior analytics, few of them integrate the personality that is also a closely related factor. As a classic indicator for personality representation, Myers–Briggs type indicator (MBTI) categorizes an individual into mutually exclusive types from four dichotomous axes (extraversion versus introversion, sensing versus intuition, thinking versus feeling, judging versus perceiving). Traditional recognition method using MBTI simply measures the user’s preference frequency in each axis through questionnaires, treating the dominant value as the identified result. Such a paradigm, however, represents all the people with only 16 types and cannot distinguish heterogeneous users clearly. This article proposes a novel personality recognition method using fuzzy logic. Different from previous classifications, our new method categorizes the individual in a continuous space and represents one’s personality in a more fine-grained level. We have designed comparative psychological tests for 77 people. The validation experiments on such tests indicate that the fuzzy-logic-based method is not only consistent with the classic MBTI tests (in the sense of defuzzification) but also provides the uncertainty for each personality type. Therefore, it can be viewed as a generalization of the classic MBTI tests and promotes the representation of individual’s heterogeneity for fine-grained analytics of digital human.",
    "abstract_processed": "digit human cyberspac help provid human servic specif applic question answer system recommend system chatter robot intellig assist research focu behavior analyt integr person also close relat factor classic indic person represent myers–brigg type indic mbti categor individu mutual exclus type four dichotom axe extravers versu introvers sens versu intuit think versu feel judg versu perceiv tradit recognit method use mbti simpli measur user’ prefer frequenc axi questionnair treat domin valu identifi result paradigm howev repres peopl type cannot distinguish heterogen user clearli articl propos novel person recognit method use fuzzi logic differ previou classif new method categor individu continu space repres one’ person fine grain level design compar psycholog test peopl valid experi test indic fuzzi logic base method consist classic mbti test sens defuzzif also provid uncertainti person type therefor view gener classic mbti test promot represent individual’ heterogen fine grain analyt digit human"
  },
  {
    "doc_id": "10058022",
    "abstract_original": "The study explores the effects of an interdisciplinary learning approach on developing students’ English learning (EL) and computational thinking (CT) through two different game-based learning approaches. A quasi-experiment is conducted to evaluate the effectiveness of this approach in terms of enhancing students’ CT knowledge and their EL achievement in an elementary school English as a foreign language (EFL) learning context. A total of 52 Grade 3 students take part in the experiment, of whom 28 are assigned to the experimental group learned with a machine educational robot (machine-ER) board game and 24 are assigned to the control group learned with a character educational robot (character-ER) board game. Results indicate that both groups made significant improvements in learning achievement: 1) in English-language achievement of learning vocabulary and sentence patterns; and 2) in CT concepts, although the machine-ER board game produces a greater increase than the character-ER board game in both language learning achievement and CT knowledge, their learning anxieties are also lower than those of the control group. The analysis of behavioral patterns also reveals that students playing the machine-ER board game demonstrate better language-learning interaction, whereas the students playing character-ER board game present greater CT development in finding solutions.",
    "abstract_processed": "studi explor effect interdisciplinari learn approach develop students’ english learn el comput think ct two differ game base learn approach quasi experi conduct evalu effect approach term enhanc students’ ct knowledg el achiev elementari school english foreign languag efl learn context total grade student take part experi assign experiment group learn machin educ robot machin er board game assign control group learn charact educ robot charact er board game result indic group made signific improv learn achiev english languag achiev learn vocabulari sentenc pattern ct concept although machin er board game produc greater increas charact er board game languag learn achiev ct knowledg learn anxieti also lower control group analysi behavior pattern also reveal student play machin er board game demonstr better languag learn interact wherea student play charact er board game present greater ct develop find solut"
  },
  {
    "doc_id": "10059942",
    "abstract_original": "The emergence of cloud computing(CC), the three service levels of IaaS, PaaS and SaaS, and the cloud service delivery model of “cloud” + “end” have changed the development thinking of the entire IT industry. The education industry has also been influenced by new technologies and concepts, especially the core technologies of CC - “virtualization” and “distribution”, which make the education industry face the challenges in teaching and learning resources management and laboratory management. In particular, the core technologies of CC - “virtualization” and “distributed” - have given the education industry a revolutionary solution to the challenges faced in the management of teaching resources and laboratory management. In this paper, we design a simulation model of physical education(PE) teaching in CC based on Java. The results show that the Java-based CC PE teaching is more conducive to improving students' performance and thus physical and motor skills; stimulating students' learning needs and thus forming expectations for course learning; and being able to continuously improve students' performance. The results show that the Java-based cloud-based PE teaching is more conducive to improving students' performance and thus physical and motor skills; stimulating students' learning needs and thus forming expectations for the learning of the course; and continuously stimulating students' learning initiatives to achieve the purpose of improving academic interest indicators.",
    "abstract_processed": "emerg cloud comput cc three servic level iaa paa saa cloud servic deliveri model “cloud” “end” chang develop think entir industri educ industri also influenc new technolog concept especi core technolog cc “virtualization” “distribution” make educ industri face challeng teach learn resourc manag laboratori manag particular core technolog cc “virtualization” “distributed” given educ industri revolutionari solut challeng face manag teach resourc laboratori manag paper design simul model physic educ pe teach cc base java result show java base cc pe teach conduc improv student perform thu physic motor skill stimul student learn need thu form expect cours learn abl continu improv student perform result show java base cloud base pe teach conduc improv student perform thu physic motor skill stimul student learn need thu form expect learn cours continu stimul student learn initi achiev purpos improv academ interest indic"
  },
  {
    "doc_id": "10060059",
    "abstract_original": "Both Artificial Intelligence (otherwise called recreated intelligence) and Robotics are instances of cutting edge improvements that will affect the development of mankind as fast as doable. The idea of “artificial intelligence” may be characterized as “any sort of artificial computational framework that exhibits shrewd lead, i.e., confounded direct that is successful for appearing at focuses on.” This definition envelops the conceivable outcomes of “artificial intelligence.” Minsky said that we ought to abstain from restricting “intelligence” to exercises that explicitly require data, whether or not they are performed by people. This proposes that we ought to join various machines, including those that illustrate “specific PC based intelligence that show just bound limits in learning or thinking anyway outperform presumptions at the robotization of explicit errands, likewise as machines general artificial intelligence that expect to make a by and large canny overseer.” Robots are the fake experts filling the role of real people. The fields of electrical engineering, mechanical engineering, and computer programming are the ones that meet up to frame robotics, which is a “part of recreated intelligence” that arrangements with the association, improvement, and use of robots. A theory on artificial intelligence can be viewed as here. The improvement of PC systems has made it conceivable to achieve undertakings that previously required the intelligence of a human. A few instances of these errands incorporate visual segregation, the affirmation of discussion, the arrangement of bearing, and the investigation of tongue contrasts. The subject matter expert, who is the “performer” in this reference, brings forth the item and polishes itself off in the body of the hardware. This is the key piece of the reference. The association between these two is that the control of the robot is an item expert that looks at input from the sensors, comes to a choice on what to do right away, and afterward guides the effectors to act in reality. The reason for this study is to give essential, basic measurements on two arising progressions: artificial intelligence (recreated intelligence), and robotics, as well as how much they are available in India. Consequently, the range of the things being examined is the primary significant part of these two disciplines. Moreover, it is feasible to portray them as being testing, engaging, and between disciplinary in nature. A flexible robot that was intended to complete various undertakings simultaneously to decide the ideal gathering that has the most noteworthy effectiveness extent of CAS model.",
    "abstract_processed": "artifici intellig otherwis call recreat intellig robot instanc cut edg improv affect develop mankind fast doabl idea “artifici intelligence” may character “ani sort artifici comput framework exhibit shrewd lead e confound direct success appear focus ” definit envelop conceiv outcom “artifici intellig ” minski said ought abstain restrict “intelligence” exercis explicitli requir data whether perform peopl propos ought join variou machin includ illustr “specif pc base intellig show bound limit learn think anyway outperform presumpt robot explicit errand likewis machin gener artifici intellig expect make larg canni overs ” robot fake expert fill role real peopl field electr engin mechan engin comput program one meet frame robot “part recreat intelligence” arrang associ improv use robot theori artifici intellig view improv pc system made conceiv achiev undertak previous requir intellig human instanc errand incorpor visual segreg affirm discuss arrang bear investig tongu contrast subject matter expert “performer” refer bring forth item polish bodi hardwar key piec refer associ two control robot item expert look input sensor come choic right away afterward guid effector act realiti reason studi give essenti basic measur two aris progress artifici intellig recreat intellig robot well much avail india consequ rang thing examin primari signific part two disciplin moreov feasibl portray test engag disciplinari natur flexibl robot intend complet variou undertak simultan decid ideal gather noteworthi effect extent ca model"
  },
  {
    "doc_id": "10061264",
    "abstract_original": "In 2022, the image governs daily life. The Image guides navigation, the sharing of affections, political geography, and the evolution of knowledge in the most varied scientific areas. In this article, we will try to reflect on the positioning of the subject before digital technology and on how we can think about the real at this moment in history. In practical terms, the real has imposed itself in the last three years in which the pandemic by COVID-19 made us rethink the bases of our existence. Its relationship with image expressions, like indexicality, mimicry or visibility, seems obvious. However, the complexity of the image brought by digital technologies that capture, edit and/or construct in a participative way in realtime, implies that expressions like illusion, participation, simulation or creativity; become much more pertinent to the discussion of the image and the positioning of the subject. By dislocating/displacing reality, /replacing it, through the manipulative capacity offered by the technology that is essentially plasma through computer graphics and exponentiated in portable devices, the image lost one of the fundamental characteristics of its essence as testimony, gaining an interactive synaesthetic dimension and enhancing the creativity of the users/fruiters.",
    "abstract_processed": "imag govern daili life imag guid navig share affect polit geographi evolut knowledg vari scientif area articl tri reflect posit subject digit technolog think real moment histori practic term real impos last three year pandem covid made us rethink base exist relationship imag express like index mimicri visibl seem obviou howev complex imag brought digit technolog captur edit construct particip way realtim impli express like illus particip simul creativ becom much pertin discuss imag posit subject disloc displac realiti replac manipul capac offer technolog essenti plasma comput graphic exponenti portabl devic imag lost one fundament characterist essenc testimoni gain interact synaesthet dimens enhanc creativ user fruiter"
  },
  {
    "doc_id": "10061374",
    "abstract_original": "The foreign object doped in the conveying belt is the most important factor to cause the tearing of the conveying belt. In order to solve the problem of low accuracy and poor real-time performance of foreign object detection, a new method based on improved Nanodet is proposed in this paper. The hardware of conveyor belt foreign object detection system is designed with ARM processor, and the system software is designed based on Android. It uses a conveyor belt foreign object detection system to detect foreign object. In order to detect foreign object images, a better Nanodet model is suggested. In order to increase detection accuracy while preserving processing speed, the model uses SIoU in place of the original position loss function. When the enhanced Nanodet model is applied to the conveyor belt foreign object detection system, the image of the foreign object appearing on the conveyor belt can be identified. The experimental findings indicate that a conveyor belt foreign object detection system based on an ARM processor and an Android operating system is capable of detecting foreign objects on conveyor belts with an average detection accuracy of 94.3%, a detection speed of 30 frames per second. The application of this method in the detection of foreign objects in conveyor belt can solve the shortcomings of existing methods. At the same time meet the requirements of the conveyor belt foreign object detection site environment.",
    "abstract_processed": "foreign object dope convey belt import factor caus tear convey belt order solv problem low accuraci poor real time perform foreign object detect new method base improv nanodet propos paper hardwar conveyor belt foreign object detect system design arm processor system softwar design base android use conveyor belt foreign object detect system detect foreign object order detect foreign object imag better nanodet model suggest order increas detect accuraci preserv process speed model use siou place origin posit loss function enhanc nanodet model appli conveyor belt foreign object detect system imag foreign object appear conveyor belt identifi experiment find indic conveyor belt foreign object detect system base arm processor android oper system capabl detect foreign object conveyor belt averag detect accuraci detect speed frame per second applic method detect foreign object conveyor belt solv shortcom exist method time meet requir conveyor belt foreign object detect site environ"
  },
  {
    "doc_id": "10063777",
    "abstract_original": "This research purpose is to figure out whether educational robotics is a strategy to develop young children's computational thinking. The method used in this research was quantitative with a descriptive exploratory scope, with an inductive-deductive approach. The sample consisted of 28 students taken from the population of the tenth-grade students of “Santa Mariana de Jesús” high school. The technique used was the survey and the data collection instrument was a questionnaire at the beginning (Pre-Test) and at the end of the process (Post Test). A \"Rubric to evaluate computational thinking\" using the Likert scale was used for its tabulation, with the use of the STEAM instructional framework learning methodology, and a \"Checklist\" was used to monitor the progress of the project. The result of the data analysis showed positive increase in computational thinking skills, due to in the Post Test the students reached the scale Very well with 64%, taking into account that in the beginning (PreTest) it was 14%, concluding that educational robotics is a didactic strategy that promotes computational thinking.",
    "abstract_processed": "research purpos figur whether educ robot strategi develop young children comput think method use research quantit descript exploratori scope induct deduct approach sampl consist student taken popul tenth grade student “santa mariana de jesús” high school techniqu use survey data collect instrument questionnair begin pre test end process post test rubric evalu comput think use likert scale use tabul use steam instruct framework learn methodolog checklist use monitor progress project result data analysi show posit increas comput think skill due post test student reach scale well take account begin pretest conclud educ robot didact strategi promot comput think"
  },
  {
    "doc_id": "10066039",
    "abstract_original": "The deep multi-view stereo (MVS) approaches generally construct a cost volume pyramid in a coarse- to- fine manner to regularize and regress the depth or disparity, which is often built upon a feature pyramid encoding geometry or an image pyramid. A pyramid is an excellent approach to reducing memory, and many papers said even low-resolution images or features contain enough information for estimating low-resolution depth maps. However, recent papers show that the higher the image resolution, the better the output depth map, which means the resolution of depth maps in each stage cause effect on the final outputs. Therefore, we think the low-resolution depth map may not be enough for the high-resolution depth map. In this paper, we propose a sub-pixel upsampling module for post-processing the cost volume to generate a big resolution depth map at each stage. Besides, we also proposed an edge-weighted loss function for optimizing those inaccurate depth values in the edge regions of objects. Finally, we implement them on CasMVSNet, showing the effectiveness of our proposed method. The content of abstract.",
    "abstract_processed": "deep multi view stereo mv approach gener construct cost volum pyramid coars fine manner regular regress depth dispar often built upon featur pyramid encod geometri imag pyramid pyramid excel approach reduc memori mani paper said even low resolut imag featur contain enough inform estim low resolut depth map howev recent paper show higher imag resolut better output depth map mean resolut depth map stage caus effect final output therefor think low resolut depth map may enough high resolut depth map paper propos sub pixel upsampl modul post process cost volum gener big resolut depth map stage besid also propos edg weight loss function optim inaccur depth valu edg region object final implement casmvsnet show effect propos method content abstract"
  },
  {
    "doc_id": "1006638",
    "abstract_original": "Nowadays, it is easy to find a number of different hybrid approaches for fuzzy modeling. All these approaches were built in a very ad-hoc manner, and did not follow a systematic approach. However, we think that some kind of information system which helps in the study of how algorithms can combine to model systems in a fuzzy fashion should be very helpful. In this article, we propose METALA (META-Learning Architecture), an architecture to study the typical processes of machine learning, to study the particular issue of fuzzy modeling.",
    "abstract_processed": "nowaday easi find number differ hybrid approach fuzzi model approach built ad hoc manner follow systemat approach howev think kind inform system help studi algorithm combin model system fuzzi fashion help articl propos metala meta learn architectur architectur studi typic process machin learn studi particular issu fuzzi model"
  },
  {
    "doc_id": "10066827",
    "abstract_original": "As 5G is deployed and applied, a large number of mobile devices have been increasingly deployed on the network. Scenarios such as smartphones, smart car, smart transportation, smart wearable devices, and smart industry are increasingly demanding for networks. And the Internet of Things (IoT), as a new and high technology, will play an important role and generate huge economic benefits. However, IoT security also faces many challenges due to the inherent security vulnerabilities in multiple device interactions and the data also needs more accurate processing. Big data and deep learning have been gradually applied in various industries. Therefore, we have summarized and analyzed the use of big data and deep learning technology to solve the hidden dangers of the IoT security under the consideration of some suggestions and thinking for industry applications.",
    "abstract_processed": "g deploy appli larg number mobil devic increasingli deploy network scenario smartphon smart car smart transport smart wearabl devic smart industri increasingli demand network internet thing iot new high technolog play import role gener huge econom benefit howev iot secur also face mani challeng due inher secur vulner multipl devic interact data also need accur process big data deep learn gradual appli variou industri therefor summar analyz use big data deep learn technolog solv hidden danger iot secur consider suggest think industri applic"
  },
  {
    "doc_id": "10067330",
    "abstract_original": "The artificial intelligence algorithm Generative Adversarial Networks (GAN) is excellent in creating works that simulate human output. As a result, many researchers have created impressive and satisfying art pieces such as images of non-existent people or expressive paintings. The Hijazi heritage is full of unique art forms, including the Rawashin that adorn Hijazi buildings. With the remarkable technical progress of recent years, it has become necessary to highlight this identity in a contemporary way. This work aims to exploit and explore the capabilities of artificial intelligence techniques and GAN networks in creating and producing innovative new shapes with regard to Rawashin (wooden windows). The aim is to integrate such shapes with Arabic lettering in order to produce unprecedented designs in terms of Hijazi buildings. This is done by training the machine using a dataset consisting of images of different building shapes containing Rawashin and some Arabic calligraphy using two types of GAN models. As a result, the model was able to learn and produce a new style of Rawashin.",
    "abstract_processed": "artifici intellig algorithm gener adversari network gan excel creat work simul human output result mani research creat impress satisfi art piec imag non exist peopl express paint hijazi heritag full uniqu art form includ rawashin adorn hijazi build remark technic progress recent year becom necessari highlight ident contemporari way work aim exploit explor capabl artifici intellig techniqu gan network creat produc innov new shape regard rawashin wooden window aim integr shape arab letter order produc unpreced design term hijazi build done train machin use dataset consist imag differ build shape contain rawashin arab calligraphi use two type gan model result model abl learn produc new style rawashin"
  },
  {
    "doc_id": "10069714",
    "abstract_original": "Robotic technologies have opened up hundreds of new limitless perspectives for educational reform. We have conducted research to study the impact and outcomes of Robotic teaching in systematic studies, experimental studies, and surveys. The conclusions of this study reveal that educational robots have an impact on children, teachers, and students. We looked into how robots affect children’s behavior, learning outcomes, perceptions, and human interactions. The learning efficacy of educational Robot teachers is determined by a variety of factors, including learning outcome, student behavior and mood during class sessions, student reaction, and student involvement during workshops/class participation/quizzes/Q&A sessions. The majority of the research articles we chose were experimental studies, and they all met their objectives, which included teaching mathematical problems, unit conversion problems, teaching English/secondary language, developing analytical, and computational skills, behavior, and attitude development, critical thinking, and improving communication skills.",
    "abstract_processed": "robot technolog open hundr new limitless perspect educ reform conduct research studi impact outcom robot teach systemat studi experiment studi survey conclus studi reveal educ robot impact children teacher student look robot affect children’ behavior learn outcom percept human interact learn efficaci educ robot teacher determin varieti factor includ learn outcom student behavior mood class session student reaction student involv workshop class particip quizz q session major research articl chose experiment studi met object includ teach mathemat problem unit convers problem teach english secondari languag develop analyt comput skill behavior attitud develop critic think improv commun skill"
  },
  {
    "doc_id": "10070941",
    "abstract_original": "Facing the growing complexity of Deep Neural Networks (DNNs), high-performance and power-efficient AI accelerators are desired to provide effective and affordable cloud inference services. We introduce our flagship product, i.e., the Cloudblazer i20 accelerator, which integrates the innovated Deep Thinking Unit (DTU 2.0). The design is driven by requests drawn from various AI inference applications and insights learned from our previous products. With careful tradeoffs in hardware-software co-design, Cloudblazer i20 delivers impressive performance and energy efficiency while maintaining acceptable hardware costs and software complexity/flexibility. To tackle computation- and data-intensive workloads, DTU 2.0 integrates powerful vector/matrix engines and a large-capacity multi-level memory hierarchy with high bandwidth. It supports comprehensive data flow and synchronization patterns to fully exploit parallelism in computation/memory access within or among concurrent tasks. Moreover, it enables sparse data compression/decompression, data broadcasting, repeated data transfer, and kernel code prefetching to optimize bandwidth utilization and reduce data access overheads. To utilize the underlying hardware and simplify the development of customized DNNs/operators, the software stack enables automatic optimizations (such as operator fusion and data flow tuning) and provides diverse programming interfaces for developers. Lastly, the energy consumption is optimized through dynamic power integrity and efficiency management, eliminating integrity risks and energy wastes. Based on the performance requirement, developers also can assign their workloads with the entire or partial hardware resources accordingly. Evaluated with 10 representative DNN models widely adopted in various domains, Cloudblazer i20 outperforms Nvidia T4 and A10 GPUs with a geometric mean of 2.22x and 1.16x in performance and 1.04x and 1.17x in energy efficiency, respectively. The improvements demonstrate the effectiveness of Cloudblazer i20’s design that emphasizes performance, efficiency, and flexibility.",
    "abstract_processed": "face grow complex deep neural network dnn high perform power effici ai acceler desir provid effect afford cloud infer servic introduc flagship product e cloudblaz acceler integr innov deep think unit dtu design driven request drawn variou ai infer applic insight learn previou product care tradeoff hardwar softwar co design cloudblaz deliv impress perform energi effici maintain accept hardwar cost softwar complex flexibl tackl comput data intens workload dtu integr power vector matrix engin larg capac multi level memori hierarchi high bandwidth support comprehens data flow synchron pattern fulli exploit parallel comput memori access within among concurr task moreov enabl spars data compress decompress data broadcast repeat data transfer kernel code prefetch optim bandwidth util reduc data access overhead util underli hardwar simplifi develop custom dnn oper softwar stack enabl automat optim oper fusion data flow tune provid divers program interfac develop lastli energi consumpt optim dynam power integr effici manag elimin integr risk energi wast base perform requir develop also assign workload entir partial hardwar resourc accordingli evalu repres dnn model wide adopt variou domain cloudblaz outperform nvidia gpu geometr mean x x perform x x energi effici respect improv demonstr effect cloudblaz ’s design emphas perform effici flexibl"
  },
  {
    "doc_id": "10070992",
    "abstract_original": "This paper first presents an input-stationary (IS) implemented crossbar accelerator (INCA), supporting inference and training for deep neural networks (DNNs). Processing-in-memory (PIM) accelerators for DNNs have been actively researched, specifically, with resistive random-access memory (RRAM), due to RRAM’s computing and memorizing capabilities and device merits. To the best of our knowledge, all previous PIM accelerators have saved weights into RRAMs and inputs (activations) into conventional memories—it naturally forms weight-stationary (WS) dataflow. WS has generally been considered the most optimized choice for high parallelism and data reuse. How-ever, WS-based PIM accelerators show fundamental limitations: first, remaining high dependency on DRAM and buffers for fetching and saving inputs (activations); second, a remarkable number of extra RRAMs for transposed weights and additional computational intermediates in training; third, coarse-grained arrays demanding high-bit analog-to-digital converters (ADCs) and introducing poor utilization in depthwise and pointwise convolution; last, degraded accuracy due to its sensitivity to weights which are affected by RRAM’s nonideality. On the other hand, we observe that IS dataflow, where RRAMs retain inputs (activations), can effectively address the limitations of WS, because of low dependency by only loading weights, no need for extra RRAMs, feasibility of fine-grained accelerator design, and less impact of input (activation) variance on accuracy. But IS dataflow is hardly achievable by the existing crossbar structure because it is difficult to implement kernel sliding and preserve the high parallelism. To support kernel movement, we constitute a cell structure with two-transistor-one-RRAM (2T1R). Based on the 2T1R cell, we design a novel three-dimensional (3D) architecture for high parallelism in batch training. Our experiment results prove the potential of INCA. Compared to the WS accelerator, INCA achieves up to 20.6× and 260× energy efficiency improvement in inference and training, respectively; 4.8× (inference) and 18.6× (training) speedup as well. While accuracy in WS drops to 15% in our high-noise simulation, INCA presents an even more robust result as 86% accuracy.",
    "abstract_processed": "paper first present input stationari implement crossbar acceler inca support infer train deep neural network dnn process memori pim acceler dnn activ research specif resist random access memori rram due rram’ comput memor capabl devic merit best knowledg previou pim acceler save weight rram input activ convent memories—it natur form weight stationari ws dataflow ws gener consid optim choic high parallel data reus ever ws base pim acceler show fundament limit first remain high depend dram buffer fetch save input activ second remark number extra rram transpos weight addit comput intermedi train third coars grain array demand high bit analog digit convert adc introduc poor util depthwis pointwis convolut last degrad accuraci due sensit weight affect rram’ nonid hand observ dataflow rram retain input activ effect address limit ws low depend load weight need extra rram feasibl fine grain acceler design less impact input activ varianc accuraci dataflow hardli achiev exist crossbar structur difficult implement kernel slide preserv high parallel support kernel movement constitut cell structur two transistor one rram r base r cell design novel three dimension architectur high parallel batch train experi result prove potenti inca compar ws acceler inca achiev × × energi effici improv infer train respect × infer × train speedup well accuraci ws drop high nois simul inca present even robust result accuraci"
  },
  {
    "doc_id": "10071224",
    "abstract_original": "With the increasing number of Internet applications and frequent network interactions, the resources in the Internet show explosive growth. Under the impact of this wave, methods based on large-scale data, such as deep learning, have been put forward, and scholars have begun to think about many classical tasks from a new perspective. The LDA model is used to mine the topic information in the texts in parallel corpora, and the polynomial distribution of thesaurus is used to represent the topic, so as to judge the proportion of each document topic in the document collection. The specific words are obtained according to the polynomial distribution of the corresponding thesaurus of the topic by probability sampling. The monolingual corpus of the target language is processed by maximum likelihood estimation method, and the parallel corpus is taken as the training target. The monolingual corpus of the target language is estimated by importance sampling and full probability formula, and a machine English translation model is established. The estimated expected value is obtained by beam search method, so that English sentence translation can be realized. When disambiguating 2000 groups of random phrases, the correct rate of word sense disambiguation was 79.9%, and the correct rate of structure disambiguation was 85.7%, which was 8.6% and 3.9% higher than the original system respectively.",
    "abstract_processed": "increas number internet applic frequent network interact resourc internet show explos growth impact wave method base larg scale data deep learn put forward scholar begun think mani classic task new perspect lda model use mine topic inform text parallel corpora polynomi distribut thesauru use repres topic judg proport document topic document collect specif word obtain accord polynomi distribut correspond thesauru topic probabl sampl monolingu corpu target languag process maximum likelihood estim method parallel corpu taken train target monolingu corpu target languag estim import sampl full probabl formula machin english translat model establish estim expect valu obtain beam search method english sentenc translat realiz disambigu group random phrase correct rate word sens disambigu correct rate structur disambigu higher origin system respect"
  },
  {
    "doc_id": "10074154",
    "abstract_original": "Software development techniques has been understood and give systematical model used to plan, design, test, implement, verification, validation and control the designing processes for developing an information-based system and satisfied the end-user’s requirements and needs. Human-centred software development, is a design methodology that provides a solution-based approach to solving user’s-oriented problems and fulfill the human-centredneeds and provides framework to provides results according to end-user’s requirements. In this paper we analyze the systematic literature reviews (Ss) and mapping studies and covering numerous primary research studies on different aspects of human centred software development(HCSD) exists. Software development has been turned focus from developed the application phase to user’s-oriented application and switched all the development scenario toward the human centred development. In this paper we review the different literature views papers on software development approaches in past and provide the comparative studies between those approaches and in final we provide the objective and proposed research overview.",
    "abstract_processed": "softwar develop techniqu understood give systemat model use plan design test implement verif valid control design process develop inform base system satisfi end user’ requir need human centr softwar develop design methodolog provid solut base approach solv user’ orient problem fulfil human centredne provid framework provid result accord end user’ requir paper analyz systemat literatur review ss map studi cover numer primari research studi differ aspect human centr softwar develop hcsd exist softwar develop turn focu develop applic phase user’ orient applic switch develop scenario toward human centr develop paper review differ literatur view paper softwar develop approach past provid compar studi approach final provid object propos research overview"
  },
  {
    "doc_id": "10074398",
    "abstract_original": "A form of artificial intelligence (AI) that is advanced and involves rules that are applied to data to simulate a person's thought process in a particular area, knowledge engineering can be described as an advanced form of artificial intelligence (AI). Knowledge engineering had evolved from its original form when it focused on transferring and analyzing knowledge from human problem-solvers into computer programs that could do the same. .It is essential to realize that transfer processing has limitations because humans make decisions differently than machines do. Non-linear thinking and analogous reasoning, often not logical, have not been considered in this case.It is becoming increasingly common today to use a modeling process for knowledge engineering, which creates a system that can reach the same conclusions as experts without following the same path or acquiring the same information from the same sources. In this paper, we aim to represent Knowledge engineering to transform knowledge into software that makes decisions similar to those made by human experts, such as financial advisors, whose decisions are based on their learning.Eventually, it is expected that human experts will be replaced by knowledge engineering in decision support software",
    "abstract_processed": "form artifici intellig ai advanc involv rule appli data simul person thought process particular area knowledg engin describ advanc form artifici intellig ai knowledg engin evolv origin form focus transfer analyz knowledg human problem solver comput program could essenti realiz transfer process limit human make decis differ machin non linear think analog reason often logic consid case becom increasingli common today use model process knowledg engin creat system reach conclus expert without follow path acquir inform sourc paper aim repres knowledg engin transform knowledg softwar make decis similar made human expert financi advisor whose decis base learn eventu expect human expert replac knowledg engin decis support softwar"
  },
  {
    "doc_id": "10074596",
    "abstract_original": "The purpose of this paper is to analyze the integration of information and communication technologies in the education sector and identify the most promising barriers that affect the efficient implementation of these technologies in the education sector.For this study, various research papers were analysed and a survey was conducted to identify the barriers that affect the integration of information and communication technologies in the education sector. Interpretive Structured Modeling (ISM) methodology has been used in this work to level up the barriers to identify which among the identified barriers is the most and the least significant.The findings reveal that Limited Awareness is the most significant barrier to the implementation of ICTs in the education sector along with other barriers which include Poor Infrastructure, Budget, Lack of Experience, Privacy, Lack of Communication, Resistance to Change, Restricted Training on New Software, Management Issues and Complex to Implement.",
    "abstract_processed": "purpos paper analyz integr inform commun technolog educ sector identifi promis barrier affect effici implement technolog educ sector studi variou research paper analys survey conduct identifi barrier affect integr inform commun technolog educ sector interpret structur model ism methodolog use work level barrier identifi among identifi barrier least signific find reveal limit awar signific barrier implement ict educ sector along barrier includ poor infrastructur budget lack experi privaci lack commun resist chang restrict train new softwar manag issu complex implement"
  },
  {
    "doc_id": "10075649",
    "abstract_original": "User interactions with visualization systems have been shown to encode a great deal of information about the the users’ thinking processes, and analyzing their interaction trails can teach us more about the users, their approach, and how they arrived at insights. This deeper understanding is critical to improving their experience and outcomes, and there are tools available to visualize logs of interactions. It can be difficult to determine the structurally interesting parts of interaction data, though, like what set of button clicks constitutes an action that matters. In the case of visual analytics systems that use machine learning models, there is a convenient marker of when the user has significantly altered the state of the system via interaction: when the model is updated based on new information. We present a method for numerical analytic provenance using high-dimensional visualization to show and compare the trails of these sequences of model states of the system. We evaluate this approach with a prototype tool, ModelSpace, applied to two case studies on experimental data from model-steering visual analytics tools. ModelSpace reveals individual user’s progress, the relationships between their paths, and the characteristics of certain regions of the space of possible models.",
    "abstract_processed": "user interact visual system shown encod great deal inform users’ think process analyz interact trail teach us user approach arriv insight deeper understand critic improv experi outcom tool avail visual log interact difficult determin structur interest part interact data though like set button click constitut action matter case visual analyt system use machin learn model conveni marker user significantli alter state system via interact model updat base new inform present method numer analyt proven use high dimension visual show compar trail sequenc model state system evalu approach prototyp tool modelspac appli two case studi experiment data model steer visual analyt tool modelspac reveal individu user’ progress relationship path characterist certain region space possibl model"
  },
  {
    "doc_id": "10075775",
    "abstract_original": "Current pandemic situation has a significant impact affecting human life not only socially and economically, but emotionally and psychologically as well. This impact can be easily observed on social media platforms. Along with the knowledge exchange related to Covid-19 pandemic on social media, there is an emotional trauma wave that can be felt by carefully analyzing the activities of this social media. Keeping this view in thought, we analyze around 12000 tweets of Indian people to find out whether there is a trend shift of thinking pattern and mindset of Indian people as the pandemic progresses. The study is bifurcated into stages to clearly see the paradigm shift. We use tweets since twitter is a rich medium that can be leveraged to its optimum to have a good amount of understanding of the sentiments of the people. Analyzing the twitter dataset, we derive results and find out whether the amount of negative tweets v/s positive (or motivational) tweets have increased or not as the pandemic progresses. The study is supported by graphical visualizations of the polarity of the tweets month wise. Further, Wordmap approach is used to perform qualitative mining analysis in addition to the sentiment score based calculation. This work helps us to understand how the public opinions are changing with the changes in the spread dynamics of the virus. This kind of mood mining helps in identifying the Covid-19 situation from the psychological perspective that whether there is a sense of fear among people or they are quite optimistic of the situation. It can help in a great extend to the strategic and decision making bodies to plan out for future decisions. Further, such kind of studies can be used as reference to provide insights about mental health of people for any future incident or event of such nature.",
    "abstract_processed": "current pandem situat signific impact affect human life social econom emot psycholog well impact easili observ social media platform along knowledg exchang relat covid pandem social media emot trauma wave felt care analyz activ social media keep view thought analyz around tweet indian peopl find whether trend shift think pattern mindset indian peopl pandem progress studi bifurc stage clearli see paradigm shift use tweet sinc twitter rich medium leverag optimum good amount understand sentiment peopl analyz twitter dataset deriv result find whether amount neg tweet v posit motiv tweet increas pandem progress studi support graphic visual polar tweet month wise wordmap approach use perform qualit mine analysi addit sentiment score base calcul work help us understand public opinion chang chang spread dynam viru kind mood mine help identifi covid situat psycholog perspect whether sens fear among peopl quit optimist situat help great extend strateg decis make bodi plan futur decis kind studi use refer provid insight mental health peopl futur incid event natur"
  },
  {
    "doc_id": "10076418",
    "abstract_original": "Disease detection/recognition with limited data sets and labels in the medical image domain is a very costly and greatest challenge. Although open image data sets have increased recently, researches on this problem still need to be developed. Researches to diversify data sets are both costly and face the problem of subjectivity. Unseen classes can be trained with the Zero-Shot Learning (ZSL) in order to overcome this problem. In this paper, we aimed to strengthen ZSL by using ontology as an auxiliary information for class embeddings. In our approach, ZSL is supported by the image embeddings and class embeddings of the multi-labelled ChestX-ray14 data set, as well as the semantic data from DBpedia. In this paper, which we believe will be pioneering in the medical image domain, the Cosine, Hamming and Euclidean distances were taken into account in order to maximize the similarities. We trained ResNet50 neural network with different parameters on the multi-labelled ChestX-ray14 data set. 23.25% precision value in one-to-one matching and 29.59% precision value in at least one matching were obtained. We think that this paper will make a significant contribution to the medical image domain by detecting/recognizing unseen disease images.",
    "abstract_processed": "diseas detect recognit limit data set label medic imag domain costli greatest challeng although open imag data set increas recent research problem still need develop research diversifi data set costli face problem subject unseen class train zero shot learn zsl order overcom problem paper aim strengthen zsl use ontolog auxiliari inform class embed approach zsl support imag embed class embed multi label chestx ray data set well semant data dbpedia paper believ pioneer medic imag domain cosin ham euclidean distanc taken account order maxim similar train resnet neural network differ paramet multi label chestx ray data set precis valu one one match precis valu least one match obtain think paper make signific contribut medic imag domain detect recogn unseen diseas imag"
  },
  {
    "doc_id": "10077006",
    "abstract_original": "This paper is inspired by the beauty of the mathematical optimisations, such as Euler's theory, and Rosenbrock's banana function. By seasoning with the idea of economic marginal theory, this research reveals the detailed characteristic of experiment data, makes a creative fusion as the luminance stimulation controlling colour model in creative computing, which has the potential usage for the future digital colour software, such as the connotation based human computer interaction and potentially able to adjust filmcolour automatically.",
    "abstract_processed": "paper inspir beauti mathemat optimis euler theori rosenbrock banana function season idea econom margin theori research reveal detail characterist experi data make creativ fusion lumin stimul control colour model creativ comput potenti usag futur digit colour softwar connot base human comput interact potenti abl adjust filmcolour automat"
  },
  {
    "doc_id": "10078050",
    "abstract_original": "The proclivity of today&#x2019;s technology to think like humans may be seen in new developing disciplines such as neural computing, fuzzy logic, evolutionary computation, machine learning, and probabilistic reasoning. These strategies are grouped together into one main technique known as &#x201C;soft computing.&#x201D; This book discusses the most recent soft computing and fuzzy logic-based applications and innovations in industrial advancements, supply chain and logistics, system optimization, decision-making, artificial intelligence, smart systems, and other rapidly evolving technologies. In today's competitive world, the book provides soft computing solutions to help companies overcome the obstacles posed by sophisticated decision-making systems.",
    "abstract_processed": "procliv today x technolog think like human may seen new develop disciplin neural comput fuzzi logic evolutionari comput machin learn probabilist reason strategi group togeth one main techniqu known x c soft comput x book discuss recent soft comput fuzzi logic base applic innov industri advanc suppli chain logist system optim decis make artifici intellig smart system rapidli evolv technolog today competit world book provid soft comput solut help compani overcom obstacl pose sophist decis make system"
  },
  {
    "doc_id": "10079806",
    "abstract_original": "Artificial Wisdom is advancement of Artificial Intelligence where wisdom should be recognized with the intelligence. It means the constructive behavior and values of humanity need to be the part of Artificial intelligence by incorporating wisdom. These can be demonstrates by simulating thought process and hence thinking ability of human beings is recognized as the consciousness. Currently researchers are working on thoughts and consciousness. These thoughts are coexisted with the particular mental factor. Abhidhamma model of ancient Indian literature are claimed 52 mental factors which are categorized in basic three classes such as Ethically Variable Factor, Unwholesome Factor and Beautiful Factor. Proposed model demonstrates the classification of the mental states. Dataset consists of 445 samples collected from various respondents by asking three questions. Preprocessing is performed by using the techniques of Natural language processing and Non-axiomatic logic. Convolutional Neural Network Machine learning technique applied to classify the mental factors. Performance of the proposed system is measured by applying statistical measures such as Accuracy, Precision, Specificity, Recall and F1-Score. Accuracy for small and large database is obtained as 86.92 percent and 93.02 percent respectively.",
    "abstract_processed": "artifici wisdom advanc artifici intellig wisdom recogn intellig mean construct behavior valu human need part artifici intellig incorpor wisdom demonstr simul thought process henc think abil human be recogn conscious current research work thought conscious thought coexist particular mental factor abhidhamma model ancient indian literatur claim mental factor categor basic three class ethic variabl factor unwholesom factor beauti factor propos model demonstr classif mental state dataset consist sampl collect variou respond ask three question preprocess perform use techniqu natur languag process non axiomat logic convolut neural network machin learn techniqu appli classifi mental factor perform propos system measur appli statist measur accuraci precis specif recal f score accuraci small larg databas obtain percent percent respect"
  },
  {
    "doc_id": "10079832",
    "abstract_original": "Sentiment analysis, otherwise called emotion AI, is the computational analysis of raw data that uses text to detect a person's sentiment. Opinions and feelings are communicated more frequently and extensively than ever before in the age of social media. The number of likes for social media opinions reveals which subjects are receiving the most attention, allowing companies and artists to better understand what their customers think of their products. As a result, the problem of picture or text sentiment categorization is of tremendous interest. Document level, phrase level, and aspect level sentiment analysis are the three ways for doing sentiment analysis. There are three major jobs at the aspect level. The most important and first objective is to recognise and extract question parts. The second goal is to identify the extremes of diverse points of view on various characteristics: positive, negative, and neutral. Next task is determined by compiling a list of terms that are similar to features. The goal of aspect-level sentiment analysis is to predict the sentiment polarity of each individual aspect term in a sentence, which is a notable challenge in natural language processing. Fine-grained sentiment analysis at the aspect level is a research hotspot.",
    "abstract_processed": "sentiment analysi otherwis call emot ai comput analysi raw data use text detect person sentiment opinion feel commun frequent extens ever age social media number like social media opinion reveal subject receiv attent allow compani artist better understand custom think product result problem pictur text sentiment categor tremend interest document level phrase level aspect level sentiment analysi three way sentiment analysi three major job aspect level import first object recognis extract question part second goal identifi extrem divers point view variou characterist posit neg neutral next task determin compil list term similar featur goal aspect level sentiment analysi predict sentiment polar individu aspect term sentenc notabl challeng natur languag process fine grain sentiment analysi aspect level research hotspot"
  },
  {
    "doc_id": "10083435",
    "abstract_original": "In this paper we summarize results of our internet survey which took place in Spring 2021 having over 3400 respondents and focused on adolescent sexting presence on the Instagram social network. We were interested in the frequency of this phenomena, awareness and general experience of adolescents with sexting and in general in Instagram social network security regarding adolescents. Results in terms of the danger of this phenomena are clear and demonstrable: a significant amount of the teenagers came across with it. The linkage and necessity of awareness in terms of secure behaviour on the internet and relevance with computational thinking is obvious but out of scope of this work.",
    "abstract_processed": "paper summar result internet survey took place spring respond focus adolesc sext presenc instagram social network interest frequenc phenomena awar gener experi adolesc sext gener instagram social network secur regard adolesc result term danger phenomena clear demonstr signific amount teenag came across linkag necess awar term secur behaviour internet relev comput think obviou scope work"
  },
  {
    "doc_id": "10083709",
    "abstract_original": "In this Hybrid K-Means Clustering for Grouping research work, the k-means methodology is a well-known process for grouping things together. Most of the time, this algorithm sorts the objects into a set number of clusters, but in this case, the user gives the number k. At first, it picks cluster centres at random and measures how far apart k points are. This kind of cluster centre is called k centroids, and it will keep changing until there are no more changes. When making applications that use machine intelligence, a machine should be able to think like a person and make the right choices. In this case, it's not possible to get k-points from the user. So, the Genetic Algorithm (GA) is used to search with heuristics to find the initial cluster centres. The goal of this research work is to look at how k-means clustering with GA can be used to optimise. The performance evaluation of hybrid k means method illustrates the precision and accuracy of the selected clustering methods. The result states that precision was 78.35% and its accuracy was 72.67% found while using the approach. The ROC curve analysis is performed with sensitivity and specificity data. The result states that the area under curve of the approach is 84.0%.",
    "abstract_processed": "hybrid k mean cluster group research work k mean methodolog well known process group thing togeth time algorithm sort object set number cluster case user give number k first pick cluster centr random measur far apart k point kind cluster centr call k centroid keep chang chang make applic use machin intellig machin abl think like person make right choic case possibl get k point user genet algorithm ga use search heurist find initi cluster centr goal research work look k mean cluster ga use optimis perform evalu hybrid k mean method illustr precis accuraci select cluster method result state precis accuraci found use approach roc curv analysi perform sensit specif data result state area curv approach"
  },
  {
    "doc_id": "10084967",
    "abstract_original": "In this era, Machine Learning is transforming human lives in a very different way. The need to give machines the power to make decisions or giving the moral compass is a big dilemma when humanity is more divided than it has ever been. There are two main ways in which law and AI interact. AI may be subject to legal restrictions and be employed in courtroom procedures. The world around us is being significantly and swiftly changed by AI in all of its manifestations. Public law includes important facets such as nondiscrimination law and labor law. In a manner similar to this when artificial intelligence (AI) is applied to tangible technology like robots. In certain cases, artificial intelligence (AI) might be hardly noticeable to customers but evident to those who built and are using it. The behavior research offers suggestions for how to build enduring and beneficial interactions between intelligent robots and people. The human improvement is main obstacles in the development and implementation of artificial intelligence. Best practices in this area are not governed by any one strategy that is generally acknowledged. Machine learning is about to revolutionize society as it is know it. It is crucial to give intelligent computers a moral compass now more than ever before because of how divided mankind is. Although machine learning has limitless potential, inappropriate usage might have detrimental long-term implications. It will think about how, for instance, earlier cultures built trust and improved social interactions via creative answers to many of the ethical issues that machine learning is posing now.",
    "abstract_processed": "era machin learn transform human live differ way need give machin power make decis give moral compass big dilemma human divid ever two main way law ai interact ai may subject legal restrict employ courtroom procedur world around us significantli swiftli chang ai manifest public law includ import facet nondiscrimin law labor law manner similar artifici intellig ai appli tangibl technolog like robot certain case artifici intellig ai might hardli notic custom evid built use behavior research offer suggest build endur benefici interact intellig robot peopl human improv main obstacl develop implement artifici intellig best practic area govern one strategi gener acknowledg machin learn revolution societi know crucial give intellig comput moral compass ever divid mankind although machin learn limitless potenti inappropri usag might detriment long term implic think instanc earlier cultur built trust improv social interact via creativ answer mani ethic issu machin learn pose"
  },
  {
    "doc_id": "10085124",
    "abstract_original": "With the world becoming more and more reliant on technology, we are transitioning from a society that values rational evaluation over intuitive thinking to one in which both of those methods coexist. AI devices rely solely on rational evaluation and machine learning allows us to focus on intuition. The task of intelligence is to deduce which method should be relied upon when solving various problems via the establishment of realistic judgments, according to what kind it identifies as being best for that particular problem. However, human judgments cannot simply be quantitatively compared and ranked by a computer according to conditions set by algorithms because certain difficult-to-measure criteria are not easily passable through algorithm systems such as ethics and common sense. In this research, the authors focus on developing judgment classification models using random forest and support vector machine. The authors attempt to test the effectiveness of sentiment proportions as features in judgment classification models.",
    "abstract_processed": "world becom reliant technolog transit societi valu ration evalu intuit think one method coexist ai devic reli sole ration evalu machin learn allow us focu intuit task intellig deduc method reli upon solv variou problem via establish realist judgment accord kind identifi best particular problem howev human judgment cannot simpli quantit compar rank comput accord condit set algorithm certain difficult measur criteria easili passabl algorithm system ethic common sens research author focu develop judgment classif model use random forest support vector machin author attempt test effect sentiment proport featur judgment classif model"
  },
  {
    "doc_id": "10086259",
    "abstract_original": "The outbreak of COVID-19 has impacted traditional teaching methods in schools, and blended teaching in the post-pandemic has gradually become a hot topic of research in higher education. Computational thinking, as one of the core literacies to be acquired in the 21st century, can help students realize the importance of computers as well as enable them to solve specific problems more effectively when facing real-life situations. The article takes the C language programming course as an example, analyzes the problems faced in teaching in the post-pandemic, introduces the concept of computational thinking and integrates it into all aspects of blended teaching design, pays attention to students' individual differences, and proposes a blended teaching model based on computational thinking and puts it into practice. The results show that this teaching model can improve students' learning performance, exercise students' computational thinking skills, and promote blended teaching reform and students' personalized development.",
    "abstract_processed": "outbreak covid impact tradit teach method school blend teach post pandem gradual becom hot topic research higher educ comput think one core literaci acquir st centuri help student realiz import comput well enabl solv specif problem effect face real life situat articl take c languag program cours exampl analyz problem face teach post pandem introduc concept comput think integr aspect blend teach design pay attent student individu differ propos blend teach model base comput think put practic result show teach model improv student learn perform exercis student comput think skill promot blend teach reform student person develop"
  },
  {
    "doc_id": "10089249",
    "abstract_original": "We live in a complex world where uncertainty is the only certainty. Today's compelling business problem is replaced tomorrow with a problem which was not even imagined yesterday. Data driven decision systems are used by managers in support of their strategic decisions and should be agile and flexibility to survive in our ever change world of complex decisions. The argument presented in this conceptual paper is that data vault modeling is inherently better equipped than dimensional modelling to handle the turbulations of our complex world. The paper investigates the underlying assumptions of dimensional modelling and data vault modelling in terms of requirements collection and the resulting data modelling techniques. It uses critical systems thinking as guiding philosophy to reflect on the benefits of understanding and modelling a variety of perspectives in a problem situation. Critical systems thinking also promotes equal opportunity and accountability. It is argued that both these aspirations can better be achieved by using dimensional modeling as alternative to dimensional modelling. We hope to promote the development of sustainable data driven decision systems which can stand the test of our turbulent times.",
    "abstract_processed": "live complex world uncertainti certainti today compel busi problem replac tomorrow problem even imagin yesterday data driven decis system use manag support strateg decis agil flexibl surviv ever chang world complex decis argument present conceptu paper data vault model inher better equip dimension model handl turbul complex world paper investig underli assumpt dimension model data vault model term requir collect result data model techniqu use critic system think guid philosophi reflect benefit understand model varieti perspect problem situat critic system think also promot equal opportun account argu aspir better achiev use dimension model altern dimension model hope promot develop sustain data driven decis system stand test turbul time"
  },
  {
    "doc_id": "10090213",
    "abstract_original": "Literature of studying algal growth has started to take advantages of data mining and machine learning methods, such as classification, clustering, regression, correlation analysis and principal component analysis. However, the performance of such methods might heavily rely on the data collectable for the studies sites. Moreover, some factors directly relate to algal growth, including hydrodynamics, weather and ecology, are notoriously difficult to model and predict. In this paper we present a study to model algal bloom using deep learning methods. It is assumed that algal bloom is the consequence of all factors that are more or less associated with the growth of algal. This offers a new way of thinking that even unknown factors or those factors far too complicated to model can still be inexplicitly represented by the deep learning models. We evaluate this new approach through our studies of algal bloom in the JinJi Lake, Suzhou, China. The experimental results are compared with the popular machine learning methods used in literature. It has been found that the deep learning method can achieve a better accuracy in comparison with other well applied machine learning methods.",
    "abstract_processed": "literatur studi algal growth start take advantag data mine machin learn method classif cluster regress correl analysi princip compon analysi howev perform method might heavili reli data collect studi site moreov factor directli relat algal growth includ hydrodynam weather ecolog notori difficult model predict paper present studi model algal bloom use deep learn method assum algal bloom consequ factor less associ growth algal offer new way think even unknown factor factor far complic model still inexplicitli repres deep learn model evalu new approach studi algal bloom jinji lake suzhou china experiment result compar popular machin learn method use literatur found deep learn method achiev better accuraci comparison well appli machin learn method"
  },
  {
    "doc_id": "10092318",
    "abstract_original": "This study presents the introduction of Arduino to undergraduate architecture students through a series of project-based exercises in two different universities. The main motivation of study is based on supporting students’ motivation, engagement, and creativity under remote education conditions in the context of digital fabrication. This research consolidates the digital fabrication pedagogy efficiency in the time of post COVID-19 using both distant and hybrid learning modes. Students have exerted a dedication effort and enjoyed digital craft especially while using Arduino despite the virtual teaching classes. Kinetic applications have received students' total endorsement and hands-on involvement supported with theoretical lectures focusing on fabrication techniques, materials and tools along with parametric algorithmic design. Assignments are both structured and semi-structured to promote their skills and grant them a free-flexible pedagogical approach.",
    "abstract_processed": "studi present introduct arduino undergradu architectur student seri project base exercis two differ univers main motiv studi base support students’ motiv engag creativ remot educ condit context digit fabric research consolid digit fabric pedagogi effici time post covid use distant hybrid learn mode student exert dedic effort enjoy digit craft especi use arduino despit virtual teach class kinet applic receiv student total endors hand involv support theoret lectur focus fabric techniqu materi tool along parametr algorithm design assign structur semi structur promot skill grant free flexibl pedagog approach"
  },
  {
    "doc_id": "10097489",
    "abstract_original": "Humans have rich experience applying linear models and logical thinking, but only experts understand the behaviour of non-linear systems. However, the deep neural network (DNN) implementation of text non-linear systems outperforms optimal linear models. Therefore, the forward DNN (the pattern recognition system in this paper) attracts attention to the necessity of interpreting the results obtained by DNN. To preserve the high performance of DNN, we focus on a post-hoc explanation; this approach means building an explainable model for the decision obtained by the black box. To avoid the interpretation of a set of millions of non-linear functions, we divide DNN into two parts: the feature extractor and the classifier. Following that, we argue for a specific interpretation of each of them. While for classifiers, we have several suitable explainable models (and we decided on the fuzzy logical function), we believe that feature interpretation is a creative scientific activity corresponding to the usual research. The paper presents a tool to help researchers and users understand extracted features not necessarily known in the specific application domain. Explaining the new features offers a way to learn from computers.",
    "abstract_processed": "human rich experi appli linear model logic think expert understand behaviour non linear system howev deep neural network dnn implement text non linear system outperform optim linear model therefor forward dnn pattern recognit system paper attract attent necess interpret result obtain dnn preserv high perform dnn focu post hoc explan approach mean build explain model decis obtain black box avoid interpret set million non linear function divid dnn two part featur extractor classifi follow argu specif interpret classifi sever suitabl explain model decid fuzzi logic function believ featur interpret creativ scientif activ correspond usual research paper present tool help research user understand extract featur necessarili known specif applic domain explain new featur offer way learn comput"
  },
  {
    "doc_id": "10097957",
    "abstract_original": "The requirement of explainability is gaining more and more importance in Artificial Intelligence applications based on Machine Learning techniques, especially in those contexts where critical decisions are entrusted to software systems (think, for example, of financial and medical consultancy). In this paper, we propose an Argumentation-based methodology for explaining the results predicted by Machine Learning models. Argumentation provides frameworks that can be used to represent and analyse logical relations between pieces of information, serving as a basis for constructing human tailored rational explanations to a given problem. In particular, we use extension-based semantics to find the rationale behind a class prediction.",
    "abstract_processed": "requir explain gain import artifici intellig applic base machin learn techniqu especi context critic decis entrust softwar system think exampl financi medic consult paper propos argument base methodolog explain result predict machin learn model argument provid framework use repres analys logic relat piec inform serv basi construct human tailor ration explan given problem particular use extens base semant find rational behind class predict"
  },
  {
    "doc_id": "10097999",
    "abstract_original": "Ethics should be a practice, not a checkbox. Data scientists want to answer questions about individuals and society using the vast torrent of data that flows around us. Machine learning practitioners want to develop and connect complex models of the world and use them safely in critical situations. Ethical issues can be seen as getting in the way of the core idea and form pain points around managing, using and learning from data, as well as designing human-centric and ethical systems. This is because there is a design gap around ethics in data science and machine learning: the tools that we use do not support ethical data use, which means that data scientists and machine learning practitioners, already engaged in technically complex, multidisciplinary work, must add another dimension to their thinking. This work proposes and outlines an infrastructure and framework that can support in-the-moment ethical decision making and recording, as well as post-hoc audits and ethical model deployment.",
    "abstract_processed": "ethic practic checkbox data scientist want answer question individu societi use vast torrent data flow around us machin learn practition want develop connect complex model world use safe critic situat ethic issu seen get way core idea form pain point around manag use learn data well design human centric ethic system design gap around ethic data scienc machin learn tool use support ethic data use mean data scientist machin learn practition alreadi engag technic complex multidisciplinari work must add anoth dimens think work propos outlin infrastructur framework support moment ethic decis make record well post hoc audit ethic model deploy"
  },
  {
    "doc_id": "10099179",
    "abstract_original": "This paper presents a systematic approach to using the Socratic method in developing prompt templates that effectively interact with large language models, including GPT-3. Various methods are examined, and those that yield precise answers and justifications while fostering creativity and imagination to enhance creative writing are identified. Techniques such as definition, elenchus, dialectic, maieutics, generalization, and counterfactual reasoning are discussed for their application in engineering prompt templates and their connections to inductive, deductive, and abductive reasoning. Through examples, the effectiveness of these dialogue and reasoning methods is demonstrated. An interesting observation is made that when the task's goal and user intent are conveyed to GPT-3 via ChatGPT before the start of a dialogue, the large language model seems to connect to the external context expressed in the intent and perform more effectively.",
    "abstract_processed": "paper present systemat approach use socrat method develop prompt templat effect interact larg languag model includ gpt variou method examin yield precis answer justif foster creativ imagin enhanc creativ write identifi techniqu definit elenchu dialect maieutic gener counterfactu reason discuss applic engin prompt templat connect induct deduct abduct reason exampl effect dialogu reason method demonstr interest observ made task goal user intent convey gpt via chatgpt start dialogu larg languag model seem connect extern context express intent perform effect"
  },
  {
    "doc_id": "10099445",
    "abstract_original": "Artificial general intelligence revived in recent years after people achieved significant advances in machine learning and deep learning. This leads to the thinking of how real intelligence could be created. Consciousness theories believe that general intelligence is essentially conscious, yet no universal definition is agreed upon. In this work, global workspace (GW) theory is implemented and integrated with crucial cognitive components. With the focus on episodic memory and inspiration from the nature of episodic memory in psychology and neuroscience, the episodic memory component is implemented within the GW framework. In our experiment, the robotic agent operates in a real-world interactive context, forming episodic memory and demonstrating static, temporal, and context memory capabilities during interactions. Consciousness in this work engages in all formation, maintenance, and retrieval processes of episodic memory. The novelty and contributions of this work are: 1) this work is implementing episodic memory within the consciousness framework, suggesting the sustainable potential of such an integrated approach to cognitive agents with artificial general intelligence (AGI); 2) regarding the limited examples in consciousness-based cognitive architectures, this work attempts to contribute to the diversity of perspectives and approaches; 3) extant episodic memory implementations are suffering from various limitations, while this work summarises some key features for modeling episodic memory within a cognitive architecture; and 4) authors discuss the relationship between episodic memory, consciousness, and general intelligence, proposing the compatibility and relationship between machine consciousness and other AGI research. It is believed that a better alignment between them would further boost the fusion of diverse research for achieving desired cognitive machines.",
    "abstract_processed": "artifici gener intellig reviv recent year peopl achiev signific advanc machin learn deep learn lead think real intellig could creat conscious theori believ gener intellig essenti consciou yet univers definit agre upon work global workspac gw theori implement integr crucial cognit compon focu episod memori inspir natur episod memori psycholog neurosci episod memori compon implement within gw framework experi robot agent oper real world interact context form episod memori demonstr static tempor context memori capabl interact conscious work engag format mainten retriev process episod memori novelti contribut work work implement episod memori within conscious framework suggest sustain potenti integr approach cognit agent artifici gener intellig agi regard limit exampl conscious base cognit architectur work attempt contribut divers perspect approach extant episod memori implement suffer variou limit work summaris key featur model episod memori within cognit architectur author discuss relationship episod memori conscious gener intellig propos compat relationship machin conscious agi research believ better align would boost fusion divers research achiev desir cognit machin"
  },
  {
    "doc_id": "10101670",
    "abstract_original": "The emergence of abstract sciences as a counterpart of classic concrete sciences is presented in this work. The framework of abstract sciences encompasses data, information, knowledge, and intelligence sciences from the bottom up. It is found that intelligence is the ultimate level of cognitive objects generated in human brains aggregated from data (sensory), information (cognition), and knowledge (comprehension). However, there is a lack of rigorous studies and coherent theories towards the theoretical framework of abstract sciences as the counterpart of classical concrete sciences. This paper explores the cognitive and mathematical models of abstract mental objects in the brain. The taxonomy and cognitive foundations of them are explored. A set of mathematical models of data, information, knowledge, and intelligence is formally created in intelligent mathematics. Based on the cognitive and mathematical models of the cognitive objects, formal properties and relationship of contemporary data, information, knowledge, and intelligence sciences are rigorously explained.",
    "abstract_processed": "emerg abstract scienc counterpart classic concret scienc present work framework abstract scienc encompass data inform knowledg intellig scienc bottom found intellig ultim level cognit object gener human brain aggreg data sensori inform cognit knowledg comprehens howev lack rigor studi coher theori toward theoret framework abstract scienc counterpart classic concret scienc paper explor cognit mathemat model abstract mental object brain taxonomi cognit foundat explor set mathemat model data inform knowledg intellig formal creat intellig mathemat base cognit mathemat model cognit object formal properti relationship contemporari data inform knowledg intellig scienc rigor explain"
  },
  {
    "doc_id": "10102868",
    "abstract_original": "This article presents a course that relates environmental education and the development of STEAM skills through the valorization of WEEE (Waste of Electrical and Electronic Equipment). As a didactic tool, the BEAM Robots are used, which are simple robots that can be built with elements extracted from WEEE. For the execution of the course, a four-phase curriculum design is developed: propaedeutics, assembly, Computational Thinking (CT), and WEEE. The course is built in a modular way and implemented virtually. The students were evaluated with pre and post-surveys, to investigate the impact of the course. In addition, evaluation activities were created that made it possible to follow the development of the students. In general, it can be concluded that the course had a positive impact on students' STEAM skills and knowledge, as well as an improvement in environmental awareness related to the creative reuse of WEEE.",
    "abstract_processed": "articl present cours relat environment educ develop steam skill valor weee wast electr electron equip didact tool beam robot use simpl robot built element extract weee execut cours four phase curriculum design develop propaedeut assembl comput think ct weee cours built modular way implement virtual student evalu pre post survey investig impact cours addit evalu activ creat made possibl follow develop student gener conclud cours posit impact student steam skill knowledg well improv environment awar relat creativ reus weee"
  },
  {
    "doc_id": "10104848",
    "abstract_original": "Artificial Intelligence is a booming technology and is applied in almost every domain of application. To design an intelligent system, a thorough understanding of complex AI Algorithm is required. The idea behind the AI Algorithm Simulator was born from the recognition that algorithms are a critical component of a person’s computational thinking and programming abilities. Despite their complexity, our AI Algorithm simulator seeks to make the subject more accessible and engaging for learners. The AI Algorithm Simulator is designed to be both interactive and visually appealing, providing learners with hands-on experience in implementing algorithms.",
    "abstract_processed": "artifici intellig boom technolog appli almost everi domain applic design intellig system thorough understand complex ai algorithm requir idea behind ai algorithm simul born recognit algorithm critic compon person’ comput think program abil despit complex ai algorithm simul seek make subject access engag learner ai algorithm simul design interact visual appeal provid learner hand experi implement algorithm"
  },
  {
    "doc_id": "10105236",
    "abstract_original": "ChatGPT has sparked both excitement and skepticism in education. To analyze its impact on teaching and learning it is crucial to understand how students perceive ChatGPT and assess its potential and challenges. Toward this, we conducted a two-stage study with senior students in a computer engineering program ( $n=56$ ). In the first stage, we asked the students to evaluate ChatGPT using their own words after they used it to complete one learning activity. The returned responses (3136 words) were analyzed by coding and theme building (36 codes and 15 themes). In the second stage, we used the derived codes and themes to create a 27-item questionnaire. The students responded to this questionnaire three weeks later after completing other activities with the help of ChatGPT. The results show that the students admire the capabilities of ChatGPT and find it interesting, motivating, and helpful for study and work. They find it easy to use and appreciate its human-like interface that provides well-structured responses and good explanations. However, many students feel that ChatGPT’s answers are not always accurate and most of them believe that it requires good background knowledge to work with since it does not replace human intelligence. So, most students think that ChatGPT needs to be improved but are optimistic that this will happen soon. When it comes to the negative impact of ChatGPT on learning, academic integrity, jobs, and life, the students are divided. We conclude that ChatGPT can and should be used for learning. However, students should be aware of its limitations. Educators should try using ChatGPT and guide students on effective prompting techniques and how to assess generated responses. The developers should improve their models to enhance the accuracy of given answers. The study provides insights into the capabilities and limitations of ChatGPT in education and informs future research and development.",
    "abstract_processed": "chatgpt spark excit skeptic educ analyz impact teach learn crucial understand student perceiv chatgpt assess potenti challeng toward conduct two stage studi senior student comput engin program n first stage ask student evalu chatgpt use word use complet one learn activ return respons word analyz code theme build code theme second stage use deriv code theme creat item questionnair student respond questionnair three week later complet activ help chatgpt result show student admir capabl chatgpt find interest motiv help studi work find easi use appreci human like interfac provid well structur respons good explan howev mani student feel chatgpt’ answer alway accur believ requir good background knowledg work sinc replac human intellig student think chatgpt need improv optimist happen soon come neg impact chatgpt learn academ integr job life student divid conclud chatgpt use learn howev student awar limit educ tri use chatgpt guid student effect prompt techniqu assess gener respons develop improv model enhanc accuraci given answer studi provid insight capabl limit chatgpt educ inform futur research develop"
  },
  {
    "doc_id": "10105336",
    "abstract_original": "The manual assessment of creativity by human raters is coupled with unavoidable subjectivity and often costs much time and human resources. To address these issues, this paper explores how to apply natural language processing (NLP) methods to the assessment of creativity. Using the Alternative Use Task (AUT), participants were encouraged to generate ideas as fast as possible for a fixed time. It was hypothesized that the similarity of ideas would decrease over time in the AUT, considering the design fixation and the limitation of working memory. In the first study, 12 university students completed the AUT in paper-pencil form and generated a total of 376 responses. We applied two NLP models, namely BERT (Bidirectional Encoder Representations from Transformers) and USE (Universal Sentence Encoder), to assess the similarity of responses between individuals. The results did not confirm our hypothesis. One prominent reason might be that the applied models represent millions of sentence structures that are over-ecological and too dissimilar to the sentence structures participants had used while finishing the AUT. Nevertheless, the results did show that BERT and USE could more accurately express the semantic information of responses pace with the Latent Semantic Analysis, a popular computer-aided model for AUT response assessment. In study 2, we proposed an algorithm to reanalyze the 376 responses in study 1 based on word embedding with crowdsourced responses. There were 1690 crowdsourced responses collected from 550 participants who completed an online version of the AUT. The results supported our hypothesis and showed that the similarity of responses increases as time passes. This indicates the proposed algorithm would alleviate the influence of sentence structure in AUT tasks. The differences between BERT, USE, and proposed algorithms are discussed in relation to the assessment of creativity, and the implications for future work are explored in-depth.",
    "abstract_processed": "manual assess creativ human rater coupl unavoid subject often cost much time human resourc address issu paper explor appli natur languag process nlp method assess creativ use altern use task aut particip encourag gener idea fast possibl fix time hypothes similar idea would decreas time aut consid design fixat limit work memori first studi univers student complet aut paper pencil form gener total respons appli two nlp model name bert bidirect encod represent transform use univers sentenc encod assess similar respons individu result confirm hypothesi one promin reason might appli model repres million sentenc structur ecolog dissimilar sentenc structur particip use finish aut nevertheless result show bert use could accur express semant inform respons pace latent semant analysi popular comput aid model aut respons assess studi propos algorithm reanalyz respons studi base word embed crowdsourc respons crowdsourc respons collect particip complet onlin version aut result support hypothesi show similar respons increas time pass indic propos algorithm would allevi influenc sentenc structur aut task differ bert use propos algorithm discuss relat assess creativ implic futur work explor depth"
  },
  {
    "doc_id": "10106116",
    "abstract_original": "The purpose of this article is to historize the definition of computer science, particularly the characteristic ambiguity of the discipline toward the computer. This ambiguity is foundational to computer science and has its roots in the response of university computer centers to the commercialization of computing in the mid-1950s. University computing experts developed an understanding of the activity of computing disentangled from the computer itself, a conceptual shift that went together with a parallel process of dematerialization of the notion of computer. These transformations were facilitated by the ascendance of a high modernist agenda in the sciences in the United States. University computing experts embraced the high modernist agenda and developed analogies across programs, notations, and a notion of the computer now understood as a model of computation. This immaterial conflation of notations, programs, and representations of the machine, would become one of the core tenets of computer science.",
    "abstract_processed": "purpos articl histor definit comput scienc particularli characterist ambigu disciplin toward comput ambigu foundat comput scienc root respons univers comput center commerci comput mid univers comput expert develop understand activ comput disentangl comput conceptu shift went togeth parallel process demateri notion comput transform facilit ascend high modernist agenda scienc unit state univers comput expert embrac high modernist agenda develop analog across program notat notion comput understood model comput immateri conflat notat program represent machin would becom one core tenet comput scienc"
  },
  {
    "doc_id": "10107843",
    "abstract_original": "Computational thinking, as one of the core literacies of the Chinese IT courses, is an important area of IT education in primary and secondary schools. This research aims to improve the level of computational thinking of high school students by using Minecraft as a tool for Python gamified programming teaching design and analyzing the effectiveness of 60 high school students’ improvement in algorithmic thinking, problem solving, creativity, critical thinking, and collaboration after the teaching practice. The research results show that gamified programming teaching can significantly improve high school students’ computational thinking, providing a new teaching approach and ideas for high school IT education and computational thinking development.",
    "abstract_processed": "comput think one core literaci chines cours import area educ primari secondari school research aim improv level comput think high school student use minecraft tool python gamifi program teach design analyz effect high school students’ improv algorithm think problem solv creativ critic think collabor teach practic research result show gamifi program teach significantli improv high school students’ comput think provid new teach approach idea high school educ comput think develop"
  },
  {
    "doc_id": "10107885",
    "abstract_original": "The assessment of computational thinking (CT) skills based on text-based programming is a necessary part of the implementation of CT education in higher education. However, the current research on CT assessment is mostly single-approach, which is not effective in accurately measuring numerous competencies of CT skills and has the disadvantage of assessment limitation. In order to solve the problem of assessment limitations, this paper defines the content of CT evaluation from the perspective of text-based programming and constructs a multidimensional test method. Different test schemes are selected according to the characteristics of CT skills, and assessment tools are developed by combining the question test, programming test and scale survey, and the assessment tools are used to evaluate and analyze learners' CT skills from qualitative and quantitative perspectives. The results show that the evaluation indicators and test questions designed on text-based programming are more consistent with the evaluation objectives. And the approach of evaluating CT skills from both qualitative and quantitative perspectives can reflect learners' CT skills more comprehensively and accurately.",
    "abstract_processed": "assess comput think ct skill base text base program necessari part implement ct educ higher educ howev current research ct assess mostli singl approach effect accur measur numer compet ct skill disadvantag assess limit order solv problem assess limit paper defin content ct evalu perspect text base program construct multidimension test method differ test scheme select accord characterist ct skill assess tool develop combin question test program test scale survey assess tool use evalu analyz learner ct skill qualit quantit perspect result show evalu indic test question design text base program consist evalu object approach evalu ct skill qualit quantit perspect reflect learner ct skill comprehens accur"
  },
  {
    "doc_id": "10109435",
    "abstract_original": "This unprecedented time of the COVID-19 outbreak challenged the status-quo whether it is on business operation, political leadership, scientific capability, engineering implementation, data analysis, and strategic thinking, in terms of resiliency, agility, and innovativeness. Due to some identified constraints, while addressing the issue of global health, human ingenuity has proven again that in times of crisis, it is our best asset. Constraints like limited testing capacity and lack of real-time information regarding the spread of the virus, are the highest priority in the mitigation process, aside from the development of vaccines and the pushing through of vaccination programs. Using the available Chest X-Ray Images dataset and an AI-Computer Vision Technique called Convolutional Neural Network, features of the images were extracted and classified as COVID-19 positive or not. This paper proposes the usage of the 18-layer Residual Neural Network (ResNet-18) as an architecture instead of other ResNet with a higher number of layers. The researcher achieves the highest validation accuracy of 99.26%. Moving forward, using this lower number of layers in training a model classifier, resolves the issue of device constraints such as storage capacity and computing resources while still assuring highly accurate outputs.",
    "abstract_processed": "unpreced time covid outbreak challeng statu quo whether busi oper polit leadership scientif capabl engin implement data analysi strateg think term resili agil innov due identifi constraint address issu global health human ingenu proven time crisi best asset constraint like limit test capac lack real time inform regard spread viru highest prioriti mitig process asid develop vaccin push vaccin program use avail chest x ray imag dataset ai comput vision techniqu call convolut neural network featur imag extract classifi covid posit paper propos usag layer residu neural network resnet architectur instead resnet higher number layer research achiev highest valid accuraci move forward use lower number layer train model classifi resolv issu devic constraint storag capac comput resourc still assur highli accur output"
  },
  {
    "doc_id": "10110199",
    "abstract_original": "Proper Pronunciation is essential for a successful career. In the present era, recruiters do not want mug pots or rote learners i.e one that scores well in the technical or the core area. The need of the hour demands a holistic personality which must include good communication skills, critical thinking, managerial skills & logical reasoning. In the present study, the researchers have studied the mother tongue influence (MTI) in the English language spoken by the regional speakers of the Kumaun region. In the present study, the researchers have observed that the students of Uttarakhand have high MTI (Mother Tongue Influence) which is noticeable in their communication. They face difficulty in articulation of certain consonant sounds like sh (ꭍ), v, w, etc. Words like sheep /ꭍi:p/ are mispronounced as seep /si:p/, career/kₔriₔ/ as carrier /kᵆriₔ/ (Kay-rier). Due to poor pronunciation, they face challenges not only in the recruitment process but also in survival in Multi-National Companies where the American / British accent is widely used. The researchers conducted a diagnostic test to identify the extent and frequency of flaws in the articulation of words. It was observed that the performance of the regional learners was poor and required improvement. They implemented a Pre-Defined Algorithm model for improving the performance of the regional students. It was followed by a post-implementation test which was conducted through the proposed model. The proposed model has a better outcome concerning reducing the MTI in general pronunciation of the English Language among Kumauoni speakers of Uttarakhand.",
    "abstract_processed": "proper pronunci essenti success career present era recruit want mug pot rote learner e one score well technic core area need hour demand holist person must includ good commun skill critic think manageri skill logic reason present studi research studi mother tongu influenc mti english languag spoken region speaker kumaun region present studi research observ student uttarakhand high mti mother tongu influenc notic commun face difficulti articul certain conson sound like sh ꭍ v w etc word like sheep ꭍi p mispronounc seep si p career kₔriₔ carrier kᵆriₔ kay rier due poor pronunci face challeng recruit process also surviv multi nation compani american british accent wide use research conduct diagnost test identifi extent frequenc flaw articul word observ perform region learner poor requir improv implement pre defin algorithm model improv perform region student follow post implement test conduct propos model propos model better outcom concern reduc mti gener pronunci english languag among kumauoni speaker uttarakhand"
  },
  {
    "doc_id": "10111198",
    "abstract_original": "In this paper, we create a learning path and curate projects that let students learn certain computational concepts in a consistent way that bridges story, conversation, visual programming, and text-based programming. Our approach is to provide young children with both visual and text-based programming materials that are directly associated with the computational logic in some selected children’s daily dialogues and stories. We demonstrate this combo-design idea with examples of roleplaying, Snap! program, and Python code. Our design pattern and examples could be adapted to other suitable children’s activities in different school settings on a variety of technology platforms.",
    "abstract_processed": "paper creat learn path curat project let student learn certain comput concept consist way bridg stori convers visual program text base program approach provid young children visual text base program materi directli associ comput logic select children’ daili dialogu stori demonstr combo design idea exampl roleplay snap program python code design pattern exampl could adapt suitabl children’ activ differ school set varieti technolog platform"
  },
  {
    "doc_id": "10111237",
    "abstract_original": "With the rapid development of science and technology over the world, programming education has shown as a trend in decades. Programming courses have been offered in primary education to promote students’ computational thinking skills. However, teaching and learning programming in primary schools involve different knowledge including complex mathematical concepts and programming syntax. Also, traditional teaching methods may not effectively cater for students’ individual needs and learning trajectories. Thus, learning difficulties are common among students. Teachers keep examining innovation on programming education to improve their teaching. This study investigated used a pretest-posttest method with two groups of grade five students in Macao, to compare the influence of two pedagogical strategies, flipped classroom and traditional teaching, in students’ learning achievements. The major findings of the study showed that the experimental group in flipped classroom had significantly higher learning achievements than the control group in the programming course. Moreover, the students in the flipped classroom showed a significant effective mastery of more complex programming concepts, such as conditions and loops.",
    "abstract_processed": "rapid develop scienc technolog world program educ shown trend decad program cours offer primari educ promot students’ comput think skill howev teach learn program primari school involv differ knowledg includ complex mathemat concept program syntax also tradit teach method may effect cater students’ individu need learn trajectori thu learn difficulti common among student teacher keep examin innov program educ improv teach studi investig use pretest posttest method two group grade five student macao compar influenc two pedagog strategi flip classroom tradit teach students’ learn achiev major find studi show experiment group flip classroom significantli higher learn achiev control group program cours moreov student flip classroom show signific effect masteri complex program concept condit loop"
  },
  {
    "doc_id": "1011207",
    "abstract_original": "In previous papers, the Fourier transform (FT) has been generalized into the fractional Fourier transform (FRFT), the linear canonical transform (LCT), and the simplified fractional Fourier transform (SFRFT). Because the cosine, sine, and Hartley transforms are very similar to the FT, it is reasonable to think they can also be generalized by the similar way. We introduce several new transforms. They are all the generalization of the cosine, sine, or Hartley transform. We first derive the fractional cosine, sine, and Hartley transforms (FRCT/FRST/FRHT). They are analogous to the FRFT. Then, we derive the canonical cosine and sine transforms (CCT/CST). They are analogous to the LCT. We also derive the simplified fractional cosine, sine, and Hartley transforms (SFRCT/SFRST/SFRHT). They are analogous to the SFRFT and have the advantage of real-input-real-output. We also discuss the properties, digital implementation, and applications (e.g., the applications for filter design and space-variant pattern recognition) of these transforms. The transforms introduced in this paper are very efficient for digital implementation. We can just use one half or one fourth of the real multiplications required for the FRFT and LCT to implement them. When we want to process even, odd, or pure real/imaginary functions, we can use these transforms instead of the FRFT and LCT. Besides, we also show that the FRCT/FRST, CCT/CST, and SFRCT/SFRST are also useful for the one-sided (t /spl isin/ [0, /spl infin/]) signal processing.",
    "abstract_processed": "previou paper fourier transform ft gener fraction fourier transform frft linear canon transform lct simplifi fraction fourier transform sfrft cosin sine hartley transform similar ft reason think also gener similar way introduc sever new transform gener cosin sine hartley transform first deriv fraction cosin sine hartley transform frct frst frht analog frft deriv canon cosin sine transform cct cst analog lct also deriv simplifi fraction cosin sine hartley transform sfrct sfrst sfrht analog sfrft advantag real input real output also discuss properti digit implement applic e g applic filter design space variant pattern recognit transform transform introduc paper effici digit implement use one half one fourth real multipl requir frft lct implement want process even odd pure real imaginari function use transform instead frft lct besid also show frct frst cct cst sfrct sfrst also use one side spl isin spl infin signal process"
  },
  {
    "doc_id": "10112083",
    "abstract_original": "The healthcare industry generates vast amounts of data that are crucial for improving patient outcomes and advancing medical research. However, traditional on premise solutions for data storage and analysis can become inadequate to handle the increasing volume, variety and velocity of healthcare data. The study aims to investigate the potential benefits and challenges of using cloud-based solutions for data analytics in healthcare. This paper reports about latest development and detailed role of using Artificial intelligence and capabilities of cloud Computing in health care sector/industry to foster innovative thinking, optimum wellbeing of the patient, focused medicinal support. This paper discusses various applications, algorithms and future of big data analytics with a focus on architecture, application and applicability of big data analytics using Hadoop and Cloud Computing in healthcare industry such as monitoring, prediction, performance, management etc including intensive care unit. many cloud platforms, like MMAP, are working in this field to provide a fast, reliable cost effective, efficient, and patient centric and solution to community health issues with capability of forecasting the health impact of various diseases on community for a given region or nation. Cloud computing framework, along with Artificial intelligence and Hadoop, aids healthcare management in completing analytical computations to identify logical, pertinent, and factual trends essential to strategize and enhanced readiness in event of catastrophes by facilitating data exchange among all stake holders.",
    "abstract_processed": "healthcar industri gener vast amount data crucial improv patient outcom advanc medic research howev tradit premis solut data storag analysi becom inadequ handl increas volum varieti veloc healthcar data studi aim investig potenti benefit challeng use cloud base solut data analyt healthcar paper report latest develop detail role use artifici intellig capabl cloud comput health care sector industri foster innov think optimum wellb patient focus medicin support paper discuss variou applic algorithm futur big data analyt focu architectur applic applic big data analyt use hadoop cloud comput healthcar industri monitor predict perform manag etc includ intens care unit mani cloud platform like mmap work field provid fast reliabl cost effect effici patient centric solut commun health issu capabl forecast health impact variou diseas commun given region nation cloud comput framework along artifici intellig hadoop aid healthcar manag complet analyt comput identifi logic pertin factual trend essenti strateg enhanc readi event catastroph facilit data exchang among stake holder"
  },
  {
    "doc_id": "10112848",
    "abstract_original": "A daily commitment to our health and exercise routines helps us to become more energized and effective in our lives. But merely having the intention won't ever be sufficient to get to point of the aim. Health and fitness routine is always a mandatory segment of life, which helps us to become more productive and energetic in our day to day life. But that intention alone can never be enough to achieve the destination. In our project, we're creating a novel tool that can assist people in ensuring their general health, simply by collecting their food data and making dietary recommendations for doing the exercises to reach their objectives. By consulting a nutritionist, anybody could possibly get the guidance to reach their objective of getting healthier and stronger. Our model which has the aim to solve the daily life style problems caused by the unselective foods. Every sports person and the people in health and fitness area are aware of their foods by the consultation of nutritionist. But in the rapid moving times, normal people in day to day life, don't have the needed time and space to meet the nutritionist every time. Our model which tries to replace the space of the nutritionist by giving consultation and addressing the nutritional values of foods to the end users",
    "abstract_processed": "daili commit health exercis routin help us becom energ effect live mere intent ever suffici get point aim health fit routin alway mandatori segment life help us becom product energet day day life intent alon never enough achiev destin project creat novel tool assist peopl ensur gener health simpli collect food data make dietari recommend exercis reach object consult nutritionist anybodi could possibl get guidanc reach object get healthier stronger model aim solv daili life style problem caus unselect food everi sport person peopl health fit area awar food consult nutritionist rapid move time normal peopl day day life need time space meet nutritionist everi time model tri replac space nutritionist give consult address nutrit valu food end user"
  },
  {
    "doc_id": "10113096",
    "abstract_original": "Augmented Reality (AR), a unique method of integrating the virtual world into the real world, has the potential to increase academic attainment in the classroom. This research work focuses on developing and evaluating a strategy for enhancing student education with AR in the classroom. AR enables unique human-computer interactions in real time between the physical and digital worlds. The effectiveness of AR in the classroom will depend on its development, deployment, and integration into both standard and nontraditional teaching environments. Throughout the creation and implementation of an AR classroom, collaborative learning practices and other methodologies were taken into account. Collaboration occurs when two or more individuals work together, share information, and gain insights from one another. This research offers a succinct summary of the promise and challenges of adopting AR to transform the classroom.",
    "abstract_processed": "augment realiti ar uniqu method integr virtual world real world potenti increas academ attain classroom research work focus develop evalu strategi enhanc student educ ar classroom ar enabl uniqu human comput interact real time physic digit world effect ar classroom depend develop deploy integr standard nontradit teach environ throughout creation implement ar classroom collabor learn practic methodolog taken account collabor occur two individu work togeth share inform gain insight one anoth research offer succinct summari promis challeng adopt ar transform classroom"
  },
  {
    "doc_id": "10118041",
    "abstract_original": "The accessibility of fawning and observational information over the NASA database has made a wide extend of exercises conceivable, counting the distinguishing proof of planets and the forecast of their directions for the elucidation and improvement of machine learning models. We require photographs with higher picture quality for ideal representation. Pictures of a geological range so grant the watcher a establishment for understanding how characteristics can alter both spatially and transiently. The required data almost the target regularly impacts the imaging innovation determination. Conventional imaging strategies regularly make utilize of well characterized signals, such as enthusiastic impartial molecules or photons with a restricted range run. In any case, a number of viable imaging strategies have been made for analyzing different planetary and space situations utilizing long-wavelength electromagnetic radio waves. The categorization and show of planets employing a consecutive demonstrate are hence finished in this think about exertion with the help of the dataset, which is vital for investigate purposes. Profound learning and machine learning methods are utilized to achieve this. The proposed sequential model offers the highest degree of precision for further investigations.",
    "abstract_processed": "access fawn observ inform nasa databas made wide extend exercis conceiv count distinguish proof planet forecast direct elucid improv machin learn model requir photograph higher pictur qualiti ideal represent pictur geolog rang grant watcher establish understand characterist alter spatial transient requir data almost target regularli impact imag innov determin convent imag strategi regularli make util well character signal enthusiast imparti molecul photon restrict rang run case number viabl imag strategi made analyz differ planetari space situat util long wavelength electromagnet radio wave categor show planet employ consecut demonstr henc finish think exert help dataset vital investig purpos profound learn machin learn method util achiev propos sequenti model offer highest degre precis investig"
  },
  {
    "doc_id": "10118630",
    "abstract_original": "The role of computers is indispensable in various aspects of life, especially in the Production Monitoring information system which increases work productivity. PT Citra Banjar Abadi is a company that produces iron and steel electric towers for the needs of making High Voltage Power Line Towers, where this research takes place. The problem that occurs at this time is that the steel production monitoring information system is not optimal because it still uses a manual system so that there are often problems, one of which is the problem of production progress that cannot be monitored properly so that the completion of production is not on time. The purpose of this study is to provide solutions to problems that occur using the FAST (Framework Analytical System Thinking) method. The result of this research is to produce a steel production monitoring information system for the Tower Extra High Voltage Power Line for PT Citra Banjar Abadi, Indonesia.",
    "abstract_processed": "role comput indispens variou aspect life especi product monitor inform system increas work product pt citra banjar abadi compani produc iron steel electr tower need make high voltag power line tower research take place problem occur time steel product monitor inform system optim still use manual system often problem one problem product progress cannot monitor properli complet product time purpos studi provid solut problem occur use fast framework analyt system think method result research produc steel product monitor inform system tower extra high voltag power line pt citra banjar abadi indonesia"
  },
  {
    "doc_id": "10121868",
    "abstract_original": "Recent years have seen rapid gaming development. As development speeds up, game complexity rises. Software engineers are using agile methodologies to enhance output. In this paper, a meta-model-based computer gaming model is shown. The meta-model was created for design reusability, with the purpose of building codes that automatically make implementations in a well-defined manner by constructing the sections individually and independently for implementation. Early game makers had little industry or resources. Space-time game modeling aids in computer game creation describes related topics and provides a game metamodel. Hand-coded parts and regulations make it harder to adapt to different game areas. MDD is an innovative software development method. Some people think drawing is enough to build a model. Diagrams are also needed. Models must have a well-defined, abstract syntax-illustrative structure consistent with met models. Building a space-time model for games allows for model language research. Meta models and OCL can close the design-implementation gap. The code structure facilitates sorting and querying models.",
    "abstract_processed": "recent year seen rapid game develop develop speed game complex rise softwar engin use agil methodolog enhanc output paper meta model base comput game model shown meta model creat design reusabl purpos build code automat make implement well defin manner construct section individu independ implement earli game maker littl industri resourc space time game model aid comput game creation describ relat topic provid game metamodel hand code part regul make harder adapt differ game area mdd innov softwar develop method peopl think draw enough build model diagram also need model must well defin abstract syntax illustr structur consist met model build space time model game allow model languag research meta model ocl close design implement gap code structur facilit sort queri model"
  },
  {
    "doc_id": "10124008",
    "abstract_original": "This study analyzes 15,453 math topic-based Scratch projects of the online Scratch community to find the relations among K–12 math topics, usage of 13 programming elements, and project popularity. Among the six math topics, only statistics and calculus significantly contribute to projecting popularity. In addition, noncore programming elements, including sound and look, are widely adapted across various math topics and contribute significantly to project popularity. Although some studies discussed the integration of computation thinking (CT) and math in the classrooms, scant research focuses on the effect of math topics on CT element adoption for achieving better integration in the creative learning context. Moreover, few studies involve a large sample size for generalizable findings.",
    "abstract_processed": "studi analyz math topic base scratch project onlin scratch commun find relat among k– math topic usag program element project popular among six math topic statist calculu significantli contribut project popular addit noncor program element includ sound look wide adapt across variou math topic contribut significantli project popular although studi discuss integr comput think ct math classroom scant research focus effect math topic ct element adopt achiev better integr creativ learn context moreov studi involv larg sampl size generaliz find"
  },
  {
    "doc_id": "10125117",
    "abstract_original": "Recent trends in Science, Technology, Engineering, and Mathematics (STEM) education are focused on developing problem-solving skills and computational thinking and empowering students with the STEM discipline's knowledge to solve real-world problems. STEM incorporates an interdisciplinary approach that includes inquiry, analysis, critical thinking, practical experimentation, and cooperative problem-solving. Technological advancements are offering new ways to integrate new tools such as drones, robotics and gaming in teaching and learning practices and modify the pedagogical approaches that are more appealing and engaging. This paper presents an innovative pedagogical approach and practice that integrate drone technology and block-based programming to foster students' computation thinking in a STEM context. The block-based visual programming languages provide an interactive environment to connect the blocks and write programs. The study was conducted in six Australian schools. Students were assigned projects to automate drones using the DroneBlocks app and make programs to fly the drone in different geometrical patterns; straight line, arch, rectangle, triangles and zig-zag and integrate the various manoeuvres; bounce, 8D flips, and throw & go along flight paths. Students' computational thinking development was examined with an emphasis on their performance in formulating and problem-solving. Results have shown that integrated drone and programming pedagogy contributed significantly to students' learning of developing computational thinking for problem-solving and decomposing a problem into smaller parts in a sequence that includes mathematical algorithms to write programs.",
    "abstract_processed": "recent trend scienc technolog engin mathemat stem educ focus develop problem solv skill comput think empow student stem disciplin knowledg solv real world problem stem incorpor interdisciplinari approach includ inquiri analysi critic think practic experiment cooper problem solv technolog advanc offer new way integr new tool drone robot game teach learn practic modifi pedagog approach appeal engag paper present innov pedagog approach practic integr drone technolog block base program foster student comput think stem context block base visual program languag provid interact environ connect block write program studi conduct six australian school student assign project autom drone use droneblock app make program fli drone differ geometr pattern straight line arch rectangl triangl zig zag integr variou manoeuvr bounc flip throw go along flight path student comput think develop examin emphasi perform formul problem solv result shown integr drone program pedagogi contribut significantli student learn develop comput think problem solv decompos problem smaller part sequenc includ mathemat algorithm write program"
  },
  {
    "doc_id": "10125266",
    "abstract_original": "Quantum mechanics is a revolutionary scientific field, which lies at the crossroad section of Physics, Mathematics, Computer and Computational Science. In essence, it is considered a cross-disciplinary STEM field, advancing the philosophy of Quantum Literacy (QL), which addresses the transdisciplinary nature of real world complex problems. QL addresses the challenges of learning and skills acquisition, through specific computing activities, within a highly bounded discipline and of access to the kind of powerful knowledge that should be more accessible to a wide group of learners. It is therefore important that quantum computing and quantum technologies knowledge is accessible to students and teachers who work with real problems, in a more inclusive and interactive way. In this paper, we argue for the necessity of exposing students to new and powerful quantum tools, as provided by cutting edge quantum computing technologies. We do that by proposing contemporary and STEM related activities and gamification scenarios, in which they acquire stronger mathematical and computational - problem decomposition and modelling skills, working as real researchers. By engaging students in games and activities related to quantum computing and quantum information processing, they acquire all necessary knowledge related to: superposition, teleportation, entanglement, quantum gates and quantum information. The serious games proposed in this paper relates to quantum strategic games, necessary for STEM activities to train students within the computational thinking 2.0 framework. All scenarios were implemented using the didactic model of inquiry-based learning using Python libraries.",
    "abstract_processed": "quantum mechan revolutionari scientif field lie crossroad section physic mathemat comput comput scienc essenc consid cross disciplinari stem field advanc philosophi quantum literaci ql address transdisciplinari natur real world complex problem ql address challeng learn skill acquisit specif comput activ within highli bound disciplin access kind power knowledg access wide group learner therefor import quantum comput quantum technolog knowledg access student teacher work real problem inclus interact way paper argu necess expos student new power quantum tool provid cut edg quantum comput technolog propos contemporari stem relat activ gamif scenario acquir stronger mathemat comput problem decomposit model skill work real research engag student game activ relat quantum comput quantum inform process acquir necessari knowledg relat superposit teleport entangl quantum gate quantum inform seriou game propos paper relat quantum strateg game necessari stem activ train student within comput think framework scenario implement use didact model inquiri base learn use python librari"
  },
  {
    "doc_id": "10127288",
    "abstract_original": "Problem based learning has been adapted by various universities and inscribed with perspectives based on the demographic challenges. The method known to be effective for producing lifelong learners and improve cognitive skills, has been experimented on several facades. Problems, being major drivers in the process, have been researched to design and the deliberate the most effective ways. Through this paper we propose a game based learning model which can be used as problems in a problem based learning framework. In contrast to learning activities supplied using more old-fashioned didactic methodologies, this strategy can be used to engage a student through meaningful activities. This paper presents a model to use game in problem based learning followed by a case study and its analysis. Giglane game was used in the process to analyze the effectiveness with respect to number of stakeholders and incidents reported. The method is validated for effectiveness and promises to be an effective strategy for reflections and self-directed learning attributes. The method directly supports the decomposition structure from the computational thinking methodology which can be combined with the problem based learning process.",
    "abstract_processed": "problem base learn adapt variou univers inscrib perspect base demograph challeng method known effect produc lifelong learner improv cognit skill experi sever facad problem major driver process research design deliber effect way paper propos game base learn model use problem problem base learn framework contrast learn activ suppli use old fashion didact methodolog strategi use engag student meaning activ paper present model use game problem base learn follow case studi analysi giglan game use process analyz effect respect number stakehold incid report method valid effect promis effect strategi reflect self direct learn attribut method directli support decomposit structur comput think methodolog combin problem base learn process"
  },
  {
    "doc_id": "10127310",
    "abstract_original": "The paradigm of education has undergone a significant transition from traditional teacher-directed instruction to student-centered problem-based learning. In various contexts, problem-based learning, computational thinking, and metaphor-based learning approaches have been used to deliver an efficacious learning of the concept. This paper puts forward a model and its usage to build metaphor based case studies directing towards cognitive thinking, self-directed learning and lifelong learning. The model directly influences on the problem solving thought process. The paper further presents a case study on application of this model and its effectiveness validated through the embedded design method. The method appears to be effective in from model analysis and feedback collected. This directly connects to the pattern recognition paradigm of the computational thinking process.",
    "abstract_processed": "paradigm educ undergon signific transit tradit teacher direct instruct student center problem base learn variou context problem base learn comput think metaphor base learn approach use deliv efficaci learn concept paper put forward model usag build metaphor base case studi direct toward cognit think self direct learn lifelong learn model directli influenc problem solv thought process paper present case studi applic model effect valid embed design method method appear effect model analysi feedback collect directli connect pattern recognit paradigm comput think process"
  },
  {
    "doc_id": "10127438",
    "abstract_original": "A problem based learning pedagogy has paved its pathway into teaching and learning standing as one of the effective contributors in the teaching and learning process. With the varying institutional philosophies, the methodology has ample scope for improvements when it comes to its design and delivery. This paper proposes a method of using abstraction from computational thinking to construct knowledge in problem based learning process. Arriving at principles is one of the major objectives of learning process and also contributes towards the self-directed learning. A paper piece activity with shapes and sizes is designed to create free and themed scenarios and further analyzed with various attributes and its contribution towards the knowledge construction process. The paper presents a model and discusses the various perspectives of the activity. The method is found to be an effective approach to design problems that contribute to holistic learning. Knowledge construction process can aid into an effective learning method.",
    "abstract_processed": "problem base learn pedagogi pave pathway teach learn stand one effect contributor teach learn process vari institut philosophi methodolog ampl scope improv come design deliveri paper propos method use abstract comput think construct knowledg problem base learn process arriv principl one major object learn process also contribut toward self direct learn paper piec activ shape size design creat free theme scenario analyz variou attribut contribut toward knowledg construct process paper present model discuss variou perspect activ method found effect approach design problem contribut holist learn knowledg construct process aid effect learn method"
  },
  {
    "doc_id": "10127710",
    "abstract_original": "Technology has an important role in predicting a person's possible risk of chronic disease with the emergence of various kinds of research in the field of medical informatics, especially those related to the four chronic diseases that cause death in Indonesia, such as heart disease, stroke, cancer, and diabetes. Delays in medical treatment due to not predicting the disease can lead to other serious complications in the future. Therefore, doctors must think and work harder to assess patients early with factors influencing chronic disease risk. Many studies have carried out disease prediction focused only on one to two disease predictions. Still, research related to risk prediction for four diseases simultaneously has not been carried out in health and medical services. This study makes a risk prediction model for patients suffering from one or four chronic diseases, which goes through several stages in data mining from medical record data and assessments. We used 29 variables from two combination data sources, calculated using the C4.5 algorithm to predict the patient's risk for the disease. Based on the accuracy test results, the chronic disease prediction model has an accuracy value of 84%.This shows that the resulting model has good decision-making and high accuracy. For further research, other parameters can be used to predict disease, such as dietary habits in a certain period.",
    "abstract_processed": "technolog import role predict person possibl risk chronic diseas emerg variou kind research field medic informat especi relat four chronic diseas caus death indonesia heart diseas stroke cancer diabet delay medic treatment due predict diseas lead seriou complic futur therefor doctor must think work harder assess patient earli factor influenc chronic diseas risk mani studi carri diseas predict focus one two diseas predict still research relat risk predict four diseas simultan carri health medic servic studi make risk predict model patient suffer one four chronic diseas goe sever stage data mine medic record data assess use variabl two combin data sourc calcul use c algorithm predict patient risk diseas base accuraci test result chronic diseas predict model accuraci valu show result model good decis make high accuraci research paramet use predict diseas dietari habit certain period"
  },
  {
    "doc_id": "10130181",
    "abstract_original": "This work reports an innovative product-based pedagogy that was developed by incorporating entrepreneurial education into the upper-level undergraduate and graduate courses in the Electrical Engineering department at the University of Texas (UT) at Tyler. Several aspects make this work different from existing research. We adopted an iterative challenge-based STAR cycle and investigated the effectiveness of computational thinking in our course projects. In addition, entrepreneurial components were incorporated into a series of senior and graduate-level courses with the goal of creating student entrepreneurs. The entrepreneurship-focused curriculum encouraged students to participate in regional pitch competitions and conference presentations. The findings from this work suggest a positive impact of entrepreneurial learning on student learning outcomes.",
    "abstract_processed": "work report innov product base pedagogi develop incorpor entrepreneuri educ upper level undergradu graduat cours electr engin depart univers texa ut tyler sever aspect make work differ exist research adopt iter challeng base star cycl investig effect comput think cours project addit entrepreneuri compon incorpor seri senior graduat level cours goal creat student entrepreneur entrepreneurship focus curriculum encourag student particip region pitch competit confer present find work suggest posit impact entrepreneuri learn student learn outcom"
  },
  {
    "doc_id": "10131683",
    "abstract_original": "This research paper critically analyzes whether current business curriculum and teaching methods address the integration of emerging technologies. It examines the challenges and opportunities educational institutions face in incorporating technology into the business curriculum. The paper identifies the new skill sets required by industries due to rapid technological changes and highlights the existing gap. It concludes by outlining the challenges and opportunities for bridging the gap between industry needs and educational offerings. The paper is based on secondary data and establishes a conceptual foundation for future primary research.",
    "abstract_processed": "research paper critic analyz whether current busi curriculum teach method address integr emerg technolog examin challeng opportun educ institut face incorpor technolog busi curriculum paper identifi new skill set requir industri due rapid technolog chang highlight exist gap conclud outlin challeng opportun bridg gap industri need educ offer paper base secondari data establish conceptu foundat futur primari research"
  },
  {
    "doc_id": "10131704",
    "abstract_original": "An effective prediction of orthodontics treatment outcome is highly essential for further scheme of clinical treatment for the patient with the simplified cost. An appropriate utilization of information technology simplifies the treatment for teeth irregularities and misaligned jaws in an effective manner. Lot of research works carried out in the area of dentistry to come out with an optimistic result. With the advent of artificial intelligence and machine learning methodologies in recent years, lot of clinical problems and difficulties can be efficiently managed and overcome by orthodontists. This research article provides the complete insight about the impact of intelligent technologies in the field of orthodontics. It provides a complete overview of futuristic applications in the field of orthodontic clinical diagnosis, planning of treatment for various cases and the correct prediction of outcome of clinical treatment which regularly faced by an orthodontist in the health care sector.",
    "abstract_processed": "effect predict orthodont treatment outcom highli essenti scheme clinic treatment patient simplifi cost appropri util inform technolog simplifi treatment teeth irregular misalign jaw effect manner lot research work carri area dentistri come optimist result advent artifici intellig machin learn methodolog recent year lot clinic problem difficulti effici manag overcom orthodontist research articl provid complet insight impact intellig technolog field orthodont provid complet overview futurist applic field orthodont clinic diagnosi plan treatment variou case correct predict outcom clinic treatment regularli face orthodontist health care sector"
  },
  {
    "doc_id": "10131752",
    "abstract_original": "Global business environment in the modern times is being impacted by various forces such as advancement in technology, borderless trade, economic tremors and disruptions of business which have resulted in organizations adopting and using business excellence practices in order to achieve success in all domains of their business. There are several business excellence models available which are very famous amongst businesses, government and private accreditation agencies, regulators and policy makers. ISO has remained an all-time favorite quality standard for businesses. In the journey of excellence, most of the companies start with getting them in line with ISO standards and get certification. EFQM has also become very popular amongst modern day businesses as it sets more comprehensive view of business excellence and quality assurance. The aim of this paper is to understand the significance of business excellence and its internationally recognized models such as EFQM and ISO which assist in improving business performance. The paper also intends to highlight the similarities and dissimilarities between the two models and their implementation. Also, this is an effort to compare the two models (ISO and EFQM) to see their relevance and impact in the area of quality assurance and business excellence.",
    "abstract_processed": "global busi environ modern time impact variou forc advanc technolog borderless trade econom tremor disrupt busi result organ adopt use busi excel practic order achiev success domain busi sever busi excel model avail famou amongst busi govern privat accredit agenc regul polici maker iso remain time favorit qualiti standard busi journey excel compani start get line iso standard get certif efqm also becom popular amongst modern day busi set comprehens view busi excel qualiti assur aim paper understand signific busi excel intern recogn model efqm iso assist improv busi perform paper also intend highlight similar dissimilar two model implement also effort compar two model iso efqm see relev impact area qualiti assur busi excel"
  },
  {
    "doc_id": "10131894",
    "abstract_original": "Traditionally, many people still wish to write on pen and paper. However, it has some drawbacks, like accessing and storing physical documents efficiently, searching through them, and sharing them efficiently. Handwriting to Text Conversion (HTC) classifies and converts an individual’s handwriting into digital form. However, HTC removes all the mentioned problems as storing, retrieving, and using the text as and when required is easier. Emotions are a basic and particularly important aspect of one’s life. To understand this important aspect of an individual’s life, we must detect emotions using affect data like text, voice, and image. We have used text as the effect data for this work. We can find a person’s emotions behind his text by sentiment analysis. Sentiment recognition and analysis is a topic with wide research as many brands, companies, and even famous personalities are very much interested in getting feedback and thus do the evaluation of their performance and knowing what people think about them around the world. Authors have proposed a model where they collected data from social media reviews and classified it into three broad categories, which are positive, negative, and neutral. Find the emotions category viz. happiness, sadness, shame, anger, disgust, fear, surprise, or neutral from three types of classified sentiments. The proposed model combined machine learning, deep learning, and natural language processing techniques to achieve the best outcome.",
    "abstract_processed": "tradit mani peopl still wish write pen paper howev drawback like access store physic document effici search share effici handwrit text convers htc classifi convert individual’ handwrit digit form howev htc remov mention problem store retriev use text requir easier emot basic particularli import aspect one’ life understand import aspect individual’ life must detect emot use affect data like text voic imag use text effect data work find person’ emot behind text sentiment analysi sentiment recognit analysi topic wide research mani brand compani even famou person much interest get feedback thu evalu perform know peopl think around world author propos model collect data social media review classifi three broad categori posit neg neutral find emot categori viz happi sad shame anger disgust fear surpris neutral three type classifi sentiment propos model combin machin learn deep learn natur languag process techniqu achiev best outcom"
  },
  {
    "doc_id": "10132652",
    "abstract_original": "If I were to point to a group of professionals who are constantly updating their mental models and technological frameworks to correspond to new social and scientific knowledge, I would choose doctors. As a layperson, I think about the tangle of race in medicine a lot because my own experience with it doesn&#x0027;t fit neatly into computational categories. I am a Black woman with light skin, and people often don&#x0027;t know what racial or ethnic category to put me in. I&#x0027;ve been asked if I am Black, white, Puerto Rican, Egyptian, Israeli&#x2014;the whole spectrum. For the purposes of medical forms, I usually write that I am multiracial. My mother was white, my father was Black, and I want my doctors to be aware of any genetic or epigenetic factors that might be inherited along either family line. As the cultural conversation about race has evolved over the years, I&#x0027;ve noticed my doctors adapting their practices.",
    "abstract_processed": "point group profession constantli updat mental model technolog framework correspond new social scientif knowledg would choos doctor layperson think tangl race medicin lot experi x fit neatli comput categori black woman light skin peopl often x know racial ethnic categori put x ask black white puerto rican egyptian isra x whole spectrum purpos medic form usual write multiraci mother white father black want doctor awar genet epigenet factor might inherit along either famili line cultur convers race evolv year x notic doctor adapt practic"
  },
  {
    "doc_id": "10132718",
    "abstract_original": "Humans cannot easily manage large stacks of unsorted items&#x2014; think of millions of different items randomly dumped and heaped in a warehouse.<superscript>1</superscript> The usual way for us to deal with a mess is to give it some order; for example, to find a name among one million we typically invest a lot of upfront work to sort all those names alphabetically; that investment pays back each time we look for a name, because then we know in advance where it is, and we don&#x0027;t have to read one million names to find the one we are looking for. The same in mathematics: to handle one million mathematical points we typically inscribe them in an equation, so we deal with just a few lines of algebraic script instead of having to deal with one million coordinates. In applied sciences, as in design, we do not handle dimensionless mathematical points, but physical particles, pixels, or voxels&#x2014;chunks of images and of three-dimensional objects; yet the logic is the same. No human can notate and calculate one billion parts (chunks, pixels, voxels) one by one. Life is too short for that. When dealing with data, simplification is the humans&#x0027; inescapable lot. That&#x0027;s the way our mind works.",
    "abstract_processed": "human cannot easili manag larg stack unsort item x think million differ item randomli dump heap warehous superscript superscript usual way us deal mess give order exampl find name among one million typic invest lot upfront work sort name alphabet invest pay back time look name know advanc x read one million name find one look mathemat handl one million mathemat point typic inscrib equat deal line algebra script instead deal one million coordin appli scienc design handl dimensionless mathemat point physic particl pixel voxel x chunk imag three dimension object yet logic human notat calcul one billion part chunk pixel voxel one one life short deal data simplif human x inescap lot x way mind work"
  },
  {
    "doc_id": "10134081",
    "abstract_original": "As methodology has created and sensors have been scaled down, there have been endeavors to utilize contemporary innovation in different fields to work on the nature of human existence. One of the significant areas of examination that has been distinguished is the consideration of innovation in the medical services business. Individuals who require medical care administrations think that they are preposterously costly, particularly in creating nations. The main part involves utilizing sensors like ECG signal, Temperature, Glucose and heart beat sensors to distinguish a patient's vitals, the second sending information to cloud capacity, and the third conveying the noticed information for ML model like SVM and KNN to anticipate regardless of whether the individual having heart illness or not and then the performance of both the models are compared. The information might be seen from a distance, permitting a specialist or gatekeeper to screen a patient's wellbeing state even while they are not in the emergency clinic. The Web of Things (IoT) has been generally used to interface promptly accessible clinical assets and give patients with insightful, trustworthy, and viable medical care administrations.",
    "abstract_processed": "methodolog creat sensor scale endeavor util contemporari innov differ field work natur human exist one signific area examin distinguish consider innov medic servic busi individu requir medic care administr think preposter costli particularli creat nation main part involv util sensor like ecg signal temperatur glucos heart beat sensor distinguish patient vital second send inform cloud capac third convey notic inform ml model like svm knn anticip regardless whether individu heart ill perform model compar inform might seen distanc permit specialist gatekeep screen patient wellb state even emerg clinic web thing iot gener use interfac promptli access clinic asset give patient insight trustworthi viabl medic care administr"
  },
  {
    "doc_id": "10134169",
    "abstract_original": "Social media has become an essential means for communicating the review/opinions of people around the world due to the rapid expansion and availability of the internet. Reviews and opinions are expressed both as text and audio. But text communication via networking media is overwhelming. Each and every second, a vast amount of information is produced online because of social media sites. However, online reviews on social media provides an excellent and trustworthy channel for examining the areas that require improvement and for understanding the needs of customers. This paper tries to understand the various topics that are discussed by customers about food with the aim of providing an insight to improve the area where there are negative comments. By doing this, customer retention will increase and gradually the business also. Topic modeling is done to find the hidden topic in a set of comments or customer reviews to find out on which topic customers are talking, thinking, or discussing more about restaurant services. It helps to read customers' mindsets, and accordingly, improvements can be made to increase consumer demand for a restaurant. So, a system is proposed to detect topics of textual reviews of different restaurants using the latent Dirichlet allocation (LDA) modelling approach. A probabilistic, statistical strategy for document designing called latent document analysis (LDA) identifies latent semantic topics in sizable corpora. The dataset used for this study was taken from Kaggle, which had 111,105 reviews. First, topics from reviews were extracted using the LDA model, then data was visualised using the LDAvis tool. The experiment's findings show that the analysis obtained a successful topic division outcome especially in long-to-short text level topic classification.",
    "abstract_processed": "social media becom essenti mean commun review opinion peopl around world due rapid expans avail internet review opinion express text audio text commun via network media overwhelm everi second vast amount inform produc onlin social media site howev onlin review social media provid excel trustworthi channel examin area requir improv understand need custom paper tri understand variou topic discuss custom food aim provid insight improv area neg comment custom retent increas gradual busi also topic model done find hidden topic set comment custom review find topic custom talk think discuss restaur servic help read custom mindset accordingli improv made increas consum demand restaur system propos detect topic textual review differ restaur use latent dirichlet alloc lda model approach probabilist statist strategi document design call latent document analysi lda identifi latent semant topic sizabl corpora dataset use studi taken kaggl review first topic review extract use lda model data visualis use ldavi tool experi find show analysi obtain success topic divis outcom especi long short text level topic classif"
  },
  {
    "doc_id": "10134585",
    "abstract_original": "In recent years, with the continuous development of digitalization, all kinds of data on the Internet have increased rapidly, and knowledge graphs have emerged. Knowledge graphs have become one of the important means for us to manage and utilize knowledge. Knowledge reasoning is part of building a knowledge graph. There are many different methods of knowledge reasoning, which are mainly divided into traditional knowledge reasoning and knowledge reasoning over knowledge graph. The knowledge reasoning manner based on neural network has stronger thinking ability and generalization ability. The inference effect is better. The utilization rate of the relation, entity, attribute and text information in the knowledge base is higher. In this paper, the basic ideas of knowledge graph are introduced in detail. The basic principle of knowledge reasoning is expounded. In addition, from the three dimensions of semantics, structure and auxiliary storage. Three inference methods are introduced. Furthermore, the problems of neural network are summarized, and the challenges of knowledge reasoning are described. Finally, The development prospect of neural network and knowledge reasoning are prospected.",
    "abstract_processed": "recent year continu develop digit kind data internet increas rapidli knowledg graph emerg knowledg graph becom one import mean us manag util knowledg knowledg reason part build knowledg graph mani differ method knowledg reason mainli divid tradit knowledg reason knowledg reason knowledg graph knowledg reason manner base neural network stronger think abil gener abil infer effect better util rate relat entiti attribut text inform knowledg base higher paper basic idea knowledg graph introduc detail basic principl knowledg reason expound addit three dimens semant structur auxiliari storag three infer method introduc furthermor problem neural network summar challeng knowledg reason describ final develop prospect neural network knowledg reason prospect"
  },
  {
    "doc_id": "10134633",
    "abstract_original": "The study aims to learn deep features from EEG signals corresponding to the imagery of words to design a BCI(Brain computer interface) system based on human thoughts. Topological plots of time-averaged EEG signals across all the trials corresponding to the imagery of a particular word are fed as input to the designed deep neural network algorithm. Designed deep learning architecture has an amalgamation of the Two-dimensional convolutional neural network and LSTM that takes the assistance of the capabilities and assets of both neural network architectures. The proposed neural network architecture achieves admirable accuracy in identifying imagined words from the EEG-based Kara one dataset. The accuracy of the designed CNN-LSTM model with topological plots as input features was 20-25% more than chance level accuracy and comparable to the state of arts.",
    "abstract_processed": "studi aim learn deep featur eeg signal correspond imageri word design bci brain comput interfac system base human thought topolog plot time averag eeg signal across trial correspond imageri particular word fed input design deep neural network algorithm design deep learn architectur amalgam two dimension convolut neural network lstm take assist capabl asset neural network architectur propos neural network architectur achiev admir accuraci identifi imagin word eeg base kara one dataset accuraci design cnn lstm model topolog plot input featur chanc level accuraci compar state art"
  },
  {
    "doc_id": "10137840",
    "abstract_original": "Three-way decisions model adopts the idea of’’rule by three divisions’’ and “simplify complexity which provides a multi-level and multi granularity thinking framework and implementation method for solving complex uncertain problems. Within this framework, how to extend the application of the generalized model from decision system to interval-valued decision system is an important issue. In this paper, we propose multigranulation sequential three-way decision models in inter-valvalued information system. Firstly, three types of similarity relations from the view of optimistic, pessimistic and weighted are defined. Based on these similarity relations, the lower and upper approximations under multiple granular structures are computed. Then optimistic, pessimistic and weighted arithmetic strategies are adopted to compute three disjoint regions in each level of multigranulation sequential three-way decisions. Furthermore, nine types of multigranulation sequential threeway decision models were analysed. Finally, the experimental results show that the size of the probabilistic regions varies with the similarity relations and aggregation strategies.",
    "abstract_processed": "three way decis model adopt idea of’’rul three divisions’’ “simplifi complex provid multi level multi granular think framework implement method solv complex uncertain problem within framework extend applic gener model decis system interv valu decis system import issu paper propos multigranul sequenti three way decis model inter valvalu inform system firstli three type similar relat view optimist pessimist weight defin base similar relat lower upper approxim multipl granular structur comput optimist pessimist weight arithmet strategi adopt comput three disjoint region level multigranul sequenti three way decis furthermor nine type multigranul sequenti threeway decis model analys final experiment result show size probabilist region vari similar relat aggreg strategi"
  },
  {
    "doc_id": "10138187",
    "abstract_original": "This work proposes a transformer-based model capable of generating music in its symbolic domain, in a controllable fashion. The ultimate goal of this is to build a system with which people can compose music collaboratively with a computer. Using an NLP model as a base (GPT-2), we take advantage of the similarities across symbolic music representation and written language to build a model capable of conditionally predicting musical sequences. Controllability is achieved without explicit programming for it, and does not require extensive retraining of the model. A study with 939 participants was performed to evaluate this controllability. The results of this suggest the proposed method is indeed effective and can be used to control the generation of music in its symbolic domain. The method itself is flexible to any desired “control”, but this work focuses specifically on the emotion conveyed when one listens to a piece of music.",
    "abstract_processed": "work propos transform base model capabl gener music symbol domain control fashion ultim goal build system peopl compos music collabor comput use nlp model base gpt take advantag similar across symbol music represent written languag build model capabl condit predict music sequenc control achiev without explicit program requir extens retrain model studi particip perform evalu control result suggest propos method inde effect use control gener music symbol domain method flexibl desir “control” work focus specif emot convey one listen piec music"
  },
  {
    "doc_id": "10138574",
    "abstract_original": "This manuscript presents a ring-core Bragg Fiber (RC-BF) for orbital angular momentum (OAM) modes propagation and supercontinuum generation. The proposed RC-BF is composed of alternating layers of soft glasses SF57 and LLF1 to render high nonlinearity to the fiber. Mode analysis using full-vectorial finite element method resulted in obtaining HE/EH modes to support vector modes as well as orbital angular momentum modes. The optimized fiber supports 22 OAM modes and exhibits a zero-dispersion wavelength (ZDW). The small effective area of Fiber 3 aided in achieving the highest nonlinearity,  $\\gamma $  = 91.51  $\\text{W}^{-1}$ km $^{-1}$ . A near-infrared supercontinuum is generated with a 35 dB flatness over a bandwidth of  $\\sim $ 1087 - 2024 nm in a 20 cm long RC-BF using a chirp-free hyperbolic secant pulse of width 200 fs and peak power of 5 kW.",
    "abstract_processed": "manuscript present ring core bragg fiber rc bf orbit angular momentum oam mode propag supercontinuum gener propos rc bf compos altern layer soft glass sf llf render high nonlinear fiber mode analysi use full vectori finit element method result obtain eh mode support vector mode well orbit angular momentum mode optim fiber support oam mode exhibit zero dispers wavelength zdw small effect area fiber aid achiev highest nonlinear \\gamma \\text w km near infrar supercontinuum gener db flat bandwidth \\sim nm cm long rc bf use chirp free hyperbol secant puls width fs peak power kw"
  },
  {
    "doc_id": "10139678",
    "abstract_original": "The last decade has seen a surge in expanding access to Computer Science (CS) education, especially for K-12, with many states even stipulating student learning standards in CS and Computational Thinking (CT). Our 21st century K-12 students are no longer just computer users, but are now required to be computationally literate creators with proficient skills both in the concepts and practices of CS and CT. At the same time, technology continues to pervade our lives and expand at a relentless pace and all aspects of our lives are now embedded in technology surrounded by Artificial Intelligence (AI). AI in the form of Machine Learning (ML) is a key technology in a diversity of applications, where we use sensors to meaningfully perceive the world around us, analyze and organize the perceived data, and autonomously use that data to make predictions and decisions. In higher education, AI/ML courses proliferate, with many institutions now conferring degrees and certifications in these. To an extent, some high schools (grades 9–12) have started introducing these concepts in a technology class, or a robotics club, or as an after-school activity. As for middle (grades 6–8) and elementary school (grades K-5), there are very few examples of such instruction. In this paper, we present a complete framework for elementary and middle school teachers to help them prepare and incorporate AI/ML lessons in their classrooms using hands-on active learning strategies. We want to empower these teachers to impart improved learning to their students, which in turn will prepare their students to become effective thinkers, problem solvers, communicators, and gain necessary skills for high-skilled and high-demand jobs. We describe a detailed AI/ML lesson plan based on standards and framework, AI4K12 big ideas, art and science of curriculum design, active learning, and culturally responsive and inclusive pedagogy. Then we discuss our experiences in teaching the same to $\\boldsymbol{4}^{\\mathbf{th}}$ grade students in an elementary school.",
    "abstract_processed": "last decad seen surg expand access comput scienc cs educ especi k mani state even stipul student learn standard cs comput think ct st centuri k student longer comput user requir comput liter creator profici skill concept practic cs ct time technolog continu pervad live expand relentless pace aspect live embed technolog surround artifici intellig ai ai form machin learn ml key technolog divers applic use sensor meaning perceiv world around us analyz organ perceiv data autonom use data make predict decis higher educ ai ml cours prolifer mani institut confer degre certif extent high school grade – start introduc concept technolog class robot club school activ middl grade – elementari school grade k exampl instruct paper present complet framework elementari middl school teacher help prepar incorpor ai ml lesson classroom use hand activ learn strategi want empow teacher impart improv learn student turn prepar student becom effect thinker problem solver commun gain necessari skill high skill high demand job describ detail ai ml lesson plan base standard framework ai k big idea art scienc curriculum design activ learn cultur respons inclus pedagogi discuss experi teach \\boldsymbol \\mathbf th grade student elementari school"
  },
  {
    "doc_id": "10140549",
    "abstract_original": "The fermentation process refers to the reaction process in which specialized metabolites are produced and accumulated in large quantities through the growth, culture and chemical changes of microorganisms (or animal and plant cells). The biomass parameters play a key role, and they cannot be detected online. Measurement technology offers a solution. Expert system technology can solve the problems of complicated fermentation process classification and numerous mechanism models in the process of biomass soft sensing modeling. This paper presents the structure of an expert system for biomass detection in fermentation process. This expert system provides a new technical method for the division of soft-sensing hybrid models.",
    "abstract_processed": "ferment process refer reaction process special metabolit produc accumul larg quantiti growth cultur chemic chang microorgan anim plant cell biomass paramet play key role cannot detect onlin measur technolog offer solut expert system technolog solv problem complic ferment process classif numer mechan model process biomass soft sens model paper present structur expert system biomass detect ferment process expert system provid new technic method divis soft sens hybrid model"
  },
  {
    "doc_id": "10140623",
    "abstract_original": "In mechanical design, this paper uses CAD interface for 3D modeling to generate 3D solids. This paper clarifies the intelligent standard view generation technology in 3D CAD software and its intelligent technologies such as axonometric drawing, internal structure, auxiliary view, intelligent annotation, parametric design and assembly design, showing its powerful application function. According to the principle of shape design in 3D conception, this paper discusses the teaching mode of combining composition theory with 3D CAD application, and using 3D CAD system to cultivate students' abstract thinking, image thinking and innovative thinking.",
    "abstract_processed": "mechan design paper use cad interfac model gener solid paper clarifi intellig standard view gener technolog cad softwar intellig technolog axonometr draw intern structur auxiliari view intellig annot parametr design assembl design show power applic function accord principl shape design concept paper discuss teach mode combin composit theori cad applic use cad system cultiv student abstract think imag think innov think"
  },
  {
    "doc_id": "10140696",
    "abstract_original": "This paper highlighted the key challenges impacting Management Education in India (MEI) in the current digitalized scenario, especially after COVID-19. Initially, an exploratory research design was utilized and then it was descriptive to analyze the collected data. The sample size was 100(valid responses) being the management educator of Meerut city as a sample unit. Table & Descriptive Statistics were used to define the data and ‘Correlation and Multiple Regression Analysis’ were used for calculating the outcomes. Major respondents were young-aged educators that truly believe in a challenging and dynamic MEI as of now. The crisis management ability was the most crucial challenge of MEI. \"Industry orientation\" and \"international perspective\" were not significant challenges. The study was highly practical because \"MEI\" has been undergoing a roundabout transformation in the current digitalized scenario, and there has been a paradigm shift in overall higher education following COVID-19. It was highly important because budding managers and forthcoming business leaders have to perform in a highly dynamic environment, and the paper was original as 100 primary responses of management educators in Meerut City were taken into account for study.",
    "abstract_processed": "paper highlight key challeng impact manag educ india mei current digit scenario especi covid initi exploratori research design util descript analyz collect data sampl size valid respons manag educ meerut citi sampl unit tabl descript statist use defin data ‘correl multipl regress analysis’ use calcul outcom major respond young age educ truli believ challeng dynam mei crisi manag abil crucial challeng mei industri orient intern perspect signific challeng studi highli practic mei undergo roundabout transform current digit scenario paradigm shift overal higher educ follow covid highli import bud manag forthcom busi leader perform highli dynam environ paper origin primari respons manag educ meerut citi taken account studi"
  },
  {
    "doc_id": "10141836",
    "abstract_original": "In present study the fractal theory has been reviewed in the context of bio-functional and biomedical complex systems. The chaotic approach is a critical component of the theoretical framework and can be used in analyzing complex biological structures such as chromatin structures. Fractality is a metric of complexity in biological functions; it is an indicator of the complication level of the self-similar structure, while chaos is a sort of dynamic behavior that usually produces totally arbitrary patterns. Fractal measurements in vivo could be used to predict the efficiency of painful therapy. The fractal technique can be used to assess carcinogenesis, tumor progression, chemoprophylaxis, and treatment with the convergence of modern sensing techniques in nano-scale spectroscopic techniques, which is a prospective biomarker. The mathematical principles of fractals and chaos in biological systems are presented in the context of the condition of health treatment and their significance. Fractality in different biological functions including the heart has now been investigated and measured the dosing quantity with chaos and fractal level. As excessive amounts of chaos and fractal complexity are harmful to biological predictions. For biological applications, chaos analysis may be advantageous. This paper is a review which highlights the fractal and chaos theories for biological functions and biomedical systems. The focus will be to explore biological functions, due to its computational machine learning-based demands and capability in mathematical complexity.",
    "abstract_processed": "present studi fractal theori review context bio function biomed complex system chaotic approach critic compon theoret framework use analyz complex biolog structur chromatin structur fractal metric complex biolog function indic complic level self similar structur chao sort dynam behavior usual produc total arbitrari pattern fractal measur vivo could use predict effici pain therapi fractal techniqu use assess carcinogenesi tumor progress chemoprophylaxi treatment converg modern sens techniqu nano scale spectroscop techniqu prospect biomark mathemat principl fractal chao biolog system present context condit health treatment signific fractal differ biolog function includ heart investig measur dose quantiti chao fractal level excess amount chao fractal complex harm biolog predict biolog applic chao analysi may advantag paper review highlight fractal chao theori biolog function biomed system focu explor biolog function due comput machin learn base demand capabl mathemat complex"
  },
  {
    "doc_id": "10142352",
    "abstract_original": "The ascent of a few insightful labor and products throughout the course of recent years, as well as their business feasibility and financial impacts, have driven some to contemplate whether the ongoing coming of computer based intelligence is just marketing publicity or really can possibly change society. The review investigates the few impacts of artificial intelligence (artificial intelligence), and digs further into both good and troublesome consequences for legislatures, networks, organizations, and individuals. The entire impacts of simulated intelligence, from exploration and advancement to execution, are analyzed in this paper. With the advancement of computer based intelligence innovations, the marketing business is developing rapidly. Artificial intelligence offers numerous open doors, including the capacity to acquire data, hyper-customize administrations, further develop consumer loyalty, save working expenses, support efficiency, and so forth. For both monetary administrations organizations and advertisers, artificial intelligence has changed the game.",
    "abstract_processed": "ascent insight labor product throughout cours recent year well busi feasibl financi impact driven contempl whether ongo come comput base intellig market public realli possibl chang societi review investig impact artifici intellig artifici intellig dig good troublesom consequ legislatur network organ individu entir impact simul intellig explor advanc execut analyz paper advanc comput base intellig innov market busi develop rapidli artifici intellig offer numer open door includ capac acquir data hyper custom administr develop consum loyalti save work expens support effici forth monetari administr organ advertis artifici intellig chang game"
  },
  {
    "doc_id": "10143123",
    "abstract_original": "Chat Generative Pretrained Transformer (Chat-GPT) and related Generative AI models are leading a paradigm shift in the acceptance and application of Artificial Intelligence (AI) across all disciplines and industry sectors. Despite the criticisms of an ‘intelligence without knowledge or reasoning or the notions of truth’, ChatGPT is highly effective at human-like conversation with seemingly sophisticated and useful responses to questions, summarization, classification, extraction and generation tasks. Unlike similar large AI models in the modalities of image, audio and video, text-based conversation is straightforward and familiar to a large audience of regular users of the Internet and smartphone applications. This is further accentuated by the large-scale adoption of ‘standard’ chatbot technologies for trivial conversations in task-specific automation, across every industry sector. This rare combination of highly effective human-like conversation, familiarity of foundational technology and versatility of intelligent application, has led to several challenges and opportunities in leveraging generative AI. A primary challenge is its impact on the academic integrity of scholarly work, where AI-generated content can be useful and detrimental in both teaching and research. On the other hand, ChatGPT presents a unique opportunity in augmenting preexisting (‘standard’) chatbots with human-like conversation for advanced intelligent automation, across all application domains. Although diametrically opposed, the challenge of addressing academic integrity and the opportunity of augmenting pre-existing chatbots are grounded in the conversational AI capabilities of ChatGPT and similar generative AI models. In this paper, we investigate these formative capabilities and present guidelines for leveraging ChatGPT and similar generative AI models.",
    "abstract_processed": "chat gener pretrain transform chat gpt relat gener ai model lead paradigm shift accept applic artifici intellig ai across disciplin industri sector despit critic ‘intellig without knowledg reason notion truth’ chatgpt highli effect human like convers seemingli sophist use respons question summar classif extract gener task unlik similar larg ai model modal imag audio video text base convers straightforward familiar larg audienc regular user internet smartphon applic accentu larg scale adopt ‘standard’ chatbot technolog trivial convers task specif autom across everi industri sector rare combin highli effect human like convers familiar foundat technolog versatil intellig applic led sever challeng opportun leverag gener ai primari challeng impact academ integr scholarli work ai gener content use detriment teach research hand chatgpt present uniqu opportun augment preexist ‘standard’ chatbot human like convers advanc intellig autom across applic domain although diametr oppos challeng address academ integr opportun augment pre exist chatbot ground convers ai capabl chatgpt similar gener ai model paper investig form capabl present guidelin leverag chatgpt similar gener ai model"
  },
  {
    "doc_id": "10143578",
    "abstract_original": "With the rapid development of DNA microarray technology, the application of informatics research methods in oncology is becoming more and more popular. Because the gene expression data extraction experiment has the characteristics of a large number of genes and complex and changeable experimental conditions, clustering technology has been introduced into the field of molecular biology to assist research and analyze gene expression data. Currently, many clustering algorithms are applied in gene expression analysis. Nevertheless, owing to the high dimensionality of gene expression data, many algorithms face the problem of low computational efficiency. The method based on the graph theory thinks of the sample of gene expression data as the point in high-dimensional space. Its low sample performance determines that the constructed matrix is small in size. Therefore, it has lower computational complexity. Therefore, the graph regularized non-negative matrices factorization (GNMF) proposed by Cai et al. has been widely used for gene clustering. However, the deficiency of the GNMF algorithm is unstable with data variation for gene clustering. In this paper, we propose post-processing of Graph Regularized Nonnegative Matrix Factorization Algorithm for Gene Clustering, called pGNMF. In the pGNMF method, we first normalize the solution of GNMF, thereby reducing the sensitivity of the traditional GNMF method to the prior selection of genes or initial conditions, and effectively improving the robustness of the algorithm. Experimental results show that the proposed algorithms outperform existing GNMF algorithms for gene clustering.",
    "abstract_processed": "rapid develop dna microarray technolog applic informat research method oncolog becom popular gene express data extract experi characterist larg number gene complex changeabl experiment condit cluster technolog introduc field molecular biolog assist research analyz gene express data current mani cluster algorithm appli gene express analysi nevertheless owe high dimension gene express data mani algorithm face problem low comput effici method base graph theori think sampl gene express data point high dimension space low sampl perform determin construct matrix small size therefor lower comput complex therefor graph regular non neg matric factor gnmf propos cai et al wide use gene cluster howev defici gnmf algorithm unstabl data variat gene cluster paper propos post process graph regular nonneg matrix factor algorithm gene cluster call pgnmf pgnmf method first normal solut gnmf therebi reduc sensit tradit gnmf method prior select gene initi condit effect improv robust algorithm experiment result show propos algorithm outperform exist gnmf algorithm gene cluster"
  },
  {
    "doc_id": "10143650",
    "abstract_original": "Social media has revolutionized the way individuals connect and share information globally. However, the rise of these platforms has led to the proliferation of cyber-hate, which is a significant concern that has garnered attention from researchers. To combat this issue, various solutions have been proposed, utilizing Machine learning and Deep learning techniques such as Naive Bayes, Logistic Regression, Convolutional Neural Networks, and Recurrent Neural Networks. These methods rely on a mathematical approach to distinguish one class from another. However, when dealing with sentiment-oriented data, a more “critical thinking” perspective is needed for accurate classification, as it provides a more realistic representation of how people interpret online messages. Based on a literature review conducted to explore efficient classification techniques, this study applied two machine learning classifiers, Multinomial Naive Bayes and Logistic Regression, to four online hate datasets. The results of the classifiers were optimized using bio-inspired optimization techniques such as Particle Swarm Optimization and Genetic Algorithms, in conjunction with Fuzzy Logic, to gain a deeper understanding of the text in the datasets.",
    "abstract_processed": "social media revolution way individu connect share inform global howev rise platform led prolifer cyber hate signific concern garner attent research combat issu variou solut propos util machin learn deep learn techniqu naiv bay logist regress convolut neural network recurr neural network method reli mathemat approach distinguish one class anoth howev deal sentiment orient data “critic thinking” perspect need accur classif provid realist represent peopl interpret onlin messag base literatur review conduct explor effici classif techniqu studi appli two machin learn classifi multinomi naiv bay logist regress four onlin hate dataset result classifi optim use bio inspir optim techniqu particl swarm optim genet algorithm conjunct fuzzi logic gain deeper understand text dataset"
  },
  {
    "doc_id": "10143930",
    "abstract_original": "This research explored the degree of learning self-efficacy of machine learning experience (MLSE) and artificial intelligence learning anxiety (AILA) of elementary and junior high school teachers. The participants were in-service teachers in the technology domain. This research applied the AI2 Robot City, which is a computational thinking board game, to in-service teacher education. The learning content was image classification for AI application. Elementary and junior high school teachers operated the MIT App Inventor(MAI) and Personal Image Classifier(PIC) platform, and trained the model for practicing AI to implement supervised machine learning on the PIC platform. The learners then inserted the model they had trained into the block-based programming environment of MAI. They completed the smart phone app and used the app to recognize the board game cards so as to control the movement of the smart cars on the table map to meet the requirements of the task in the AI2 Robot City board game. In order to understand affective factors such as the self-efficacy and learning anxiety of the elementary and middle school teachers participating in the AI teacher training workshop, the MLSE and AILA scales were administered before and after the classes. A total of 28 samples were collected. The results showed that there was no significant difference between the MLSE of the elementary and junior high school teachers. However, the average AILA degree of the junior high school teachers was significantly higher than that of the elementary school teachers. It was found that AILA was significantly negatively correlated with MLSE. The elementary and junior high school teachers were confident that they could study AI-related courses. However, the AILA of the junior high school teachers was higher than that of the elementary school teachers. Therefore, more teacher training workshops on AI application can be conducted for junior high school teachers to generally improve their familiarity with AI application. Future research can further explore whether teachers will gradually improve their AILA and MLSE with time and as training courses increase.",
    "abstract_processed": "research explor degre learn self efficaci machin learn experi mlse artifici intellig learn anxieti aila elementari junior high school teacher particip servic teacher technolog domain research appli ai robot citi comput think board game servic teacher educ learn content imag classif ai applic elementari junior high school teacher oper mit app inventor mai person imag classifi pic platform train model practic ai implement supervis machin learn pic platform learner insert model train block base program environ mai complet smart phone app use app recogn board game card control movement smart car tabl map meet requir task ai robot citi board game order understand affect factor self efficaci learn anxieti elementari middl school teacher particip ai teacher train workshop mlse aila scale administ class total sampl collect result show signific differ mlse elementari junior high school teacher howev averag aila degre junior high school teacher significantli higher elementari school teacher found aila significantli neg correl mlse elementari junior high school teacher confid could studi ai relat cours howev aila junior high school teacher higher elementari school teacher therefor teacher train workshop ai applic conduct junior high school teacher gener improv familiar ai applic futur research explor whether teacher gradual improv aila mlse time train cours increas"
  },
  {
    "doc_id": "10143932",
    "abstract_original": "Computational thinking (CT), one of the 21st-century essential competencies, has been broadly accepted by artificial intelligence (AI) and STEM. However, little was conducted to explore its potential in foreign language (FL) learning and teaching. To examine its possibilities, the relevant challenges, computer-language input and output process, and literature shreds of evidence were offered and analyzed. English grammar learning and teaching practice based on CT principal skills steps-focused mode further confirmed its social mediation tool in English learning and teaching.",
    "abstract_processed": "comput think ct one st centuri essenti compet broadli accept artifici intellig ai stem howev littl conduct explor potenti foreign languag fl learn teach examin possibl relev challeng comput languag input output process literatur shred evid offer analyz english grammar learn teach practic base ct princip skill step focus mode confirm social mediat tool english learn teach"
  },
  {
    "doc_id": "10145792",
    "abstract_original": "Even without hearing or seeing individuals, humans are able to determine subtle emotions from a range of indicators and surroundings. However, existing research on emotion recognition is mostly focused on recognizing the emotions of speakers across complete modalities. In real-world situations, emotion reasoning is an interesting field for inferring human emotions from a person’s surroundings when neither the face nor voice can be observed. Therefore, in this paper, we propose a novel multimodal approach for predicting emotion from missing one or more modalities based on attention mechanisms. Specifically, we employ self-attention for each unimodal representation to extract the dominant features and utilize the compounded paired-modality attention (CPMA) among sets of modalities to identify the context of the considered individual, such as the interplay of modalities, and capture people’s interactions in the video. The proposed model is trained on the Multimodal Emotion Reasoning (MEmoR) dataset, which includes multimedia inputs such as visual, audio, text, and personality. The proposed model achieves a weighted F1-score of 50.63% for the primary emotion group and 42.7% for the fine-grained one. According to the results, our proposed model outperforms the conventional approaches in terms of emotion reasoning.",
    "abstract_processed": "even without hear see individu human abl determin subtl emot rang indic surround howev exist research emot recognit mostli focus recogn emot speaker across complet modal real world situat emot reason interest field infer human emot person’ surround neither face voic observ therefor paper propos novel multimod approach predict emot miss one modal base attent mechan specif employ self attent unimod represent extract domin featur util compound pair modal attent cpma among set modal identifi context consid individu interplay modal captur people’ interact video propos model train multimod emot reason memor dataset includ multimedia input visual audio text person propos model achiev weight f score primari emot group fine grain one accord result propos model outperform convent approach term emot reason"
  },
  {
    "doc_id": "10148299",
    "abstract_original": "Recent years have seen a high volume of computational thinking (CT) review studies. However, there have been no existing studies that map these reviews with the goal of achieving comprehensive understanding of the field of CT. This paper utilizes Tikva & Tambouris’ (2021) K-12 CT research domain conceptual model as the basis for identifying and defining CT reviews, then maps the identified 38 CT reviews onto the identified domains. We pinpoint eight potential future review topics, including \"communities\" of tools, \"modeling simulations,\" \"problem-solving\" and \"scaffolding\" of learning strategies, \"demographic attributes\" of factors, \"practices\" and \"perspectives\" of the knowledge-based areas, and the \"teacher training\" of capacity building. We also examine the topical keywords of the reviews and identify that the scope of the term \"unplugged\" is vaguely defined among the existing research, suggesting a need to refine the definition of this frequently discussed topic so as to be able to more effectively conduct supplementary reviews. Our results help to better understand the CT review field and formulate future directions.",
    "abstract_processed": "recent year seen high volum comput think ct review studi howev exist studi map review goal achiev comprehens understand field ct paper util tikva tambouris’ k ct research domain conceptu model basi identifi defin ct review map identifi ct review onto identifi domain pinpoint eight potenti futur review topic includ commun tool model simul problem solv scaffold learn strategi demograph attribut factor practic perspect knowledg base area teacher train capac build also examin topic keyword review identifi scope term unplug vagu defin among exist research suggest need refin definit frequent discuss topic abl effect conduct supplementari review result help better understand ct review field formul futur direct"
  },
  {
    "doc_id": "10148382",
    "abstract_original": "In this work, we aim to improve code writing skill in Python-based introductory programming courses for first-year university students. In such courses, students as novice programmers would benefit from personalised and formative feedback to: 1) quickly identify issues in their computational thinking process or coding techniques, and 2) know how to proceed when facing a certain problem. Due to the large number of students, it is impractical for instructors to manually assess all the work of each student to provide tailored feedback. We design and implement Automatic Programming Coach (AP-Coach), a web-based tool for automatically generating formative feedback for exercises on basic programming concepts. AP-Coach combines software engineering techniques (code similarity measures based on abstract syntax trees, and unit testing), and AI techniques (machine translation) in a novel manner to provide relevant feedback. We report promising results for AP-Coach in the following aspects: 1) quantitative evaluation of code similarity computation and machine translation, 2) qualitative evaluation of the perceived quality and usability of auto-generated feedback, and 3) experience of a selected group of computing students using the system.",
    "abstract_processed": "work aim improv code write skill python base introductori program cours first year univers student cours student novic programm would benefit personalis form feedback quickli identifi issu comput think process code techniqu know proceed face certain problem due larg number student impract instructor manual assess work student provid tailor feedback design implement automat program coach ap coach web base tool automat gener form feedback exercis basic program concept ap coach combin softwar engin techniqu code similar measur base abstract syntax tree unit test ai techniqu machin translat novel manner provid relev feedback report promis result ap coach follow aspect quantit evalu code similar comput machin translat qualit evalu perceiv qualiti usabl auto gener feedback experi select group comput student use system"
  },
  {
    "doc_id": "10148435",
    "abstract_original": "The computer science industry suffers from a significant gender gap. This situation likely hinders the creation of inclusive and user-friendly systems due to a bias in perspectives. To narrow this gender gap, this study investigates how females program to increase interest in computer sciences. Specifically, 60 open Scratch projects on the web are analyzed to clarify differences in the Computational Thinking scores with respect to gender. The difference in the Computational Thinking score by gender suggests that the gap may be due to the lack of the Synchronization element in female users’ projects. A deeper understanding of how people program based on gender should support creating an effective and inclusive learning environment and allow educators to create programming materials that attract both genders equally into the field.",
    "abstract_processed": "comput scienc industri suffer signific gender gap situat like hinder creation inclus user friendli system due bia perspect narrow gender gap studi investig femal program increas interest comput scienc specif open scratch project web analyz clarifi differ comput think score respect gender differ comput think score gender suggest gap may due lack synchron element femal users’ project deeper understand peopl program base gender support creat effect inclus learn environ allow educ creat program materi attract gender equal field"
  },
  {
    "doc_id": "10148486",
    "abstract_original": "Large extant studies highlighted the importance of motivation in promoting students’ CT skills. However, few of them focused on basic psychological needs satisfaction (BPNS) and behavioral engagement. Since needs satisfaction could influence intrinsic motivation and lead to better performance. It is critical to understand whether, and to what extent, the learners’ CT skills are influenced by the level of BPNS. In light of this, the work-in-progress study employed a semester-long intervention to explore the role of BPNS in students’ CT skill development. A total of 600 primary students participated in this study. The findings of this study will contribute to a better understanding of primary students’ motivation in programming learning.",
    "abstract_processed": "larg extant studi highlight import motiv promot students’ ct skill howev focus basic psycholog need satisfact bpn behavior engag sinc need satisfact could influenc intrins motiv lead better perform critic understand whether extent learners’ ct skill influenc level bpn light work progress studi employ semest long intervent explor role bpn students’ ct skill develop total primari student particip studi find studi contribut better understand primari students’ motiv program learn"
  },
  {
    "doc_id": "10148487",
    "abstract_original": "We conducted a systematic review of studies aimed at exploring the state of parental involvement in computational thinking (CT) education to facilitate students’ efficiency in learning computational thinking. In this review, we started with reviewing theories of parental involvement. Then we investigated and categorized types of parental involvement, parent roles, and parents’ psychological factors in the parenting process. We also supplemented a new involvement form in Level 2 of Hoover-Dempsey and Sandler’s Model of Parental Involvement in CT Education, namely parents’ support with concerns about using technology and CT tools. We proposed the Model of Parental Involvement in Computational Thinking Education. We conducted comprehensive research of related studies on parental involvement in CT education and identified the research gap in involving parents in children’s CT learning.",
    "abstract_processed": "conduct systemat review studi aim explor state parent involv comput think ct educ facilit students’ effici learn comput think review start review theori parent involv investig categor type parent involv parent role parents’ psycholog factor parent process also supplement new involv form level hoover dempsey sandler’ model parent involv ct educ name parents’ support concern use technolog ct tool propos model parent involv comput think educ conduct comprehens research relat studi parent involv ct educ identifi research gap involv parent children’ ct learn"
  },
  {
    "doc_id": "10148553",
    "abstract_original": "With the worldwide momentum of promoting computational thinking (CT) education, greater attention has been received on assessing learning effects in both cognitive and attitudinal aspects. However, the cross-lagged relations between the two were unknown. This study investigated the cross-lagged association between CT cognitive performance and attitudinal beliefs of primary students through a three-wave longitudinal design. The paper reported the first two waves of data collection, with an 8-month time interval, involving a sample of 392 students (age 9-11). At each wave, students were asked to complete a CT cognitive test and a self-reported attitude survey. Through cross-lagged analyses, the results showed that prior CT cognitive performance significantly predicted later learning attitudes, and the paths remained significant after controlling for students’ demographics and learning experiences. The study contributes to the literature by pioneering documenting the cross-lagged relations between students’ cognitive and attitudinal attainments in the context of CT education.",
    "abstract_processed": "worldwid momentum promot comput think ct educ greater attent receiv assess learn effect cognit attitudin aspect howev cross lag relat two unknown studi investig cross lag associ ct cognit perform attitudin belief primari student three wave longitudin design paper report first two wave data collect month time interv involv sampl student age wave student ask complet ct cognit test self report attitud survey cross lag analys result show prior ct cognit perform significantli predict later learn attitud path remain signific control students’ demograph learn experi studi contribut literatur pioneer document cross lag relat students’ cognit attitudin attain context ct educ"
  },
  {
    "doc_id": "10148557",
    "abstract_original": "As Computational Thinking (CT) becomes an increasingly necessary skill, it is crucial to examine how CT can be taught in the classroom. Pedagogical Content Knowledge (PCK) is a practical concept to examine how CT education can be developed. This systematic literature review presents the discussion of K-8 teachers’ PCK in the implementation of CT- related activities in the classroom. Studies were extracted from Google Scholar’s database. Among these studies, 14 articles were deemed to be relevant for a more in-depth examination. Findings from this preliminary literature review suggest that teachers have clear purposes and goals for teaching CT and various instructional strategies for teaching CT. However, the existing studies lacked information about teachers’ knowledge and beliefs regarding the methods for assessing students’ CT. Practical implications and future directions to enhance K-8 teachers’ PCK on CT are discussed in this study.",
    "abstract_processed": "comput think ct becom increasingli necessari skill crucial examin ct taught classroom pedagog content knowledg pck practic concept examin ct educ develop systemat literatur review present discuss k teachers’ pck implement ct relat activ classroom studi extract googl scholar’ databas among studi articl deem relev depth examin find preliminari literatur review suggest teacher clear purpos goal teach ct variou instruct strategi teach ct howev exist studi lack inform teachers’ knowledg belief regard method assess students’ ct practic implic futur direct enhanc k teachers’ pck ct discuss studi"
  },
  {
    "doc_id": "10151565",
    "abstract_original": "Depigmentation of the skin is a primary symptom of the vitiligo disorder. By reducing their self-esteem and causing them psychological distress, it lowers patients’ quality of life. The study made use of a number of computational tools, including Cyto Hubba, BioVia Discovery Studio through, Open babel, Drug bank, Avogadro, Auto dock, and Protein-Interaction Ligand profiler. The interaction between 6AAH and (Myristic acid, Heptadecanoic acid, Riboflavin, Propanol, 2,6-Dimethyl-7-octene-2,3,6-trio1) has been examined in this study using Cyto Hubba and PILP clustering interactions, followed by Molecular Docking of Protein and Ligand. Due to its polygenic nature, vitiligo is frequently associated with a number of autoimmune or autoinflammatory disorders, including thyroid disease, psoriasis, atopic dermatitis, diabetes mellitus, and pernicious anaemia. Hence, it is conceivable to think about riboflavin as a possible drug for Vitiligo treatment. The findings imply that riboflavin laboratory tests reveal its inhibitory potential on skin depigmentation",
    "abstract_processed": "depigment skin primari symptom vitiligo disord reduc self esteem caus psycholog distress lower patients’ qualiti life studi made use number comput tool includ cyto hubba biovia discoveri studio open babel drug bank avogadro auto dock protein interact ligand profil interact aah myrist acid heptadecano acid riboflavin propanol dimethyl octen trio examin studi use cyto hubba pilp cluster interact follow molecular dock protein ligand due polygen natur vitiligo frequent associ number autoimmun autoinflammatori disord includ thyroid diseas psoriasi atop dermat diabet mellitu pernici anaemia henc conceiv think riboflavin possibl drug vitiligo treatment find impli riboflavin laboratori test reveal inhibitori potenti skin depigment"
  },
  {
    "doc_id": "10152154",
    "abstract_original": "Supported by a state grant, our team of researchers (consisting of both Computer Science faculty and Teacher Education faculty) is offering a series of Professional Development sessions to K-8 teachers. These Professional Development (or PD) sessions are meant to help K-8 teachers develop their understanding of core computing concepts (such as algorithms, programming, data analysis, and networks) and thereby develop strong computer science programs for their students. In order to offer effective and meaningful Professional Development (PD) sessions, our research team first intended to understand the perceptions and experiences of K-8 teachers about Computer Science (CS) and Computational Thinking (CT) education. This paper presents the results of a K-8 teacher survey that we conducted as a pre-cursor to our PD series. The results of this survey provided valuable insights about elementary and middle-school teachers' perceptions of computer science education, self-perception of their ability to teach and learn CS, and understanding of CS discipline and those who typically engage in CS activities. The impact of teachers' perceptions impact how leaders in education and the CS industry can meet the needs of teachers, who in turn can meet the growing demand of CS education in K-8 schools.",
    "abstract_processed": "support state grant team research consist comput scienc faculti teacher educ faculti offer seri profession develop session k teacher profession develop pd session meant help k teacher develop understand core comput concept algorithm program data analysi network therebi develop strong comput scienc program student order offer effect meaning profession develop pd session research team first intend understand percept experi k teacher comput scienc cs comput think ct educ paper present result k teacher survey conduct pre cursor pd seri result survey provid valuabl insight elementari middl school teacher percept comput scienc educ self percept abil teach learn cs understand cs disciplin typic engag cs activ impact teacher percept impact leader educ cs industri meet need teacher turn meet grow demand cs educ k school"
  },
  {
    "doc_id": "10156061",
    "abstract_original": "Reinforcement learning (RL) is effective in optimizing cumulative rewards, and it provides policies that account for how the system will interact over the future with the agent. However, when more than one learning agents are present, developing efficient collaborations/interactions is a challenging issue; not every agent may have access to the same amount of information and computational resources; not every agent may make the same assumptions about the decision-making mechanisms of one another; and many agents may not even be aware of the existence of other agents. These cognitive and physical limitations can be seen as a form of bounded rationality. Several recent experimental and empirical studies have found that the initial responses of decision-makers in multi-player games are often far from the equilibrium, which is very often out-predicted by structural non-equilibrium (e.g., cognitive hierarchy) models. This is because non-equilibrium play models allow for players who are boundedly rational and have limited information, so that their policy is not necessarily a best response to the actual adjustment laws of other agents. This tutorial talk will present computationally and communicationally efficient approaches for decision-making in boundedly rational stochastic games. Motivated by the inherent complexity of computing Nash equilibria, as well as the innate tendency of agents to choose non-equilibrium strategies, two models of bounded rationality based on recursive reasoning will be described. In the first model, named level-k thinking, each agent assumes that everyone else has a cognitive level immediately lower than theirs, and—given such an assumption—chooses their policy to be a best response to them. In the second model, named cognitive hierarchy, each agent conjectures that the rest of the agents have a cognitive level that is lower than theirs, but follows a distribution instead of being deterministic. To explicitly compute the boundedly rational policies, this tutorial talk will present both a level-recursive as well as a level-paralleled algorithm, where the latter can have an overall reduced computational complexity. For more information please see the main tutorial paper [1].",
    "abstract_processed": "reinforc learn rl effect optim cumul reward provid polici account system interact futur agent howev one learn agent present develop effici collabor interact challeng issu everi agent may access amount inform comput resourc everi agent may make assumpt decis make mechan one anoth mani agent may even awar exist agent cognit physic limit seen form bound ration sever recent experiment empir studi found initi respons decis maker multi player game often far equilibrium often predict structur non equilibrium e g cognit hierarchi model non equilibrium play model allow player boundedli ration limit inform polici necessarili best respons actual adjust law agent tutori talk present comput commun effici approach decis make boundedli ration stochast game motiv inher complex comput nash equilibria well innat tendenc agent choos non equilibrium strategi two model bound ration base recurs reason describ first model name level k think agent assum everyon els cognit level immedi lower and—given assumption—choos polici best respons second model name cognit hierarchi agent conjectur rest agent cognit level lower follow distribut instead determinist explicitli comput boundedli ration polici tutori talk present level recurs well level parallel algorithm latter overal reduc comput complex inform pleas see main tutori paper"
  },
  {
    "doc_id": "10156712",
    "abstract_original": "We live in the age of Artificial Intelligence (AI) which permeates all aspects of our lives, from spam filtering to image classification on social media. While it is already well-established in industries ranging from heavy manufacturing to the IT field, its impact on the design professions remains relatively unexplored. This essay explores the use of neural networks in architecture, which is arguably the first genuinely 21st-century design technique and discusses experiments with Generative Adversarial Networks (GANs) to generate unexplored futuristic possible noble forms in architecture. In this way this paper also raises the question if machine can generate noble forms through its creative data optimization process. In this process one of the most famous heritages building of Bangladesh 60 dome mosque (Shat Gombuj Moshjid) has been examined to get expected result. Furthermore, this paper discusses how AI can be used as a personalized tool for architects to generate and express design ideas. It evaluates popular datasets for architectural purposes and considers the potential outcomes of experiments. The input of AI in the design process could usher in a new era of architectural design. As data continues to grow, it is shaping our collective future. Therefore, this paper concludes that it is essential to prepare our trained datasets to accept the future which might open up an extraordinary new chapter in the architectural realm.",
    "abstract_processed": "live age artifici intellig ai permeat aspect live spam filter imag classif social media alreadi well establish industri rang heavi manufactur field impact design profess remain rel unexplor essay explor use neural network architectur arguabl first genuin st centuri design techniqu discuss experi gener adversari network gan gener unexplor futurist possibl nobl form architectur way paper also rais question machin gener nobl form creativ data optim process process one famou heritag build bangladesh dome mosqu shat gombuj moshjid examin get expect result furthermor paper discuss ai use person tool architect gener express design idea evalu popular dataset architectur purpos consid potenti outcom experi input ai design process could usher new era architectur design data continu grow shape collect futur therefor paper conclud essenti prepar train dataset accept futur might open extraordinari new chapter architectur realm"
  },
  {
    "doc_id": "10158192",
    "abstract_original": "The application of virtual reality technology for landscape planning and design, designers will have a more intuitive and interactive space experience, but also better reflect the authenticity of the landscape scene, so as to help designers constantly improve the design scheme. In addition, through the virtual reality system, the audience can watch the scheme design from multiple angles, which not only deepens the understanding of the designer’s design intention, but also makes them feel as if they are on the scene. This paper takes virtual reality technology as the research object and focuses on its specific application in assisting landscape planning and design. Firstly, the literature on computer aided technology and its application at home and abroad is analyzed and studied. It also introduces modern landscape planning and design, including the thinking of landscape planning and design, advantages of computer-aided landscape planning and design and related design software. Secondly, the concept and theory of virtual reality technology are simply analyzed, and the application of virtual reality technology in each stage of landscape architecture is analyzed, and the key technologies of virtual reality technology assisted landscape architecture design are introduced emphatically. Thirdly, it introduces the software of landscape planning and design assisted by virtual reality technology, and analyzes its practical application, such as SketchUp modeling technology, Lumion3D technology and baking technology. Finally, from the actual case, the specific operation of landscape architecture design assisted by virtual reality technology is analyzed and studied.",
    "abstract_processed": "applic virtual realiti technolog landscap plan design design intuit interact space experi also better reflect authent landscap scene help design constantli improv design scheme addit virtual realiti system audienc watch scheme design multipl angl deepen understand designer’ design intent also make feel scene paper take virtual realiti technolog research object focus specif applic assist landscap plan design firstli literatur comput aid technolog applic home abroad analyz studi also introduc modern landscap plan design includ think landscap plan design advantag comput aid landscap plan design relat design softwar secondli concept theori virtual realiti technolog simpli analyz applic virtual realiti technolog stage landscap architectur analyz key technolog virtual realiti technolog assist landscap architectur design introduc emphat thirdli introduc softwar landscap plan design assist virtual realiti technolog analyz practic applic sketchup model technolog lumion technolog bake technolog final actual case specif oper landscap architectur design assist virtual realiti technolog analyz studi"
  },
  {
    "doc_id": "10158548",
    "abstract_original": "In the competitive economy of the 21st century, innovation and the attitude to innovation are key factors. The depletion of traditional natural resources in today’s fast-changing world has virtually eliminated the former engine of economic growth, and a new approach is needed to enable economic actors to cope with the new environment. New solutions are the only way to overcome the anomaly of natural resources. It is essential that all economic actors, from micro to large enterprises, can play their part in this process. It is therefore of the utmost importance that the conditions are created in the near future to promote and stimulate innovation. The aim of this study is to present the Hungarian SME sector’s view on the factors that stimulate innovation, assessing the potential characteristics that can contribute to these processes and behaviours.",
    "abstract_processed": "competit economi st centuri innov attitud innov key factor deplet tradit natur resourc today’ fast chang world virtual elimin former engin econom growth new approach need enabl econom actor cope new environ new solut way overcom anomali natur resourc essenti econom actor micro larg enterpris play part process therefor utmost import condit creat near futur promot stimul innov aim studi present hungarian sme sector’ view factor stimul innov assess potenti characterist contribut process behaviour"
  },
  {
    "doc_id": "10158552",
    "abstract_original": "The events of recent years have shed new light on the crisis and change management practices of economic actors. It has been a truism that actors who are more receptive to change can be more successful and efficient than their peers in business markets. Perhaps the most significant changes in recent years have confirmed this even more. One only has to think of the impact of pandemic COVID-19, the energy crisis or the Russian-Ukrainian conflict. In a very short period of time, these events have brought about very significant changes and their impact has been largely negative for most economic actors. If it has not been sufficiently understood so far why it can be important to adapt to changes in a timely and appropriate way, or why good crisis management practices can be important, perhaps everyone will now. Meanwhile, other trends are shaping the global economy and will have an impact on the future state of the economy and society. Examples include sustainability (or the green transition) and digitalisation. Two global changes that will certainly have a long-term impact on society and business processes. No one can afford the luxury of ignoring these changes. What is more, the most competitive economic players are seeking to turn them to their advantage and to reap the benefits of sustainability or digitalisation. It is clear that our world has become faster and more complex than ever before. More and more things are changing around us, with ever more intense consequences. We need to recognise in time how we can respond to changing environmental conditions or circumstances. This is the subject of the present paper, which, after a brief literature review, draws on research findings to illustrate the importance and relevance of digitalisation.",
    "abstract_processed": "event recent year shed new light crisi chang manag practic econom actor truism actor recept chang success effici peer busi market perhap signific chang recent year confirm even one think impact pandem covid energi crisi russian ukrainian conflict short period time event brought signific chang impact larg neg econom actor suffici understood far import adapt chang time appropri way good crisi manag practic import perhap everyon meanwhil trend shape global economi impact futur state economi societi exampl includ sustain green transit digitalis two global chang certainli long term impact societi busi process one afford luxuri ignor chang competit econom player seek turn advantag reap benefit sustain digitalis clear world becom faster complex ever thing chang around us ever intens consequ need recognis time respond chang environment condit circumst subject present paper brief literatur review draw research find illustr import relev digitalis"
  },
  {
    "doc_id": "10158582",
    "abstract_original": "Aim of the study is to show the importance and necessity of the course “Philosophy” in a medical university. This study elaborates on the philosophy role in the educational, humanizing aspect in the formation of a holistic personality of the future doctors. Questions about “crisis” of philosophy in medicine, a new scientific cognitive system creation necessity, ethical aspects in medicine, Mathematical modeling of moral structures represented. The ideological atmosphere in which the formation of the personality of a doctor is carried out today is influenced by the latest trends associated with the latest achievements in the field of biotechnology, which can even generate threats and risks to the biological nature of man.",
    "abstract_processed": "aim studi show import necess cours “philosophy” medic univers studi elabor philosophi role educ human aspect format holist person futur doctor question “crisis” philosophi medicin new scientif cognit system creation necess ethic aspect medicin mathemat model moral structur repres ideolog atmospher format person doctor carri today influenc latest trend associ latest achiev field biotechnolog even gener threat risk biolog natur man"
  },
  {
    "doc_id": "10158648",
    "abstract_original": "Our qualitative research was inspired by the 75-year long Harvard University Happiness Survey.In October-November 2022, 65 young marketing undergraduates from Generation Z were asked what value and happiness meant to them. Today’s 20-year-olds were forced to live one tenth of their lives, i.e., 2 years, locked in their homes, isolated from friends and university peers, during the COVID -19 pandemic. Hardly had they recovered from the threat of the pandemic, from their grief, when they were hit by another trauma, as were other members of society. War in neighbouring Ukraine, serious energy crisis, climate crisis, skyrocketing inflation, uncertain future…The focus of the research was therefore on the question of what kind of life they would be satisfied with, and what they would do to achieve the quality of life they want. What goals do they have, what do they want to achieve in their lives? Are human relationships important to them? As our interviewees were marketing students, we asked them if they were happy buying a product or using a service, how important is the experience of buying a product or service to them? How do they think about this topic, what strategy do they want to follow as marketing employees based on their life experiences? Their way of thinking is also decisive at a societal level.",
    "abstract_processed": "qualit research inspir year long harvard univers happi survey octob novemb young market undergradu gener z ask valu happi meant today’ year old forc live one tenth live e year lock home isol friend univers peer covid pandem hardli recov threat pandem grief hit anoth trauma member societi war neighbour ukrain seriou energi crisi climat crisi skyrocket inflat uncertain future…th focu research therefor question kind life would satisfi would achiev qualiti life want goal want achiev live human relationship import interviewe market student ask happi buy product use servic import experi buy product servic think topic strategi want follow market employe base life experi way think also decis societ level"
  },
  {
    "doc_id": "10158658",
    "abstract_original": "With the appearance of 2D graphical user interfaces in the 1980s, users began to carry out most operations on 2D icon-based interfaces instead of using line-based terminals. With the emergence of smartphones in the 2010s, the notion of portable 2D graphical user interfaces was born, and by today, users accessing digital services are no longer tethered to a single location. All of these advances have led to immense changes in our conceptualization of digital information systems, the effects of which are difficult to overestimate. Recent developments in virtual and augmented reality (VR/AR), as well as in Internet of Things (IoT) and artificial intelligence (AI) are poised to lead to the next major breakthrough in this series of cognitive expansions, bringing to the forefront portable, context-aware spatial interfaces. A consequence of these developments is that users are expecting to be able to access a growing multitude and variety of digital content in ways that are increasingly contextualized and personalized, i.e., relevant to the time, location and topic from the perspective of the users’ personal history. In this paper, we propose an adaptive content labeling and storage model that is suitable to these challenges. Our model, called the Graph-Indexed Tensor Store (GITS) has the benefits of being adaptive and personalized, while also allowing for content retrieval to be carried out based on associative search operations. In a preliminary analysis of the model, we address the challenges of what we refer to as syntactic, semantic and pragmatic saturation, and provide ways to quantity and further explore their effects.",
    "abstract_processed": "appear graphic user interfac user began carri oper icon base interfac instead use line base termin emerg smartphon notion portabl graphic user interfac born today user access digit servic longer tether singl locat advanc led immens chang conceptu digit inform system effect difficult overestim recent develop virtual augment realiti vr ar well internet thing iot artifici intellig ai pois lead next major breakthrough seri cognit expans bring forefront portabl context awar spatial interfac consequ develop user expect abl access grow multitud varieti digit content way increasingli contextu person e relev time locat topic perspect users’ person histori paper propos adapt content label storag model suitabl challeng model call graph index tensor store git benefit adapt person also allow content retriev carri base associ search oper preliminari analysi model address challeng refer syntact semant pragmat satur provid way quantiti explor effect"
  },
  {
    "doc_id": "10158668",
    "abstract_original": "Today’s technological developments are also having an impact on education. In higher education, there are more and more innovations in content and methodology, such as educational robots, which can be used not only for teaching programming, but also as teaching assistants and pedagogical assistants. Tutor robots offer new opportunities for curriculum development, motivating students, stimulating interest and developing soft skills, while preparing young people to use the latest technological tools. In our online survey, conducted in summer 2022, we explored the views of educators in 14 countries on the characteristics of robot-supported innovation in higher education. The results of the survey show that educators are open to educational innovations. Educational robots are mainly used for teaching programming. They believe that the use of social robots significantly improves students’ creativity and self-expression. The results of this research have shown that the use of educational social robots is an excellent opportunity for methodological innovation and provides scope for experimental teaching.",
    "abstract_processed": "today’ technolog develop also impact educ higher educ innov content methodolog educ robot use teach program also teach assist pedagog assist tutor robot offer new opportun curriculum develop motiv student stimul interest develop soft skill prepar young peopl use latest technolog tool onlin survey conduct summer explor view educ countri characterist robot support innov higher educ result survey show educ open educ innov educ robot mainli use teach program believ use social robot significantli improv students’ creativ self express result research shown use educ social robot excel opportun methodolog innov provid scope experiment teach"
  },
  {
    "doc_id": "10159750",
    "abstract_original": "Critical and computational thinking in primary and secondary education in recent years shows growing importance in methodical approaches used in the classroom. Although many examples exist for using critical and computational thinking in STEM educational area, the social sciences i.e., non-STEM areas were somehow left out due to the relatively more difficult design of such content, especially in the part of the development of computational thinking. In that context, in this paper we present one way of using critical and computational thinking in non-STEM education, more specifically on the example of historical data sources, through the use of programming in Python. As an example, we use historical data for Trans-Atlantic Slave Trade routes, that were the largest long-distance coerced movement of people in history up to the mid-nineteenth century, for connecting concepts of databases, Data Science and programming for development of critical and computational thinking in context of history science. This way of using modern approaches in classroom should give teachers and pupils a broader picture of importance of interdisciplinary education for critical and computational thinking development through STEM and non-STEM classes that give pupils novel skills needed for future labor market.",
    "abstract_processed": "critic comput think primari secondari educ recent year show grow import method approach use classroom although mani exampl exist use critic comput think stem educ area social scienc e non stem area somehow left due rel difficult design content especi part develop comput think context paper present one way use critic comput think non stem educ specif exampl histor data sourc use program python exampl use histor data tran atlant slave trade rout largest long distanc coerc movement peopl histori mid nineteenth centuri connect concept databas data scienc program develop critic comput think context histori scienc way use modern approach classroom give teacher pupil broader pictur import interdisciplinari educ critic comput think develop stem non stem class give pupil novel skill need futur labor market"
  },
  {
    "doc_id": "10165540",
    "abstract_original": "ChatGPT is a pre-trained model in the field of natural language processing. As a generative model, the technical foundation of ChatGPT is a deep learning model called the \"Generative Adversarial Network\". The pre-trained large model architecture of ChatGPT can be summarized as \"corpus system+pre-training+fine-tuning\". Under the combined force of massive data, super large models, and enormous computing power, chatGPT has ushered in the era of universal artificial intelligence and formed a new paradigm of generative AI development. Generative AI products represented by ChatGPT will promote the development and implementation of Artificial Intelligence Generated Content (AIGC), and trigger significant changes in areas such as information acquisition methods and economic and social cost structures",
    "abstract_processed": "chatgpt pre train model field natur languag process gener model technic foundat chatgpt deep learn model call gener adversari network pre train larg model architectur chatgpt summar corpu system pre train fine tune combin forc massiv data super larg model enorm comput power chatgpt usher era univers artifici intellig form new paradigm gener ai develop gener ai product repres chatgpt promot develop implement artifici intellig gener content aigc trigger signific chang area inform acquisit method econom social cost structur"
  },
  {
    "doc_id": "10168286",
    "abstract_original": "The main aspect powering GNNs is the multi-layer network architecture to learn the nonlinear representation for graph learning task. The core operation in GNNs is the message propagation in which each node updates its information by aggregating the information from its neighbors. Existing GNNs usually adopt either linear neighborhood aggregation (e.g. mean, sum) or max aggregator in their message propagation. 1) For linear aggregators, the whole nonlinearity and network's capacity of GNNs are generally limited because deeper GNNs usually suffer from the over-smoothing issue due to their inherent information propagation mechanism. Also, linear aggregators are usually vulnerable to the spatial perturbations. 2) For max aggregator, it usually fails to be aware of the detailed information of node representations within neighborhood. To overcome these issues, we re-think the message propagation mechanism in GNNs and develop the new general nonlinear aggregators for neighborhood information aggregation in GNNs. One main aspect of our nonlinear aggregators is that they all provide the optimally balanced aggregator between max and mean/sum aggregators. Thus, they can inherit both i) high nonlinearity that enhances network's capacity, robustness and ii) detail-sensitivity that is aware of the detailed information of node representations in GNNs’ message propagation. Promising experiments show the effectiveness, high capacity and robustness of the proposed methods.",
    "abstract_processed": "main aspect power gnn multi layer network architectur learn nonlinear represent graph learn task core oper gnn messag propag node updat inform aggreg inform neighbor exist gnn usual adopt either linear neighborhood aggreg e g mean sum max aggreg messag propag linear aggreg whole nonlinear network capac gnn gener limit deeper gnn usual suffer smooth issu due inher inform propag mechan also linear aggreg usual vulner spatial perturb max aggreg usual fail awar detail inform node represent within neighborhood overcom issu think messag propag mechan gnn develop new gener nonlinear aggreg neighborhood inform aggreg gnn one main aspect nonlinear aggreg provid optim balanc aggreg max mean sum aggreg thu inherit high nonlinear enhanc network capac robust ii detail sensit awar detail inform node represent gnns’ messag propag promis experi show effect high capac robust propos method"
  },
  {
    "doc_id": "10169436",
    "abstract_original": "Suppose that you are the boss of a company and you want to accomplish a specific task through two groups of employees. Where, one group involves old and expert employees and the other consists of young and inexperienced ones. In this case, we think that your best choice is to establish a teamwork from both groups to ensure this mission will be done rapidly with high quality, of course, if the team members could work in consistence with each other. In this research, we are interested in investigating the benefit of applying this concept in search with two groups, one consists of a set of informed algorithms with different complexity based on their search mechanism, and the other group includes a collection of heuristic functions has varying degree of simplicity based on their informedness. The main goal of our study is the distinguishing of work teams that should be used to improve the efficiency of exploring the search space of a sliding-tile puzzle. The actual computational time of our experiments proved that choosing a proper teamwork can rapidly find optimal solutions by professionally exploiting the heuristic informedness and reducing the algorithm complexity.",
    "abstract_processed": "suppos boss compani want accomplish specif task two group employe one group involv old expert employe consist young inexperienc one case think best choic establish teamwork group ensur mission done rapidli high qualiti cours team member could work consist research interest investig benefit appli concept search two group one consist set inform algorithm differ complex base search mechan group includ collect heurist function vari degre simplic base informed main goal studi distinguish work team use improv effici explor search space slide tile puzzl actual comput time experi prove choos proper teamwork rapidli find optim solut profession exploit heurist informed reduc algorithm complex"
  },
  {
    "doc_id": "10169561",
    "abstract_original": "The revolution of the Internet of Things (IoT) is increasing dramatically, where everything has become smart, and this new technology has helped facilitate plenty of things for humanity and made life easier in terms of applications and machines that think like humans using artificial intelligence. Currently, many applications of the Internet of Things affect our daily lives. Although the Internet of Things has brought us ease of life, it has brought many challenges related to security. However, solving these issues and challenges requires a high degree of skills. The approach that addresses the increment of cybercrimes is IoT Forensics. IoT forensics is a call for investigating and mitigating these cybercrimes. In this study, we overview the basics of IoT and present an illustrative study of digital forensics and IoT Forensics, then discussing that with some differences between IoT Forensics, Digital Forensics, and IoT Security, and an overview of the Process of IoT Forensics have been discussed. In addition, this work focuses on recent research work from 2018 onwards in terms of IoT Forensics models, frameworks, analysis, and use cases; finally, IoT and Digital Forensics Challenges and open issues have been discussed.",
    "abstract_processed": "revolut internet thing iot increas dramat everyth becom smart new technolog help facilit plenti thing human made life easier term applic machin think like human use artifici intellig current mani applic internet thing affect daili live although internet thing brought us eas life brought mani challeng relat secur howev solv issu challeng requir high degre skill approach address increment cybercrim iot forens iot forens call investig mitig cybercrim studi overview basic iot present illustr studi digit forens iot forens discuss differ iot forens digit forens iot secur overview process iot forens discuss addit work focus recent research work onward term iot forens model framework analysi use case final iot digit forens challeng open issu discuss"
  },
  {
    "doc_id": "10170028",
    "abstract_original": "Learning how to program has become a trend in Taiwan even for younger students. IoT is a topic to interest new learners in programming. Given the fact that there are already plenty of tools e.g. Micro:bit and Arduino designed to make IoT programming simple and full of fun, it is usually believed that adopting IoT topics is beneficial for younger students learning how to program. However, younger students’ learning performance in programming courses varies dramatically depending on the tools mentioned above. There are many metrics to predict the academic achievements of young students. Among them, the operation span is an objective one. Operation span mainly assesses one’s working memory capacity. According to the research results, one’s working memory capacity predicts individual high-level cognitive performance. Furthermore, students’ cognitive performance was highly related to their learning performance in programming courses. Nevertheless, the relationship between operation span and the learning performance of programming courses for junior high school students has not been researched yet. In Taiwan, computer programming has already been included as a mandatory subject in the junior high school curriculum for developing students' computational thinking and problem-solving skills. As such, understanding the relationship between OSPAN and programming performance is crucial for effective teaching and learning in this subject. We designed an experiment for an IoT-related after-school club in a junior high school to evaluate the relationship between students’ operation span and learning performance.",
    "abstract_processed": "learn program becom trend taiwan even younger student iot topic interest new learner program given fact alreadi plenti tool e g micro bit arduino design make iot program simpl full fun usual believ adopt iot topic benefici younger student learn program howev younger students’ learn perform program cours vari dramat depend tool mention mani metric predict academ achiev young student among oper span object one oper span mainli assess one’ work memori capac accord research result one’ work memori capac predict individu high level cognit perform furthermor students’ cognit perform highli relat learn perform program cours nevertheless relationship oper span learn perform program cours junior high school student research yet taiwan comput program alreadi includ mandatori subject junior high school curriculum develop student comput think problem solv skill understand relationship ospan program perform crucial effect teach learn subject design experi iot relat school club junior high school evalu relationship students’ oper span learn perform"
  },
  {
    "doc_id": "10170138",
    "abstract_original": "The field of machine learning and artificial intelligence is growing rapidly. The deep neural network is a field of ML which is showing greater possibility. The deep neural network has been widely acknowledged as being in a golden age and advancing with the advent of new technologies. It is slowly becoming the leader of the technological world in artificial intelligence. The models which are built by machine learning algorithms with great accuracy help in every sector of human evolution. Image and audio processing is done through many algorithms to intensify its behavioral pattern. The development of modern art is largely dependent on the painters who are developing the style. The Deep Dream algorithm can also do the artistic creation of the image and audio. The deep dream algorithm which googles engineer Alexander Mordvintsevin built in the year 2015. It enhances the patterns in the multimedia through algorithmic pareidolia. It creates a dream-like effect. It gives a new vision of hallucinations to images. This could be used in the health sector for the purpose of detecting diseases and defects through scans of the patients. It is redefining lower-definition multimedia to higher-definition multimedia. Previous model were able to only generate one of the multimedia format. Proposed system will be able to create multimedia based on DeepDream and link different formats together so that they appear to be generated together.",
    "abstract_processed": "field machin learn artifici intellig grow rapidli deep neural network field ml show greater possibl deep neural network wide acknowledg golden age advanc advent new technolog slowli becom leader technolog world artifici intellig model built machin learn algorithm great accuraci help everi sector human evolut imag audio process done mani algorithm intensifi behavior pattern develop modern art larg depend painter develop style deep dream algorithm also artist creation imag audio deep dream algorithm googl engin alexand mordvintsevin built year enhanc pattern multimedia algorithm pareidolia creat dream like effect give new vision hallucin imag could use health sector purpos detect diseas defect scan patient redefin lower definit multimedia higher definit multimedia previou model abl gener one multimedia format propos system abl creat multimedia base deepdream link differ format togeth appear gener togeth"
  },
  {
    "doc_id": "10171767",
    "abstract_original": "Operational risk analysis of the Protections and Automations used in Power Systems is analyzed with the help of a composite model using Fuzzy Sets-Event Tree Stochastic model. On this purpose we built a complex algorithm and computer application, and we made the configuration of the analyzed system. We exemplified the analysis algorithm for the study case of the power electric protection system-SP for the example of the very used radial distribution and curled distribution. The paper exemplifies the critical analysis of the faults including abnormal workings. The most important power elements need the risk analysis, and its random events adopt with success the Fuzzy logic which is added to the Event Tree method. This allows us to build the realistic model performance-dependability, so important technical operational Risk results are computed.",
    "abstract_processed": "oper risk analysi protect autom use power system analyz help composit model use fuzzi set event tree stochast model purpos built complex algorithm comput applic made configur analyz system exemplifi analysi algorithm studi case power electr protect system sp exampl use radial distribut curl distribut paper exemplifi critic analysi fault includ abnorm work import power element need risk analysi random event adopt success fuzzi logic ad event tree method allow us build realist model perform depend import technic oper risk result comput"
  },
  {
    "doc_id": "10172317",
    "abstract_original": "Multihop reasoning is essential in knowledge graph (KG) research and applications. Current methods rely on specific KG entities, while human cognition operates at a more abstract level. This article proposes a category-aware rule-based (CRule) approach for symbolic multihop reasoning. Specifically, given a KG, CRule first categorizes entities and constructs a category-aware KG; it then uses rules retrieved from the categorized KG to perform multihop reasoning on the original KG. Experiments on five datasets show that CRule is simple, is effective, and combines the advantages of symbolic and neural network methods. It overcomes symbolic reasoning’s complexity limitations, can perform reasoning on KGs of more than 300,000 edges, and can be three times more efficient than neural network models.",
    "abstract_processed": "multihop reason essenti knowledg graph kg research applic current method reli specif kg entiti human cognit oper abstract level articl propos categori awar rule base crule approach symbol multihop reason specif given kg crule first categor entiti construct categori awar kg use rule retriev categor kg perform multihop reason origin kg experi five dataset show crule simpl effect combin advantag symbol neural network method overcom symbol reasoning’ complex limit perform reason kg edg three time effici neural network model"
  },
  {
    "doc_id": "10173917",
    "abstract_original": "Software engineering for mobile applications has its own challenges, different from when we engineer software just for desktop environments. With the emergence of smart things (including smart everyday objects embedded with connectivity, computational ability, sensors, and sometimes actuators, urban robots such as delivery and cleaning robots, smart street lighting, smart vehicles, and smart park benches, and so on) not just within the home but in public spaces, there is a need to consider software engineering challenges for software on such things. Human-centred software engineering and work on ethical behaviours in smart things will need to come together, even as we continue to understand what it takes to effectively develop software (and systems) for such emerging devices. In order to demonstrate how software (and systems) for intelligent devices in public places might be developed, findings from a quantitative survey we performed are discussed in this study. The survey was designed such that the questions focused on the socio-ethical behaviours of smart devices when interacting with people in public places. The survey was based on a supermarket scenario where the participants had to answer the different questions in the questionnaire. There were 250 participants who only completed part of the survey; of them, 60 participants finished it in full. The complete replies have been examined and analysed in this paper. To determine how people feel about employing smart technology in public places, a variety of smart devices, including robots, smart cameras, smart speakers, and smart trolleys, are utilised in the survey questions. According to the findings, more than 80 percent of respondents think it important for smart gadgets to be socially-aware and ethical in public places.General Abstract This paper examines the survey results conducted to explore if smart devices such as robots or smart cameras can be deployed in public areas. The respondents reply to survey questions asking them whether they believe it is crucial to keep smart robots, smart carts, or any other smart devices in the supermarket. The survey’s questions are constructed in such a manner that participants are asked to imagine themselves as either a customer shopping for groceries at a store or a manager running the business and dealing with the friendly robot. This survey was created with the intention of thinking carefully about how intelligent software systems may be designed from the standpoint of software engineering for public settings. Later in this article, the survey findings and insights are discussed.",
    "abstract_processed": "softwar engin mobil applic challeng differ engin softwar desktop environ emerg smart thing includ smart everyday object embed connect comput abil sensor sometim actuat urban robot deliveri clean robot smart street light smart vehicl smart park bench within home public space need consid softwar engin challeng softwar thing human centr softwar engin work ethic behaviour smart thing need come togeth even continu understand take effect develop softwar system emerg devic order demonstr softwar system intellig devic public place might develop find quantit survey perform discuss studi survey design question focus socio ethic behaviour smart devic interact peopl public place survey base supermarket scenario particip answer differ question questionnair particip complet part survey particip finish full complet repli examin analys paper determin peopl feel employ smart technolog public place varieti smart devic includ robot smart camera smart speaker smart trolley utilis survey question accord find percent respond think import smart gadget social awar ethic public place gener abstract paper examin survey result conduct explor smart devic robot smart camera deploy public area respond repli survey question ask whether believ crucial keep smart robot smart cart smart devic supermarket survey’ question construct manner particip ask imagin either custom shop groceri store manag run busi deal friendli robot survey creat intent think care intellig softwar system may design standpoint softwar engin public set later articl survey find insight discuss"
  },
  {
    "doc_id": "10179136",
    "abstract_original": "Recent advances in text-conditioned generative models have provided us with neural networks capable of creating images of astonishing quality, be they realistic, abstract, or even creative. These models have in common that (more or less explicitly) they all aim to produce a high-quality one-off output given certain conditions, and in that they are not well suited for a creative collaboration framework. Drawing on theories from cognitive science that model how professional designers and artists think, we argue how this setting differs from the former and introduce CICADA: a Collaborative, Interactive Context-Aware Drawing Agent. CICADA uses a vector-based synthesis-by-optimisation method to take a partial sketch (such as might be provided by a user) and develop it towards a goal by adding and/or sensibly modifying traces. Given that this topic has been scarcely explored, we also introduce a way to evaluate desired characteristics of a model in this context by means of proposing a diversity measure. CICADA is shown to produce sketches of quality comparable to a human user’s, enhanced diversity and most importantly to be able to cope with change by continuing the sketch minding the user's contributions in a flexible manner.",
    "abstract_processed": "recent advanc text condit gener model provid us neural network capabl creat imag astonish qualiti realist abstract even creativ model common less explicitli aim produc high qualiti one output given certain condit well suit creativ collabor framework draw theori cognit scienc model profession design artist think argu set differ former introduc cicada collabor interact context awar draw agent cicada use vector base synthesi optimis method take partial sketch might provid user develop toward goal ad sensibl modifi trace given topic scarc explor also introduc way evalu desir characterist model context mean propos divers measur cicada shown produc sketch qualiti compar human user’ enhanc divers importantli abl cope chang continu sketch mind user contribut flexibl manner"
  },
  {
    "doc_id": "10179639",
    "abstract_original": "Thinking about life without using the internet is impossible. Internet and network have become a part of our daily life. Sharing confidential information through internet and doing lots of important and confidential official work is done easily by using internet. One side internet has made life easy and another side is it cheap and fast compare to other methods such as letter or fax. With the growing technology some third party cybercriminals and hackers are trying to use the internet for their personal gain and harm the users or organizations. Malware is one of those malicious software whose sole purpose is to harm the user, system or organization and steal information and sent it to third party for harmful use. It is necessary to find this malicious software and prevent them from harming through the internet. The proposed model detects the harmful malware lurking on the internet and prevent the user and system from any potential harmful effect. The model is very simple and cost effective yet very efficient. the accuracy of the model is 99.72%.",
    "abstract_processed": "think life without use internet imposs internet network becom part daili life share confidenti inform internet lot import confidenti offici work done easili use internet one side internet made life easi anoth side cheap fast compar method letter fax grow technolog third parti cybercrimin hacker tri use internet person gain harm user organ malwar one malici softwar whose sole purpos harm user system organ steal inform sent third parti harm use necessari find malici softwar prevent harm internet propos model detect harm malwar lurk internet prevent user system potenti harm effect model simpl cost effect yet effici accuraci model"
  },
  {
    "doc_id": "10179854",
    "abstract_original": "Due to the advancement of technology network has become a part of our daily life. Thinking about life without network has become impossible. Sharing important and confidential information through network has become common. It is important to maintain the data integrity and confidentiality to maintain the trust on the network. Thus, network need to have strong and strict security. There are lots of criminal and unwanted ways to destroy the data integrity and confidentiality. It is import to prevent and block those illigal ways. This paper focus on Beth dataset. This analysis will give an insight of the Beth dataset. This gives researcher scientist an idea to if they can use this dataset to build strong and efficient anomaly detection model for the network.",
    "abstract_processed": "due advanc technolog network becom part daili life think life without network becom imposs share import confidenti inform network becom common import maintain data integr confidenti maintain trust network thu network need strong strict secur lot crimin unwant way destroy data integr confidenti import prevent block illig way paper focu beth dataset analysi give insight beth dataset give research scientist idea use dataset build strong effici anomali detect model network"
  },
  {
    "doc_id": "10181148",
    "abstract_original": "Graph Neural Networks (GNNs) train neural networks that combine the topological properties of a graph with the vertex and edge features to perform tasks such as node classification and link prediction. We propose a novel middleware that approaches GNN training from the perspective of a vertex-centric model (VCM) of distributed graph processing and overlays neural network training over it. Giraph Graph Neural Network (G2N2) uses a three-phase execution pattern by construction a distributed computation graph per mini-batch, and maps the forward and backward passes of the GNN training to VCM. We implement a prototype of G2N2 in Apache Giraph and report results from a preliminary evaluation using two real-world graphs on a commodity cluster.",
    "abstract_processed": "graph neural network gnn train neural network combin topolog properti graph vertex edg featur perform task node classif link predict propos novel middlewar approach gnn train perspect vertex centric model vcm distribut graph process overlay neural network train giraph graph neural network g n use three phase execut pattern construct distribut comput graph per mini batch map forward backward pass gnn train vcm implement prototyp g n apach giraph report result preliminari evalu use two real world graph commod cluster"
  },
  {
    "doc_id": "10181711",
    "abstract_original": "Currently we see globalization and technological advances accelerating worldwide, transforming the world of work and human coexistence. We still notice that the educational systems, in their majority, are disconnected from these global realities. In this sense, it is necessary to have an educational formation more aligned to the contemporary world, preparing young people for the challenges of the 21st century, how to deal with technological resources and processes, developing soft and hard skills. In this way, it can be observed that in recent years computational thinking has gained relevance in this scenario, being a field of research in the most varied areas of knowledge, developing communication skills, creativity, leadership, problem solving, familiarity with technologies, management, transforming young people into autonomous individuals who are prepared for the technological changes that the world requires. Taking these transformations as a reference, this paper describes/presents the development of an online tool to stimulate computational thinking in elementary school, through online games. he use of the ThinkinGame makes it possible to identify the pillars to be worked on with young people, after its use, thus improving the approaches to be given in the formation of these young people, being able to turn attention to the challenge of teaching additional skills, such as sophisticated thinking and flexible problem solving.",
    "abstract_processed": "current see global technolog advanc acceler worldwid transform world work human coexist still notic educ system major disconnect global realiti sens necessari educ format align contemporari world prepar young peopl challeng st centuri deal technolog resourc process develop soft hard skill way observ recent year comput think gain relev scenario field research vari area knowledg develop commun skill creativ leadership problem solv familiar technolog manag transform young peopl autonom individu prepar technolog chang world requir take transform refer paper describ present develop onlin tool stimul comput think elementari school onlin game use thinkingam make possibl identifi pillar work young peopl use thu improv approach given format young peopl abl turn attent challeng teach addit skill sophist think flexibl problem solv"
  },
  {
    "doc_id": "10182189",
    "abstract_original": "Computational thinking is a fundamental competence for the 21st century. It refers to a set of capacities and skills that can be stimulated to facilitate the teaching-learning process in a wide range of fields, including Science, Technology, Engineering and Mathematics (STEM). Experts in information technology argue that the earlier children are exposed to programming through digital platforms appropriate for their age, the easier it will be for them to assimilate their concepts in the future. This effort should be continued throughout the educational stages of children and youth to increase students' interest in pursuing STEM studies and careers.This paper describes the Scratch4All project promoted by the consortium CASPAE (a Private Social Solidarity Institution) and Inova-Ria, with technical assistance from professors at the public higher education institution Coimbra Institute of Engineering. Scratch4All Project includes the activities Scratch on Road, Programming and Robotics Lab, and the Scratch4All Digital Platform. According to the impact assessment for the school year 2020-2021, the Scratch4All project promotes school success and true equality in access to new technologies for students in the 1st, 2nd, and 3rd cycles of elementary school, developing essential skills for their academic and professional future such as computational thinking, STEM competencies and social skills. By encouraging young girls to participate in technological projects, this project also aims to combat gender stereotypes.",
    "abstract_processed": "comput think fundament compet st centuri refer set capac skill stimul facilit teach learn process wide rang field includ scienc technolog engin mathemat stem expert inform technolog argu earlier children expos program digit platform appropri age easier assimil concept futur effort continu throughout educ stage children youth increas student interest pursu stem studi career paper describ scratch project promot consortium caspa privat social solidar institut inova ria technic assist professor public higher educ institut coimbra institut engin scratch project includ activ scratch road program robot lab scratch digit platform accord impact assess school year scratch project promot school success true equal access new technolog student st nd rd cycl elementari school develop essenti skill academ profession futur comput think stem compet social skill encourag young girl particip technolog project project also aim combat gender stereotyp"
  },
  {
    "doc_id": "10182534",
    "abstract_original": "A person with mild cognitive disability (MCD), a kind of memory loss that affects both memory and thinking skills, may be at an increased risk of acquiring dementia brought on by Alzheimer's disease or other neurological diseases. MCD affects between 13 and 19% of those who are 60 years of age or older. People who suffer from cognitive abnormalities should seek therapy and diagnosis as soon as they can. The major effect of MCD on the target is its effect on memory. Accurate MCD diagnosis is quite challenging with the current approaches. A hybrid approach is put forward in this study to identify MCD at an early stage. EEG data from MCD individuals and healthy controls was collected for this purpose. With the use of machine learning models including Support Vector Machines (SVM), Decision Trees (DT), k-Nearest Neighbour (KNN), and the hybrid approach ACO KNN, Renyi entropy (RE) and Discrete Wavelet Transform (DWT) characteristics were retrieved (combined Ant Colony Optimisation with k-Nearest Neighbour). The performance of the system is assessed based on an accuracy comparison with machine learning models. When compared to other models, RE and ACO KNN had an accuracy of 85.0%.",
    "abstract_processed": "person mild cognit disabl mcd kind memori loss affect memori think skill may increas risk acquir dementia brought alzheim diseas neurolog diseas mcd affect year age older peopl suffer cognit abnorm seek therapi diagnosi soon major effect mcd target effect memori accur mcd diagnosi quit challeng current approach hybrid approach put forward studi identifi mcd earli stage eeg data mcd individu healthi control collect purpos use machin learn model includ support vector machin svm decis tree dt k nearest neighbour knn hybrid approach aco knn renyi entropi discret wavelet transform dwt characterist retriev combin ant coloni optimis k nearest neighbour perform system assess base accuraci comparison machin learn model compar model aco knn accuraci"
  },
  {
    "doc_id": "10182654",
    "abstract_original": "Internet of Medical Things (IoMT) is gaining interest as an emerging paradigm for healthcare improvement. Cyber-security is one of the major issues breaking down its expansion. Indeed, IoMT ecosystem complexities and cyber-attacks development require thinking about smart and efficient security solutions. Machine Learning (ML) techniques are widely used to help detecting abnormalities and intrusions in such environments in order to improve trustworthiness in Connected Medical Devices (CMD). Towards this direction, risk assessment is also proposed to proactively evaluate the security of such platforms. Regarding the complexity and heterogeneity of IoMT, dealing with the inherent security risks is a challenging task. In this context, we aim to evaluate the cumulative risk of CMD based on anomaly detection in IoMT traffic via ML algorithms. Our model relies on anomalies detection coupled with intrinsic risk assessment of medical devices trying to have a holistic risk evaluation for the platform.",
    "abstract_processed": "internet medic thing iomt gain interest emerg paradigm healthcar improv cyber secur one major issu break expans inde iomt ecosystem complex cyber attack develop requir think smart effici secur solut machin learn ml techniqu wide use help detect abnorm intrus environ order improv trustworthi connect medic devic cmd toward direct risk assess also propos proactiv evalu secur platform regard complex heterogen iomt deal inher secur risk challeng task context aim evalu cumul risk cmd base anomali detect iomt traffic via ml algorithm model reli anomali detect coupl intrins risk assess medic devic tri holist risk evalu platform"
  },
  {
    "doc_id": "10182738",
    "abstract_original": "The successful distribution of computer services, including software, storage needs, analytics, intelligence, and many others, is reflected in cloud computing. Additionally, it provides quicker innovation while simultaneously providing flexible resources.Deep learning (DL), a subset of artificial intelligence (AI) and machine learning, is widely seen as a key technology of the Fourth Industrial Revolution (4IR or Industry 4.0). The artificial neural network (ANN)-based technique known as deep learning (DL) has gained popularity in the computing world due to its capacity for learning from data. frequently used in a variety of application fields, including cybersecurity, healthcare, visual recognition, and many more. However, because of the dynamic nature and differences in real-world environments, creating an acceptable DL model is a difficult process. issues and information Additionally, because of a lack of fundamental knowledge, DL techniques become black-box devices that hinder standard level progress.A cloud computing system in an organization offers high data security at a cheap maintenance cost. Business cooperation has increased significantly as a result of cloud technology. Use of AI has enhanced each of those procedures. The use of artificial intelligence in certain industries has a considerable impact on how successful cloud services techniques are, resulting in a consequence, the two innovations' cumulative effect boosts the prosperity of such businesses. The use of smart - device and computer vision models improve the effectiveness of public clouds. It has also demonstrated implementing AI into public cloud strategies may benefit enterprises in a variety of ways.This essay includes a thorough introduction and an insightful literature review. Three objectives are outlined in a methodological approach that has also been given.",
    "abstract_processed": "success distribut comput servic includ softwar storag need analyt intellig mani other reflect cloud comput addit provid quicker innov simultan provid flexibl resourc deep learn dl subset artifici intellig ai machin learn wide seen key technolog fourth industri revolut ir industri artifici neural network ann base techniqu known deep learn dl gain popular comput world due capac learn data frequent use varieti applic field includ cybersecur healthcar visual recognit mani howev dynam natur differ real world environ creat accept dl model difficult process issu inform addit lack fundament knowledg dl techniqu becom black box devic hinder standard level progress cloud comput system organ offer high data secur cheap mainten cost busi cooper increas significantli result cloud technolog use ai enhanc procedur use artifici intellig certain industri consider impact success cloud servic techniqu result consequ two innov cumul effect boost prosper busi use smart devic comput vision model improv effect public cloud also demonstr implement ai public cloud strategi may benefit enterpris varieti way essay includ thorough introduct insight literatur review three object outlin methodolog approach also given"
  },
  {
    "doc_id": "10183057",
    "abstract_original": "With the introduction of low-cost and widely accessible sensors such as cellphones, drones, satellites, voice recorders, and bio-logging equipment, the amount of information collected about animals has expanded. Meanwhile, modern data processing systems prohibit them from collecting, digesting, and condensing data into usable information. We think that machine learning, especially deep learning algorithms, will be able to tackle this analytical difficulty by enhancing our understanding, monitoring capacities, and animal welfare. By merging machine learning with ecological processes, it may be feasible to expand the inputs to population and behavior models, resulting in integrated hybrid modeling tools where machine learning models give data-supported insights and ecological models act as constraints. Animal ecologists may basically profit from the quantity of data created by contemporary sensor technologies by integrating cutting-edge machine learning methods with ecological domain expertise. This will enable them to assess population abundances more precisely, research animal behavior, and reduce human-wildlife conflicts.",
    "abstract_processed": "introduct low cost wide access sensor cellphon drone satellit voic record bio log equip amount inform collect anim expand meanwhil modern data process system prohibit collect digest condens data usabl inform think machin learn especi deep learn algorithm abl tackl analyt difficulti enhanc understand monitor capac anim welfar merg machin learn ecolog process may feasibl expand input popul behavior model result integr hybrid model tool machin learn model give data support insight ecolog model act constraint anim ecologist may basic profit quantiti data creat contemporari sensor technolog integr cut edg machin learn method ecolog domain expertis enabl assess popul abund precis research anim behavior reduc human wildlif conflict"
  },
  {
    "doc_id": "10183290",
    "abstract_original": "In a number of tasks for assessing natural and medical prints, deep neural networks have bettered humans. These achievements, however, are solely reliant on properly labelled training data. When presented with a few samples of noisy-labelled images, the network training strategy might encounter difficulties, resulting in a suboptimal classification models. The quality of medical picture annotations strongly depends on the knowledge and experience of the annotators, which makes this difficulty more acute in the context of medical image analysis. Such problem arises due to a number of reasons ranging from human error, inexperience or even misreading of the images. But at the same time, proper labels are exceptionally useful in training models, while improperly labelled data actually hampers the efficiency of the model. Label for a lot of the image dataset out there is actually already generated, but when we think about the noisy labelled data and go for an unsupervised learning model instead of a supervised model the labels that are correct are also going to waste. To solve this problem without wasting labels, a sparsely supervised learning strategy based on transfer learning is constructed with the aid of the keras Xception model. This paper compares the efficiency of a sparsely supervised learning model employing transfer learning to that of other traditional CNN models based on their performance metrics.",
    "abstract_processed": "number task assess natur medic print deep neural network better human achiev howev sole reliant properli label train data present sampl noisi label imag network train strategi might encount difficulti result suboptim classif model qualiti medic pictur annot strongli depend knowledg experi annot make difficulti acut context medic imag analysi problem aris due number reason rang human error inexperi even misread imag time proper label except use train model improperli label data actual hamper effici model label lot imag dataset actual alreadi gener think noisi label data go unsupervis learn model instead supervis model label correct also go wast solv problem without wast label spars supervis learn strategi base transfer learn construct aid kera xception model paper compar effici spars supervis learn model employ transfer learn tradit cnn model base perform metric"
  },
  {
    "doc_id": "10183482",
    "abstract_original": "Story Generation through Deep Learning is a fascinating area of research in Artificial Intelligence that aims to create computer systems that can produce original and compelling narratives and is an interesting concept that has flourished in the domain of Machine Learning applications starting from 2018. Most of the research carried out in this specific area has shown advances in Modelling and efficiency of story generation. However, some of the setbacks in Artificial Story Generation include little to no coherency with human generating pattern, tokens/words limitation, missing plot twists and direction of story. In this paper, we have performed a comparative study on Automatic Story Generation as well as the proposed scheme of this paper has main focus on generating a meaningful story with the help of conditional text generation using keywords upto five hundred words by optimizing hugging face generative pre trained model Version Two catering towards the problem of coherency in the text generated. As a result each sentence is semantically coherent and the first three sentences are indeed related to the title itself. The experimental results show a BLEU score of 0.704 averaging over ten genres.",
    "abstract_processed": "stori gener deep learn fascin area research artifici intellig aim creat comput system produc origin compel narr interest concept flourish domain machin learn applic start research carri specif area shown advanc model effici stori gener howev setback artifici stori gener includ littl coher human gener pattern token word limit miss plot twist direct stori paper perform compar studi automat stori gener well propos scheme paper main focu gener meaning stori help condit text gener use keyword upto five hundr word optim hug face gener pre train model version two cater toward problem coher text gener result sentenc semant coher first three sentenc inde relat titl experiment result show bleu score averag ten genr"
  },
  {
    "doc_id": "10183895",
    "abstract_original": "6G is currently under definition, often being addressed from a plain telecommunications perspective as an evolutionary paradigm that represents an extension of 5G. Having as its horizon 2030, 6G initiatives are being deployed across the globe, to further ignite the development of 6G services. In its philosophy core, 6G embodies the &#x201C;human in the loop&#x201D; principle. The research effort aimed at 6G requires an interdisciplinary approach that ignites discussion across different key technological sectors, ranging from communications to services and business cases. The contribution of this book to research in the field concerns an evolutionary and interdisciplinary design of 6G as a paradigm that can be addressed by working together the four different computational areas of CONASENSE: communications; satellites and navigation; sensing; services. This book starts with a perspective on 6G challenges towards sustainability and addressing new business models, moving on to key topics concerning communications. It ends with chapters focusing on 6G service design. This book is, therefore, envisioned to assist in developing critical thinking to back up novel networking, applications, and services towards 6G.",
    "abstract_processed": "g current definit often address plain telecommun perspect evolutionari paradigm repres extens g horizon g initi deploy across globe ignit develop g servic philosophi core g embodi x c human loop x principl research effort aim g requir interdisciplinari approach ignit discuss across differ key technolog sector rang commun servic busi case contribut book research field concern evolutionari interdisciplinari design g paradigm address work togeth four differ comput area conasens commun satellit navig sens servic book start perspect g challeng toward sustain address new busi model move key topic concern commun end chapter focus g servic design book therefor envis assist develop critic think back novel network applic servic toward g"
  },
  {
    "doc_id": "10183901",
    "abstract_original": "6G is currently under definition, often being addressed from a plain telecommunications perspective as an evolutionary paradigm that represents an extension of 5G. Having as its horizon 2030, 6G initiatives are being deployed across the globe, to further ignite the development of 6G services. In its philosophy core, 6G embodies the &#x201C;human in the loop&#x201D; principle. The research effort aimed at 6G requires an interdisciplinary approach that ignites discussion across different key technological sectors, ranging from communications to services and business cases. The contribution of this book to research in the field concerns an evolutionary and interdisciplinary design of 6G as a paradigm that can be addressed by working together the four different computational areas of CONASENSE: communications; satellites and navigation; sensing; services. This book starts with a perspective on 6G challenges towards sustainability and addressing new business models, moving on to key topics concerning communications. It ends with chapters focusing on 6G service design. This book is, therefore, envisioned to assist in developing critical thinking to back up novel networking, applications, and services towards 6G.",
    "abstract_processed": "g current definit often address plain telecommun perspect evolutionari paradigm repres extens g horizon g initi deploy across globe ignit develop g servic philosophi core g embodi x c human loop x principl research effort aim g requir interdisciplinari approach ignit discuss across differ key technolog sector rang commun servic busi case contribut book research field concern evolutionari interdisciplinari design g paradigm address work togeth four differ comput area conasens commun satellit navig sens servic book start perspect g challeng toward sustain address new busi model move key topic concern commun end chapter focus g servic design book therefor envis assist develop critic think back novel network applic servic toward g"
  },
  {
    "doc_id": "10183902",
    "abstract_original": "6G is currently under definition, often being addressed from a plain telecommunications perspective as an evolutionary paradigm that represents an extension of 5G. Having as its horizon 2030, 6G initiatives are being deployed across the globe, to further ignite the development of 6G services. In its philosophy core, 6G embodies the &#x201C;human in the loop&#x201D; principle. The research effort aimed at 6G requires an interdisciplinary approach that ignites discussion across different key technological sectors, ranging from communications to services and business cases. The contribution of this book to research in the field concerns an evolutionary and interdisciplinary design of 6G as a paradigm that can be addressed by working together the four different computational areas of CONASENSE: communications; satellites and navigation; sensing; services. This book starts with a perspective on 6G challenges towards sustainability and addressing new business models, moving on to key topics concerning communications. It ends with chapters focusing on 6G service design. This book is, therefore, envisioned to assist in developing critical thinking to back up novel networking, applications, and services towards 6G.",
    "abstract_processed": "g current definit often address plain telecommun perspect evolutionari paradigm repres extens g horizon g initi deploy across globe ignit develop g servic philosophi core g embodi x c human loop x principl research effort aim g requir interdisciplinari approach ignit discuss across differ key technolog sector rang commun servic busi case contribut book research field concern evolutionari interdisciplinari design g paradigm address work togeth four differ comput area conasens commun satellit navig sens servic book start perspect g challeng toward sustain address new busi model move key topic concern commun end chapter focus g servic design book therefor envis assist develop critic think back novel network applic servic toward g"
  },
  {
    "doc_id": "10183904",
    "abstract_original": "6G is currently under definition, often being addressed from a plain telecommunications perspective as an evolutionary paradigm that represents an extension of 5G. Having as its horizon 2030, 6G initiatives are being deployed across the globe, to further ignite the development of 6G services. In its philosophy core, 6G embodies the &#x201C;human in the loop&#x201D; principle. The research effort aimed at 6G requires an interdisciplinary approach that ignites discussion across different key technological sectors, ranging from communications to services and business cases. The contribution of this book to research in the field concerns an evolutionary and interdisciplinary design of 6G as a paradigm that can be addressed by working together the four different computational areas of CONASENSE: communications; satellites and navigation; sensing; services. This book starts with a perspective on 6G challenges towards sustainability and addressing new business models, moving on to key topics concerning communications. It ends with chapters focusing on 6G service design. This book is, therefore, envisioned to assist in developing critical thinking to back up novel networking, applications, and services towards 6G.",
    "abstract_processed": "g current definit often address plain telecommun perspect evolutionari paradigm repres extens g horizon g initi deploy across globe ignit develop g servic philosophi core g embodi x c human loop x principl research effort aim g requir interdisciplinari approach ignit discuss across differ key technolog sector rang commun servic busi case contribut book research field concern evolutionari interdisciplinari design g paradigm address work togeth four differ comput area conasens commun satellit navig sens servic book start perspect g challeng toward sustain address new busi model move key topic concern commun end chapter focus g servic design book therefor envis assist develop critic think back novel network applic servic toward g"
  },
  {
    "doc_id": "10183906",
    "abstract_original": "6G is currently under definition, often being addressed from a plain telecommunications perspective as an evolutionary paradigm that represents an extension of 5G. Having as its horizon 2030, 6G initiatives are being deployed across the globe, to further ignite the development of 6G services. In its philosophy core, 6G embodies the &#x201C;human in the loop&#x201D; principle. The research effort aimed at 6G requires an interdisciplinary approach that ignites discussion across different key technological sectors, ranging from communications to services and business cases. The contribution of this book to research in the field concerns an evolutionary and interdisciplinary design of 6G as a paradigm that can be addressed by working together the four different computational areas of CONASENSE: communications; satellites and navigation; sensing; services. This book starts with a perspective on 6G challenges towards sustainability and addressing new business models, moving on to key topics concerning communications. It ends with chapters focusing on 6G service design. This book is, therefore, envisioned to assist in developing critical thinking to back up novel networking, applications, and services towards 6G.",
    "abstract_processed": "g current definit often address plain telecommun perspect evolutionari paradigm repres extens g horizon g initi deploy across globe ignit develop g servic philosophi core g embodi x c human loop x principl research effort aim g requir interdisciplinari approach ignit discuss across differ key technolog sector rang commun servic busi case contribut book research field concern evolutionari interdisciplinari design g paradigm address work togeth four differ comput area conasens commun satellit navig sens servic book start perspect g challeng toward sustain address new busi model move key topic concern commun end chapter focus g servic design book therefor envis assist develop critic think back novel network applic servic toward g"
  },
  {
    "doc_id": "10183907",
    "abstract_original": "6G is currently under definition, often being addressed from a plain telecommunications perspective as an evolutionary paradigm that represents an extension of 5G. Having as its horizon 2030, 6G initiatives are being deployed across the globe, to further ignite the development of 6G services. In its philosophy core, 6G embodies the &#x201C;human in the loop&#x201D; principle. The research effort aimed at 6G requires an interdisciplinary approach that ignites discussion across different key technological sectors, ranging from communications to services and business cases. The contribution of this book to research in the field concerns an evolutionary and interdisciplinary design of 6G as a paradigm that can be addressed by working together the four different computational areas of CONASENSE: communications; satellites and navigation; sensing; services. This book starts with a perspective on 6G challenges towards sustainability and addressing new business models, moving on to key topics concerning communications. It ends with chapters focusing on 6G service design. This book is, therefore, envisioned to assist in developing critical thinking to back up novel networking, applications, and services towards 6G.",
    "abstract_processed": "g current definit often address plain telecommun perspect evolutionari paradigm repres extens g horizon g initi deploy across globe ignit develop g servic philosophi core g embodi x c human loop x principl research effort aim g requir interdisciplinari approach ignit discuss across differ key technolog sector rang commun servic busi case contribut book research field concern evolutionari interdisciplinari design g paradigm address work togeth four differ comput area conasens commun satellit navig sens servic book start perspect g challeng toward sustain address new busi model move key topic concern commun end chapter focus g servic design book therefor envis assist develop critic think back novel network applic servic toward g"
  },
  {
    "doc_id": "10183910",
    "abstract_original": "6G is currently under definition, often being addressed from a plain telecommunications perspective as an evolutionary paradigm that represents an extension of 5G. Having as its horizon 2030, 6G initiatives are being deployed across the globe, to further ignite the development of 6G services. In its philosophy core, 6G embodies the &#x201C;human in the loop&#x201D; principle. The research effort aimed at 6G requires an interdisciplinary approach that ignites discussion across different key technological sectors, ranging from communications to services and business cases. The contribution of this book to research in the field concerns an evolutionary and interdisciplinary design of 6G as a paradigm that can be addressed by working together the four different computational areas of CONASENSE: communications; satellites and navigation; sensing; services. This book starts with a perspective on 6G challenges towards sustainability and addressing new business models, moving on to key topics concerning communications. It ends with chapters focusing on 6G service design. This book is, therefore, envisioned to assist in developing critical thinking to back up novel networking, applications, and services towards 6G.",
    "abstract_processed": "g current definit often address plain telecommun perspect evolutionari paradigm repres extens g horizon g initi deploy across globe ignit develop g servic philosophi core g embodi x c human loop x principl research effort aim g requir interdisciplinari approach ignit discuss across differ key technolog sector rang commun servic busi case contribut book research field concern evolutionari interdisciplinari design g paradigm address work togeth four differ comput area conasens commun satellit navig sens servic book start perspect g challeng toward sustain address new busi model move key topic concern commun end chapter focus g servic design book therefor envis assist develop critic think back novel network applic servic toward g"
  },
  {
    "doc_id": "10183912",
    "abstract_original": "6G is currently under definition, often being addressed from a plain telecommunications perspective as an evolutionary paradigm that represents an extension of 5G. Having as its horizon 2030, 6G initiatives are being deployed across the globe, to further ignite the development of 6G services. In its philosophy core, 6G embodies the &#x201C;human in the loop&#x201D; principle. The research effort aimed at 6G requires an interdisciplinary approach that ignites discussion across different key technological sectors, ranging from communications to services and business cases. The contribution of this book to research in the field concerns an evolutionary and interdisciplinary design of 6G as a paradigm that can be addressed by working together the four different computational areas of CONASENSE: communications; satellites and navigation; sensing; services. This book starts with a perspective on 6G challenges towards sustainability and addressing new business models, moving on to key topics concerning communications. It ends with chapters focusing on 6G service design. This book is, therefore, envisioned to assist in developing critical thinking to back up novel networking, applications, and services towards 6G.",
    "abstract_processed": "g current definit often address plain telecommun perspect evolutionari paradigm repres extens g horizon g initi deploy across globe ignit develop g servic philosophi core g embodi x c human loop x principl research effort aim g requir interdisciplinari approach ignit discuss across differ key technolog sector rang commun servic busi case contribut book research field concern evolutionari interdisciplinari design g paradigm address work togeth four differ comput area conasens commun satellit navig sens servic book start perspect g challeng toward sustain address new busi model move key topic concern commun end chapter focus g servic design book therefor envis assist develop critic think back novel network applic servic toward g"
  },
  {
    "doc_id": "10183914",
    "abstract_original": "6G is currently under definition, often being addressed from a plain telecommunications perspective as an evolutionary paradigm that represents an extension of 5G. Having as its horizon 2030, 6G initiatives are being deployed across the globe, to further ignite the development of 6G services. In its philosophy core, 6G embodies the &#x201C;human in the loop&#x201D; principle. The research effort aimed at 6G requires an interdisciplinary approach that ignites discussion across different key technological sectors, ranging from communications to services and business cases. The contribution of this book to research in the field concerns an evolutionary and interdisciplinary design of 6G as a paradigm that can be addressed by working together the four different computational areas of CONASENSE: communications; satellites and navigation; sensing; services. This book starts with a perspective on 6G challenges towards sustainability and addressing new business models, moving on to key topics concerning communications. It ends with chapters focusing on 6G service design. This book is, therefore, envisioned to assist in developing critical thinking to back up novel networking, applications, and services towards 6G.",
    "abstract_processed": "g current definit often address plain telecommun perspect evolutionari paradigm repres extens g horizon g initi deploy across globe ignit develop g servic philosophi core g embodi x c human loop x principl research effort aim g requir interdisciplinari approach ignit discuss across differ key technolog sector rang commun servic busi case contribut book research field concern evolutionari interdisciplinari design g paradigm address work togeth four differ comput area conasens commun satellit navig sens servic book start perspect g challeng toward sustain address new busi model move key topic concern commun end chapter focus g servic design book therefor envis assist develop critic think back novel network applic servic toward g"
  },
  {
    "doc_id": "10184343",
    "abstract_original": "The article considers the possibilities of integrating computer modeling into the process of the formation of probabilistic thinking in teaching mathematics students. We give an example of studying the features of heavy-tailed distributions in comparison with the properties of a normal distribution.",
    "abstract_processed": "articl consid possibl integr comput model process format probabilist think teach mathemat student give exampl studi featur heavi tail distribut comparison properti normal distribut"
  },
  {
    "doc_id": "10184658",
    "abstract_original": "In intelligent transportation systems, accurate long-term traffic forecasting is informative for administrators and travelers to make wise decisions in advance. Recently proposed spatial-temporal forecasting models perform well for short-term traffic forecasting, but two challenges hinder their applications for long-term forecasting in practice. Firstly, existing traffic forecasting models do not have satisfactory scalability on effectiveness and efficiency, i.e., as the prediction time spans extend, existing models either cannot capture the long-term spatial-temporal dynamics of traffic data or equip global receptive fields at the cost of quadratic computational complexity. Secondly, the dilemma between the models’ strong appetite for high-quality training data and their generalization ability is also a challenge we have to face. Thus how to improve data utilization efficiency deserves thoughtful thinking. Aiming at solving the long-term traffic forecasting problem and facilitating the deployment of traffic forecasting models in practice, this paper proposes an efficient and effective Self-supervised Spatial-Temporal Bottleneck Attentive Network (SSTBAN). Specifically, SSTBAN follows a multi-task framework by incorporating a self-supervised learner to produce robust latent representations for historical traffic data, so as to improve its generalization performance and robustness for forecasting. Besides, we design a spatial-temporal bottleneck attention mechanism, reducing the computational complexity meanwhile encoding global spatial-temporal dynamics. Extensive experiments on real-world long-term traffic forecasting tasks, including traffic speed forecasting and traffic flow forecasting under nine scenarios, demonstrate that SSTBAN not only achieves the overall best performance but also has good computation efficiency and data utilization efficiency.",
    "abstract_processed": "intellig transport system accur long term traffic forecast inform administr travel make wise decis advanc recent propos spatial tempor forecast model perform well short term traffic forecast two challeng hinder applic long term forecast practic firstli exist traffic forecast model satisfactori scalabl effect effici e predict time span extend exist model either cannot captur long term spatial tempor dynam traffic data equip global recept field cost quadrat comput complex secondli dilemma models’ strong appetit high qualiti train data gener abil also challeng face thu improv data util effici deserv thought think aim solv long term traffic forecast problem facilit deploy traffic forecast model practic paper propos effici effect self supervis spatial tempor bottleneck attent network sstban specif sstban follow multi task framework incorpor self supervis learner produc robust latent represent histor traffic data improv gener perform robust forecast besid design spatial tempor bottleneck attent mechan reduc comput complex meanwhil encod global spatial tempor dynam extens experi real world long term traffic forecast task includ traffic speed forecast traffic flow forecast nine scenario demonstr sstban achiev overal best perform also good comput effici data util effici"
  },
  {
    "doc_id": "10184757",
    "abstract_original": "The k-core of a graph is the largest induced sub-graph with minimum degree k. The problem of k-core decomposition finds the k-cores of a graph for all valid values of k, and it has many applications such as network analysis, computational biology and graph visualization. Currently, there are two types of parallel algorithms for k-core decomposition: (1) degree-based vertex peeling, and (2) iterative h-index refinement. There is, however, few studies on accelerating k-core decomposition using GPU. In this paper, we propose a highly optimized peeling algorithm on a GPU, and compare it with possible implementations on top of think-like-a-vertex graph-parallel GPU systems as well as existing serial and parallel k-core decomposition algorithms on CPUs. Extensive experiments show that our GPU algorithm is the overall winner in both time and space. Our source code is released at https://github.com/akhlaqueak/KCoreGPU.",
    "abstract_processed": "k core graph largest induc sub graph minimum degre k problem k core decomposit find k core graph valid valu k mani applic network analysi comput biolog graph visual current two type parallel algorithm k core decomposit degre base vertex peel iter h index refin howev studi acceler k core decomposit use gpu paper propos highli optim peel algorithm gpu compar possibl implement top think like vertex graph parallel gpu system well exist serial parallel k core decomposit algorithm cpu extens experi show gpu algorithm overal winner time space sourc code releas http github com akhlaqueak kcoregpu"
  },
  {
    "doc_id": "10184775",
    "abstract_original": "Collaborative filtering (CF) from implicit datasets has attracted much attention in recent years. The current mainstream pairwise methods optimize the Area Under the Curve (AUC) and are empirically proven to be helpful to exploit implicit feedback, but lead to not addressing the rank-biased scenarios where positive items are supposed to be placed on the top-k positions. Although there exist listwise methods, they have low efficiency and are not particularly adequate for general implicit feedback situations. To that end, in this paper, we propose a new framework, namely Collaborative List-and-Pairwise Filtering (CLAPF), which aims to introduce pairwise thinking into listwise methods. Specifically, we first smooth a well-known rank-biased measure called Mean Average Precision (MAP) as a low-bound version to make it can be optimized. After that, we combined the objective functions of optimizing the MAP with pairwise comparisons. The CLAPF framework is a new hybrid model that provides the idea of utilizing a listwise measure in a pairwise way on implicit feedback.",
    "abstract_processed": "collabor filter cf implicit dataset attract much attent recent year current mainstream pairwis method optim area curv auc empir proven help exploit implicit feedback lead address rank bias scenario posit item suppos place top k posit although exist listwis method low effici particularli adequ gener implicit feedback situat end paper propos new framework name collabor list pairwis filter clapf aim introduc pairwis think listwis method specif first smooth well known rank bias measur call mean averag precis map low bound version make optim combin object function optim map pairwis comparison clapf framework new hybrid model provid idea util listwis measur pairwis way implicit feedback"
  },
  {
    "doc_id": "10187381",
    "abstract_original": "Graph neural cellular automata are a recently introduced class of computational models that extend neural cellular automata to arbitrary graphs. They are promising in various applications based on preliminary test results and the successes of related computational models, such as neural cellular automata and convolutional and graph neural networks. However, all previous graph neural cellular automaton implementations have only been able to modify data associated with the vertices and edges, not the underlying graph topology itself. Here we introduce a method of encoding graph topology information as vertex data by assigning each edge and vertex an opacity value, which is the confidence with which the model thinks that that edge or vertex should be present in the output graph. Graph neural cellular automata equipped with this encoding method, henceforth referred to as translucent graph neural cellular automata, were tested in their ability to learn to reconstruct graphs from random subgraphs of them as a proof of concept. The results suggest that translucent graph neural cellular automata are capable of this task, albeit with optimal learning rates highly dependent on the graph to be reconstructed.",
    "abstract_processed": "graph neural cellular automata recent introduc class comput model extend neural cellular automata arbitrari graph promis variou applic base preliminari test result success relat comput model neural cellular automata convolut graph neural network howev previou graph neural cellular automaton implement abl modifi data associ vertic edg underli graph topolog introduc method encod graph topolog inform vertex data assign edg vertex opac valu confid model think edg vertex present output graph graph neural cellular automata equip encod method henceforth refer transluc graph neural cellular automata test abil learn reconstruct graph random subgraph proof concept result suggest transluc graph neural cellular automata capabl task albeit optim learn rate highli depend graph reconstruct"
  },
  {
    "doc_id": "1018760",
    "abstract_original": "The notion of the necessary criticality (both with respect to path and to activity) of a network with imprecisely defined (by means of intervals or fuzzy intervals) activity duration times is introduced and analyzed. It is shown, in the interval case, that both the problem of asserting whether a given path is necessarily critical and the problem of determining an arbitrary necessarily critical path (more exactly, a subnetwork covering all the necessarily critical paths) are easy. The corresponding solution algorithms are proposed. However, the problem of evaluating whether a given activity is necessarily critical does not seem to be so easy. Certain conditions are formulated which, in some situations (but not in all possible situations), allow the necessary criticality of activities to be evaluated. The results obtained for networks with interval activity duration times are generalized to the case of networks with fuzzy activity duration times. Two effective algorithms for calculating the degree of necessary criticality of a fixed path, as well as an algorithm for determining the paths that are necessarily critical to the maximum degree, are proposed.",
    "abstract_processed": "notion necessari critic respect path activ network imprecis defin mean interv fuzzi interv activ durat time introduc analyz shown interv case problem assert whether given path necessarili critic problem determin arbitrari necessarili critic path exactli subnetwork cover necessarili critic path easi correspond solut algorithm propos howev problem evalu whether given activ necessarili critic seem easi certain condit formul situat possibl situat allow necessari critic activ evalu result obtain network interv activ durat time gener case network fuzzi activ durat time two effect algorithm calcul degre necessari critic fix path well algorithm determin path necessarili critic maximum degre propos"
  },
  {
    "doc_id": "10188391",
    "abstract_original": "Depth estimation for light field (LF) images is the cornerstone of many applications of light field cameras, such as 3D reconstruction, defects inspection, face liveness detection, and so forth. In recent years, convolutional neural network (CNN) has dominated the primary workhorse for depth estimation. However, the interpretability of the network and the accuracy of the depth estimation results still need to be improved. This paper uses the conditional random field (CRF) theory to explain and model the LF depth estimation. Further, from the perspective of sequence analysis, we extract the sequence features of epipolar plane image (EPI) patches with recurrent neural network (RNN) and serve as the unary term of the energy function in the CRF. Then, a unified neural network (called as LFRNN) is designed to solve the CRF and get the disparity map. Our LFRNN builds upon two-stage architecture, involving a local depth estimation and a depth refinement. In the first part, we design an RNN to analyze the vector sequences in EPI patches and obtain local disparity values. There are two thinking behind the design of this part. The first is the general principle that the slope of the straight line in the EPI is inversely proportional to the depth; the second is our unique observation that those straight lines are distributed in vector sequences. In the second part, continuous CRF is used to optimize the output of the first part. We train LFRNN on a synthetic LF dataset and test it on both synthetic and real-world LF datasets. Quantitative and qualitative results validate the superior performance of our LFRNN over the state-of-the-art methods.",
    "abstract_processed": "depth estim light field lf imag cornerston mani applic light field camera reconstruct defect inspect face live detect forth recent year convolut neural network cnn domin primari workhors depth estim howev interpret network accuraci depth estim result still need improv paper use condit random field crf theori explain model lf depth estim perspect sequenc analysi extract sequenc featur epipolar plane imag epi patch recurr neural network rnn serv unari term energi function crf unifi neural network call lfrnn design solv crf get dispar map lfrnn build upon two stage architectur involv local depth estim depth refin first part design rnn analyz vector sequenc epi patch obtain local dispar valu two think behind design part first gener principl slope straight line epi invers proport depth second uniqu observ straight line distribut vector sequenc second part continu crf use optim output first part train lfrnn synthet lf dataset test synthet real world lf dataset quantit qualit result valid superior perform lfrnn state art method"
  },
  {
    "doc_id": "10189158",
    "abstract_original": "A software product line models the variability of highly configurable systems. Complete exploration of all valid configurations (the configuration space) is infeasible as it grows exponentially with the number of features in the worst case. In practice, few representative configurations are sampled instead, which may be used for software testing or hardware verification. Pseudo-randomness of modern computers introduces statistical bias into these samples. Quantum computing enables truly random, uniform configuration sampling based on inherently random quantum physical effects. We propose a method to encode the entire configuration space in a superposition and then measure one random sample. We show the method's uniformity over multiple samples and investigate its scale for different feature models. We discuss the possibilities and limitations of quantum computing for uniform random sampling regarding current and future quantum hardware.",
    "abstract_processed": "softwar product line model variabl highli configur system complet explor valid configur configur space infeas grow exponenti number featur worst case practic repres configur sampl instead may use softwar test hardwar verif pseudo random modern comput introduc statist bia sampl quantum comput enabl truli random uniform configur sampl base inher random quantum physic effect propos method encod entir configur space superposit measur one random sampl show method uniform multipl sampl investig scale differ featur model discuss possibl limit quantum comput uniform random sampl regard current futur quantum hardwar"
  },
  {
    "doc_id": "10190491",
    "abstract_original": "Proof-of-Learning (PoL) proposes that a model owner logs training checkpoints to establish a proof of having expended the computation necessary for training. The authors of PoL forego cryptographic approaches and trade rigorous security guarantees for scalability to deep learning. They empirically argued the benefit of this approach by showing how spoofing—computing a proof for a stolen model—is as expensive as obtaining the proof honestly by training the model. However, recent work has provided a counter-example and thus has invalidated this observation.In this work we demonstrate, first, that while it is true that current PoL verification is not robust to adversaries, recent work has largely underestimated this lack of robustness. This is because existing spoofing strategies are either unreproducible or target weakened instantiations of PoL—meaning they are easily thwarted by changing hyperparameters of the verification. Instead, we introduce the first spoofing strategies that can be reproduced across different configurations of the PoL verification and can be done for a fraction of the cost of previous spoofing strategies. This is possible because we identify key vulnerabilities of PoL and systematically analyze the underlying assumptions needed for robust verification of a proof. On the theoretical side, we show how realizing these assumptions reduces to open problems in learning theory. We conclude that one cannot develop a provably robust PoL verification mechanism without further understanding of optimization in deep learning.",
    "abstract_processed": "proof learn pol propos model owner log train checkpoint establish proof expend comput necessari train author pol forego cryptograph approach trade rigor secur guarante scalabl deep learn empir argu benefit approach show spoofing—comput proof stolen model—i expens obtain proof honestli train model howev recent work provid counter exampl thu invalid observ work demonstr first true current pol verif robust adversari recent work larg underestim lack robust exist spoof strategi either unreproduc target weaken instanti pol—mean easili thwart chang hyperparamet verif instead introduc first spoof strategi reproduc across differ configur pol verif done fraction cost previou spoof strategi possibl identifi key vulner pol systemat analyz underli assumpt need robust verif proof theoret side show realiz assumpt reduc open problem learn theori conclud one cannot develop provabl robust pol verif mechan without understand optim deep learn"
  },
  {
    "doc_id": "10190587",
    "abstract_original": "Owing to the no free lunch theorem, no single optimisation algorithm can solve all optimisation problems accurately, so new optimisation techniques are required. In this paper, a novel metaheuristic called the deep sleep optimiser (DSO) is proposed. The deep sleep optimiser mimics the sleeping patterns of humans to solve optimisation problems. The DSO is modelled on the rise and fall of homeostatic pressure during the human sleep process. Human sleep is often modelled on the four sleep stages and the deep sleep stage is employed in this work. The mathematical model of sleep homeostatic pressure is employed to simulate and determine the deep sleep state. The performance of DSO is demonstrated by employing 23 traditional functions (i.e., unimodal, multimodal, and fixed multi-modal functions), six composite functions, three engineering design problems, two knapsack problems, and six widely known travelling salesman’s problems. Additionally, the performance is evaluated in terms of accuracy, computational running time, the Wilcoxon rank sum, and the Friedman test. Lastly, the DSO is compared with 11 other metaheuristics, including GA, PSO, TLBO, and GWO. The DSO fares comparably well and, in most instances, it outperforms other metaheuristics.",
    "abstract_processed": "owe free lunch theorem singl optimis algorithm solv optimis problem accur new optimis techniqu requir paper novel metaheurist call deep sleep optimis dso propos deep sleep optimis mimic sleep pattern human solv optimis problem dso model rise fall homeostat pressur human sleep process human sleep often model four sleep stage deep sleep stage employ work mathemat model sleep homeostat pressur employ simul determin deep sleep state perform dso demonstr employ tradit function e unimod multimod fix multi modal function six composit function three engin design problem two knapsack problem six wide known travel salesman’ problem addit perform evalu term accuraci comput run time wilcoxon rank sum friedman test lastli dso compar metaheurist includ ga pso tlbo gwo dso fare compar well instanc outperform metaheurist"
  },
  {
    "doc_id": "10190621",
    "abstract_original": "Project-based learning (PBL) is an active learning methodology focused on developing both soft and hard skills by solving real-world problems. In PBL, teachers act as facilitators while students take charge of their own learning. While the practice of this methodology in computing education has been growing in recent years, it still poses some challenges that need to be addressed. Integrating Scrum and Agile methodologies into PBL can be a valuable addition when teaching computing subjects to students. Therefore, this paper presents a case study of a successful implementation of PBL with Scrum, applying Agile values and principles to teach Artificial Intelligence to undergraduate students. This study contributes to the limited research on Scrum in education, as well as helps bridge the research gap in AI teaching and learning. The case study involved 30 students from an undergraduate computing program, divided into five groups, who successfully developed five different Machine Learning (ML) models to tackle the challenging real-life problem of breast cancer prediction for the Cancer Institute of the State of São Paulo. The findings of the study indicate that the students effectively utilized Scrum and Agile methodologies throughout the process and expressed satisfaction with the approach. Additionally, they developed problem-solving abilities, critical thinking and communication skills, teamwork capabilities, and gained experience in working with real-life situations and problems. The study also demonstrates that the proposed technique aligns with the foundations of the PBL approach in computing education discussed in previous literature. It serves as a valuable resource for future research on PBL implementation, by comparing similarities and differences with existing literature and discussing the strategies employed to address implementation challenges.",
    "abstract_processed": "project base learn pbl activ learn methodolog focus develop soft hard skill solv real world problem pbl teacher act facilit student take charg learn practic methodolog comput educ grow recent year still pose challeng need address integr scrum agil methodolog pbl valuabl addit teach comput subject student therefor paper present case studi success implement pbl scrum appli agil valu principl teach artifici intellig undergradu student studi contribut limit research scrum educ well help bridg research gap ai teach learn case studi involv student undergradu comput program divid five group success develop five differ machin learn ml model tackl challeng real life problem breast cancer predict cancer institut state são paulo find studi indic student effect util scrum agil methodolog throughout process express satisfact approach addit develop problem solv abil critic think commun skill teamwork capabl gain experi work real life situat problem studi also demonstr propos techniqu align foundat pbl approach comput educ discuss previou literatur serv valuabl resourc futur research pbl implement compar similar differ exist literatur discuss strategi employ address implement challeng"
  },
  {
    "doc_id": "10190626",
    "abstract_original": "Technologies like AI and IoT have been employed in farming for some time now, along with other forms of cutting-edge computer science. There has been a shift in recent years toward thinking about how to put this new technology to use. Agriculture has provided a large portion of humanity’s sustenance for thousands of years, with its most notable contribution being the widespread use of effective agricultural practices for several crop types. The advent of cutting-edge IoT know-how with the ability to monitor agricultural ecosystems and guarantee high-quality production is underway. Smart Sustainable Agriculture continues to face formidable hurdles due to the widespread dispersion of agricultural procedures, such as the deployment and administration of IoT and AI devices, the sharing of data and administration, interoperability, and the analysis and storage of enormous data quantities. This work initially analyses existing Internet-of-Things technologies used in Smart Sustainable Agriculture (SSA) to discover architectural components that might facilitate the development of SSA platforms. This paper examines the state of research and development in SSA, pays attention to the current form of information, and proposes an Internet of Things (IoT) and artificial intelligence (AI) framework as a starting point for SSA.",
    "abstract_processed": "technolog like ai iot employ farm time along form cut edg comput scienc shift recent year toward think put new technolog use agricultur provid larg portion humanity’ susten thousand year notabl contribut widespread use effect agricultur practic sever crop type advent cut edg iot know abil monitor agricultur ecosystem guarante high qualiti product underway smart sustain agricultur continu face formid hurdl due widespread dispers agricultur procedur deploy administr iot ai devic share data administr interoper analysi storag enorm data quantiti work initi analys exist internet thing technolog use smart sustain agricultur ssa discov architectur compon might facilit develop ssa platform paper examin state research develop ssa pay attent current form inform propos internet thing iot artifici intellig ai framework start point ssa"
  },
  {
    "doc_id": "10193910",
    "abstract_original": "This paper presents a part of research into e-waste and e-cycling in Lebanon; it describes the status quo of today's governmental and NGO's actions, tools, and intentions about e-waste. The research questions answered throughout this paper are two: the first one wonders if the Lebanese society and government are aware of the e-waste hazards and whether there is any action taken, on the governmental level, to avert an environmental catastrophe. Whereas the second one is concerned with finding out, what Lebanese think about e-waste and whether they are willing to fight against it? Answers to the first question resulted from interviews. The authors have visited Company A and NGO B, the first is concerned with collecting waste in greater Beirut while the second aims at spreading awareness to e-waste's dangers on governmental and social levels alike. Question two was discussed throughout surveys filled by random individuals from Lebanese society. The answers to both research questions came in a way that proves both hypotheses assumed at the beginning of the research, namely that e-waste poses a great threat to the Lebanese environment and that laws must be implemented to regulate collection and disposal of electronic appliances; also, e-cycling initiatives must be encouraged to reduce the quantities of generated e-waste. Hypothesis two if environment friendliness and affinity to right e-waste disposal depend on the educational level of any given citizen has been proven to be true while analyzing the answers in the survey.",
    "abstract_processed": "paper present part research e wast e cycl lebanon describ statu quo today government ngo action tool intent e wast research question answer throughout paper two first one wonder lebanes societi govern awar e wast hazard whether action taken government level avert environment catastroph wherea second one concern find lebanes think e wast whether will fight answer first question result interview author visit compani ngo b first concern collect wast greater beirut second aim spread awar e wast danger government social level alik question two discuss throughout survey fill random individu lebanes societi answer research question came way prove hypothes assum begin research name e wast pose great threat lebanes environ law must implement regul collect dispos electron applianc also e cycl initi must encourag reduc quantiti gener e wast hypothesi two environ friendli affin right e wast dispos depend educ level given citizen proven true analyz answer survey"
  },
  {
    "doc_id": "10194140",
    "abstract_original": "Everyone has a distinct handwriting style, even identical twins who share the same genes. This distinctiveness has allowed researchers to develop systems that can classify the writer's traits, including gender, age, handedness, and others. A gender classification system, for instance, classifies handwriting patterns to predict the writer's gender. With the advancement of deep learning, it is now possible to automatically extract features from the document and classify them. In this paper, two gender classification models based on Alex-Net and LeNet-5 CNN were proposed, trained, and tested on a private Urdu handwriting dataset containing 284,000 pre-segmented characters from 200 males and 200 females. The proposed models achieved state-of- the-art performance compared to existing deep learning models for gender classification. The Alex-Net model achieved an overall accuracy of 99.14%, while the LeNet-5 model achieved an overall accuracy of 98.55%.",
    "abstract_processed": "everyon distinct handwrit style even ident twin share gene distinct allow research develop system classifi writer trait includ gender age handed other gender classif system instanc classifi handwrit pattern predict writer gender advanc deep learn possibl automat extract featur document classifi paper two gender classif model base alex net lenet cnn propos train test privat urdu handwrit dataset contain pre segment charact male femal propos model achiev state art perform compar exist deep learn model gender classif alex net model achiev overal accuraci lenet model achiev overal accuraci"
  },
  {
    "doc_id": "10194187",
    "abstract_original": "In this paper, we propose a genetic algorithm based on behavioral psychology developed by Carl Gustav Jung (16 Personalities model), in which we describe the person's behavioral features related to his personality. The model used for inherence is based on 40 years of psychology studies from the book “The 16personalityy types that determinate how we live, love and work” [1] by Otto Kroeger and Janet M. Thuesen, published in 1988, but using inference extracted from an MBTI (Myers-Briggs Personality Type Indicator) dataset of online posts based on person personality and it thinks from 2018 [2].",
    "abstract_processed": "paper propos genet algorithm base behavior psycholog develop carl gustav jung person model describ person behavior featur relat person model use inher base year psycholog studi book “the personalityy type determin live love work” otto kroeger janet thuesen publish use infer extract mbti myer brigg person type indic dataset onlin post base person person think"
  },
  {
    "doc_id": "10194240",
    "abstract_original": "Very recently, intensive discussions and studies on Industry 5.0 have sprung up and caused the attention of researchers, entrepreneurs, and policymakers from various sectors around the world. However, there is no consensus on why and what is Industry 5.0 yet. In this paper, we define Industry 5.0 from its philosophical and historical origin and evolution, emphasize its new thinking on virtual-real duality and human-machine interaction, and introduce its new theory and technology based on parallel intelligence (PI), artificial societies, computational experiments, and parallel execution (the ACP method), and cyber-physical-social systems (CPSS). Case studies and applications of Industry 5.0 over the last decade have been briefly summarized and analyzed with suggestions for its future development. We believe that Industry 5.0 of virtual-real interactive parallel industries has great potentials and is critical for building smart societies. Steps are outlined to ensure a roadmap that would lead to a smooth transition from CPS-based Industry 4.0 to CPSS-based Industry 5.0 for a better world which is Safe in physical spaces, Secure in cyberspaces, Sustainable in ecology, Sensitive in indi-vidual privacy and rights, Service for all, and Smartness of all.",
    "abstract_processed": "recent intens discuss studi industri sprung caus attent research entrepreneur policymak variou sector around world howev consensu industri yet paper defin industri philosoph histor origin evolut emphas new think virtual real dualiti human machin interact introduc new theori technolog base parallel intellig pi artifici societi comput experi parallel execut acp method cyber physic social system cpss case studi applic industri last decad briefli summar analyz suggest futur develop believ industri virtual real interact parallel industri great potenti critic build smart societi step outlin ensur roadmap would lead smooth transit cp base industri cpss base industri better world safe physic space secur cyberspac sustain ecolog sensit indi vidual privaci right servic smart"
  },
  {
    "doc_id": "10195075",
    "abstract_original": "Artificial Intelligence technology has made remarkable progress in machine learning, but it is still in its infancy in creative thinking or computational creativity. In 2018, Yang and Li proposed that the physiological basis for the formation of memories and concepts in the human brain is engram cells (interneuron), and creative thinking is the process of forming new engram cells to connect previously seemingly unrelated concepts. During this process, association and prediction play a key role. In this study, a computational model based on engram cell theory was coded in Python to mimic the process of creative thinking. The validity of the model was tested by simulating the phenomenon of language generation and summarizing the artificial food-set regularity in the plus maze. The results show that, given 29 initial words and certain grammatical rules, the language generation program generates 25,405 sentences after 130,000 calculations, and these generated sentences can be combined into various short paragraphs. After 50 times of training in the cross maze puzzle solving program, the model can master 100% of the rules of artificial food settings. In conclusion, a computational model of creative thinking based on engram cell theory can creatively and automatically generate sentences and paragraphs, and can learn and summarize laws to solve simple puzzles. We plan to further use this model to address complex real-world problems, such as the study of cancer therapeutic targets",
    "abstract_processed": "artifici intellig technolog made remark progress machin learn still infanc creativ think comput creativ yang li propos physiolog basi format memori concept human brain engram cell interneuron creativ think process form new engram cell connect previous seemingli unrel concept process associ predict play key role studi comput model base engram cell theori code python mimic process creativ think valid model test simul phenomenon languag gener summar artifici food set regular plu maze result show given initi word certain grammat rule languag gener program gener sentenc calcul gener sentenc combin variou short paragraph time train cross maze puzzl solv program model master rule artifici food set conclus comput model creativ think base engram cell theori creativ automat gener sentenc paragraph learn summar law solv simpl puzzl plan use model address complex real world problem studi cancer therapeut target"
  },
  {
    "doc_id": "10195993",
    "abstract_original": "Intelligent and networked vehicle is a popular developing trend in future. However, Data Loss Prevention (DLP) is an import problem need to be solved. Especially, in the Vehicle Sharing System (VSS), the data authority is hard to be guaranteed based on the current technology. VSS provides the users with a convenient way to access vehicles nearby. However, the driving data security which can be used to record the driving conditions cannot be guaranteed by either cloud server or the vehicle. The camera in the cab is also not accepted because it will leak the user's privacy. This article solves this problem based on the cryptography with the public auditing technology. We design a multi-signature scheme so that the OBU and the PDA equipment of the vehicle renter can jointly sign a signature as a meta data for the driving information and upload it to the cloud server together with the raw data. In the event of a dispute, such as a vehicle accident, anyone can conduct an integrity checking with batch jobs on the stored data in the cloud server, so that the cloud and the vehicle renter cannot deny these information. We think that our scheme can be used to prevent some obvious data modification in cloud or as a part of the reference for accident identification. We also use the provable security technology to prove that our protocol is secure, and we realize its core algorithms. The experimental result shows that our scheme is efficient.",
    "abstract_processed": "intellig network vehicl popular develop trend futur howev data loss prevent dlp import problem need solv especi vehicl share system vss data author hard guarante base current technolog vss provid user conveni way access vehicl nearbi howev drive data secur use record drive condit cannot guarante either cloud server vehicl camera cab also accept leak user privaci articl solv problem base cryptographi public audit technolog design multi signatur scheme obu pda equip vehicl renter jointli sign signatur meta data drive inform upload cloud server togeth raw data event disput vehicl accid anyon conduct integr check batch job store data cloud server cloud vehicl renter cannot deni inform think scheme use prevent obviou data modif cloud part refer accid identif also use provabl secur technolog prove protocol secur realiz core algorithm experiment result show scheme effici"
  },
  {
    "doc_id": "10196862",
    "abstract_original": "Mental health is just as important as physical health. Globally, there is a growing concern due to the rise of mental health problems. Mental health problems impair individuals’ ability to think clearly, behave responsively, or express themselves. The recent pandemic has led to a spike in people using social media to express themselves. Data from these social media platforms can be used to learn more about users’ mental states and determine the causes of mental health problems. However, due to the variability and complexity of users’ language, it is very challenging for conventional machine learning and deep learning models to identify these causes. In this research, we propose a novel sentence-level analysis framework based on a hybrid deep learning model to overcome these challenges. We evaluated our model’s efficacy using data from the social media platform Reddit, and our model outperforms several baseline models. Our research findings provide a new perspective on identifying the causes behind mental health issues and would help mental health professionals develop better diagnoses and treatments for patients.",
    "abstract_processed": "mental health import physic health global grow concern due rise mental health problem mental health problem impair individuals’ abil think clearli behav respons express recent pandem led spike peopl use social media express data social media platform use learn users’ mental state determin caus mental health problem howev due variabl complex users’ languag challeng convent machin learn deep learn model identifi caus research propos novel sentenc level analysi framework base hybrid deep learn model overcom challeng evalu model’ efficaci use data social media platform reddit model outperform sever baselin model research find provid new perspect identifi caus behind mental health issu would help mental health profession develop better diagnos treatment patient"
  },
  {
    "doc_id": "10196883",
    "abstract_original": "This paper reports on a pilot study of using ChatGPT, a language model based on GPT-3.5 architecture, for automatic generation of metamorphic relations (MRs), in the context of testing of autonomous driving systems (ADSs). The oracle problem is a major challenge in testing such systems, where it is difficult to determine whether or not the output of a system is correct. Metamorphic testing (MT) can alleviate this problem by checking the consistency of the system’s outputs under various transformations. However, manual generation of MRs is often a time-consuming and error-prone process. Automated MR generation can yield several benefits, including enhanced efficiency, quality, coverage, scalability, and reusability in software testing, thereby facilitating a more comprehensive and effective testing process. In this paper, we investigate the effectiveness of using ChatGPT for automatic generation of MRs for ADSs. We provide a detailed methodology for generating MRs using ChatGPT and evaluate the generated MRs using our domain knowledge and existing MRs. The results of our study indicate that our proposed approach is effective at generating high-quality MRs, and can significantly reduce the manual effort required for MR generation. Furthermore, we discuss the practical implications and limitations of using ChatGPT for MR generation and provide recommendations for future research. Our study contributes to the advancement of automated testing of ADSs, which is crucial for ensuring their safety and reliability in real-world scenarios.",
    "abstract_processed": "paper report pilot studi use chatgpt languag model base gpt architectur automat gener metamorph relat mr context test autonom drive system adss oracl problem major challeng test system difficult determin whether output system correct metamorph test mt allevi problem check consist system’ output variou transform howev manual gener mr often time consum error prone process autom mr gener yield sever benefit includ enhanc effici qualiti coverag scalabl reusabl softwar test therebi facilit comprehens effect test process paper investig effect use chatgpt automat gener mr adss provid detail methodolog gener mr use chatgpt evalu gener mr use domain knowledg exist mr result studi indic propos approach effect gener high qualiti mr significantli reduc manual effort requir mr gener furthermor discuss practic implic limit use chatgpt mr gener provid recommend futur research studi contribut advanc autom test adss crucial ensur safeti reliabl real world scenario"
  },
  {
    "doc_id": "10197372",
    "abstract_original": "The accomplishment of blockchain has increased the focus on the various applications for simplifying the confidentiality and transaction sanctuary using the decentralized architecture via consensus mechanisms between different internet of things (IoT) nodes in daily increasing societal areas. The growth of blockchain lasted to grow and used to do compare technologies. The major shortcomings of blockchain is the lack of scalability in modern application settings. Holochain technology vends itself as a “thinking” exterior to blocks, and it is a peer-to-peer disseminated ledger technology. It works contrarily compared to the blockchain, and it offers an exclusive value in the existing market. IoT devices are continuously used in distributed environments, in various smart applications. The peer-to-peer IoT networks, connected to smart agricultural systems are exposed to the security issues. Specifically, the personal data of agricultural land records need protection against unauthorized access and eradicate corruption in land transactions. The Blockchain offers a possible solution based on distributed ledger, but it has scalability issues due to high storage and processing requirements with growing network size. Also data is not locally stored in a Blockchain. This paper studies the conventions of holochain technology, its architecture and challenges, and critical mechanisms of holochain applications. We also analyze the numerous models utilized for the implementation of protected transactions. We discuss an agent centric framework with distributed hash table for secured applications.",
    "abstract_processed": "accomplish blockchain increas focu variou applic simplifi confidenti transact sanctuari use decentr architectur via consensu mechan differ internet thing iot node daili increas societ area growth blockchain last grow use compar technolog major shortcom blockchain lack scalabl modern applic set holochain technolog vend “thinking” exterior block peer peer dissemin ledger technolog work contrarili compar blockchain offer exclus valu exist market iot devic continu use distribut environ variou smart applic peer peer iot network connect smart agricultur system expos secur issu specif person data agricultur land record need protect unauthor access erad corrupt land transact blockchain offer possibl solut base distribut ledger scalabl issu due high storag process requir grow network size also data local store blockchain paper studi convent holochain technolog architectur challeng critic mechan holochain applic also analyz numer model util implement protect transact discuss agent centric framework distribut hash tabl secur applic"
  },
  {
    "doc_id": "10198449",
    "abstract_original": "This paper proposed an innovative method for aesthetic education by integrating shape grammar and neuroaesthetics. Aesthetic education can be divided into bottom-up aesthetic cultivation and top-down knowledge education, which correspond to the characteristics of shape grammar and neuroaesthetics, respectively. In this study, we redefined the state space of traditional shape grammar by replacing the computer-dominated label set with the affective-dominated emotion set of neuroaesthetics. This resulted in a neuroaesthetic shape grammar that is led by the designer and complementary to human intuition and algorithmic logic. We validated this method through practical design cases in the field of aesthetic education.",
    "abstract_processed": "paper propos innov method aesthet educ integr shape grammar neuroaesthet aesthet educ divid bottom aesthet cultiv top knowledg educ correspond characterist shape grammar neuroaesthet respect studi redefin state space tradit shape grammar replac comput domin label set affect domin emot set neuroaesthet result neuroaesthet shape grammar led design complementari human intuit algorithm logic valid method practic design case field aesthet educ"
  },
  {
    "doc_id": "10200202",
    "abstract_original": "Over the last two decades, the relevant literature has focused a lot on the human intelligence of (EI) and the machine intelligence of AI. The present research integrates these two schools of thinking and examines how employee retention and productivity are impacted by mental agility and artificial intelligence. How successfully individuals execute tasks during their internal and external services contacts with clients and colleagues, respectively. These interactions may take place either internally or outside and are categorized as either internal or external. The research demonstrates that emotive artificial intelligence has a major effect on both the performance of employees and their retention rates.",
    "abstract_processed": "last two decad relev literatur focus lot human intellig ei machin intellig ai present research integr two school think examin employe retent product impact mental agil artifici intellig success individu execut task intern extern servic contact client colleagu respect interact may take place either intern outsid categor either intern extern research demonstr emot artifici intellig major effect perform employe retent rate"
  },
  {
    "doc_id": "10200806",
    "abstract_original": "Sentiment analysis is the process of categorizing and locating the emotions represented in a textual source. Sentiment analysis can be used widely in different areas, such as customer review data, feedback data classification, survey responses, and social media comments. Tweets on Twitter contain a variety of sentiments reflecting the perception, thinking, and working background of the user. With the help of the sentiment analyzer, it can define the response of others on any matter or subject of interest. Here, we used machine learning-based NLP (natural language processing) and text analysis technology to define an automated model that can classify the sentiment of a large dataset. Here we used the following three machine-learning classifiers: logistic regression, SVM, and Bernoulli Naïve Bayes. The effectiveness and performance of these classifiers are assessed using F1 scores and accuracy. The accuracy of these models is 83%(LR), 81%(SVM), and 80%(BNB) So logistic regression model provides the best result among these.",
    "abstract_processed": "sentiment analysi process categor locat emot repres textual sourc sentiment analysi use wide differ area custom review data feedback data classif survey respons social media comment tweet twitter contain varieti sentiment reflect percept think work background user help sentiment analyz defin respons other matter subject interest use machin learn base nlp natur languag process text analysi technolog defin autom model classifi sentiment larg dataset use follow three machin learn classifi logist regress svm bernoulli naïv bay effect perform classifi assess use f score accuraci accuraci model lr svm bnb logist regress model provid best result among"
  },
  {
    "doc_id": "10200951",
    "abstract_original": "Visual information model design needs to integrate with big data sharing, intelligent interaction, authentication security, model building, optimization and energy saving, node privacy and other aspects to give play to the important role of blockchain intelligent interactive data. This paper builds a visual cognitive model around knowledge graph and intelligent interactive data, proposes multiple structures, thinking cognition, multiple modules and intelligent data, and aims at multiple visual cognitive paths of “driving task-effectiveness activity – map visualization – intelligent interaction – model processing” and “data rotation -information graph – multiple knowledge – cognitive model”. It draws the conclusion of the multi-distributed and information intelligentized non-center model structure, realizes the openness, transparency and traceability of all kinds of information data, and makes the blockchain intelligent interactive data more visualization, intelligence, humanization and technicalization. According to the intelligent type media of blockchain, large databases are stored and classified, and a partition block data model is established. A chain structure relationship is formed between block data models, and a layer-by-layer oriented structure is formed. The representation design and interaction design of blockchain intelligent interactive data visualization needs to meet the requirement that the cognitive subject and artificial intelligence can work cooperatively and integrate, so as to create a compound cognitive block model.",
    "abstract_processed": "visual inform model design need integr big data share intellig interact authent secur model build optim energi save node privaci aspect give play import role blockchain intellig interact data paper build visual cognit model around knowledg graph intellig interact data propos multipl structur think cognit multipl modul intellig data aim multipl visual cognit path “drive task effect activ – map visual – intellig interact – model processing” “data rotat inform graph – multipl knowledg – cognit model” draw conclus multi distribut inform intelligent non center model structur realiz open transpar traceabl kind inform data make blockchain intellig interact data visual intellig human technic accord intellig type media blockchain larg databas store classifi partit block data model establish chain structur relationship form block data model layer layer orient structur form represent design interact design blockchain intellig interact data visual need meet requir cognit subject artifici intellig work cooper integr creat compound cognit block model"
  },
  {
    "doc_id": "10201110",
    "abstract_original": "The identification of suicidal thoughts in online social networks is an expanding field of study fraught with major challenges. Recent studies have shown that the readily available data, dispersed over many online life phases, contains useful clues for accurately identifying persons with suicidal intentions. The primary challenge in preventing suicide is learning to recognize and respond appropriately to the sometimes-confusing risk factors and warning indications that may precipitate an attempt. Indicators useful for diagnosing people with suicide thoughts can be found in publicly available material shared over social media platforms, according to recent studies. Understanding and recognizing the myriad risk factors and warning symptoms that may precede a suicide attempt is the primary difficulty in this area of public health. In this research, we developed a benchmark for multi-class categorization using machine learning models. We used a majority classifier, a frequency-based technique, and two deep learning models as our models. Both deep learning models outperformed the majority and the word frequency classifier, with results that were very comparable. These classification results are on par with the state-of-the-art on similar problems and, in most cases, with human results.",
    "abstract_processed": "identif suicid thought onlin social network expand field studi fraught major challeng recent studi shown readili avail data dispers mani onlin life phase contain use clue accur identifi person suicid intent primari challeng prevent suicid learn recogn respond appropri sometim confus risk factor warn indic may precipit attempt indic use diagnos peopl suicid thought found publicli avail materi share social media platform accord recent studi understand recogn myriad risk factor warn symptom may preced suicid attempt primari difficulti area public health research develop benchmark multi class categor use machin learn model use major classifi frequenc base techniqu two deep learn model model deep learn model outperform major word frequenc classifi result compar classif result par state art similar problem case human result"
  },
  {
    "doc_id": "10205335",
    "abstract_original": "Recent advances in 3D point cloud analysis bring a diverse set of network architectures to the field. However, the lack of a unified framework to interpret those networks makes any systematic comparison, contrast, or analysis challenging, and practically limits healthy development of the field. In this paper, we take the initiative to explore and propose a unified framework called PointMeta, to which the popular 3D point cloud analysis approaches could fit. This brings three benefits. First, it allows us to compare different approaches in a fair manner, and use quick experiments to verify any empirical observations or assumptions summarized from the comparison. Second, the big picture brought by PointMeta enables us to think across different components, and revisit common beliefs and key design decisions made by the popular approaches. Third, based on the learnings from the previous two analyses, by doing simple tweaks on the existing approaches, we are able to derive a basic building block, termed PointMetaBase. It shows very strong performance in efficiency and effectiveness through extensive experiments on challenging benchmarks, and thus verifies the necessity and benefits of high-level interpretation, contrast, and comparison like PointMeta. In particular, PointMetaBase surpasses the previous state-of-the-art method by 0.7%/1.4/%2.1% mIoU with only 2%/11%/13% of the computation cost on the S3DIS datasets. The code and models are available at https://github.com/linhaojia13/PointMetaBase.",
    "abstract_processed": "recent advanc point cloud analysi bring divers set network architectur field howev lack unifi framework interpret network make systemat comparison contrast analysi challeng practic limit healthi develop field paper take initi explor propos unifi framework call pointmeta popular point cloud analysi approach could fit bring three benefit first allow us compar differ approach fair manner use quick experi verifi empir observ assumpt summar comparison second big pictur brought pointmeta enabl us think across differ compon revisit common belief key design decis made popular approach third base learn previou two analys simpl tweak exist approach abl deriv basic build block term pointmetabas show strong perform effici effect extens experi challeng benchmark thu verifi necess benefit high level interpret contrast comparison like pointmeta particular pointmetabas surpass previou state art method miou comput cost di dataset code model avail http github com linhaojia pointmetabas"
  },
  {
    "doc_id": "10205798",
    "abstract_original": "This system proposes a question-answer model to analyze answers given by the users to the open-ended question. For this system, we use a squad dataset. The squad dataset is helpful for open-ended questions. The model uses NLP and the BERT question-answer model for handling the answers. Problem-solving deals with the analysis of questions and answering them in a creative, feasible, and efficient way. The problem-solving the approach gives the way of thinking of the problem solver. Computational methods along with NLP are being developed to calculate these indices. With the help of question-answer systems in NLP, the users’ answers are analyzed and measured are being attempts to perform such analysis but the answers to the questions are varied from person to person which makes answer analysis challenging. Answers given by users and answer for the question present in the squad dataset is compared by using cosine similarity to calculate the creativity index. The creativity index is a linear combination of fluency, flexibility, uniqueness, and elaboration indices; calculated for every given answer by comparing given answers and the stored answers. The system is trained and tested for the general questions present in the squad dataset. This system is beneficial to predict and measure the creative thinking, problem-solving ability, and thinking ability of the user. It helps to build the work culture, societal culture, and behavior of individuals in the institution, community, and workplace. The CI is a tremendously useful tool for businesses, office employees, and students. Thinking and problem-solving skills are calculated using this technique.",
    "abstract_processed": "system propos question answer model analyz answer given user open end question system use squad dataset squad dataset help open end question model use nlp bert question answer model handl answer problem solv deal analysi question answer creativ feasibl effici way problem solv approach give way think problem solver comput method along nlp develop calcul indic help question answer system nlp users’ answer analyz measur attempt perform analysi answer question vari person person make answer analysi challeng answer given user answer question present squad dataset compar use cosin similar calcul creativ index creativ index linear combin fluenci flexibl uniqu elabor indic calcul everi given answer compar given answer store answer system train test gener question present squad dataset system benefici predict measur creativ think problem solv abil think abil user help build work cultur societ cultur behavior individu institut commun workplac ci tremend use tool busi offic employe student think problem solv skill calcul use techniqu"
  },
  {
    "doc_id": "10206089",
    "abstract_original": "This study suggests that the mainstream tendencies in computational aesthetics, as in artificial intelligence, are based on the mind-body duality governing mainstream psychology. So, by following the guidelines of dialectic and the cultural-historical activity theory, an alternative contradictions-based meanings qualitative model is proposed. Apart from the mainstream connectionist and mechanistic mainstream, aesthetics -as consciousness in general- is considered the empirical manifestation in practice to satisfy the human’s needs and the representation/answer of human perturbations. Moreover, this paper attempts to introduce a formalized version of art therapy.",
    "abstract_processed": "studi suggest mainstream tendenc comput aesthet artifici intellig base mind bodi dualiti govern mainstream psycholog follow guidelin dialect cultur histor activ theori altern contradict base mean qualit model propos apart mainstream connectionist mechanist mainstream aesthet conscious gener consid empir manifest practic satisfi human’ need represent answer human perturb moreov paper attempt introduc formal version art therapi"
  },
  {
    "doc_id": "10209089",
    "abstract_original": "Several practical engineering optimization problems are computationally demanding, requiring a large amount of computer time, processing power, and memory. These challenges can be mitigated by human-engineered systems exhibiting intelligent behavior. With the evolution of high-speed digital computers, the use of computational intelligence (CI) techniques has increased rapidly. According to Bezdek [1], “A system is called computationally intelligent if it deals with low-level data such as numerical data, has a pattern-recognition component and does not use knowledge in the artificial intelligence (AI) sense, and additionally when it begins to exhibit computational adaptivity, fault tolerance, speed approaching human-like turnaround and error rates that approximate human performance.” Another definition, by Engelbrecht [2], states that “CI is the study of adaptive mechanisms that enable or facilitate intelligent behavior in complex and changing environments. These mechanisms include those Artificial Intelligence paradigms that exhibit an ability to learn or adapt to new situations, to generalize, abstract, discover and associate.” Thus, CI is the general term used to classify all such nature-inspired methodologies and their associated theories and applications. The five important paradigms of the CI technique are artificial neural networks (ANNs), swarm intelligence (SI), evolutionary computation (EC), and fuzzy systems (FSs). The origin of each technique can be connected to a natural system; for example, an ANN imitates the biological neural system. SI models the behavior of organisms living in swarms, whereas EC models the natural evolution system. Similarly, an FS originates from human thinking processes. Many of the problems involved in designing next-generation systems can be resolved using these CI techniques or their combinations.",
    "abstract_processed": "sever practic engin optim problem comput demand requir larg amount comput time process power memori challeng mitig human engin system exhibit intellig behavior evolut high speed digit comput use comput intellig ci techniqu increas rapidli accord bezdek “a system call comput intellig deal low level data numer data pattern recognit compon use knowledg artifici intellig ai sens addit begin exhibit comput adapt fault toler speed approach human like turnaround error rate approxim human perform ” anoth definit engelbrecht state “ci studi adapt mechan enabl facilit intellig behavior complex chang environ mechan includ artifici intellig paradigm exhibit abil learn adapt new situat gener abstract discov associ ” thu ci gener term use classifi natur inspir methodolog associ theori applic five import paradigm ci techniqu artifici neural network ann swarm intellig si evolutionari comput ec fuzzi system fss origin techniqu connect natur system exampl ann imit biolog neural system si model behavior organ live swarm wherea ec model natur evolut system similarli fs origin human think process mani problem involv design next gener system resolv use ci techniqu combin"
  },
  {
    "doc_id": "10211374",
    "abstract_original": "The “Scratch4All” project aims to reduce school dropout rates by encouraging and motivating students in the 1st, 2nd, and 3rd cycles of elementary schools to achieve academic success. In addition, the project promotes true equality of opportunity in terms of educational resources. A learning environment that contributes positively to the improvement of educational results is created through the use of new technologies, specifically programming in the Scratch language and robotics. Impact indicators were developed and used as project evaluation tools based on Theory of Change. This paper presents and analyzes the changes observed from the perspective of the project’s teachers’ stakeholders during the 2020/2021 school year. This group of beneficiaries is critical to the project’s success and continuation, not only because of the special relationship they have with the students, but also with their families and the school. The assessment of impact is very positive in terms of indicators such as school success and motivation, particularly in Mathematics and Portuguese Language, as well as in the reduction of inequalities, access to new technologies, and contribution to gender equality.",
    "abstract_processed": "“scratch all” project aim reduc school dropout rate encourag motiv student st nd rd cycl elementari school achiev academ success addit project promot true equal opportun term educ resourc learn environ contribut posit improv educ result creat use new technolog specif program scratch languag robot impact indic develop use project evalu tool base theori chang paper present analyz chang observ perspect project’ teachers’ stakehold school year group beneficiari critic project’ success continu special relationship student also famili school assess impact posit term indic school success motiv particularli mathemat portugues languag well reduct inequ access new technolog contribut gender equal"
  },
  {
    "doc_id": "10211596",
    "abstract_original": "This paper describes a computational infrastructure used to support creative design in detecting emergent shapes in the specific context of shape grammar implementation. Shape grammars have been used to represent the knowledge behind the creative work of architects, designers and artists. This kind of grammars are inherently visual and they allow the implementation of computational mechanisms to either synthesize or analyze designs of visual languages, including the detection of emergent sub-shapes languages. They have obvious applications to design, including for marketing. The infrastructure presented, together with the algorithm to which it gives support, the latter proposed in another, twin, paper, is a core component of a system, described in our past work, that allows users to build their own shape grammars and experiment with and use them.",
    "abstract_processed": "paper describ comput infrastructur use support creativ design detect emerg shape specif context shape grammar implement shape grammar use repres knowledg behind creativ work architect design artist kind grammar inher visual allow implement comput mechan either synthes analyz design visual languag includ detect emerg sub shape languag obviou applic design includ market infrastructur present togeth algorithm give support latter propos anoth twin paper core compon system describ past work allow user build shape grammar experi use"
  },
  {
    "doc_id": "10211961",
    "abstract_original": "This work addressed the teaching of Computational Thinking for children from 7 to 11 years of elementary school I for the teaching of logical reasoning. From studies on accessibility in games for children aged 7 to 11 years old, with hearing impairment, an inclusive game was developed to support the teaching of computational thinking in the learning of logic. For the development of the game, not only Computational Thinking were studied, but educational games for children with hearing impairment, in addition to web accessibility guidelines. As a result of the research carried out, an inclusive game, FruitSort, was implemented for children with hearing impairment, which addressed the Merge Sort Sorting Algorithm, to support the teaching of Computational Thinking through a playful and inclusive environment.",
    "abstract_processed": "work address teach comput think children year elementari school teach logic reason studi access game children age year old hear impair inclus game develop support teach comput think learn logic develop game comput think studi educ game children hear impair addit web access guidelin result research carri inclus game fruitsort implement children hear impair address merg sort sort algorithm support teach comput think play inclus environ"
  },
  {
    "doc_id": "10213204",
    "abstract_original": "Hyperspectral images occupy a very important position when it comes to remote sensing imaging due to their multi band and high precision characteristics. However, due to the redundancy caused by various bands and the large amount of calculation, Reducing the size of hyperspectral photographs is important. This article proposes a program that combines cross genetic thinking with artificial bee colony algorithm (hereinafter referred to as Ag) to select the features of hyperspectral images, In the preprocessing stage, the initial feature set of the image is screened by using the outlier detection method based on the percentage level, and the feature set after the initial screening is selected by Ag algorithm. Finally, the selected band combination is sent to the neural network combining three-dimensional convolution and two-dimensional convolution for training, Experimental results on the Pavia University and Indian Pines datasets show that the algorithm has good convergence, and the band combination obtained with low computational complexity can achieve better classification accuracy and consistency in image classification.",
    "abstract_processed": "hyperspectr imag occupi import posit come remot sens imag due multi band high precis characterist howev due redund caus variou band larg amount calcul reduc size hyperspectr photograph import articl propos program combin cross genet think artifici bee coloni algorithm hereinaft refer ag select featur hyperspectr imag preprocess stage initi featur set imag screen use outlier detect method base percentag level featur set initi screen select ag algorithm final select band combin sent neural network combin three dimension convolut two dimension convolut train experiment result pavia univers indian pine dataset show algorithm good converg band combin obtain low comput complex achiev better classif accuraci consist imag classif"
  },
  {
    "doc_id": "1021322",
    "abstract_original": "Past research on software comprehension tools has produced a wealth of lessons in building good tools. However, our explanations of these tools tend to be weakly grounded in existing theories of cognition and human-computer interaction. As a result, the interesting rationales underlying their design are poorly articulated, leaving the lessons primarily implicit. This paper describes a way of using existing program comprehension theories to rationalize tool designs. To illustrate the technique, key design rationales underlying a prominent reverse engineering tool (the Reflexion Model Tool) are reconstructed. The reconstruction shows that theories of cognitive support can be applied to existing cognitive models of software developer behaviour. The method for constructing the rationales is described, and implications are drawn for codifying existing design knowledge, evaluating tools and improving design reasoning.",
    "abstract_processed": "past research softwar comprehens tool produc wealth lesson build good tool howev explan tool tend weakli ground exist theori cognit human comput interact result interest rational underli design poorli articul leav lesson primarili implicit paper describ way use exist program comprehens theori ration tool design illustr techniqu key design rational underli promin revers engin tool reflexion model tool reconstruct reconstruct show theori cognit support appli exist cognit model softwar develop behaviour method construct rational describ implic drawn codifi exist design knowledg evalu tool improv design reason"
  },
  {
    "doc_id": "10213395",
    "abstract_original": "Contribution: This study represents the first systematic attempt to develop Science, Technology, Engineering, Arts, and Mathematics (STEAM) integrated project-based learning (PBL) as a transdisciplinary teaching method for fostering students’ creativity and computational thinking (CT) skills. Background: With the growing importance of creativity and CT skills in the modern world, there is a need for innovative teaching methods that can effectively nurture these abilities in students. This study explores the potential of integrating STEAM into PBL as a transdisciplinary teaching approach to address this need. Intended Outcomes: The outcomes of this approach include significant improvements in various dimensions of students’ creativity (fluency, flexibility, originality, and elaboration) and enhanced CT skills, particularly in medium and hard tasks. Application Design: The study involved 54 junior high school seventh-graders, with 28 students in the experimental group and 26 students in the comparison group. The experimental group was exposed to a semester of STEAM PBL, while the comparison group followed the regular curriculum. Findings: After a semester of STEAM PBL, the experimental group demonstrated significant improvements in creativity dimensions, while the comparison group showed no significant changes. In terms of CT skills, the experimental group exhibited significant improvements in medium and hard tasks, whereas the comparison group did not. These results highlight the potential benefits of integrating STEAM into PBL as a transdisciplinary teaching approach for enhancing students’ creativity and CT skills. The implications for educational practice and future research are discussed in depth.",
    "abstract_processed": "contribut studi repres first systemat attempt develop scienc technolog engin art mathemat steam integr project base learn pbl transdisciplinari teach method foster students’ creativ comput think ct skill background grow import creativ ct skill modern world need innov teach method effect nurtur abil student studi explor potenti integr steam pbl transdisciplinari teach approach address need intend outcom outcom approach includ signific improv variou dimens students’ creativ fluenci flexibl origin elabor enhanc ct skill particularli medium hard task applic design studi involv junior high school seventh grader student experiment group student comparison group experiment group expos semest steam pbl comparison group follow regular curriculum find semest steam pbl experiment group demonstr signific improv creativ dimens comparison group show signific chang term ct skill experiment group exhibit signific improv medium hard task wherea comparison group result highlight potenti benefit integr steam pbl transdisciplinari teach approach enhanc students’ creativ ct skill implic educ practic futur research discuss depth"
  },
  {
    "doc_id": "10214664",
    "abstract_original": "Recently, many researchers have applied Graph Convolutional Neural Networks (GCN) to multi-label learning tasks by establishing relations among labels. However, these researchers have only used GCN as an auxiliary module and have lacked exploration of object relations, which has limited the inference capability of GCN. Applying GCN to multi-label classification in information systems poses significant challenges to address because information systems are considered as a graph with only nodes and no edges. This article proposes a multi-granularity graph convolutional neural network (MG-GCN) based on object relations to enhance the versatility of GCN and demonstrate its reasoning ability. The MG-GCN efficiently solves complex multi-label classification problems in information systems. Firstly, based on the multi-granularity thinking, the attribute set is divided into several attribute subsets based on granularity. Secondly, a graph of differences representing the relationship between objects is established under each attribute subset. Finally, based on the attention mechanism and multiple difference matrices of objects, MG-GCN is proposed and applied to multi-label classification within information systems. The effectiveness and significance of performance of MG-GCN has been verified through ranking-based indicators and hypothesis tests, respectively.",
    "abstract_processed": "recent mani research appli graph convolut neural network gcn multi label learn task establish relat among label howev research use gcn auxiliari modul lack explor object relat limit infer capabl gcn appli gcn multi label classif inform system pose signific challeng address inform system consid graph node edg articl propos multi granular graph convolut neural network mg gcn base object relat enhanc versatil gcn demonstr reason abil mg gcn effici solv complex multi label classif problem inform system firstli base multi granular think attribut set divid sever attribut subset base granular secondli graph differ repres relationship object establish attribut subset final base attent mechan multipl differ matric object mg gcn propos appli multi label classif within inform system effect signific perform mg gcn verifi rank base indic hypothesi test respect"
  },
  {
    "doc_id": "10215001",
    "abstract_original": "The recent advancements in deep learning techniques and computational power have promoted the development of novel approaches for music generation. In this study, generating alapana, an improvisational form of Carnatic music was proposed, by leveraging Generative Adversarial Networks (GANs) and Finite State Machines (FSM). The goal is to create melodious alapana sequences that follow a given input Raga, ensuring continuity and coherence throughout the generated musical piece. The proposed approach incorporates Carnatic music theory rules into the generation process to enhance the structural coherence of the generated alapana. Additionally, various hyperparameter settings were explored to achieve the best performance. The Fréchet Audio Distance, Percentage of Correct Pitches and the Subjective evaluation through human listeners are the evaluation metrics of this approach. The result of this study demonstrates the potential of using GANs and FSM for generating continuous and pleasing alapana sequences in Carnatic music, contributing to the growing body of research in computational music generation.",
    "abstract_processed": "recent advanc deep learn techniqu comput power promot develop novel approach music gener studi gener alapana improvis form carnat music propos leverag gener adversari network gan finit state machin fsm goal creat melodi alapana sequenc follow given input raga ensur continu coher throughout gener music piec propos approach incorpor carnat music theori rule gener process enhanc structur coher gener alapana addit variou hyperparamet set explor achiev best perform fréchet audio distanc percentag correct pitch subject evalu human listen evalu metric approach result studi demonstr potenti use gan fsm gener continu pleas alapana sequenc carnat music contribut grow bodi research comput music gener"
  },
  {
    "doc_id": "10216405",
    "abstract_original": "Huge efforts have been made so far aiming to classify human thoughts. Controlling machines using the concept of Brain-Computer Interface (BCI) is a practical method that opens the way toward a fully synchronized method between human thoughts and controlled objects. Furthermore, a reliable design of a BCI-based Internet of Things (IoT) system is still in the early stages because it still has several challenges, such as the issue of accurately implementing the individual's intention. This paper presents a method for brain waves recognition using deep learning based on shapes and colors for use in merging concepts of the IoT and BCI, which we defined as the “Internet of Brain Controlled Things (IoBCT).” We used a low-cost 8-channel Electroencephalography (EEG) headset, and the results showed an acceptable accuracy of 93% in the brain waves pattern recognition, which opens the way for designing a reliable IoBCT.",
    "abstract_processed": "huge effort made far aim classifi human thought control machin use concept brain comput interfac bci practic method open way toward fulli synchron method human thought control object furthermor reliabl design bci base internet thing iot system still earli stage still sever challeng issu accur implement individu intent paper present method brain wave recognit use deep learn base shape color use merg concept iot bci defin “internet brain control thing iobct ” use low cost channel electroencephalographi eeg headset result show accept accuraci brain wave pattern recognit open way design reliabl iobct"
  },
  {
    "doc_id": "10216466",
    "abstract_original": "Computational thinking (CT) is a key component of computer science and a foundational thinking process in K-12 classrooms. CT can be easily integrated into science lessons with the right policies, programs, and practices in place. This paper explores the current practices of CT in a northeast US state based on survey data collected from teachers. The research uncovers how much teaching time is spent teaching science and the percentage of lessons that have CT concepts and approaches present in the science instruction while describing what these lessons look like. This paper then discusses the next steps for implementation efforts based on the described CT practices in elementary science.",
    "abstract_processed": "comput think ct key compon comput scienc foundat think process k classroom ct easili integr scienc lesson right polici program practic place paper explor current practic ct northeast us state base survey data collect teacher research uncov much teach time spent teach scienc percentag lesson ct concept approach present scienc instruct describ lesson look like paper discuss next step implement effort base describ ct practic elementari scienc"
  },
  {
    "doc_id": "10216497",
    "abstract_original": "It is essential to initiate a curriculum concerning mobile device forensics and law enforcement in the intermediate grades in Mississippi using a facet of multidisciplinary subjects: biology, chemistry, computer science, criminology, and physics. The students participated in engaged teams who gathered the evidence (critical thinking), analyzed the evidence (deductive reasoning), and drew conclusions (inference) in a story-based scenario entitled “Cyberbullying Mobile Device Criminal Investigation.” This research presents cyberbullying while bringing awareness to the law enforcement community by understanding digital forensics; furthermore, it shows how STEM and Criminology are presented to intermediate students by solving a middle school mystery based on a multidisciplinary framework. By including a multidisciplinary curriculum in this process, students developed an appreciation of the interrelatedness between the STEM Sciences and Liberal Arts Education.",
    "abstract_processed": "essenti initi curriculum concern mobil devic forens law enforc intermedi grade mississippi use facet multidisciplinari subject biolog chemistri comput scienc criminolog physic student particip engag team gather evid critic think analyz evid deduct reason drew conclus infer stori base scenario entitl “cyberbulli mobil devic crimin investig ” research present cyberbulli bring awar law enforc commun understand digit forens furthermor show stem criminolog present intermedi student solv middl school mysteri base multidisciplinari framework includ multidisciplinari curriculum process student develop appreci interrelated stem scienc liber art educ"
  },
  {
    "doc_id": "10216563",
    "abstract_original": "For the last two decades, the world of pre-academic and academic education has been occupied with ways of developing computational thinking. Responding to the common perception to develop those thinking skills in all learners, and indeed in the entire population, we developed a MOOC on computational thinking. The course advocates the development of computational thinking skills in every human being, at any age, and in any subject matter, emphasizing the common, essential computational thinking skills: problem decomposition, abstraction, and generalization. Based on our belief in the importance of the application of computational thinking skills when using computerized environments, and the importance of its significant application in developing an understanding of any discipline, the course is based on the development of simulations of computational processes in any area of knowledge. We widely discuss the pedagogical challenges of developing a MOOC on thinking skills without teacher-learner interaction, and share how we overcame these challenges by implementing the Four Pedagogies for Developing Computational Thinking (4P4CT) framework, which integrates the pedagogies of active learning, project-based learning, product-based learning, and context-based learning. We present preliminary findings from research we conducted during the first two MOOC cycles with about 1,600 learners. Specifically, quantitative and qualitative data analysis of students' learning processes are discussed, reflecting the students' multi-faceted and deep engagement in the MOOC.",
    "abstract_processed": "last two decad world pre academ academ educ occupi way develop comput think respond common percept develop think skill learner inde entir popul develop mooc comput think cours advoc develop comput think skill everi human age subject matter emphas common essenti comput think skill problem decomposit abstract gener base belief import applic comput think skill use computer environ import signific applic develop understand disciplin cours base develop simul comput process area knowledg wide discuss pedagog challeng develop mooc think skill without teacher learner interact share overcam challeng implement four pedagogi develop comput think p ct framework integr pedagogi activ learn project base learn product base learn context base learn present preliminari find research conduct first two mooc cycl learner specif quantit qualit data analysi student learn process discuss reflect student multi facet deep engag mooc"
  },
  {
    "doc_id": "10216660",
    "abstract_original": "The Digital Logic and Computer Architecture related courses are one of the key knowledge areas in Computer Science (CS) used to enhance students' understanding of Boolean algebra, logic gates, registers, arithmetic logic units, etc. and provides insights how software and hardware are related in a computing system. Experimental Centric based Instructional Pedagogy (ECP) with portable laboratory instrumentation might provide real hands-on experience to obtain a practical understanding of the concepts at a lower cost compared to virtual hands-on laboratories. This paper presents the initial adaptation of an evidence-based, experiment-focused teaching approach to introduce the fundamentals of digital logic concepts using the commercial ADALM 1K Active Learning Module in a Computer Architecture course for the first time in the CS department at a university serving predominantly minority students. To evaluate the impact of the ECP on student performance in the Computer Architecture course, we conducted three different evaluations, which are class observation, signature assignment, and the Motivated Strategies for Learning Questionnaires (MLSQ) survey. The results of the Classroom Observation Protocol for Undergraduate STEM (COPUS) show more student engagement when ECP is implemented; the output of the signature assignment shows an increase in students' learning outcomes; and the MLSQ survey, which tests the students' motivation, critical thinking, curiosity, collaboration, and metacognition, ascertains the effect of the ECP on the CS students who participated in the experiment.",
    "abstract_processed": "digit logic comput architectur relat cours one key knowledg area comput scienc cs use enhanc student understand boolean algebra logic gate regist arithmet logic unit etc provid insight softwar hardwar relat comput system experiment centric base instruct pedagogi ecp portabl laboratori instrument might provid real hand experi obtain practic understand concept lower cost compar virtual hand laboratori paper present initi adapt evid base experi focus teach approach introduc fundament digit logic concept use commerci adalm k activ learn modul comput architectur cours first time cs depart univers serv predominantli minor student evalu impact ecp student perform comput architectur cours conduct three differ evalu class observ signatur assign motiv strategi learn questionnair mlsq survey result classroom observ protocol undergradu stem copu show student engag ecp implement output signatur assign show increas student learn outcom mlsq survey test student motiv critic think curios collabor metacognit ascertain effect ecp cs student particip experi"
  },
  {
    "doc_id": "10216683",
    "abstract_original": "The increasing societal dependence on software, and the negative consequences of undesirable behavior of software, calls for ever more attention to software quality. The purpose of software quality control is activities that support the achievement of desirable levels of software quality, and software testing is one such activity. In order to preserve the intent of software testing, it must be deliberated carefully, and given necessary time and due diligence, before being acted upon. In that regard, this paper adopts a human-centered approach to software testing, embraces mind mapping as a lightweight technique for early software testing-related commitments, provides elements of a theoretical basis for mind mapping, and offers a guided tour of software testing-related mind maps using practical examples relevant in academia as well as industry.",
    "abstract_processed": "increas societ depend softwar neg consequ undesir behavior softwar call ever attent softwar qualiti purpos softwar qualiti control activ support achiev desir level softwar qualiti softwar test one activ order preserv intent softwar test must deliber care given necessari time due dilig act upon regard paper adopt human center approach softwar test embrac mind map lightweight techniqu earli softwar test relat commit provid element theoret basi mind map offer guid tour softwar test relat mind map use practic exampl relev academia well industri"
  },
  {
    "doc_id": "10216687",
    "abstract_original": "The human mind is a truly remarkable thing that does so much that we are not even aware of. Controlling machines using the concept of Brain-Computer Interface (BCI) is a practical method that opens the way to a fully synchronized method between human thoughts and controlled objects. Using BCI to control a drone will open the way toward smooth and high-response flight. Deep learning is a new-age skill that has made many breakthroughs and influenced modern technologies. It has made it possible to predict and identify even the most complex and abstract patterns that even we humans would be very challenged to catch ourselves. In this paper, a method of controlling a drone using BCI has been presented using an 8-channel Electroencephalogram (EEG) headset. Deep learning has been employed to process and classify human brain waves. After testing the resulting deep learning algorithm, the overall classification accuracy was 90% to distinguish between four different movements of the drone.",
    "abstract_processed": "human mind truli remark thing much even awar control machin use concept brain comput interfac bci practic method open way fulli synchron method human thought control object use bci control drone open way toward smooth high respons flight deep learn new age skill made mani breakthrough influenc modern technolog made possibl predict identifi even complex abstract pattern even human would challeng catch paper method control drone use bci present use channel electroencephalogram eeg headset deep learn employ process classifi human brain wave test result deep learn algorithm overal classif accuraci distinguish four differ movement drone"
  },
  {
    "doc_id": "10216751",
    "abstract_original": "Educational robotics provides an interdisciplinary approach to STEM, computer science, and 21stcentury skill acquisition for students of all ages. Robotics can increase student perceptions of STEM subjects as well as foundational skills through an engaging and authentic learning environment. However, the many benefits of robotics for students and teachers are dependent on the curriculum. In this paper we describe how using the Understanding by Design pedagogical framework supports the development of truly integrated and interdisciplinary educational robotics curriculum. Two examples are provided for a virtual robot that showcase this pedagogical approach for combining STEM, art, and programming in an authentic manner.",
    "abstract_processed": "educ robot provid interdisciplinari approach stem comput scienc stcenturi skill acquisit student age robot increas student percept stem subject well foundat skill engag authent learn environ howev mani benefit robot student teacher depend curriculum paper describ use understand design pedagog framework support develop truli integr interdisciplinari educ robot curriculum two exampl provid virtual robot showcas pedagog approach combin stem art program authent manner"
  },
  {
    "doc_id": "10218039",
    "abstract_original": "This paper presents a conceptual framework for designing relational agents (RAs) in healthcare contexts, developed through the findings from multiple user studies on RAs about their acceptance, efficacy, and usability. The framework emphasizes a user-centered design (UCD) approach that takes into account the unique needs and preferences of patients, non-patient users, and healthcare professionals (HCPs). Based on the results of these studies, we analyzed and refined the RA designs and proposed a UCD-based conceptual framework for designing effective and user-friendly healthcare RAs. The paper aims to provide an initial resource for researchers, designers, and developers interested in developing RAs for healthcare contexts by thinking of UCD techniques.",
    "abstract_processed": "paper present conceptu framework design relat agent ra healthcar context develop find multipl user studi ra accept efficaci usabl framework emphas user center design ucd approach take account uniqu need prefer patient non patient user healthcar profession hcp base result studi analyz refin ra design propos ucd base conceptu framework design effect user friendli healthcar ra paper aim provid initi resourc research design develop interest develop ra healthcar context think ucd techniqu"
  },
  {
    "doc_id": "10219538",
    "abstract_original": "The research aims to conduct a psychophysical experiment to explore the subjective emotion perception of the observers under white light sources with different illuminance, correlated color temperature (CCT), and distance to the black-body locus (Duv). Based on the experimental results, appropriate lighting conditions will be derived, and an evaluation model is established for beauty and aromatherapy to assess emotion perception under different white light sources based on the large amount of data obtained from the experiment.",
    "abstract_processed": "research aim conduct psychophys experi explor subject emot percept observ white light sourc differ illumin correl color temperatur cct distanc black bodi locu duv base experiment result appropri light condit deriv evalu model establish beauti aromatherapi assess emot percept differ white light sourc base larg amount data obtain experi"
  },
  {
    "doc_id": "1022147",
    "abstract_original": "In the stage of schematic design, some data needed to calculate design cooling load can not be supplied with accurate values, designers have to assess a value according to their experience only. The calculation of a building's design cooling load is different from the load analysis of existing buildings, it is a prediction of the maximum possible load of a future building when it is put into use, so it has the characteristic of uncertainty and prediction. In order to improve calculation efficiency and enhance accuracy, expert system technology is introduced and incorporated with a load index assessment method. Consequently, an expert system for the calculation of a building's design cooling load is established on the basis of artificial neural network theories. Application examples indicate that this system is simple and workable; the calculation results thereof achieve high accuracy, and calculation methods are in conformity to the thinking habits of designers.",
    "abstract_processed": "stage schemat design data need calcul design cool load suppli accur valu design assess valu accord experi calcul build design cool load differ load analysi exist build predict maximum possibl load futur build put use characterist uncertainti predict order improv calcul effici enhanc accuraci expert system technolog introduc incorpor load index assess method consequ expert system calcul build design cool load establish basi artifici neural network theori applic exampl indic system simpl workabl calcul result thereof achiev high accuraci calcul method conform think habit design"
  },
  {
    "doc_id": "10222744",
    "abstract_original": "Artificial intelligence (AI) has recently been used as a tool for various visual storytelling, but text-to-image models are a stochastic machine learning process that requires human intervention to assist creation better. As we all know, pre-visualization is an important stage in film production, involving subjective choices by the creators. This paper investigates how AI can assist filmmakers during the pre-production stage by generating mood boards from text. We propose a novel preproduction pipeline and guidelines that leverage text-to-image models to create visual previews of film projects. We also conduct a case study to validate and evaluate our approach's effectiveness. Our case study suggests that following the guidelines we have developed can assist filmmakers in generating mood boards that effectively convey the desired atmosphere of their projects and potentially contribute to enhancing the creative process. Our paper aims to contribute to the field of AI art and the film industry.",
    "abstract_processed": "artifici intellig ai recent use tool variou visual storytel text imag model stochast machin learn process requir human intervent assist creation better know pre visual import stage film product involv subject choic creator paper investig ai assist filmmak pre product stage gener mood board text propos novel preproduct pipelin guidelin leverag text imag model creat visual preview film project also conduct case studi valid evalu approach effect case studi suggest follow guidelin develop assist filmmak gener mood board effect convey desir atmospher project potenti contribut enhanc creativ process paper aim contribut field ai art film industri"
  },
  {
    "doc_id": "10223039",
    "abstract_original": "This review explores the integration of enhanced personalization and seamless multimodal interfaces in the field of fashion design and recommendation. We examine the increasing demand for personalized fashion experiences and the potential of multimodal interfaces in facilitating effective communication between designers and users. By leveraging user preferences, body measurements, and style choices, artificial intelligence (AI) systems can deliver highly personalized fashion recommendations. The integration of various input modalities, including text, images and sketches, enables designers and users to communicate their design ideas with ease. The primary results highlight the transformative potential of enhanced personalization and seamless multimodal interfaces, empowering designers and consumers to co-create unique and personalized designs. This paradigm shift fosters a deeper level of engagement and creativity within the fashion industry. Embracing this advancement unlocks unprecedented opportunities for designers, brands, and consumers, ushering in a new era of innovation and creativity in fashion design.",
    "abstract_processed": "review explor integr enhanc person seamless multimod interfac field fashion design recommend examin increas demand person fashion experi potenti multimod interfac facilit effect commun design user leverag user prefer bodi measur style choic artifici intellig ai system deliv highli person fashion recommend integr variou input modal includ text imag sketch enabl design user commun design idea eas primari result highlight transform potenti enhanc person seamless multimod interfac empow design consum co creat uniqu person design paradigm shift foster deeper level engag creativ within fashion industri embrac advanc unlock unpreced opportun design brand consum usher new era innov creativ fashion design"
  },
  {
    "doc_id": "10223616",
    "abstract_original": "Affective computing, particularly the identification of emotions from multichannel electroencephalography (EEG) signals, has gained importance. In this study, we propose a novel deep neural network model called Cycle Consistent Multi-Task Variational Autoencoder (CycleMVAE) to simultaneously investigate pairwise translation of emotional features, signal reconstruction, and emotion classification across two different EEG recording samples. CycleMVAE comprises two Variational Autoencoders (VAEs) and a supervised classifier. Each VAE consists of an encoder and a decoder. The encoder of the first VAE transfers emotional properties from EEG sample X to a compact latent space Z, while the decoder retrieves these features from Z to transfer them to EEG sample Y. Similarly, the second VAE uses the compact latent space Z’ to transfer emotion features from EEG sample Y to EEG sample X. This forms a cyclic translation of feature among EEG sample recordings. The model is trained using reconstructed loss, cycle consistency loss, and latent vector regularization loss, with a supervised classifier used to categorize emotions into arousal, valence, and dominance categories. The proposed approach improves EEG classification performance while reducing pre-processing complexity. The effectiveness of the proposed approach has been validated by experimental findings on the multimodal DREAMER emotional database.",
    "abstract_processed": "affect comput particularli identif emot multichannel electroencephalographi eeg signal gain import studi propos novel deep neural network model call cycl consist multi task variat autoencod cyclemva simultan investig pairwis translat emot featur signal reconstruct emot classif across two differ eeg record sampl cyclemva compris two variat autoencod vae supervis classifi vae consist encod decod encod first vae transfer emot properti eeg sampl x compact latent space z decod retriev featur z transfer eeg sampl similarli second vae use compact latent space z’ transfer emot featur eeg sampl eeg sampl x form cyclic translat featur among eeg sampl record model train use reconstruct loss cycl consist loss latent vector regular loss supervis classifi use categor emot arous valenc domin categori propos approach improv eeg classif perform reduc pre process complex effect propos approach valid experiment find multimod dreamer emot databas"
  },
  {
    "doc_id": "10227116",
    "abstract_original": "This paper synthesizes three fundamental challenges within existing frameworks for the ethical regulation of artificial intelligence (AI) identified in recently published literature. These challenges have recently been raised by ethicists, computer scientists, and policymakers. More specifically, existing frameworks are encountering challenges such as the difficulties that come along with defining an AI, adapting to the needs of the public in participating in democratic governance, and considering the environmental impacts of these systems. After critically reviewing the three challenges, this paper proposes alternative regulatory approaches to address each of these regulatory challenges. To address the definition challenge, we propose a multidimensional approach to defining AI. We argue that a relational approach can be helpful for making visible the cultural context in which AI systems are embedded. Finally, we suggest that involving a systematic environmental studies approach in assessing AI is conducive to the development of not only more environmentally friendly AI systems but also AI technologies that can be used to address challenging global environmental issues.",
    "abstract_processed": "paper synthes three fundament challeng within exist framework ethic regul artifici intellig ai identifi recent publish literatur challeng recent rais ethicist comput scientist policymak specif exist framework encount challeng difficulti come along defin ai adapt need public particip democrat govern consid environment impact system critic review three challeng paper propos altern regulatori approach address regulatori challeng address definit challeng propos multidimension approach defin ai argu relat approach help make visibl cultur context ai system embed final suggest involv systemat environment studi approach assess ai conduc develop environment friendli ai system also ai technolog use address challeng global environment issu"
  },
  {
    "doc_id": "10227838",
    "abstract_original": "We report a study investigating the viability of using interactive visualizations to aid architectural design with building codes. While visualizations have been used to support general architectural design exploration, existing computational solutions treat building codes as separate from, rather than part of, the design process, creating challenges for architects. Through a series of participatory design studies with professional architects, we found that interactive visualizations have promising potential to aid design exploration and sensemaking in early stages of architectural design by providing feedback about potential allowances and consequences of design decisions. However, implementing a visualization system necessitates addressing the complexity and ambiguity inherent in building codes. To tackle these challenges, we propose various user-driven knowledge management mechanisms for integrating, negotiating, interpreting, and documenting building code rules.",
    "abstract_processed": "report studi investig viabil use interact visual aid architectur design build code visual use support gener architectur design explor exist comput solut treat build code separ rather part design process creat challeng architect seri participatori design studi profession architect found interact visual promis potenti aid design explor sensemak earli stage architectur design provid feedback potenti allow consequ design decis howev implement visual system necessit address complex ambigu inher build code tackl challeng propos variou user driven knowledg manag mechan integr negoti interpret document build code rule"
  },
  {
    "doc_id": "10229152",
    "abstract_original": "The utilization of semantic web technologies has led to the development of knowledge graphs represented as triples that allow for the exploration of specific and cross-domains. Despite the advantages of semantic links between entities in facilitating user exploration, they can also lead to an overwhelming number of exploration choices that can cause confusion, frustration, uncertainty, and a sense of being lost in the abundant graph, particularly for users who are not familiar with the domain. Thus, identifying exploration strategies is critical to improving user exploration and increasing exploration utility. This study aims to identify exploration strategies that promote knowledge utility (i.e., increase users’ domain knowledge) and exploration experience (i.e., provide users with a positive and pleasant feeling). To accomplish this goal, an experimental user study was conducted, involving lay users in the musical instrument domain, where they were presented with an exploration task and then allowed to freely explore musical instruments. Parameters related to exploration paths were used to analyze the exploration patterns that users follow during their exploration. The findings reveal exploration strategies that promote knowledge utility and exploration experience. This research contributes to the literature on intelligent methods of guiding user exploration through knowledge graphs to enhance exploration effectiveness, which can have broad applications in knowledge graph utilization.",
    "abstract_processed": "util semant web technolog led develop knowledg graph repres tripl allow explor specif cross domain despit advantag semant link entiti facilit user explor also lead overwhelm number explor choic caus confus frustrat uncertainti sens lost abund graph particularli user familiar domain thu identifi explor strategi critic improv user explor increas explor util studi aim identifi explor strategi promot knowledg util e increas users’ domain knowledg explor experi e provid user posit pleasant feel accomplish goal experiment user studi conduct involv lay user music instrument domain present explor task allow freeli explor music instrument paramet relat explor path use analyz explor pattern user follow explor find reveal explor strategi promot knowledg util explor experi research contribut literatur intellig method guid user explor knowledg graph enhanc explor effect broad applic knowledg graph util"
  },
  {
    "doc_id": "10229331",
    "abstract_original": "The paper we present [1] is an analysis of Cooperative Thinking, a model of team-based computational problem-solving that extends Computational Thinking with Agile Values.",
    "abstract_processed": "paper present analysi cooper think model team base comput problem solv extend comput think agil valu"
  },
  {
    "doc_id": "10229637",
    "abstract_original": "With the development of computer technology, people’s thinking mode has also changed dramatically. 3D animation and virtual reality (VR) technology can be seen everywhere around people. With the development of technology, 3D animation and VR technology are applied in more and more fields, such as education, medical treatment and commerce. Under the background of increasing international competition, the update speed of high-tech is changing with each passing day. With the wide application of VR technology by modern people, the 3D animation industry has been further developed. The effective combination of 3D animation scene graphic design and VR technology can further improve the overall perfection of 3D animation scene design. This paper improves the lighting model and shadow rendering algorithm according to the defects of the general lighting rendering algorithm in the application of 3D animation scenes. Based on this, a hybrid 3D scene lighting rendering algorithm is obtained. When optimizing the Cook Torrance lighting model, a geometric attenuation factor algorithm is used, and when improving the shadow rendering algorithm, a light shadow rendering algorithm based on variance shadow is used.",
    "abstract_processed": "develop comput technolog people’ think mode also chang dramat anim virtual realiti vr technolog seen everywher around peopl develop technolog anim vr technolog appli field educ medic treatment commerc background increas intern competit updat speed high tech chang pass day wide applic vr technolog modern peopl anim industri develop effect combin anim scene graphic design vr technolog improv overal perfect anim scene design paper improv light model shadow render algorithm accord defect gener light render algorithm applic anim scene base hybrid scene light render algorithm obtain optim cook torranc light model geometr attenu factor algorithm use improv shadow render algorithm light shadow render algorithm base varianc shadow use"
  },
  {
    "doc_id": "10229694",
    "abstract_original": "Targeted malware evolved in recent years and that with encrypted payload appeared. The evolved targeted malware is difficult to be detected by static analysis and dynamic analysis on a virtual or stand-alone machine. The key for encryption is generated from information of a target computer. Therefore, the key is only known by an attacker and a victim computer. However, any targeted malware must collecting information of victim computer and we think this is a feature of targeted malware. First, we introduce our proposed method which detects targeted malware with encrypted payload by finding features of the collection behavior with machine learning. As a result, all test samples were classified to benign in our evaluation. We considered that features of our simulated samples are different from those of actual samples. Therefore, in this paper, we investigate of the difference and consider how we can create more precise simulated samples. We created map images of matched n-grams of our simulated samples with actual malware samples. We found hints of more precise simulated samples by looking distribution of the matched n-grams.",
    "abstract_processed": "target malwar evolv recent year encrypt payload appear evolv target malwar difficult detect static analysi dynam analysi virtual stand alon machin key encrypt gener inform target comput therefor key known attack victim comput howev target malwar must collect inform victim comput think featur target malwar first introduc propos method detect target malwar encrypt payload find featur collect behavior machin learn result test sampl classifi benign evalu consid featur simul sampl differ actual sampl therefor paper investig differ consid creat precis simul sampl creat map imag match n gram simul sampl actual malwar sampl found hint precis simul sampl look distribut match n gram"
  },
  {
    "doc_id": "10234310",
    "abstract_original": "Explainable Artificial Intelligence (XAI) is a new paradigm of Artificial Intelligence (AI) that is giving different AI/ Machine Learning (ML) models a boost to penetrate sectors where people are thinking about adopting AI. This work focuses on the adoption of XAI in the health sector. It portrays that careful integration of XAI in both cloud and edge could change the whole healthcare industry and make humans more aware of their present health conditions, which is the need of the hour. To demonstrate the same, we have done an experiment based on the prediction of a particular medical condition called \"cardiac arrest\" in a specific subject group (patients who are 70 years old). Here, based on the explanation provided by the XAI model (e.g., SHAP, LIME) at Cloud and Edge, our system can predict the chances of a \"cardiac arrest\" for the subject with a valid explanation. This type of model will be the next big upgrade in the healthcare industry in terms of automation and a self-explanatory system that works as a personal health assistant for individuals.",
    "abstract_processed": "explain artifici intellig xai new paradigm artifici intellig ai give differ ai machin learn ml model boost penetr sector peopl think adopt ai work focus adopt xai health sector portray care integr xai cloud edg could chang whole healthcar industri make human awar present health condit need hour demonstr done experi base predict particular medic condit call cardiac arrest specif subject group patient year old base explan provid xai model e g shap lime cloud edg system predict chanc cardiac arrest subject valid explan type model next big upgrad healthcar industri term autom self explanatori system work person health assist individu"
  },
  {
    "doc_id": "10236852",
    "abstract_original": "With the rapid development of science and technology, data is increasing exponentially. Data security has become a problem that people pay close attention to. How to ensure data security has aroused people's thinking. In order to ensure the communication security of network data, this paper points out the security threats in computer network communication, clarifies the significance of data encryption technology, and analyzes the commonly used data encryption methods in computer network communication. In this paper, a computer data security application model based on edge computing is constructed. In this model, data redundancy elimination method and differential privacy protection algorithm are adopted successively. After removing duplicate data and obtaining good quality data, the computer data is privacy protected, and the data security processing based on edge computing is realized. After testing, the privacy protection budget value of the built model is 0.23, and the computer data information leakage ratio based on edge computing is the smallest. Under this condition, the maximum data information leakage ratio based on edge computing is reduced from 0.678 to 0.234, and the data security is significantly improved.",
    "abstract_processed": "rapid develop scienc technolog data increas exponenti data secur becom problem peopl pay close attent ensur data secur arous peopl think order ensur commun secur network data paper point secur threat comput network commun clarifi signific data encrypt technolog analyz commonli use data encrypt method comput network commun paper comput data secur applic model base edg comput construct model data redund elimin method differenti privaci protect algorithm adopt success remov duplic data obtain good qualiti data comput data privaci protect data secur process base edg comput realiz test privaci protect budget valu built model comput data inform leakag ratio base edg comput smallest condit maximum data inform leakag ratio base edg comput reduc data secur significantli improv"
  },
  {
    "doc_id": "10237297",
    "abstract_original": "The study explored the effects of an interdisciplinary learning approach on developing students’ English learning (EL) and computational thinking (CT) through two different game-based learning approaches. A quasi-experiment was conducted to evaluate the effectiveness of this approach in terms of enhancing students’ CT knowledge and their EL achievement in an elementary school English as a foreign language learning context. A total of 52 Grade 3 students took part in the experiment, of whom 28 assigned to the experimental group learned with a machine educational robot (machine-ER) board game and 24 assigned to the control group learned with a character educational robot (character-ER) board game. The results indicated that both groups made significant improvements in learning achievement: 1) in EL achievement of learning vocabulary and sentence patterns; 2) in CT concepts, although the machine-ER board game produced a greater increase than the character-ER board game in both language learning achievement and CT knowledge; 3) their learning anxieties were also lower than those of the control group; and 4) the analysis of behavioral patterns also revealed that students playing the machine-ER board game demonstrated better language-learning interaction, while the character-ER board game presented greater CT development in finding solutions.",
    "abstract_processed": "studi explor effect interdisciplinari learn approach develop students’ english learn el comput think ct two differ game base learn approach quasi experi conduct evalu effect approach term enhanc students’ ct knowledg el achiev elementari school english foreign languag learn context total grade student took part experi assign experiment group learn machin educ robot machin er board game assign control group learn charact educ robot charact er board game result indic group made signific improv learn achiev el achiev learn vocabulari sentenc pattern ct concept although machin er board game produc greater increas charact er board game languag learn achiev ct knowledg learn anxieti also lower control group analysi behavior pattern also reveal student play machin er board game demonstr better languag learn interact charact er board game present greater ct develop find solut"
  },
  {
    "doc_id": "10238919",
    "abstract_original": "The requirement for reductions in CO2, NOX and noise emissions from aviation have come under great assiduity. The use of electric and hybrid-electric propulsion systems within aircraft offer potential performance and efficiency improvements, through reduced fuel consumption, reduced emissions, and reduction in noise. This work proposes a novel multidisciplinary simulation tool, capable of determining optimised propulsion system parameters for various measures of merit (MoM), based on preliminary or conceptual aircraft specifications. Overall power, control and drive system which is to be used within the propulsion systems of hybrid and / or all electric aircraft applications can be determined from the simulation tool. Using an initial sizing algorithm to consider aircraft with hybrid-electric propulsion systems, taking power-to-weight ratio (P/W), wing loading (W/S), and hybridisation of power, as inputs to a mission analysis, and performing an optimisation study to determine a MoM, it has been possible to expand on work in this field with the addition of a supplementary branch in the sizing methodology to include a sizing analysis for the components of an aircraft’s electric propulsion system. The designed program enables accurate sizing of powertrain, optimises overall masses, and allows rapid sizing with minimal computational expense.",
    "abstract_processed": "requir reduct co nox nois emiss aviat come great assidu use electr hybrid electr propuls system within aircraft offer potenti perform effici improv reduc fuel consumpt reduc emiss reduct nois work propos novel multidisciplinari simul tool capabl determin optimis propuls system paramet variou measur merit mom base preliminari conceptu aircraft specif overal power control drive system use within propuls system hybrid electr aircraft applic determin simul tool use initi size algorithm consid aircraft hybrid electr propuls system take power weight ratio p w wing load w hybridis power input mission analysi perform optimis studi determin mom possibl expand work field addit supplementari branch size methodolog includ size analysi compon aircraft’ electr propuls system design program enabl accur size powertrain optimis overal mass allow rapid size minim comput expens"
  },
  {
    "doc_id": "10239284",
    "abstract_original": "The sixth-generation (6G) network will shift its focus to supporting everything including various machine-type devices (MTDs) in an every-one-centric manner. To ubiquitously cover the MTDs working in rural and disastrous areas, satellite communications become indispensable, while mobile edge computing (MEC) also plays an increasingly crucial role. Their sophisticated integration enables wide-area edge intelligence which promises to facilitate globally-distributed customized services. In this article, we present typical use cases of integrated satellite-MEC networks and discuss the main challenges therein. Inspired by the protein structure and the systematic engineering methodology, we propose three minimal integrating structures, based on which a complex integrated satellite-MEC network can be treated as their extension and combination. We discuss the unique characteristics and key problems of each minimal structure. Accordingly, we establish an on-demand network orchestration framework to enrich the hierarchy of network management, which further leads to a process-oriented network optimization method. On that basis, a case study is utilized to showcase the benefits of on-demand network orchestration and process-oriented network optimization. Finally, we outline potential research issues to envision a more intelligent, more secure, and greener integrated network.",
    "abstract_processed": "sixth gener g network shift focu support everyth includ variou machin type devic mtd everi one centric manner ubiquit cover mtd work rural disastr area satellit commun becom indispens mobil edg comput mec also play increasingli crucial role sophist integr enabl wide area edg intellig promis facilit global distribut custom servic articl present typic use case integr satellit mec network discuss main challeng therein inspir protein structur systemat engin methodolog propos three minim integr structur base complex integr satellit mec network treat extens combin discuss uniqu characterist key problem minim structur accordingli establish demand network orchestr framework enrich hierarchi network manag lead process orient network optim method basi case studi util showcas benefit demand network orchestr process orient network optim final outlin potenti research issu envis intellig secur greener integr network"
  },
  {
    "doc_id": "10242475",
    "abstract_original": "Creating background music based on vocal sounds using deep learning is challenging. The task involves multiple input and multiple output cases that require lengthy input and output as data. However, training the models with raw data using low-end computers is expensive since training takes a long time and requires high memory. Previous studies predominantly have used Recurrent Neural Networks or Transformer models trained with the pitch, timing, and amplitude of scripted musical notes to generate new background music sequences. In this research, we proposed a novel training procedure using simple Gated Recurrent Units as the basic architecture of the model, which is trained with compacted high-dimensional vectors based on raw long audio sequences. Our experiments showed promising results, even when executed on low-end hardware. Our best model achieved a cumulative moving average of the loss of around 0.016, and the model successfully produced interesting background music based on vocal sound.",
    "abstract_processed": "creat background music base vocal sound use deep learn challeng task involv multipl input multipl output case requir lengthi input output data howev train model raw data use low end comput expens sinc train take long time requir high memori previou studi predominantli use recurr neural network transform model train pitch time amplitud script music note gener new background music sequenc research propos novel train procedur use simpl gate recurr unit basic architectur model train compact high dimension vector base raw long audio sequenc experi show promis result even execut low end hardwar best model achiev cumul move averag loss around model success produc interest background music base vocal sound"
  },
  {
    "doc_id": "10242723",
    "abstract_original": "Proxy re-encryption (PRE) can guarantee the security of data sharing in the cloud making it important in ciphertext sharing in the cloud computing environment. Plenty of the current PRE algorithms based on the learning with errors (LWE) problem are constructed under the random oracle model or have problems such as long public parameter size, large ciphertext expansion rate, etc. We propose an identity-based PRE (IB-PRE) scheme using the LWE problem with short public parameters which can solve the mentioned challenges. Our scheme uses the blocking operation to decrease the public parameter size and a more useful trapdoor generation algorithm to reduce the trapdoor size. These two technologies improve the computational efficiency of the public key. We think that when we divide the identity id into 16 blocks, without much increase in computational overhead, the public key size can be reduced by 88.34%, and the scheme’s security level can remain unchanged. Our scheme achieves adaptive IND-ID-CPA security. It is unidirectional, collusion-resistant, and constructed under the standard model.",
    "abstract_processed": "proxi encrypt pre guarante secur data share cloud make import ciphertext share cloud comput environ plenti current pre algorithm base learn error lwe problem construct random oracl model problem long public paramet size larg ciphertext expans rate etc propos ident base pre ib pre scheme use lwe problem short public paramet solv mention challeng scheme use block oper decreas public paramet size use trapdoor gener algorithm reduc trapdoor size two technolog improv comput effici public key think divid ident id block without much increas comput overhead public key size reduc scheme’ secur level remain unchang scheme achiev adapt ind id cpa secur unidirect collus resist construct standard model"
  },
  {
    "doc_id": "10246878",
    "abstract_original": "Studying computer programming requires not only an understanding of theories and concepts but also coding adeptness. Success in studying or conducting such a course is definitely a challenge. This paper proposes a systematic learning style recommendation. The model is designed to evaluate students' attributes and ongoing or formative learning outcomes for suggesting the effective style-fit strategy that facilitates learners to enhance their learning performances in terms of knowledge and skill. A two-stage association analysis was designed and conducted on a dataset collected from IT major students who enrolled in the Introduction to Computer Programming course. The first stage of association rules is to analyze and discover important relationships amongst learning styles, students' attribute, and learning performance. The second stage of moderation analysis is then applied to probe the moderation effect of the different learning preferences on the relationship between student attributes and learning achievement. Experiments expose many insights, for example, mathematics and logical thinking are powerful assets of success in computer programming study. Association rules can effectively identify associations of learning styles and the learning performance in terms of knowledge or skills. By moderation analysis, students in the “Excellent” cluster have a broad learning style than other students. Two types of significant moderators, the universal and specific, exemplify how lecturers can flexibly post style-fit teaching strategies for a class-wide and specific group, respectively.",
    "abstract_processed": "studi comput program requir understand theori concept also code adept success studi conduct cours definit challeng paper propos systemat learn style recommend model design evalu student attribut ongo form learn outcom suggest effect style fit strategi facilit learner enhanc learn perform term knowledg skill two stage associ analysi design conduct dataset collect major student enrol introduct comput program cours first stage associ rule analyz discov import relationship amongst learn style student attribut learn perform second stage moder analysi appli probe moder effect differ learn prefer relationship student attribut learn achiev experi expos mani insight exampl mathemat logic think power asset success comput program studi associ rule effect identifi associ learn style learn perform term knowledg skill moder analysi student “excellent” cluster broad learn style student two type signific moder univers specif exemplifi lectur flexibl post style fit teach strategi class wide specif group respect"
  },
  {
    "doc_id": "10246990",
    "abstract_original": "Power line extraction is not only crucial for unmanned aerial vehicles (UAVs) obstacle avoidance, but also a fundamental step for fault diagnosis of power lines. Therefore, achieving robust and accurate extraction of power lines in aerial images is essential to enable intelligent UAVs inspection. Unfortunately, power line extraction is an extremely challenging task, and all the current methods attempt to utilize a single model to solve the problem of power line extraction in complex and variable scenes. This results in insufficient generalization ability and suboptimal computational efficiency. In this work, we propose a power line scene classification network based on complexity assessment, named SceneNet, which can provide a solution for tackling power line extraction challenges. First, we propose a human–machine hybrid reasoning model to obtain the ground truth of image complexity reasonably and build the first benchmark dataset that can be used for automatic classification research of power line scenes. Second, we propose an improved StyleGAN3 model and loop transfer learning strategy for data augmentation. Most importantly, the SceneNet comprises a multifeature joint embedding module and a feature encoding–decoding module. On one hand, it achieves the multilevel fusion of artificial features and high-dimensional semantic features. On the other hand, we use a self-attention mechanism to enable full use of the contextual association between each block of the fusion feature map. The SceneNet has successfully achieved the mapping and pattern recognition between the abstract concept and the concrete features. Experimental results demonstrate that the SceneNet is obviously superior to the existing 12 state-of-the-art models, and it provides guidance and delineation of applicable scenes for power line extraction methods.",
    "abstract_processed": "power line extract crucial unman aerial vehicl uav obstacl avoid also fundament step fault diagnosi power line therefor achiev robust accur extract power line aerial imag essenti enabl intellig uav inspect unfortun power line extract extrem challeng task current method attempt util singl model solv problem power line extract complex variabl scene result insuffici gener abil suboptim comput effici work propos power line scene classif network base complex assess name scenenet provid solut tackl power line extract challeng first propos human–machin hybrid reason model obtain ground truth imag complex reason build first benchmark dataset use automat classif research power line scene second propos improv stylegan model loop transfer learn strategi data augment importantli scenenet compris multifeatur joint embed modul featur encoding–decod modul one hand achiev multilevel fusion artifici featur high dimension semant featur hand use self attent mechan enabl full use contextu associ block fusion featur map scenenet success achiev map pattern recognit abstract concept concret featur experiment result demonstr scenenet obvious superior exist state art model provid guidanc delin applic scene power line extract method"
  },
  {
    "doc_id": "10247277",
    "abstract_original": "In service to the state of the art, advances are required toward redesigning the framework over which web applications are built. The semantic web lies at the intersection of web and machine understandable meaningful data, turning it into intelligent ‘web of data’. The key requirement with any intelligent system has been to find a concrete knowledge representation that can make the inferences within time and space constraints; that is, reasoning effectively and efficiently within the resource constraints posed to the problem at one hand and with insufficient data as well as incomplete knowledge on the other hand. Various Knowledge representation schemes have been proposed in the literature, each having its limitation over the others. Ontology is the key component for semantic web engineering. Ontologies are conceptual knowledge bases providing a systematic and taxonomical description of the concepts and instances under consideration. Conceptual clarity in the computational representation of a concept is vital for holistic thinking and knowledge engineering. In order to meet the needs of an application/enterprise, knowledge should be presented taking care of all possible perspectives; and represented in a hierarchical structure with differing levels of granularity. This paper discusses about bringing all the manifestations of an ontological concept/decision under one umbrella; hence describing the resultant scheme as a unit of knowledge. By representing a concept as a knowledge unit, classical ontology is claimed to be sufficient in dealing with imprecise, vague and heterogeneous knowledge for real-world web applications; and portrays the capability to acquire fresh knowledge through its thorough interaction with the external world in a given working environment.",
    "abstract_processed": "servic state art advanc requir toward redesign framework web applic built semant web lie intersect web machin understand meaning data turn intellig ‘web data’ key requir intellig system find concret knowledg represent make infer within time space constraint reason effect effici within resourc constraint pose problem one hand insuffici data well incomplet knowledg hand variou knowledg represent scheme propos literatur limit other ontolog key compon semant web engin ontolog conceptu knowledg base provid systemat taxonom descript concept instanc consider conceptu clariti comput represent concept vital holist think knowledg engin order meet need applic enterpris knowledg present take care possibl perspect repres hierarch structur differ level granular paper discuss bring manifest ontolog concept decis one umbrella henc describ result scheme unit knowledg repres concept knowledg unit classic ontolog claim suffici deal imprecis vagu heterogen knowledg real world web applic portray capabl acquir fresh knowledg thorough interact extern world given work environ"
  },
  {
    "doc_id": "10247738",
    "abstract_original": "The growing concern about offshore chip manufacturing has created considerable interest in solutions that can ensure the integrity and security of chips. Among various solutions, split manufacturing has received a lot of attention due to its security guarantees. With the recent emergence of new heterogeneous manufacturing technologies, including chiplet-based systems, there is a new opportunity for revisiting the design considerations for split manufacturing to fully exploit the opportunities presented by chiplet-based systems and improve various metrics, such as security, performance, and overhead.This work improves the state-of-the-art in secure chip manufacturing by proposing a new split manufacturing scheme. The key idea is to exploit the capabilities provided by chiplet integration technology for designing a new hybrid split manufacturing scheme that includes both vertical and horizontal splitting. Unlike existing vertical-only split manufacturing mechanisms, that target obfuscation of interconnections by splitting the design at a specific metallization layer into two portions, the proposed hybrid method increases trust by exploiting the chiplet paradigm shift, specifically, breaking the design into sub-designs, each represented by chiplets (independently fabricated), and obfuscating interconnections among them. The proposed obfuscation mechanism targets systems that exploit the chiplet technology to obtain important performance advantages, thus any chiplet-related overhead is not due to obfuscation. We evaluate our method using several experiments and compare it with the state-of-the-art using standard metrics, including area, power, delay, wirelength, and trust. Compared to conventional split manufacturing, our hybrid method achieves up to 245× higher trust, while exhibiting negligible overhead.",
    "abstract_processed": "grow concern offshor chip manufactur creat consider interest solut ensur integr secur chip among variou solut split manufactur receiv lot attent due secur guarante recent emerg new heterogen manufactur technolog includ chiplet base system new opportun revisit design consider split manufactur fulli exploit opportun present chiplet base system improv variou metric secur perform overhead work improv state art secur chip manufactur propos new split manufactur scheme key idea exploit capabl provid chiplet integr technolog design new hybrid split manufactur scheme includ vertic horizont split unlik exist vertic split manufactur mechan target obfusc interconnect split design specif metal layer two portion propos hybrid method increas trust exploit chiplet paradigm shift specif break design sub design repres chiplet independ fabric obfusc interconnect among propos obfusc mechan target system exploit chiplet technolog obtain import perform advantag thu chiplet relat overhead due obfusc evalu method use sever experi compar state art use standard metric includ area power delay wirelength trust compar convent split manufactur hybrid method achiev × higher trust exhibit neglig overhead"
  },
  {
    "doc_id": "10249502",
    "abstract_original": "Permeability is a crucial factor in oil and gas exploration and development, as it indicates a reservoir's ability to flow. To predict permeability from electrical exploration results, Critical Path Analysis (CPA) is commonly used by combining reservoir permeability and electrical conductivity. However, the accuracy of CPA decreases when unconventional reservoirs exhibit strong anisotropy, such as fractured shales. This study presents tensor-based CPA methods that utilize equivalent electrical parameters and permeability tensor to address this issue. The approach involves obtaining critical pore radius and permeability in tensor form through matrix operation. The accuracy of the CPA formula in calculating reservoir permeability is then compared with numerical simulation results. The findings indicate that the tensor-based CPA method significantly improves the permeability prediction accuracy of anisotropic media, and further improvements can be made using the revised tensor-based CPA.",
    "abstract_processed": "permeabl crucial factor oil ga explor develop indic reservoir abil flow predict permeabl electr explor result critic path analysi cpa commonli use combin reservoir permeabl electr conduct howev accuraci cpa decreas unconvent reservoir exhibit strong anisotropi fractur shale studi present tensor base cpa method util equival electr paramet permeabl tensor address issu approach involv obtain critic pore radiu permeabl tensor form matrix oper accuraci cpa formula calcul reservoir permeabl compar numer simul result find indic tensor base cpa method significantli improv permeabl predict accuraci anisotrop media improv made use revis tensor base cpa"
  },
  {
    "doc_id": "10250775",
    "abstract_original": "Neural Style Transfer (NST) is a popular technique of computer vision where the content of an image is blended with the style of another, which results in a fused image with certain properties of both original images. This approach has practical applications in various domains and has garnered significant attention in both industry and academia. An interesting application of this technique is segmented style transfer where a segmentation algorithm is used to locate objects within an image and then the style transfer method is performed locally, producing images with different styles for different objects. This approach opens up possibilities for creating visually striking compositions by seamlessly blending various artistic styles onto specific objects within an image, allowing for a new level of creative expression. This paper proposes a novel method that combines Segment Anything Model (SAM), a state-of-the-art vision transformer-based image segmentation model developed by Facebook, with style transfer. Our approach includes performing localized style transfer in selected segmentation regions of an image using classical style transfer algorithms. To ensure smooth transitions between the stylized and non-stylized border we also develop our loss function with a border smoothing technique. Experimental results demonstrate the robustness and effectiveness of the proposed methodology, including the ability to infuse multiple artistic styles into different objects within an image. The contributions of this work include integrating SAM with style transfer, proposing a novel loss function, evaluating the segmented style transfer in multiple content regions, comparing with state-of-the-art approaches, and experimenting with multiple style images for diverse stylization. Our primary focus centers on creating a model that serves as a digital painter across a wide range of image genres and artistic styles.",
    "abstract_processed": "neural style transfer nst popular techniqu comput vision content imag blend style anoth result fuse imag certain properti origin imag approach practic applic variou domain garner signific attent industri academia interest applic techniqu segment style transfer segment algorithm use locat object within imag style transfer method perform local produc imag differ style differ object approach open possibl creat visual strike composit seamlessli blend variou artist style onto specif object within imag allow new level creativ express paper propos novel method combin segment anyth model sam state art vision transform base imag segment model develop facebook style transfer approach includ perform local style transfer select segment region imag use classic style transfer algorithm ensur smooth transit styliz non styliz border also develop loss function border smooth techniqu experiment result demonstr robust effect propos methodolog includ abil infus multipl artist style differ object within imag contribut work includ integr sam style transfer propos novel loss function evalu segment style transfer multipl content region compar state art approach experi multipl style imag divers styliz primari focu center creat model serv digit painter across wide rang imag genr artist style"
  },
  {
    "doc_id": "10254729",
    "abstract_original": "There are many challenges to creating artificial intelligence systems. There are limited resources, insufficient knowledge in the field, feasibility, and many other technical problems on the way to creating AI. Artificial Intelligence currently remains a scientific field related to computer modeling of human intellectual functions. Artificial intelligence systems are generally used to refer to a computer system's ability to perform tasks that are intrinsic to human intelligence, such as logical inference and learning tasks. Any task whose solution algorithm is not known in advance or whose data are incomplete can be classified as an AI task. Systems, programs performing actions to solve a task can be classified as AI if their activity is similar to the result of a human in solving the same task. Therefore, a number of software means can be referred to as AI: text recognition systems, automated design, self-training programs, etc. But not only for this reason, but also because they operate on similar principles to humans. There are two main promising directions in AI research. The first is to bring AI systems closer to the principles of human thinking. The second is to create AI representing the integration of already developed AI systems into a single system capable of solving human problems.",
    "abstract_processed": "mani challeng creat artifici intellig system limit resourc insuffici knowledg field feasibl mani technic problem way creat ai artifici intellig current remain scientif field relat comput model human intellectu function artifici intellig system gener use refer comput system abil perform task intrins human intellig logic infer learn task task whose solut algorithm known advanc whose data incomplet classifi ai task system program perform action solv task classifi ai activ similar result human solv task therefor number softwar mean refer ai text recognit system autom design self train program etc reason also oper similar principl human two main promis direct ai research first bring ai system closer principl human think second creat ai repres integr alreadi develop ai system singl system capabl solv human problem"
  },
  {
    "doc_id": "10254740",
    "abstract_original": "Scheduling workloads on large-scale infrastructures, such as in the Edge-Cloud continuum is a challenging task. Usually, the scheduling algorithm considers only a limited sample of the infrastructure nodes, typically obtained through random sampling. The sampling reduces the number of nodes, which need to be evaluated in the scheduling pipeline, making the scheduling process more saleable. Unfortunately, current sampling approaches become largely inefficient when the infrastructure is heterogeneous and specific, scarce node characteristics are required to successfully execute a workload. Computing continuum infrastructures are heterogeneous, hence, we need to re-think the sampling process to keep it viable at scale while also being able to identify and leverage the heterogeneity of the Edge-Cloud continuum resources. In this article, we present Intelligent Sampling - a novel technique for improving sampling in large-scale and heterogeneous infrastructures. We develop a model for any heterogeneous infrastructure. Based on this model, we provide a method to sample the infrastructure nodes more accurately, considering the specific task at hand. Finally, we leverage the Alibaba PAI dataset to show that our approach is 2.5x times more accurate compared with other state-of-the-art sampling mechanisms while retaining comparable performance and scalability.",
    "abstract_processed": "schedul workload larg scale infrastructur edg cloud continuum challeng task usual schedul algorithm consid limit sampl infrastructur node typic obtain random sampl sampl reduc number node need evalu schedul pipelin make schedul process saleabl unfortun current sampl approach becom larg ineffici infrastructur heterogen specif scarc node characterist requir success execut workload comput continuum infrastructur heterogen henc need think sampl process keep viabl scale also abl identifi leverag heterogen edg cloud continuum resourc articl present intellig sampl novel techniqu improv sampl larg scale heterogen infrastructur develop model heterogen infrastructur base model provid method sampl infrastructur node accur consid specif task hand final leverag alibaba pai dataset show approach x time accur compar state art sampl mechan retain compar perform scalabl"
  },
  {
    "doc_id": "10254870",
    "abstract_original": "eScience is now an example field for conducting science using advanced computational methodologies, middle-ware and workflows. With the ever-increasing data intensity in various scientific disciplines and the opportunities provided by novel artificial intelligence (AI) and computing techniques, there is a pressing need for eScience to adapt and develop holistic approaches for AI-integrated science and interdisciplinary collaboration between science, AI and computing experts. This paper discusses the transformative shift needed in the conduct and tools of eScience from traditional workflows, often linear, pre-defined to coordinate task execution and individually developed, to integrated “teamflows”, a term coined to encapsulate methods for effective team collaboration and communication, dynamic data and service integration, and use-inspired thinking. In the AI in science era of scientific investigation, this “future of eScience” special track paper: 1) emphasizes the vital importance of eScience to the success of collaborative AI in science teams; 2) recites some requirements for open data and services for AI-enhanced workflows, team science and incentive structures to create a more inclusive and efficient discovery environment; and 3) discusses impact as a measure of success in eScience.",
    "abstract_processed": "escienc exampl field conduct scienc use advanc comput methodolog middl ware workflow ever increas data intens variou scientif disciplin opportun provid novel artifici intellig ai comput techniqu press need escienc adapt develop holist approach ai integr scienc interdisciplinari collabor scienc ai comput expert paper discuss transform shift need conduct tool escienc tradit workflow often linear pre defin coordin task execut individu develop integr “teamflows” term coin encapsul method effect team collabor commun dynam data servic integr use inspir think ai scienc era scientif investig “futur escience” special track paper emphas vital import escienc success collabor ai scienc team recit requir open data servic ai enhanc workflow team scienc incent structur creat inclus effici discoveri environ discuss impact measur success escienc"
  },
  {
    "doc_id": "10256292",
    "abstract_original": "Cyberbullying, the act of intentionally causing harm to others through electronic communication, has emerged as a critical societal concern, particularly among university students. With the rapid proliferation of digital technologies, university campuses have become hotspots for cyberbullying incidents, necessitating a comprehensive understanding of the underlying factors driving this phenomenon. This paper presents a systematic review that aims to identify and analyze the key factors influencing cyberbullying behaviours among university students. The conceptual framework that was utilized to pinpoint the factors influencing university students' cyberbullying behaviours was examined in this study. According to a systematic screening of recent research articles (from 2013 to 2023) pertaining to online bullying behaviours among university students, the findings were given. After evaluating theoretical models and associated concepts, we suggest using the Theory of Planned Behaviour to evaluate factors influencing cyberbullying behaviours among university students. The findings of this study are discussed, and it is concluded that subjective norms, attitude, perceived behavioural control, social media use, and intentions all have the ability to influence university students' cyberbullying behaviours.",
    "abstract_processed": "cyberbulli act intent caus harm other electron commun emerg critic societ concern particularli among univers student rapid prolifer digit technolog univers campus becom hotspot cyberbulli incid necessit comprehens understand underli factor drive phenomenon paper present systemat review aim identifi analyz key factor influenc cyberbulli behaviour among univers student conceptu framework util pinpoint factor influenc univers student cyberbulli behaviour examin studi accord systemat screen recent research articl pertain onlin bulli behaviour among univers student find given evalu theoret model associ concept suggest use theori plan behaviour evalu factor influenc cyberbulli behaviour among univers student find studi discuss conclud subject norm attitud perceiv behaviour control social media use intent abil influenc univers student cyberbulli behaviour"
  },
  {
    "doc_id": "10257974",
    "abstract_original": "As a game that spreads across the Internet and stimulates people to think and learn, data mining of Wordle's report counts and their distribution is particularly important. In this paper, an ARIMA model and a BP neural network model based on the WOA are developed to perform in-depth data mining on Wordle. For model I, this paper uses ARIMA model fitting to fit the trend of the total number of historical report results over time, and obtains the R2 of the model as 0.986. Based on this, this paper establishes a prediction model for the interval of the total number of reports, and gives the prediction interval of the total number of report results on March 1, 2023 as [21211], [21814]. For Model II, this paper defines word attributes as the following four indicators: for example, the commonness of the word, the number of occurrences of the same letter in the word. The Spearman correlation coefficient between the percentage of reported scores to the total reported scores in the Hard mode and the word attributes was calculated. Finally, in the Hard model, the percentage of reported scores out of the total reported scores was significantly correlated with how common the word was and whether it began with a vowel letter. For Model III, this paper constructed a BP Neural network model based on WOA, which, in this paper, uses word attributes as the input layer and the report distribution of words as the output layer. In the WOA, the optimal weights and thresholds of the BP neural network are obtained in this paper by continuous search and approximation. The final model has a Mean Absolute Error value of 0.38, both of which have good performance. At the same time, this paper predicts the results of “EERIE”, and the obtained distribution results are rounded to [1], [7], [20], [22], [21], [19], [10]. Through the above modelling and calculation, this paper mines Wordle's user data, which has some theoretical significance for the healthy development of Wordle.",
    "abstract_processed": "game spread across internet stimul peopl think learn data mine wordl report count distribut particularli import paper arima model bp neural network model base woa develop perform depth data mine wordl model paper use arima model fit fit trend total number histor report result time obtain r model base paper establish predict model interv total number report give predict interv total number report result march model ii paper defin word attribut follow four indic exampl common word number occurr letter word spearman correl coeffici percentag report score total report score hard mode word attribut calcul final hard model percentag report score total report score significantli correl common word whether began vowel letter model iii paper construct bp neural network model base woa paper use word attribut input layer report distribut word output layer woa optim weight threshold bp neural network obtain paper continu search approxim final model mean absolut error valu good perform time paper predict result “eerie” obtain distribut result round model calcul paper mine wordl user data theoret signific healthi develop wordl"
  },
  {
    "doc_id": "10258158",
    "abstract_original": "The study aims to improve the daily teaching level of the school and make students enjoy better teaching methods. Firstly, the Internet of Things (IoT) and deep learning (DL) are deeply studied through information technology (IT). Secondly, the calculation methods based on the IoT and DL are analyzed, through which the research model is constructed. Finally, a digital teaching platform is established through the research model to conduct a real-time statistical survey of students and teachers. The results show that students are leading in the daily teaching process. According to the survey results, most students spend 3 to 4 hours in daily extra-curricular learning; 45% of them acquire knowledge mainly through classroom learning, and 23% through online learning. Their main difficulty in learning is learning ability, accounting for 48%. Moreover, it is an energy problem, accounting for 28%. 64% of students are passive learning, far more than 37% of active learning students. This study combines multiple fields across disciplines, such as IT, IoT, and DL. Digital art teaching platforms usually focus on creativity and performance, and combining IoT and DL can provide art students with a more personalized, real-time teaching experience, and promote the cross-application of digital art and cutting-edge technologies.",
    "abstract_processed": "studi aim improv daili teach level school make student enjoy better teach method firstli internet thing iot deep learn dl deepli studi inform technolog secondli calcul method base iot dl analyz research model construct final digit teach platform establish research model conduct real time statist survey student teacher result show student lead daili teach process accord survey result student spend hour daili extra curricular learn acquir knowledg mainli classroom learn onlin learn main difficulti learn learn abil account moreov energi problem account student passiv learn far activ learn student studi combin multipl field across disciplin iot dl digit art teach platform usual focu creativ perform combin iot dl provid art student person real time teach experi promot cross applic digit art cut edg technolog"
  },
  {
    "doc_id": "10258164",
    "abstract_original": "Computer science uses abstractions as a tool for reasoning. It is no surprise that computer science might have something valuable to lend to the world of decentralized stablecoin design, as it is a “computing” problem. In this paper, we examine the possibility of a decentralized and capital-efficient stablecoin using smart contracts that algorithmically trade to maintain stability. By exploiting traditional abstractions from computer science, we show that a capital-efficient algorithmic stablecoin cannot be provably stable. Additionally, we provide a formal exposition of the workings of Central Bank Digital Currencies, connecting this framing to the space of possible stablecoin designs. We then discuss several outstanding conjectures from both academics and practitioners and finally highlight the regulatory similarities between money-market funds and working stablecoins. Our work builds upon the current and growing interplay between the realms of engineering and financial services, and it also demonstrates how ways of thinking as a computer scientist can aid practitioners. We believe this research is vital for understanding and developing the future of financial technology.",
    "abstract_processed": "comput scienc use abstract tool reason surpris comput scienc might someth valuabl lend world decentr stablecoin design “computing” problem paper examin possibl decentr capit effici stablecoin use smart contract algorithm trade maintain stabil exploit tradit abstract comput scienc show capit effici algorithm stablecoin cannot provabl stabl addit provid formal exposit work central bank digit currenc connect frame space possibl stablecoin design discuss sever outstand conjectur academ practition final highlight regulatori similar money market fund work stablecoin work build upon current grow interplay realm engin financi servic also demonstr way think comput scientist aid practition believ research vital understand develop futur financi technolog"
  },
  {
    "doc_id": "10258248",
    "abstract_original": "As one of the most popular visual programming languages, Scratch has a lot of evaluation around it. Reasonable evaluation can help programmers understand their projects better. At the same time, it can also provide a reference for them to browse other projects in the online community. Most of the existing evaluations on Scratch are carried from three perspectives: Computational Thinking (CT) ability, visual presentation aesthetics, and code quality. Among them, the assessment of CT and code quality is mainly carried out from the program script, while the evaluation of visual aesthetics is analyzed from the perspective of image sequences generated by project execution. The single-view evaluation focuses on the performance of a program in a certain aspect and is one-sided. In this paper, we propose a multi-view evaluation framework to integrate various evaluations using different policies. We quantitatively analyze the assessment of different views driven by data. Combined with overall evaluations that represent human opinions, we analyze their differences and connections. Through experiments, we determine the weights of different integration policies, the proposed multi-view evaluation method can generate evaluation results similar to human opinions.",
    "abstract_processed": "one popular visual program languag scratch lot evalu around reason evalu help programm understand project better time also provid refer brows project onlin commun exist evalu scratch carri three perspect comput think ct abil visual present aesthet code qualiti among assess ct code qualiti mainli carri program script evalu visual aesthet analyz perspect imag sequenc gener project execut singl view evalu focus perform program certain aspect one side paper propos multi view evalu framework integr variou evalu use differ polici quantit analyz assess differ view driven data combin overal evalu repres human opinion analyz differ connect experi determin weight differ integr polici propos multi view evalu method gener evalu result similar human opinion"
  },
  {
    "doc_id": "10260747",
    "abstract_original": "The rapid diffusion of software systems into all aspects of our lives has raised new challenges for requirements engineers. These challenges call for an in-depth understanding of system usage scenarios and user capabilities, attitudes, emotions, barriers, and more. Current methods and tools, such as the Design Thinking methodology and the Empathy Map tool, have been proposed for supporting the multifaceted requirements elicitation process. However, using these methods and tools effectively is not simple, requiring not only competency but also motivation, high self-efficacy, and positive attitudes. These emotional attributes are strongly influenced by the work environment in which the requirements engineers operate.",
    "abstract_processed": "rapid diffus softwar system aspect live rais new challeng requir engin challeng call depth understand system usag scenario user capabl attitud emot barrier current method tool design think methodolog empathi map tool propos support multifacet requir elicit process howev use method tool effect simpl requir compet also motiv high self efficaci posit attitud emot attribut strongli influenc work environ requir engin oper"
  },
  {
    "doc_id": "10260830",
    "abstract_original": "Many educational resources are available that teach children computational thinking and visual programming. As part of this initiative, we develop computational puzzles from well-known computational thinking activities. Inspired by the idea of geocaching, we made our puzzles accessible and fun for the whole family by embedding them into a scavenger hunt. We describe our approach that frames computational puzzles as an outdoor family activity. Our project was launched in 2021 and has received informal positive feedback.",
    "abstract_processed": "mani educ resourc avail teach children comput think visual program part initi develop comput puzzl well known comput think activ inspir idea geocach made puzzl access fun whole famili embed scaveng hunt describ approach frame comput puzzl outdoor famili activ project launch receiv inform posit feedback"
  },
  {
    "doc_id": "10260900",
    "abstract_original": "With the increased focus on Computational Thinking (CT) in education, there has been an increase in the development of learning platforms to teach CT. The current study developed an Online Inquiry-based learning platform for Computational Thinking (CT-ONLINQ) to support CT activities using Inquiry-based Learning (IBL) pedagogy. IBL-based CT steps include algorithm design, analysis, and comparison of algorithms. The platform allows students to explore multiple solutions and provides hints as support during problem-solving activities. A 4-week experimental study was conducted to evaluate the usability of the online platform. A total of 79 9th-grade students volunteered to participate in this study to complete six activities. Subsequently, the students completed the SUS questionnaire and open-ended feedback questions. Results showed that around 80% of the students scored above the “Good” category (70-80), with a total average score of 78.45. Also, we analyzed the difference in rating scores among groups based on multiple background factors. Findings showed an average rating above 4 with no significant difference between the ratings among factors such as gender and math performance (below-above average math scores). In addition, analysis of the feedback comments showed that the platform is user-friendly, with students enthusiastic about learning coding on the platform.",
    "abstract_processed": "increas focu comput think ct educ increas develop learn platform teach ct current studi develop onlin inquiri base learn platform comput think ct onlinq support ct activ use inquiri base learn ibl pedagogi ibl base ct step includ algorithm design analysi comparison algorithm platform allow student explor multipl solut provid hint support problem solv activ week experiment studi conduct evalu usabl onlin platform total th grade student volunt particip studi complet six activ subsequ student complet su questionnair open end feedback question result show around student score “good” categori total averag score also analyz differ rate score among group base multipl background factor find show averag rate signific differ rate among factor gender math perform averag math score addit analysi feedback comment show platform user friendli student enthusiast learn code platform"
  },
  {
    "doc_id": "10260931",
    "abstract_original": "The recent progress in generative AI models, particularly large language models (LLMs), has brought about a transformation in the field of education. Conversational LLM services, such as Google's Bard and OpenAI's ChatGPT, offer students access to many abilities such as summarization and generation of text and code, and on-demand replies to questions on expert topics. In this paper, we observe ChatGPT to explore how LLM services impact learning and instruction in higher education. First, we mapped the capabilities of the system by reviewing the grey literature on ChatGPT and using the system ourselves for two months. Second, we selected a Bachelor level computer science curriculum from a Finnish university, and examined the impact of ChatGPT on the offered courses. As an outcome of this study, we highlight 13 implications for students' learning in higher education, and discuss the contemporary future of AI-assisted learning in universities and beyond.",
    "abstract_processed": "recent progress gener ai model particularli larg languag model llm brought transform field educ convers llm servic googl bard openai chatgpt offer student access mani abil summar gener text code demand repli question expert topic paper observ chatgpt explor llm servic impact learn instruct higher educ first map capabl system review grey literatur chatgpt use system two month second select bachelor level comput scienc curriculum finnish univers examin impact chatgpt offer cours outcom studi highlight implic student learn higher educ discuss contemporari futur ai assist learn univers beyond"
  },
  {
    "doc_id": "10260990",
    "abstract_original": "Computational Thinking (CT) is a way to structure thinking to solve problems, which develops cognitive skills. Educational Digital Games (EDG) are a potential tool to work with CT, stimulating the student's interest and learning. Still, to make these games playable by children with Intellectual disabilities (ID), it is necessary to have adaptations suitable to their educational needs. Therefore, this paper presents the development and evaluation of the EDG “Pensar e Vestir” (PeV). This game addresses a daily life activity, the process of choosing clothes and the act of wearing them, and aims to promote the development of CT in children both neurotypical and with ID. The development process was supported by ID, Education, and Specialized Education Treatment specialists based on accessibility guidelines. In the end, there were two evaluations, firstly with the specialists and then with Computation students, to validate the functional and technical requirements. Currently, the game is in evaluation by its target audience.",
    "abstract_processed": "comput think ct way structur think solv problem develop cognit skill educ digit game edg potenti tool work ct stimul student interest learn still make game playabl children intellectu disabl id necessari adapt suitabl educ need therefor paper present develop evalu edg “pensar e vestir” pev game address daili life activ process choos cloth act wear aim promot develop ct children neurotyp id develop process support id educ special educ treatment specialist base access guidelin end two evalu firstli specialist comput student valid function technic requir current game evalu target audienc"
  },
  {
    "doc_id": "10261528",
    "abstract_original": "The Computer General Course is a general core course in higher education for students of non-computer science majors. With the increasing popularity of computer technology applications and the arrival of the fourth wave of the industrial revolution represented by the industrialization of the Internet, industrial intelligence, and industrial integration, the teaching of Computer General Course under the new situation also faces new dilemmas. The exploration of the integration of C-STEAM with the Computer General Course, which is oriented by culture, provides new paths to achieve the educational goal under the new situation, to realize the integration of the discipline education under the cultural orientation of the course, and to improve the students' sense of learning efficacy in the course. Through the design-based research and 2 years of exploration and practice, combined with student research and work evaluation, the curriculum reform teaching practice recognition and students' cultural literacy, thinking methods, disciplinary integration literacy, etc. have received more positive feedback, and the teaching objectives are achieved to a higher degree.",
    "abstract_processed": "comput gener cours gener core cours higher educ student non comput scienc major increas popular comput technolog applic arriv fourth wave industri revolut repres industri internet industri intellig industri integr teach comput gener cours new situat also face new dilemma explor integr c steam comput gener cours orient cultur provid new path achiev educ goal new situat realiz integr disciplin educ cultur orient cours improv student sens learn efficaci cours design base research year explor practic combin student research work evalu curriculum reform teach practic recognit student cultur literaci think method disciplinari integr literaci etc receiv posit feedback teach object achiev higher degre"
  },
  {
    "doc_id": "10261553",
    "abstract_original": "With the continuous development of information technology, computational thinking as a new thinking ability into people's vision. After the release of Information Technology Curriculum Standards for Senior High Schools (2017 Edition), computational thinking has been widely concerned. In this paper, academic papers collected in CNKI (China National Knowledge Network) from 2016 to 2021 are studied by the bibliometerization method. From the aspects of quantity, source, author, research distribution, and research hotspots, this paper analyzes the current situation and trend of computational thinking training in primary school IT teaching, so as to provide useful reference for relevant researchers.",
    "abstract_processed": "continu develop inform technolog comput think new think abil peopl vision releas inform technolog curriculum standard senior high school edit comput think wide concern paper academ paper collect cnki china nation knowledg network studi bibliometer method aspect quantiti sourc author research distribut research hotspot paper analyz current situat trend comput think train primari school teach provid use refer relev research"
  },
  {
    "doc_id": "10261563",
    "abstract_original": "Students' emotional state plays a vital role in learning. In this study, we examined the emotional changes of 69 students during the lectures of the C Language Programming Foundation and Computational Thinking in central China. This paper presents a method using Yolov7 and the convolutional neural network CoAtNet to monitor students' emotional evolution by analyzing their facial expressions and recognizing academic affective states, including boring, confused, focus, happy, and neutral. The trained model has achieved a test accuracy of 76.0%. The results showed that focus increased at the beginning of the first 10 minutes of class and then began to decline. With the decline of focus emotion, students' neutral emotions increased. We found that when a new teaching session is performed, or the teaching method of naming questions is used, the students' emotion of focus increases briefly, lasting about 8–10 minutes. Subsequently, even if the varied teaching method was used to stimulate students' attention, their level of engagement did not increase significantly. It can be suggested that teachers can use teaching methods appropriately to promote students' attention. However, students' attention span is limited, and teachers should pay attention to methods and time to improve teaching quality effectively.",
    "abstract_processed": "student emot state play vital role learn studi examin emot chang student lectur c languag program foundat comput think central china paper present method use yolov convolut neural network coatnet monitor student emot evolut analyz facial express recogn academ affect state includ bore confus focu happi neutral train model achiev test accuraci result show focu increas begin first minut class began declin declin focu emot student neutral emot increas found new teach session perform teach method name question use student emot focu increas briefli last – minut subsequ even vari teach method use stimul student attent level engag increas significantli suggest teacher use teach method appropri promot student attent howev student attent span limit teacher pay attent method time improv teach qualiti effect"
  },
  {
    "doc_id": "10261572",
    "abstract_original": "With the coming of the digital intelligence era, contemporary middle school students should have the key literacy and ability to quickly adapt to the current social development. Computational thinking, as a critical problem-solving skill in the era of artificial intelligence, has also become a basic literacy for students to face the future. However, the traditional “duck and filler” teaching mode is ineffective in developing computational thinking skills, while the gamified learning approach allows learners to interact with games in an immersive way. Therefore, this study combines games and programming teaching, builds a teaching model of gamified text programming, and develops a series of programming courses. It can develop not only computational thinking skills and improve students' programming ability but also effectively avoid the limitations of traditional programming teaching.",
    "abstract_processed": "come digit intellig era contemporari middl school student key literaci abil quickli adapt current social develop comput think critic problem solv skill era artifici intellig also becom basic literaci student face futur howev tradit “duck filler” teach mode ineffect develop comput think skill gamifi learn approach allow learner interact game immers way therefor studi combin game program teach build teach model gamifi text program develop seri program cours develop comput think skill improv student program abil also effect avoid limit tradit program teach"
  },
  {
    "doc_id": "10261600",
    "abstract_original": "Computational thinking is the third major mode of thinking in the age of artificial intelligence. Many primary and secondary schools adopt graphical programming as an important way for students' computational thinking development. However, elementary school students have less self-control in learning and are more dependent on teachers, so timely and effective teaching interaction is an important guarantee for the realization of the teaching goals of graphical programming. Through three rounds of action research, the essay investigated the impact of teaching interaction strategies on the development of students' computational thinking. The findings show that students are satisfied with the designed interaction strategies, and the interaction strategies can significantly improve students' computational thinking ability and level.",
    "abstract_processed": "comput think third major mode think age artifici intellig mani primari secondari school adopt graphic program import way student comput think develop howev elementari school student less self control learn depend teacher time effect teach interact import guarante realiz teach goal graphic program three round action research essay investig impact teach interact strategi develop student comput think find show student satisfi design interact strategi interact strategi significantli improv student comput think abil level"
  },
  {
    "doc_id": "10261627",
    "abstract_original": "Computational thinking is an important concept that is currently receiving widespread attention in the international computing community. Teaching programming is an effective way to develop students' computational thinking. Students in adult colleges and universities face the pressure of study and work, and there is a need to improve their computational thinking skills. In this paper, we design and develop a set of programming activities based on computational thinking development for adult college students, and study the changes in students' computational thinking before and after they participate in the activities. It provides a reference for frontline teachers and related researchers to design programming activities and conduct research in computational thinking.",
    "abstract_processed": "comput think import concept current receiv widespread attent intern comput commun teach program effect way develop student comput think student adult colleg univers face pressur studi work need improv comput think skill paper design develop set program activ base comput think develop adult colleg student studi chang student comput think particip activ provid refer frontlin teacher relat research design program activ conduct research comput think"
  },
  {
    "doc_id": "10263093",
    "abstract_original": "The automatic generation of image descriptions is leading the field of computer vision and natural language processing-based research. Image captioning is a key task that calls for a semantic understanding of the images and the capacity to create descriptions with right structure. Image captioning is a complex problem as it often demands accessing data that might not be visible in each scene. It will require logical thinking to evaluate or have in-depth knowledge about the object present in an image. In this study, we developed a multilayer Convolutional Neural Network to produce words that describe the images, and we used Long Short-Term Memory to accurately construct relevant sentences out of the words that are produced. To generate an accurate description, the Convolutional Neural Network (CNN) model first compares the targeted image against a huge dataset of training samples. In this study, we have used the Flickr 8k dataset. We have used the Bilingual Evaluation Understudy (BLEU) metric to determine how well our model is generating captions for the images. It evaluates the generated text that has been translated from one language to a different language to evaluate the effectiveness of the machine translation system. In this study, we have also used two pre-trained models (VGG16, and XceptionV3) for comparative study.",
    "abstract_processed": "automat gener imag descript lead field comput vision natur languag process base research imag caption key task call semant understand imag capac creat descript right structur imag caption complex problem often demand access data might visibl scene requir logic think evalu depth knowledg object present imag studi develop multilay convolut neural network produc word describ imag use long short term memori accur construct relev sentenc word produc gener accur descript convolut neural network cnn model first compar target imag huge dataset train sampl studi use flickr k dataset use bilingu evalu understudi bleu metric determin well model gener caption imag evalu gener text translat one languag differ languag evalu effect machin translat system studi also use two pre train model vgg xceptionv compar studi"
  },
  {
    "doc_id": "10263603",
    "abstract_original": "The quantity of written content about medical information is staggering, and it keeps on increasing daily. Think about the internet, which is full of websites, news, constantly updated status, blogs, and a great deal more. Utilizing search to swiftly scroll through key findings is the most effective method for navigating material mainly because the results are not arranged in any specific fashion. A considerable percentage of this stuff needs to be summarized to emphasize the most significant information. Creating a custom summary with our own two hands of everything that can be effectively done by text summarization techniques. There is a critical need for this automated method. This project incorporates technologies that are capable of summarizing the text automatically. It implies paraphrasing phrases into a single thought. We propose a hierarchical document that represents an architecture for extraction aggregation that utilizes “Longformer” as a set encoder and “Transformer” as a text encoder to represent text documents properly. This model is referred to as the Long-Trans-Extr model. One of the benefits of using Longformer as a set encoder is that the model can take in lengthy documents with a maximum of 4096 tokens, which only adds a little amount of additional processing. This quick summarization tool can be used by doctors or medical practitioners for quickly analysing emergency or critical patients.",
    "abstract_processed": "quantiti written content medic inform stagger keep increas daili think internet full websit news constantli updat statu blog great deal util search swiftli scroll key find effect method navig materi mainli result arrang specif fashion consider percentag stuff need summar emphas signific inform creat custom summari two hand everyth effect done text summar techniqu critic need autom method project incorpor technolog capabl summar text automat impli paraphras phrase singl thought propos hierarch document repres architectur extract aggreg util “longformer” set encod “transformer” text encod repres text document properli model refer long tran extr model one benefit use longform set encod model take lengthi document maximum token add littl amount addit process quick summar tool use doctor medic practition quickli analys emerg critic patient"
  },
  {
    "doc_id": "10271182",
    "abstract_original": "In recent years, with the popularization of intelligent devices, the application of computer technology in the field of education has also shown a rapid development. This paper takes the construction of Adaptive learning support model as the starting point, designs the framework of Adaptive learning based on multidimensional feature fusion of Adaboost algorithm, explores the construction, fusion and application of learner model, domain knowledge model and adaptive engine, and then implements the Adaptive learning system and conducts application research on it. By constructing an adaptive model, it is verified that the model has higher accuracy and robustness, and can effectively adapt to different students and teaching environments.",
    "abstract_processed": "recent year popular intellig devic applic comput technolog field educ also shown rapid develop paper take construct adapt learn support model start point design framework adapt learn base multidimension featur fusion adaboost algorithm explor construct fusion applic learner model domain knowledg model adapt engin implement adapt learn system conduct applic research construct adapt model verifi model higher accuraci robust effect adapt differ student teach environ"
  },
  {
    "doc_id": "10271339",
    "abstract_original": "This study employs deep learning and artificial intelligence (AI) clustering analysis techniques to evaluate the suitability of integrated rural land for three industries. Diverse datasets pertaining to rural development, encompassing land use, agricultural production, and rural tourism, are gathered and harmoniously amalgamated. An innovative land suitability assessment model, merging ResNet-50 with the k-means algorithm, is devised. Specifically, ResNet-50 is harnessed for the classification and recognition of rural land-use images, thus deriving feature vectors for each sample. These feature vectors are subsequently fed into the k-means algorithm to cluster samples with akin land-use patterns. The ensuing examination of land use composition within each cluster facilitates the evaluation of rural land’s suitability for three-industry integration. Experimental scrutiny discloses that this study achieves an accuracy rate of 88.3% in rural land-use classification and recognition, outperforming alternative algorithms by at least 3.1%. Furthermore, it yields an average intersection over union (IoU) of 67.29%. Remarkably, the k-means algorithm exhibits superior clustering outcomes. Consequently, the model introduces herein demonstrated substantial enhancements in rural land-use classification and recognition accuracy, average IoU, and clustering performance. It offers an innovative tool for policymakers to advance rural industry integration, fostering economic diversification. Additionally, this model aids decision-makers in identifying prospective opportunities and challenges, thus facilitating the formulation of forward-thinking and viable rural development strategies.",
    "abstract_processed": "studi employ deep learn artifici intellig ai cluster analysi techniqu evalu suitabl integr rural land three industri divers dataset pertain rural develop encompass land use agricultur product rural tourism gather harmoni amalgam innov land suitabl assess model merg resnet k mean algorithm devis specif resnet har classif recognit rural land use imag thu deriv featur vector sampl featur vector subsequ fed k mean algorithm cluster sampl akin land use pattern ensu examin land use composit within cluster facilit evalu rural land’ suitabl three industri integr experiment scrutini disclos studi achiev accuraci rate rural land use classif recognit outperform altern algorithm least furthermor yield averag intersect union iou remark k mean algorithm exhibit superior cluster outcom consequ model introduc herein demonstr substanti enhanc rural land use classif recognit accuraci averag iou cluster perform offer innov tool policymak advanc rural industri integr foster econom diversif addit model aid decis maker identifi prospect opportun challeng thu facilit formul forward think viabl rural develop strategi"
  },
  {
    "doc_id": "10271351",
    "abstract_original": "Winning an Academy Award is probably not something most engineers ever expect to do. But it was a fitting honor for Jim Vanns, who won a 2023 Technical Achievement Award—commonly referred to as a Technical Oscar—from the Academy of Motion Picture Arts and Sciences for his work on the high-performance computing systems behind the blockbuster films Gravity (2013) and Guardians of the Galaxy (2014). He shared the award with Mark Hills, a former colleague at the London-based visual-effects studio Framestore. The pair designed the software to manage the cutting-edge computing cluster that Framestore used to create its computer-generated imagery, or CGI. Their software is still being used today.",
    "abstract_processed": "win academi award probabl someth engin ever expect fit honor jim vann technic achiev award—commonli refer technic oscar—from academi motion pictur art scienc work high perform comput system behind blockbust film graviti guardian galaxi share award mark hill former colleagu london base visual effect studio framestor pair design softwar manag cut edg comput cluster framestor use creat comput gener imageri cgi softwar still use today"
  },
  {
    "doc_id": "10272839",
    "abstract_original": "To address pattern classification problems without involving complex computations, a Hash-Based Convolutional Deep-Thinking Pattern Classifier (HCDTPC) has been developed. This classifier draws inspiration from the human visual system and human thinking logic. The architecture consists of five layers, each serving a distinct purpose. In the initial convolutional layer, informative and distinct features are extracted, mimicking the functionality of the human visual system. The subsequent clustering layer employs a clustering algorithm to group samples within a class into smaller clusters. This arrangement allows the following layer to compare test samples across different clusters, replicating a human-like classification process where the most similar samples should belong to the same group. The hashing layer of the devised system employs a similarity-preserve hashing technique to transform feature maps into hashed data. This transformation reduces the dimensionality of the data while retaining essential similarity information. In the logical layer, Bayesian inference is employed to classify testing samples, mirroring human thought processes. The simulation section assesses the performance of the HCDTPC, demonstrating its effectiveness and efficiency in pattern classification.",
    "abstract_processed": "address pattern classif problem without involv complex comput hash base convolut deep think pattern classifi hcdtpc develop classifi draw inspir human visual system human think logic architectur consist five layer serv distinct purpos initi convolut layer inform distinct featur extract mimick function human visual system subsequ cluster layer employ cluster algorithm group sampl within class smaller cluster arrang allow follow layer compar test sampl across differ cluster replic human like classif process similar sampl belong group hash layer devis system employ similar preserv hash techniqu transform featur map hash data transform reduc dimension data retain essenti similar inform logic layer bayesian infer employ classifi test sampl mirror human thought process simul section assess perform hcdtpc demonstr effect effici pattern classif"
  },
  {
    "doc_id": "10273208",
    "abstract_original": "As the performance of generative artificial intelligence (GAI), such as ChatGPT, improves, content created by GAI will be distributed in the social media space, and knowledge and writings from unknown sources will be disseminated and reproduced. Now that GAI is becoming widespread, it is necessary to distinguish GAI from human intelligence, which constitutes knowledge. The data, information, knowledge, and work (DIKW) hierarchy is a useful framework for teaching and for checking metacognitive and explainable artificial intelligence (XAI) literacy. There are two types of collaboration between GAI and human intelligence: a combined intelligence model and a parallel intelligence model. The combined intelligence model is a method of using GAI for creating works by collecting data, organizing information, and deriving knowledge from information. This model is suitable for GAI-assisted tasks (GAIATs). The parallel intelligence model is suitable for GAI-assisted learning (GAIAL); it is a method in which a person develops abilities by analyzing and comparing tasks created by GAI after going through the data-information-knowledge-work process. The zone of proximal development (ZPD) created by educational scaffolding is a quantitative framework that is appropriate for evaluating the effects of GAI. The ZPD generated by GAI that corresponds to scaffolding should be managed so as not to favor or disadvantage specific individuals.",
    "abstract_processed": "perform gener artifici intellig gai chatgpt improv content creat gai distribut social media space knowledg write unknown sourc dissemin reproduc gai becom widespread necessari distinguish gai human intellig constitut knowledg data inform knowledg work dikw hierarchi use framework teach check metacognit explain artifici intellig xai literaci two type collabor gai human intellig combin intellig model parallel intellig model combin intellig model method use gai creat work collect data organ inform deriv knowledg inform model suitabl gai assist task gaiat parallel intellig model suitabl gai assist learn gaial method person develop abil analyz compar task creat gai go data inform knowledg work process zone proxim develop zpd creat educ scaffold quantit framework appropri evalu effect gai zpd gener gai correspond scaffold manag favor disadvantag specif individu"
  },
  {
    "doc_id": "10273694",
    "abstract_original": "Aiming at the problems of small target and low recognition accuracy of high-speed railway contact network hanging chord defects, this paper proposes a target detection algorithm for hanging chord defects based on YOLOv5. To enhance the original YOLOv5 algorithm, the MobielNetv3 module was used as the efficient and lightweight backbone feature extraction network. Depth-separable convolution was adopted instead of standard convolution, reducing the number of network parameters by  $2\\times 10 ^{6}$  and increasing detection speed by 23%. Introducing BiFPN feature pyramid structure with fusion of different feature layers in neck network improves detection accuracy by 0.4%. Adding CBAM attention mechanism at the prediction end improves the feature extraction ability of the model for small target images, which further improves the detection accuracy by 0.5%. The loss function CIoU was improved to Focal EIoU in order to solve the problems of unbalanced sample datasets and vanishing IoU gradients during the training process. The experimental results exhibit that the improved algorithm achieves an average accuracy of 98.5% on the dataset, a 39% enchancment in model detection speed and a 28% reduction in model parameters, verifying that the algorithm has the advantages of high recognition accuracy and fast detection speed. It can effectively solve the technical difficulties in the detection of defects in the existing contact network suspension chords, and provides a new way of thinking for intelligent railway inspection.",
    "abstract_processed": "aim problem small target low recognit accuraci high speed railway contact network hang chord defect paper propos target detect algorithm hang chord defect base yolov enhanc origin yolov algorithm mobielnetv modul use effici lightweight backbon featur extract network depth separ convolut adopt instead standard convolut reduc number network paramet \\time increas detect speed introduc bifpn featur pyramid structur fusion differ featur layer neck network improv detect accuraci ad cbam attent mechan predict end improv featur extract abil model small target imag improv detect accuraci loss function ciou improv focal eiou order solv problem unbalanc sampl dataset vanish iou gradient train process experiment result exhibit improv algorithm achiev averag accuraci dataset enchanc model detect speed reduct model paramet verifi algorithm advantag high recognit accuraci fast detect speed effect solv technic difficulti detect defect exist contact network suspens chord provid new way think intellig railway inspect"
  },
  {
    "doc_id": "10273912",
    "abstract_original": "As the business landscape progresses, the advancement of information systems is becoming increasingly valuable in shaping the future workforce. The rising demand for skilled employees who can navigate and manage technological tools and stay engaged in the workplace requires businesses to make significant efforts to advance their workforce's digital competencies and cognitive satisfaction. To understand this phenomenon better, considering the future workforce, specifically final-year students, could provide more valuable insights, as previous studies have been unable to capture this illustration fully. This research intends to understand willingness to engage behaviour of the future workforce through digital dexterity (i.e., personal-innovativeness, and computers self-efficacy) and psychological empowerment. A hypothesis-based framework delineated with seven paths, and data were collected through a questionnaire survey. To analyze the collected data from 147 respondents, a multivariate data analysis technique \"PLS-SEM\" was practiced. The study finding illustrated that personal innovativeness played a major role in impacting willingness to engage behavior followed by computer self-efficacy. These findings are novel and significant, providing new insights into the complex relationship between model variables among final-year students. The implications of this study would be particularly valuable for businesses looking to understand better and engage with the future workforce.",
    "abstract_processed": "busi landscap progress advanc inform system becom increasingli valuabl shape futur workforc rise demand skill employe navig manag technolog tool stay engag workplac requir busi make signific effort advanc workforc digit compet cognit satisfact understand phenomenon better consid futur workforc specif final year student could provid valuabl insight previou studi unabl captur illustr fulli research intend understand willing engag behaviour futur workforc digit dexter e person innov comput self efficaci psycholog empower hypothesi base framework delin seven path data collect questionnair survey analyz collect data respond multivari data analysi techniqu pl sem practic studi find illustr person innov play major role impact willing engag behavior follow comput self efficaci find novel signific provid new insight complex relationship model variabl among final year student implic studi would particularli valuabl busi look understand better engag futur workforc"
  },
  {
    "doc_id": "10274441",
    "abstract_original": "The widespread usage of wearables set the foundations for many new applications that process the wearable sensor data. Human Activity Recognition (HAR) is a well-studied application that targets to classify the data captured by multiple wearable sensors into one of a predefined set of activity classes. Earlier approaches in the area relied on Machine Learning (ML) classifiers, while many researchers proposed solutions based on Deep Neural Networks (DNNs), e.g., using Long Short-Term Memory (LSTMs) or Convolution Neural Network (CNNs). Even though the usage of DNNs for HAR is a widely explored field, the problem of compressing (thus reducing the computational requirements) the resulting DNN models has been disregarded by the research community. This is of paramount importance if we consider that wearables are characterized by scarce memory and computational resources. In this work, we first analyze the impact of the size of the various CNN components (focusing on the convolution and dense layers) to the model validation performance. As a second step, we focus on two CNN models with diverse memory characteristics (the lean and the fat model) and we employ three different compression techniques (Filter-Based Pruning –FBP,– Low Rank Factorization –LRF,– and dynamic range quantization) assuming various compressibility scenarios.",
    "abstract_processed": "widespread usag wearabl set foundat mani new applic process wearabl sensor data human activ recognit har well studi applic target classifi data captur multipl wearabl sensor one predefin set activ class earlier approach area reli machin learn ml classifi mani research propos solut base deep neural network dnn e g use long short term memori lstm convolut neural network cnn even though usag dnn har wide explor field problem compress thu reduc comput requir result dnn model disregard research commun paramount import consid wearabl character scarc memori comput resourc work first analyz impact size variou cnn compon focus convolut dens layer model valid perform second step focu two cnn model divers memori characterist lean fat model employ three differ compress techniqu filter base prune –fbp – low rank factor –lrf – dynam rang quantiz assum variou compress scenario"
  },
  {
    "doc_id": "10278231",
    "abstract_original": "The purpose of this study is to look at how a music programming course affects the development of computational thinking in undergraduate music conservatory students. In addition to teaching the fundamentals of computational thinking, music programming, and logic, the course addresses the Four C’s of education. The change in students’ attitudes toward computer and algorithmic skills, creativity, communication, and collaboration is measured using a pre-and post-test experimental design. Additionally, computational thinking abilities are assessed through the administration of music analysis, procedural, graphical, and logic quizzes, while creativity is evaluated through a qualitative grading of the students’ final music projects. Results show a general perceived improvement of the students’ attitudes toward the Four C’s as well as a good ability to convert learned computational models into musical creativity. However, more effort is needed in order to guarantee an overall improvement in the students’ actual computational thinking abilities.",
    "abstract_processed": "purpos studi look music program cours affect develop comput think undergradu music conservatori student addit teach fundament comput think music program logic cours address four c’ educ chang students’ attitud toward comput algorithm skill creativ commun collabor measur use pre post test experiment design addit comput think abil assess administr music analysi procedur graphic logic quizz creativ evalu qualit grade students’ final music project result show gener perceiv improv students’ attitud toward four c’ well good abil convert learn comput model music creativ howev effort need order guarante overal improv students’ actual comput think abil"
  },
  {
    "doc_id": "10280127",
    "abstract_original": "Context In many countries, it is now important to integrate learning-oriented views to foster computational thinking (CT) in the classroom. This has inspired ideas for new lesson plans, instructional strategies, teacher guidance, and, most importantly, new approaches to grading these skills. Aim: This article presents the results of a systematic review initially focused on identifying the various ways of assessing CT in school and their relationship to relevant CT skills. Method: We conducted a systematic review of the literature to assess CT in schools. This review applied a semi-automatic search for specific terms within the selected papers. These terms came from the analysis of several established definitions of CT. Results: We present a set of the most representative competencies and concepts developed in various experiences, in which the main topic is the assessment of CT, as well as some that have not been developed and that may be the subject of future works. Conclusions: The evaluation of CT in the school requires multiple approaches; it is a challenge to have a single method or strategy to evaluate everything that CT implies.",
    "abstract_processed": "context mani countri import integr learn orient view foster comput think ct classroom inspir idea new lesson plan instruct strategi teacher guidanc importantli new approach grade skill aim articl present result systemat review initi focus identifi variou way assess ct school relationship relev ct skill method conduct systemat review literatur assess ct school review appli semi automat search specif term within select paper term came analysi sever establish definit ct result present set repres compet concept develop variou experi main topic assess ct well develop may subject futur work conclus evalu ct school requir multipl approach challeng singl method strategi evalu everyth ct impli"
  },
  {
    "doc_id": "10283649",
    "abstract_original": "6G technology is expected to lead to an unpredictable increase of Internet of Things (IoT) devices. The need for maintaining continuous connectivity of these devices has in turn led to re-thinking of the traditional design of wireless networks. In particular, the integration of 6G and Digital Twin (DT) is expected to reshape the network management as it offers powerful features in design, development and optimization processes. DT is a digital representation of physical entities, which are designed around a two-way information flow. Therefore, this technology not only collects data, and employs intelligent learning methods by performing complex computations, but it also can send feedback to improve system performance for 6G-enabled massive IoT. However, deploying such a technology requires addressing complex challenges such as limited resources, seamless connectivity and lack of trust between end users and network edge. To address these challenges, we formulate the resource allocation problem including edge computation and service migration in 6G-enabled massive IoT. The contributions are threefold: First, our DT-empowered architecture is proposed that uses the real-time and historical data from end users to find the best allocation at a user. Second, it studies the impact of trust relationship between computing entities to prevent the unauthorized accesses and provides an authentication procedure. Third, it describes a Multi-Agent Reinforcement Learning (MARL) algorithm that consists of cooperative agents and aims to find the best resource allocation strategy by minimizing task processing latency. We validate the proposed DT-empowered architecture to show the reduced processing latency compared to traditional benchmark methods.",
    "abstract_processed": "g technolog expect lead unpredict increas internet thing iot devic need maintain continu connect devic turn led think tradit design wireless network particular integr g digit twin dt expect reshap network manag offer power featur design develop optim process dt digit represent physic entiti design around two way inform flow therefor technolog collect data employ intellig learn method perform complex comput also send feedback improv system perform g enabl massiv iot howev deploy technolog requir address complex challeng limit resourc seamless connect lack trust end user network edg address challeng formul resourc alloc problem includ edg comput servic migrat g enabl massiv iot contribut threefold first dt empow architectur propos use real time histor data end user find best alloc user second studi impact trust relationship comput entiti prevent unauthor access provid authent procedur third describ multi agent reinforc learn marl algorithm consist cooper agent aim find best resourc alloc strategi minim task process latenc valid propos dt empow architectur show reduc process latenc compar tradit benchmark method"
  },
  {
    "doc_id": "10285197",
    "abstract_original": "In recent years, with the extensive application of artificial intelligence in various fields, the research on how to apply artificial intelligence to education has gradually become the focus of attention. Knowledge map is a giant semantic network composed of nodes and edges, which represents the semantic association between different nodes in the form of large-scale graph. Knowledge map, as a structured storage form of multi-domain data in the real world, provides semantic relevance between data and makes it possible for artificial intelligence to make better use of data. The research of representation learning based on knowledge map realizes the distributed representation of entities and relationships, significantly improves the computational efficiency, effectively alleviates the problem of data sparseness and can realize the fusion of heterogeneous information, which is of great significance for people to obtain effective information from massive data. In view of the above situation, taking WebQA data set as an example, this paper proposes a method to simplify the original text, introduce apriori knowledge related to answers from the knowledge map, and use neural network model to generate Chinese questions. The experimental results show that the method proposed in this paper can effectively reduce the difficulty of model training and improve the quality of model problems.",
    "abstract_processed": "recent year extens applic artifici intellig variou field research appli artifici intellig educ gradual becom focu attent knowledg map giant semant network compos node edg repres semant associ differ node form larg scale graph knowledg map structur storag form multi domain data real world provid semant relev data make possibl artifici intellig make better use data research represent learn base knowledg map realiz distribut represent entiti relationship significantli improv comput effici effect allevi problem data spars realiz fusion heterogen inform great signific peopl obtain effect inform massiv data view situat take webqa data set exampl paper propos method simplifi origin text introduc apriori knowledg relat answer knowledg map use neural network model gener chines question experiment result show method propos paper effect reduc difficulti model train improv qualiti model problem"
  },
  {
    "doc_id": "10285983",
    "abstract_original": "Image inpainting is an important task in computer vision. As admirable methods are presented, the inpainted image is getting closer to reality. However, the result is still not good enough in the reconstructed texture and structure based on human vision. Although recent advances in computer hardware have enabled the development of larger and more complex models, there is still a need for lightweight models that can be used by individuals and small-sized institutions. Therefore, we propose a lightweight model that combines a specialized transformer with a traditional convolutional neural network (CNN). Furthermore, we have noticed most researchers only consider three primary colors (RGB) in inpainted images, but we think this is not enough. So we propose a new loss function to intensify color details. Extensive experiments on commonly seen datasets (Places2 and CelebA) validate the efficacy of our proposed model compared with other state-of-the-art methods. The source code and pretrained models are available at https://reurl.cc/RzD11n.",
    "abstract_processed": "imag inpaint import task comput vision admir method present inpaint imag get closer realiti howev result still good enough reconstruct textur structur base human vision although recent advanc comput hardwar enabl develop larger complex model still need lightweight model use individu small size institut therefor propos lightweight model combin special transform tradit convolut neural network cnn furthermor notic research consid three primari color rgb inpaint imag think enough propos new loss function intensifi color detail extens experi commonli seen dataset place celeba valid efficaci propos model compar state art method sourc code pretrain model avail http reurl cc rzd n"
  },
  {
    "doc_id": "10286410",
    "abstract_original": "As social robots and other intelligent machines enter the home, artificial emotional intelligence (AEI) is taking center stage to address users’ desire for deeper, more meaningful human-machine interaction. To accomplish such efficacious interaction, the next-generation AEI needs comprehensive human emotion models for training. Unlike theory of emotion, which has been the historical focus in psychology, emotion models are a descriptive tool. In practice, the strongest models need robust coverage, which means defining the smallest core set of emotions from which all others can be derived. To achieve the desired coverage, we turn to word embeddings from natural language processing. Using unsupervised clustering techniques, our experiments show that with as few as 15 discrete emotion categories, we can provide maximum coverage across six major languages–Arabic, Chinese, English, French, Spanish, and Russian. In support of our findings, we also examine annotations from two large-scale emotion recognition datasets to assess the validity of existing emotion models compared to human perception at scale. Because robust, comprehensive emotion models are foundational for developing real-world affective computing applications, this work has broad implications in social robotics, human-machine interaction, mental healthcare, computational psychology, and entertainment.",
    "abstract_processed": "social robot intellig machin enter home artifici emot intellig aei take center stage address users’ desir deeper meaning human machin interact accomplish efficaci interact next gener aei need comprehens human emot model train unlik theori emot histor focu psycholog emot model descript tool practic strongest model need robust coverag mean defin smallest core set emot other deriv achiev desir coverag turn word embed natur languag process use unsupervis cluster techniqu experi show discret emot categori provid maximum coverag across six major languages–arab chines english french spanish russian support find also examin annot two larg scale emot recognit dataset assess valid exist emot model compar human percept scale robust comprehens emot model foundat develop real world affect comput applic work broad implic social robot human machin interact mental healthcar comput psycholog entertain"
  },
  {
    "doc_id": "10287634",
    "abstract_original": "The prime focus on the deliberations related to Industry 5.0 lies in creativity, efficiency and resilience for adapting various organic components such as accurate decisions, customized demands in consumer electronics with promising/sustainable solutions. This transformation and paradigm shift inside the Industry 5.0 frame can be comprehensively understood by integrating the factors related to human values with the cutting-edge technologies of consumer electronics for compatibility with the issue of sustainable development. The present work proposes an integrated approach for extensive study with a set of criteria and possible Industry 5.0 enablers in consumer electronics using a novel decision-making approach. The approach comprises of  $T$ -spherical fuzzy information containment/processing through an analytic hierarchy process (AHP) and then utilizing the weighted aggregated sum product assessment (WASPAS) sequentially to obtain the necessary weights of selected criteria. Further, the obtained weights from AHP would be used in WASPAS for the computational assessment while finding the prioritization/ranking of industry 5.0 enablers. The results with the sensitivity analysis validate the robustness-cum-resilience of the proposed integrated approach with standard managerial implications and the findings take care of cognitive in the human socio-technical environment. The regulated adoption of Industry 5.0 enablers would help consumer electronics manufacturers in finding optimized solutions.",
    "abstract_processed": "prime focu deliber relat industri lie creativ effici resili adapt variou organ compon accur decis custom demand consum electron promis sustain solut transform paradigm shift insid industri frame comprehens understood integr factor relat human valu cut edg technolog consum electron compat issu sustain develop present work propos integr approach extens studi set criteria possibl industri enabl consum electron use novel decis make approach approach compris spheric fuzzi inform contain process analyt hierarchi process ahp util weight aggreg sum product assess waspa sequenti obtain necessari weight select criteria obtain weight ahp would use waspa comput assess find priorit rank industri enabl result sensit analysi valid robust cum resili propos integr approach standard manageri implic find take care cognit human socio technic environ regul adopt industri enabl would help consum electron manufactur find optim solut"
  },
  {
    "doc_id": "10287938",
    "abstract_original": "Cloud computing is a technology for efficiently using computing infrastructures and a business model for selling computing resources and services. However, intruders find such complex and distributed infrastructures appealing targets for cyber-attacks. Cyber-attacks are severe threats that can jeopardize the quality of service provided to clients and compromise data integrity, confidentiality, and availability. Cyber-attacks are becoming more complex, making it more challenging to detect intrusions effectively. Due to the high traffic and increased malicious activities on the Internet, a single Intrusion Detection System (IDS) can be overwhelmed. Despite the various Deep Learning (DL) approaches that have been proposed as alternative solutions, there are still pertinent security issues to be addressed especially in federated cloud computing domains. This work proposes a Secure Federated Intrusion Detection Model Version 1 (SecFedIDM-V1) using blockchain technology and Bidirectional Long Short-Term Memory (BiLSTM) Recurrent Neural Network (RNN). The Cobourg Intrusion Detection Dataset (CIDDS) was acquired, pre-processed and split into 60:20:20, 70:15:15, and 80:10:10 for training, testing, and validation respectively to develop the proposed intrusion traffic classification component of the proposed model. The developed SecFedIDM-V1 was later deployed as a Python-based web application that captures network packets for classifying attacks into normal or an attack type. The attack packets are recorded in a Hyperledger Fabric (a private blockchain technology) to serve as a signature database to be used by other nodes in the network. From the evaluation results of the intrusion classifier, the 80:10:10 BiLSTM network performed better than GRU with a Precision of 0.99624, Recall of 0.99906, F1 Score of 0.99614, False Positive Rate (FPR) of 0.00094, False Negative Rate (FNR) of 0.00395 and True Positive Rate (TPR) of 0.99605. The SecFedIDM-V1 can be deployed alongside Firewalls in a federated cloud computing environment to reinforce the security of the infrastructure.",
    "abstract_processed": "cloud comput technolog effici use comput infrastructur busi model sell comput resourc servic howev intrud find complex distribut infrastructur appeal target cyber attack cyber attack sever threat jeopard qualiti servic provid client compromis data integr confidenti avail cyber attack becom complex make challeng detect intrus effect due high traffic increas malici activ internet singl intrus detect system id overwhelm despit variou deep learn dl approach propos altern solut still pertin secur issu address especi feder cloud comput domain work propos secur feder intrus detect model version secfedidm v use blockchain technolog bidirect long short term memori bilstm recurr neural network rnn cobourg intrus detect dataset cidd acquir pre process split train test valid respect develop propos intrus traffic classif compon propos model develop secfedidm v later deploy python base web applic captur network packet classifi attack normal attack type attack packet record hyperledg fabric privat blockchain technolog serv signatur databas use node network evalu result intrus classifi bilstm network perform better gru precis recal f score fals posit rate fpr fals neg rate fnr true posit rate tpr secfedidm v deploy alongsid firewal feder cloud comput environ reinforc secur infrastructur"
  },
  {
    "doc_id": "10290980",
    "abstract_original": "Can machines think? Or can they do “whatever we know how to order” them to perform? Should machines be liberated from slavery and given “fair play” to “compete with men in all purely intellectual fields”? Or should this be associated with a fashion that decries “human reason” and a path that “leads straight to Nazism”? In the postwar years, these questions were debated by Alan Turing and Douglas Hartree, who differed in their interpretations of the digital computer as a new piece of science and technology. Hartree emphasized its unprecedented calculation speed and envisioned applications in physics, logistics, energy, and warfare. Turing, who envisioned applications in biology and cognition, emphasized its potential to outperform humans intellectually, including capabilities considered distinctly human, which Hartree downplayed by mobilizing the notes of Ada Lovelace. This article examines the Turing–Hartree disputes and draws a parallel between their positions and their perspectives on postwar Britain.",
    "abstract_processed": "machin think “whatev know order” perform machin liber slaveri given “fair play” “compet men pure intellectu fields” associ fashion decri “human reason” path “lead straight nazism” postwar year question debat alan ture dougla hartre differ interpret digit comput new piec scienc technolog hartre emphas unpreced calcul speed envis applic physic logist energi warfar ture envis applic biolog cognit emphas potenti outperform human intellectu includ capabl consid distinctli human hartre downplay mobil note ada lovelac articl examin turing–hartre disput draw parallel posit perspect postwar britain"
  },
  {
    "doc_id": "10291034",
    "abstract_original": "Visual analytics (VA) tools support data exploration by helping analysts quickly and iteratively generate views of data which reveal interesting patterns. However, these tools seldom enable explicit checks of the resulting interpretations of data—e.g., whether patterns can be accounted for by a model that implies a particular structure in the relationships between variables. We present EVM, a data exploration tool that enables users to express and check provisional interpretations of data in the form of statistical models. EVM integrates support for visualization-based model checks by rendering distributions of model predictions alongside user-generated views of data. In a user study with data scientists practicing in the private and public sector, we evaluate how model checks influence analysts' thinking during data exploration. Our analysis characterizes how participants use model checks to scrutinize expectations about data generating process and surfaces further opportunities to scaffold model exploration in VA tools.",
    "abstract_processed": "visual analyt va tool support data explor help analyst quickli iter gener view data reveal interest pattern howev tool seldom enabl explicit check result interpret data— g whether pattern account model impli particular structur relationship variabl present evm data explor tool enabl user express check provision interpret data form statist model evm integr support visual base model check render distribut model predict alongsid user gener view data user studi data scientist practic privat public sector evalu model check influenc analyst think data explor analysi character particip use model check scrutin expect data gener process surfac opportun scaffold model explor va tool"
  },
  {
    "doc_id": "10291337",
    "abstract_original": "Insitut Teknologi Del (IT Del), formerly recognized as Politeknik Informatika Del (PI Del), has consistently maintained its emphasis on the computing curriculum, establishing it as the institution's primary domain of expertise since its founding. Being recognized as a campus with its high employability rate, this paper aims to describe how IT Del develops its computing curriculum in connection to its involvement in the Decart project. This paper first presents the Indonesia curriculum guideline. This is followed by the discussion of the development process of computing curriculum emphasizing three components: knowledge, skills, and dispositions. The last component is believed to be one of the important components aimed to prepare graduates to have 21st century skills. Then we relate them to the involvement of IT Del in the DECART project, funded by Erasmus Mundus. The purpose of this paper is to demonstrate that our existing curriculum development approach has been successful to build expected graduates' competence. This is expected to give an insight to define an agile curriculum framework to face the VUCA world as one of the objectives for the DECART project.",
    "abstract_processed": "insitut teknolog del del formerli recogn politeknik informatika del pi del consist maintain emphasi comput curriculum establish institut primari domain expertis sinc found recogn campu high employ rate paper aim describ del develop comput curriculum connect involv decart project paper first present indonesia curriculum guidelin follow discuss develop process comput curriculum emphas three compon knowledg skill disposit last compon believ one import compon aim prepar graduat st centuri skill relat involv del decart project fund erasmu mundu purpos paper demonstr exist curriculum develop approach success build expect graduat compet expect give insight defin agil curriculum framework face vuca world one object decart project"
  },
  {
    "doc_id": "1029277",
    "abstract_original": "For forty years, much human electrophysiologic thinking has been based on the concept that EEG data recorded from the scalp following sensory stimulation are dominated by successive far-field correlates of bottom-up brain sensory processing, as represented in evoked potential (EP) averages. I will present evidence for an alternate view that human EEG data are dominated by oscillatory processes relating to time-varying, top-down control of cortical dynamics and attention. This view suggests a reorientation of scientific and engineering focus towards modeling brain dynamics of humans as active operators rather than as passive perceivers and programmed responders. Such research presents new engineering challenges. There is a need, first, to understand and model the process of partial phase resetting of ongoing and intermittent nonlinear oscillatory processes, and more generally, of inter-process synchronization. Methods we have developed or integrated for EEG research, including independent component analysis (ICA) and time/frequency analysis, now allow detection and modeling of such brain dynamic events from high-dimensional electrical data collected noninvasively from the human scalp. It is probable that real time signal processing capable of separating EEG processes from non-brain signals and of monitoring brain synchronization events may allow high-level cognitive monitoring that could be used in man-machine interfaces and for neuropsychological training.",
    "abstract_processed": "forti year much human electrophysiolog think base concept eeg data record scalp follow sensori stimul domin success far field correl bottom brain sensori process repres evok potenti ep averag present evid altern view human eeg data domin oscillatori process relat time vari top control cortic dynam attent view suggest reorient scientif engin focu toward model brain dynam human activ oper rather passiv perceiv program respond research present new engin challeng need first understand model process partial phase reset ongo intermitt nonlinear oscillatori process gener inter process synchron method develop integr eeg research includ independ compon analysi ica time frequenc analysi allow detect model brain dynam event high dimension electr data collect noninvas human scalp probabl real time signal process capabl separ eeg process non brain signal monitor brain synchron event may allow high level cognit monitor could use man machin interfac neuropsycholog train"
  },
  {
    "doc_id": "10293079",
    "abstract_original": "Battle commanders in modern war are facing new challenges such as massive information and short time windows. There is an urgent demand of intelligent assistant system to communicate with the commanders and staff officers, think about what they think, answer their questions, offer advises to their decision making, learn their experiences, and significantly improve their performance. Based on capability requirements analysis of such system, its system architecture was proposed, which shares data, knowledge, functions and computing power with the command information system currently in use. An AI framework based technical architecture was proposed, which has five characteristics: natural human-computer interaction, flexible function integration, knowledge system driven, continues ability evolution, and powerful computing support.",
    "abstract_processed": "battl command modern war face new challeng massiv inform short time window urgent demand intellig assist system commun command staff offic think think answer question offer advis decis make learn experi significantli improv perform base capabl requir analysi system system architectur propos share data knowledg function comput power command inform system current use ai framework base technic architectur propos five characterist natur human comput interact flexibl function integr knowledg system driven continu abil evolut power comput support"
  },
  {
    "doc_id": "10293084",
    "abstract_original": "The human brain is a marvel of complex and dynamic networks that enable us to move, sense, think, and remember. How do these networks constantly reconfigure themselves in real-time to process information? To answer this question, we need reliable methods able to capture the dynamics of the dominant functional 'states'. However, this task is challenging due to the diversity of the available pipelines that are difficult to evaluate. Here, we present an overview of a computational framework that combines electrophysiological data with dynamic functional connectivity approach (dFC) followed by dimensionality reduction methods. We highlighted the utility of such framework in tracking the dynamics of key brain network states. Then, we provide a practical example on real MEG data during fast motor task. Our analysis evaluated the effectiveness of the proposed framework including several instances of decomposition and clustering techniques in capturing relevant spatial and temporal patterns of brain network reconfiguration.",
    "abstract_processed": "human brain marvel complex dynam network enabl us move sens think rememb network constantli reconfigur real time process inform answer question need reliabl method abl captur dynam domin function state howev task challeng due divers avail pipelin difficult evalu present overview comput framework combin electrophysiolog data dynam function connect approach dfc follow dimension reduct method highlight util framework track dynam key brain network state provid practic exampl real meg data fast motor task analysi evalu effect propos framework includ sever instanc decomposit cluster techniqu captur relev spatial tempor pattern brain network reconfigur"
  },
  {
    "doc_id": "10295465",
    "abstract_original": "Different individual features of the learner data often work as essential indicators of learning and intervention needs. This work exploits the personas in the design thinking process as the theoretical basis to analyze and cluster learners’ learning behavior patterns as groups. To adapt to the learning practice, we develop data-driven personas by clustering learners’ features based on factual learning outcomes (i.e., knowledge gain, perceived learning experience, perceived social presence) based on unsupervised learning, a more accessible and objective intervention design strategy for e-reading practices. Using the Chi-square test, we quantitatively evaluate different clusters driven by various unsupervised learning methods on the multimodal SKEP dataset. Furthermore, for a more practical real-life application, we achieved automatic persona prediction based on the attention regulation behaviors of learners. The subject-independent evaluation results indicate the best classification accuracy of 70% for the four-level classification task, differentiating three personas of learners with needs and another without feedback needs. It also shows that time-based sampling on both independent and cumulative learner behaviors works as robust predictors of learner personas, achieving a stable accuracy range of 65%-70% throughout the e-reading with the SVM classifier. Our work inspires the design of a real-time feedback loop for e-learning based on conversational agents.",
    "abstract_processed": "differ individu featur learner data often work essenti indic learn intervent need work exploit persona design think process theoret basi analyz cluster learners’ learn behavior pattern group adapt learn practic develop data driven persona cluster learners’ featur base factual learn outcom e knowledg gain perceiv learn experi perceiv social presenc base unsupervis learn access object intervent design strategi e read practic use chi squar test quantit evalu differ cluster driven variou unsupervis learn method multimod skep dataset furthermor practic real life applic achiev automat persona predict base attent regul behavior learner subject independ evalu result indic best classif accuraci four level classif task differenti three persona learner need anoth without feedback need also show time base sampl independ cumul learner behavior work robust predictor learner persona achiev stabl accuraci rang throughout e read svm classifi work inspir design real time feedback loop e learn base convers agent"
  },
  {
    "doc_id": "10298533",
    "abstract_original": "Code review is a popular practice where developers critique each others' changes. Since automated builds can identify low-level issues (e.g., syntactic errors, regression bugs), it is not uncommon for software organizations to incorporate automated builds in the code review process. In such code review deployment scenarios, submitted change sets must be approved for integration by both peer code reviewers and automated build bots. Since automated builds may produce an unreliable signal of the status of a change set (e.g., due to “flaky” or non-deterministic execution behaviour), code review tools, such as Gerrit, allow developers to request a “recheck”, which repeats the build process without updating the change set. We conjecture that an unconstrained recheck command will waste time and resources if it is not applied judiciously. To explore how the recheck command is applied in a practical setting, in this paper, we conduct an empirical study of 66,932 code reviews from the OpenStack community. We quantitatively analyze (i) how often build failures are rechecked; (ii) the extent to which invoking recheck changes build failure outcomes; and (iii) how much waste is generated by invoking recheck. We observe that (i) 55% of code reviews invoke the recheck command after a failing build is reported; (ii) invoking the recheck command only changes the outcome of a failing build in 42% of the cases; and (iii) invoking the recheck command increases review waiting time by an average of 2,200% and equates to 187.4 compute years of waste-enough compute resources to compete with the oldest land living animal on earth. Our observations indicate that the recheck command is frequently used after the builds fail, but does not achieve a high likelihood of build success. Based on a developer survey and our history-based quantitative findings, we encourage reviewer teams to think twice before rechecking and be considerate of waste. While recheck currently generates plenty of wasted computational resources and bloats waiting times, it also presents exciting future opportunities for researchers and tool builders to propose solutions that can reduce waste.",
    "abstract_processed": "code review popular practic develop critiqu other chang sinc autom build identifi low level issu e g syntact error regress bug uncommon softwar organ incorpor autom build code review process code review deploy scenario submit chang set must approv integr peer code review autom build bot sinc autom build may produc unreli signal statu chang set e g due “flaky” non determinist execut behaviour code review tool gerrit allow develop request “recheck” repeat build process without updat chang set conjectur unconstrain recheck command wast time resourc appli judici explor recheck command appli practic set paper conduct empir studi code review openstack commun quantit analyz often build failur recheck ii extent invok recheck chang build failur outcom iii much wast gener invok recheck observ code review invok recheck command fail build report ii invok recheck command chang outcom fail build case iii invok recheck command increas review wait time averag equat comput year wast enough comput resourc compet oldest land live anim earth observ indic recheck command frequent use build fail achiev high likelihood build success base develop survey histori base quantit find encourag review team think twice recheck consider wast recheck current gener plenti wast comput resourc bloat wait time also present excit futur opportun research tool builder propos solut reduc wast"
  },
  {
    "doc_id": "10299505",
    "abstract_original": "The report presents the application of a developed virtual light laboratory for training lighting students. Some of the application possibilities of the developed software product are shown. Moments from working with the product are presented. Product capabilities are summarized. Some advantages and disadvantages compared to existing similar products are outlined. Shown are screenshots of the product's performance and data that can be obtained and a summary. The relevant conclusions are drawn.",
    "abstract_processed": "report present applic develop virtual light laboratori train light student applic possibl develop softwar product shown moment work product present product capabl summar advantag disadvantag compar exist similar product outlin shown screenshot product perform data obtain summari relev conclus drawn"
  },
  {
    "doc_id": "10301935",
    "abstract_original": "What role do affective feelings (feelings/emotions/moods) play in adaptive behaviour? What are the implications of this for understanding and developing artificial general intelligence? Leading theoretical models of brain function are beginning to shed light on these questions. While artificial agents have excelled within narrowly circumscribed and specialised domains, domain-general intelligence has remained an elusive goal in artificial intelligence research. By contrast, humans and nonhuman animals are characterised by a capacity for flexible behaviour and general intelligence. In this article I argue that computational models of mental phenomena in predictive processing theories of the brain are starting to reveal the mechanisms underpinning domain-general intelligence in biological agents, and can inform the understanding and development of artificial general intelligence. I focus particularly on approaches to computational phenomenology in the active inference framework. Specifically, I argue that computational mechanisms of affective feelings in active inference—affective self-modelling—are revealing of how biological agents are able to achieve flexible behavioural repertoires and general intelligence. I argue that (i) affective self-modelling functions to “tune” organisms to the most tractable goals in the environmental context; and (ii) affective and agentic self-modelling is central to the capacity to perform mental actions in goal-directed imagination and creative cognition. I use this account as a basis to argue that general intelligence of the level and kind found in biological agents will likely require machines to be implemented with analogues of affective self-modelling.",
    "abstract_processed": "role affect feel feel emot mood play adapt behaviour implic understand develop artifici gener intellig lead theoret model brain function begin shed light question artifici agent excel within narrowli circumscrib specialis domain domain gener intellig remain elus goal artifici intellig research contrast human nonhuman anim characteris capac flexibl behaviour gener intellig articl argu comput model mental phenomena predict process theori brain start reveal mechan underpin domain gener intellig biolog agent inform understand develop artifici gener intellig focu particularli approach comput phenomenolog activ infer framework specif argu comput mechan affect feel activ inference—affect self modelling—ar reveal biolog agent abl achiev flexibl behaviour repertoir gener intellig argu affect self model function “tune” organ tractabl goal environment context ii affect agent self model central capac perform mental action goal direct imagin creativ cognit use account basi argu gener intellig level kind found biolog agent like requir machin implement analogu affect self model"
  },
  {
    "doc_id": "10301980",
    "abstract_original": "In this issue, Pessoa emphasizes the importance of viewing neural activity from a perspective that functional networks form dynamically in a way that dramatically changes the functional contribution of individual brain areas. In this response, I argue that we should strive toward pluralism in understanding neural activity at both the emergent network and modular levels, on the bases that a purely emergent understanding would be incomplete, and that there are computational advantages to anatomically stable modularity.",
    "abstract_processed": "issu pessoa emphas import view neural activ perspect function network form dynam way dramat chang function contribut individu brain area respons argu strive toward plural understand neural activ emerg network modular level base pure emerg understand would incomplet comput advantag anatom stabl modular"
  },
  {
    "doc_id": "10302997",
    "abstract_original": "This paper aims to motivate the development of the metaverse by highlighting the potential of artificial-intelligence-generated content (AIGC) for the metaverse. We present the first literature review on AIGC in the metaverse with state-of-the-art research classified into 5 key application areas (avatars and Non-player Characters (NPCs), content creation, virtual world generation, automatic digital twin, and personalization). Having noticed a notable gap in research through our review, we propose ways in which state-of-the-art generative AI can be applied to the metaverse. Additionally, we offer a roadmap for future research with related ethical implications.",
    "abstract_processed": "paper aim motiv develop metavers highlight potenti artifici intellig gener content aigc metavers present first literatur review aigc metavers state art research classifi key applic area avatar non player charact npc content creation virtual world gener automat digit twin person notic notabl gap research review propos way state art gener ai appli metavers addit offer roadmap futur research relat ethic implic"
  },
  {
    "doc_id": "10305292",
    "abstract_original": "This paper exhibits a systematic literature mapping of the considerations required to develop algorithmic thinking in a first course in computer programming (CS1) in university academic programs in computing. In the methodological process of this study, 5 stages were proposed: research questions, search, selection, quality assessment and synthesis extraction. In this way, 5 guiding questions were drawn, 136 articles generated by the search stage were analyzed and the synthesis of 55 documents that met the criteria of this research was concluded, thus compiling the different practices used for the development of algorithmic thinking. In addition, as a result of the systematic literature mapping, a definition of Algorithmic Thinking oriented Software Engineering and didactics is proposed.",
    "abstract_processed": "paper exhibit systemat literatur map consider requir develop algorithm think first cours comput program cs univers academ program comput methodolog process studi stage propos research question search select qualiti assess synthesi extract way guid question drawn articl gener search stage analyz synthesi document met criteria research conclud thu compil differ practic use develop algorithm think addit result systemat literatur map definit algorithm think orient softwar engin didact propos"
  },
  {
    "doc_id": "10305639",
    "abstract_original": "This paper presents the design of a browser-based Arduino programming tool and learning management system (LMS), CASMM, that offers end-to-end support for learners utilizing Chromebooks in a classroom environment. This tool aims to support learners through the entire process of coding and using Arduinos in group projects at scale in formal classrooms. The novelty of this tool and its discussion for the VL/HCC community lies in the design and customization of this tool to meet real world constraints of formal classrooms. In addition, it encourages expansion of who we consider users and requires inclusion of where and how learning takes place to truly support human-centered development of programming tools. In this paper, we shift the focus from individual users to multiple groups of student users and 1–3 teachers/mentors in a classroom environment. In particular, this paper aims to make explicit the unique needs of teachers and students who may have limited technology expertise both in coding and using Arduinos in formal classroom environments, the human and technological constraints of a formal classroom and features we've designed into CASMM to address these needs. Through this paper, we aim to spark discussion about the human-centered requirements of these users and how tools that support learners end-to-end in the development process may be necessary to truly provide accessible programming languages and environments for a wide range of novices (i.e., students, classroom teachers, and college mentors/volunteers).",
    "abstract_processed": "paper present design browser base arduino program tool learn manag system lm casmm offer end end support learner util chromebook classroom environ tool aim support learner entir process code use arduino group project scale formal classroom novelti tool discuss vl hcc commun lie design custom tool meet real world constraint formal classroom addit encourag expans consid user requir inclus learn take place truli support human center develop program tool paper shift focu individu user multipl group student user – teacher mentor classroom environ particular paper aim make explicit uniqu need teacher student may limit technolog expertis code use arduino formal classroom environ human technolog constraint formal classroom featur design casmm address need paper aim spark discuss human center requir user tool support learner end end develop process may necessari truli provid access program languag environ wide rang novic e student classroom teacher colleg mentor volunt"
  },
  {
    "doc_id": "10305646",
    "abstract_original": "The construction industry is a new avenue for big data and data science with sensors and cyber-physical systems deployed in the field. Construction students need to develop computational thinking skills to help make sense of this data, but existing data science environments designed with textual programming languages create a significant barrier to entry. To bridge this gap, we introduce Octave, an end-user programming environment designed to help non-expert programmers analyze spatiotemporal data (e.g., as gathered by a GPS sensor) in an interactive graphical user interface. To aid exploration and understanding, Octave's design incorporates a high degree of liveness, highlighting the interconnection between data, computation, and visualization. We share the underlying design principles behind Octave and details about the system design and implementation. To evaluate Octave, we conducted a usability study with students studying construction. The results show that non-programmer construction students were able to learn Octave easily and were able to effectively use it to solve domain-specific problems from construction education. The participants appreciated Octave's liveness and felt they could easily connect it to real-life problems in their field. Our work informs the design of future accessible end-user programming environments for data analysis targeting non-experts.",
    "abstract_processed": "construct industri new avenu big data data scienc sensor cyber physic system deploy field construct student need develop comput think skill help make sens data exist data scienc environ design textual program languag creat signific barrier entri bridg gap introduc octav end user program environ design help non expert programm analyz spatiotempor data e g gather gp sensor interact graphic user interfac aid explor understand octav design incorpor high degre live highlight interconnect data comput visual share underli design principl behind octav detail system design implement evalu octav conduct usabl studi student studi construct result show non programm construct student abl learn octav easili abl effect use solv domain specif problem construct educ particip appreci octav live felt could easili connect real life problem field work inform design futur access end user program environ data analysi target non expert"
  },
  {
    "doc_id": "10306472",
    "abstract_original": "Alzheimer's Detection is a dementia type affecting memory, thinking and behavior and the early detection is very critical due to the incurable nature of Alzheimer's. This literature proposes a method to contribute towards the early detection research of Alzheimer's disease. This paper introduces the fundamental theorem of Support Vector Machine algorithm and Convolution Neural Network classification ideas implemented on brain MRI images to early detect Alzheimer's disease. CNN and SVM are the types of research focuses of the classification and machine learning community. The paper uses Oasis data set consisting of cross-sectional and Longitudinal MRI data Kaggle dataset which contains brain MRI images. The paper compares SVM and the CNN model and compares the accuracy of the two algorithms. The literature can be very helpful in classification applications and studying the final prospects of SVM and CNN.",
    "abstract_processed": "alzheim detect dementia type affect memori think behavior earli detect critic due incur natur alzheim literatur propos method contribut toward earli detect research alzheim diseas paper introduc fundament theorem support vector machin algorithm convolut neural network classif idea implement brain mri imag earli detect alzheim diseas cnn svm type research focus classif machin learn commun paper use oasi data set consist cross section longitudin mri data kaggl dataset contain brain mri imag paper compar svm cnn model compar accuraci two algorithm literatur help classif applic studi final prospect svm cnn"
  },
  {
    "doc_id": "10306609",
    "abstract_original": "Sentiment analysis is a field within natural language processing that seeks to recognize and extract personal and emotional data from textual information, including feelings, viewpoints, and attitudes. Reviews have now turned into an indispensable data source for both consumers and businesses. Analyzing the sentiment of such reviews can offer valuable ideas into customers' likes, contentment, and discontentment. In recent times, Chat Generative Pre-trained Transformer (ChatGPT) has paved new paths in the area of Artificial Intelligence and Natural Language Processing. In our work, sentiment of people is analyzed through reviews taken from people of various age groups from different educational backgrounds to understand the efficiency of ChatGPT. A comparative analysis was carried out by using four different machine learning models and two hybrid models using SVM + Decision Tree and Random Forest + Logistic Regression. The survey also analyzed various effects of using ChatGPT and how it contributes in making people lethargic and decreases logical thinking ability and problem-solving skills.",
    "abstract_processed": "sentiment analysi field within natur languag process seek recogn extract person emot data textual inform includ feel viewpoint attitud review turn indispens data sourc consum busi analyz sentiment review offer valuabl idea custom like content discontent recent time chat gener pre train transform chatgpt pave new path area artifici intellig natur languag process work sentiment peopl analyz review taken peopl variou age group differ educ background understand effici chatgpt compar analysi carri use four differ machin learn model two hybrid model use svm decis tree random forest logist regress survey also analyz variou effect use chatgpt contribut make peopl letharg decreas logic think abil problem solv skill"
  },
  {
    "doc_id": "10308238",
    "abstract_original": "Facial expression is one of the most effective and universal ways to express emotions and intentions. It reflects what a person is thinking or experiencing. Thus, the expression recognition is one of the key aspects of understanding non-verbal communication and interpreting emotions in social interactions. Some emotions are very confusing, and separating the features between them becomes difficult because they share the same feature space. For example, the distinction between fear, anger, and disgust is confusing. This work tried to improve the model’s class-wise performance to detect each class correctly. A distinct combination of deep-learning models is used to calculate the performance of the model, such as ResNet, XceptionNet, DenseNet, etc. The datasets like Real-world Affective Faces Database (RAF-DB), Japanese Female Facial Expression (JAFFE) & Facial Expression Recognition 2013 Plus (FER+) are used to evaluate the model’s performance. The proposed model achieved better results and overcame the previous work’s limitations. CDE’s performance on RAF-DB and FER+ evaluations was significantly better than the current SOTA methods, with an increase in accuracy of 5.18% and 3.98%, respectively.",
    "abstract_processed": "facial express one effect univers way express emot intent reflect person think experienc thu express recognit one key aspect understand non verbal commun interpret emot social interact emot confus separ featur becom difficult share featur space exampl distinct fear anger disgust confus work tri improv model’ class wise perform detect class correctli distinct combin deep learn model use calcul perform model resnet xceptionnet densenet etc dataset like real world affect face databas raf db japanes femal facial express jaff facial express recognit plu fer use evalu model’ perform propos model achiev better result overcam previou work’ limit cde’ perform raf db fer evalu significantli better current sota method increas accuraci respect"
  },
  {
    "doc_id": "10309332",
    "abstract_original": "As child-robot interactions become more and more common in daily life environment, it is important to examine how robot’s errors influence children’s behavior. We explored how a robot’s unexpected behaviors affect child-robot interactions during two workshops on active reading: one in a modern art museum and one in a school. We observed the behavior and attitudes of 42 children from three age groups: 6-7 years, 8-10 years, and 10-12 years. Through our observations, we identified six different types of surprising robot behaviors: personality, movement malfunctions, inconsistent behavior, mispronunciation, delays, and freezing. Using a qualitative analysis, we examined how children responded to each type of behavior, and we observed similarities and differences between the age groups. Based on our findings, we propose guidelines for designing age-appropriate learning interactions with social robots.",
    "abstract_processed": "child robot interact becom common daili life environ import examin robot’ error influenc children’ behavior explor robot’ unexpect behavior affect child robot interact two workshop activ read one modern art museum one school observ behavior attitud children three age group year year year observ identifi six differ type surpris robot behavior person movement malfunct inconsist behavior mispronunci delay freez use qualit analysi examin children respond type behavior observ similar differ age group base find propos guidelin design age appropri learn interact social robot"
  },
  {
    "doc_id": "10309353",
    "abstract_original": "A robot can affect its social environment beyond the person who is interacting with it. Within this context, we believe it is important to explore Human-Robot Interactions (HRI) in complex social settings. We examine the effect of different robot shapes in a multi-person context during dance routines and observe how the design of the robot enhances the artistic process. We identify key factors through which human preferences are being shaped, within a novel third party setting human-robot-human interaction (HRHI).",
    "abstract_processed": "robot affect social environ beyond person interact within context believ import explor human robot interact hri complex social set examin effect differ robot shape multi person context danc routin observ design robot enhanc artist process identifi key factor human prefer shape within novel third parti set human robot human interact hrhi"
  },
  {
    "doc_id": "10315051",
    "abstract_original": "Scene graph generation (SGG) and human-object interaction (HOI) detection are two important visual tasks aiming at localising and recognising relationships between objects, and interactions between humans and objects, respectively. Prevailing works treat these tasks as distinct tasks, leading to the development of task-specific models tailored to individual datasets. However, we posit that the presence of visual relationships can furnish crucial contextual and intricate relational cues that significantly augment the inference of human-object interactions. This motivates us to think if there is a natural intrinsic relationship between the two tasks, where scene graphs can serve as a source for inferring human-object interactions. In light of this, we introduce SG2HOI+, a unified one-step model based on the Transformer architecture. Our approach employs two interactive hierarchical Transformers to seamlessly unify the tasks of SGG and HOI detection. Concretely, we initiate a relation Transformer tasked with generating relation triples from a suite of visual features. Subsequently, we employ another transformer-based decoder to predict human-object interactions based on the generated relation triples. A comprehensive series of experiments conducted across established benchmark datasets including Visual Genome, V-COCO, and HICO-DET demonstrates the compelling performance of our SG2HOI+ model in comparison to prevalent one-stage SGG models. Remarkably, our approach achieves competitive performance when compared to state-of-the-art HOI methods. Additionally, we observe that our SG2HOI+ jointly trained on both SGG and HOI tasks in an end-to-end manner yields substantial improvements for both tasks compared to individualized training paradigms.",
    "abstract_processed": "scene graph gener sgg human object interact hoi detect two import visual task aim localis recognis relationship object interact human object respect prevail work treat task distinct task lead develop task specif model tailor individu dataset howev posit presenc visual relationship furnish crucial contextu intric relat cue significantli augment infer human object interact motiv us think natur intrins relationship two task scene graph serv sourc infer human object interact light introduc sg hoi unifi one step model base transform architectur approach employ two interact hierarch transform seamlessli unifi task sgg hoi detect concret initi relat transform task gener relat tripl suit visual featur subsequ employ anoth transform base decod predict human object interact base gener relat tripl comprehens seri experi conduct across establish benchmark dataset includ visual genom v coco hico det demonstr compel perform sg hoi model comparison preval one stage sgg model remark approach achiev competit perform compar state art hoi method addit observ sg hoi jointli train sgg hoi task end end manner yield substanti improv task compar individu train paradigm"
  },
  {
    "doc_id": "10315697",
    "abstract_original": "Objective: The objective of this paper is to present preliminary work on the development of an EduChatBot tool and the measurement of the effects of its use aimed at providing effective feedback to programming course students. This bot, hereinafter referred to as tutorBot+, was constructed based on chatGPT3.5 and is tasked with assisting and providing timely positive feedback to students in computer science programming courses at UCSC. Methods/Analysis: The proposed method consists of four stages: (1) Immersion in the feedback and Large Language Models (LLMs) topic; (2) Development of tutorBot+ prototypes in both non-conversational and conversational versions; (3) Experiment design; and (4) Intervention and evaluation. The first stage involves a literature review on feedback and learning, the use of intelligent tutors in the educational context, as well as the topics of LLMs and chatGPT. The second and third stages detail the development of tutorBot+ in its two versions, and the final stage lays the foundation for a quasi-experimental study involving students in the curriculum activities of Programming Workshop and Database Workshop, focusing on learning outcomes related to the development of computational thinking skills, and facilitating the use and measurement of the tool’s effects. Findings: The preliminary results of this work are promising, as two functional prototypes of tutorBot+ have been developed for both the non-conversational and conversational versions. Additionally, there is ongoing exploration into the possibility of creating a domain-specific model based on pretrained models for programming, integrating tutorBot+ with other platforms, and designing an experiment to measure student performance, motivation, and the tool’s effectiveness.",
    "abstract_processed": "object object paper present preliminari work develop educhatbot tool measur effect use aim provid effect feedback program cours student bot hereinaft refer tutorbot construct base chatgpt task assist provid time posit feedback student comput scienc program cours ucsc method analysi propos method consist four stage immers feedback larg languag model llm topic develop tutorbot prototyp non convers convers version experi design intervent evalu first stage involv literatur review feedback learn use intellig tutor educ context well topic llm chatgpt second third stage detail develop tutorbot two version final stage lay foundat quasi experiment studi involv student curriculum activ program workshop databas workshop focus learn outcom relat develop comput think skill facilit use measur tool’ effect find preliminari result work promis two function prototyp tutorbot develop non convers convers version addit ongo explor possibl creat domain specif model base pretrain model program integr tutorbot platform design experi measur student perform motiv tool’ effect"
  },
  {
    "doc_id": "10315732",
    "abstract_original": "This paper proposes a method to grade programming exam questions automatically. Our motivation is that there are no robust and scalable automatic methods for the analysis of computational thinking from source code programmed by elementary-level students. The approach to this problem supports the improvement of PC development in primary and secondary school students. The validation of the method is performed through the assessment of the answers of primary school students to programming exercises using a programming language called LIE++. The method assesses student answers using several techniques such as the analysis of programming structures, code clones and the execution of code based on input and output values defined during the specification of the exercises. The use of these techniques provides specific scores to obtain a grade of the student’s answer. The source code analysis and scoring of exercise answers is carried out using high-performance computing for improving system response time. This research contributes a scalable method for the automatic evaluation of exams, which we expect to support the development of PC.",
    "abstract_processed": "paper propos method grade program exam question automat motiv robust scalabl automat method analysi comput think sourc code program elementari level student approach problem support improv pc develop primari secondari school student valid method perform assess answer primari school student program exercis use program languag call lie method assess student answer use sever techniqu analysi program structur code clone execut code base input output valu defin specif exercis use techniqu provid specif score obtain grade student’ answer sourc code analysi score exercis answer carri use high perform comput improv system respons time research contribut scalabl method automat evalu exam expect support develop pc"
  },
  {
    "doc_id": "10318237",
    "abstract_original": "The generalization ability of current intent recognition methods is insufficient, and the evaluation of confidence level of intent recognition is the key to its popularization and application in the high-reliability military and civilian fields. The spatiotemporal Knowledge Graph can uniformly represent and efficiently organize entities containing spatial location information and temporal information. Battlefield situational objectives and their relationships can be abstractly expressed as a triplet composed of two specific types of spatiotemporal entities and combat intent relationships. Using typical confrontation scenario data to train neural networks, and fusing the confidence levels of the entity and Knowledge Graph, the confidence level evaluation results of the intent triple facing the existing spatiotemporal knowledge base are calculated. The simulation test results show that the method can effectively evaluate the confidence level of intent recognition results, and the accuracy rate is improved by more than 9% compared with the KGTTM model. This method breaks the “closed” assumption of the Knowledge Graph update and completion algorithm from the level of algorithm thinking, and completes the last link of the popularization and application of intent recognition methods.",
    "abstract_processed": "gener abil current intent recognit method insuffici evalu confid level intent recognit key popular applic high reliabl militari civilian field spatiotempor knowledg graph uniformli repres effici organ entiti contain spatial locat inform tempor inform battlefield situat object relationship abstractli express triplet compos two specif type spatiotempor entiti combat intent relationship use typic confront scenario data train neural network fuse confid level entiti knowledg graph confid level evalu result intent tripl face exist spatiotempor knowledg base calcul simul test result show method effect evalu confid level intent recognit result accuraci rate improv compar kgttm model method break “closed” assumpt knowledg graph updat complet algorithm level algorithm think complet last link popular applic intent recognit method"
  },
  {
    "doc_id": "10319380",
    "abstract_original": "In this study, the specific absorption rate (SAR) and exposure index (EI) of access points (APs) and user equipment (UEs) in fourth-generation (4G) and fifth-generation (5G) wireless technologies are examined with regard to the effects of exposure to radiofrequency (RF) electromagnetic fields (EMF) radiation and the implications of their reduction. We characterize the EI using a classical mathematical method while considering the power density, the SAR, the electric field strength, and the tissue's density and conductivity. As such, a novel exposure-index open-loop power control algorithm is proposed to evaluate the realistic RF-EMF radiation exposure on human users from both the downlink (DL) and uplink (UL) communication devices. To solve an EI minimization problem using the open-loop power control algorithm, we formulate it in the form of a mixed-integer nonlinear programming (MINLP) problem. As the energy capacity (i.e., power density) in wireless networks determines the radiation exposure (SAR and EI), it minimizes the EI by controlling and managing the transmitted and received powers under the restrictions of Quality of Service (QoS), interference, and power, while ensuring the users' QoS requirements are met. Our proposed scheme is numerically compared to other heuristic algorithms and exposure limits established by the International Commission on Non-Ionizing Radiation Protection (ICNIRP) and other similar organizations. Lastly, we compare the emissions from 4G and 5G networks to the emissions from UL and DL transmissions. Our simulation findings indicate that our proposed technique is a good alternative. Our assessment, in terms of numerical results and evaluation, also verifies that the exposures are bearable, fall within the recommended limits, and are minimized without impairing the users' QoS.",
    "abstract_processed": "studi specif absorpt rate sar exposur index ei access point ap user equip ue fourth gener g fifth gener g wireless technolog examin regard effect exposur radiofrequ rf electromagnet field emf radiat implic reduct character ei use classic mathemat method consid power densiti sar electr field strength tissu densiti conduct novel exposur index open loop power control algorithm propos evalu realist rf emf radiat exposur human user downlink dl uplink ul commun devic solv ei minim problem use open loop power control algorithm formul form mix integ nonlinear program minlp problem energi capac e power densiti wireless network determin radiat exposur sar ei minim ei control manag transmit receiv power restrict qualiti servic qo interfer power ensur user qo requir met propos scheme numer compar heurist algorithm exposur limit establish intern commiss non ioniz radiat protect icnirp similar organ lastli compar emiss g g network emiss ul dl transmiss simul find indic propos techniqu good altern assess term numer result evalu also verifi exposur bearabl fall within recommend limit minim without impair user qo"
  },
  {
    "doc_id": "10320320",
    "abstract_original": "Recent research has shed light on integrating cutting-edge technologies in various organisations to support daily operations in the digital age. However, this implementation has resulted in undesirable consequences, notably contributing to global warming and climate change, primarily due to unchecked carbon emissions. Higher Educational Institutions are expected to lead by example in reducing global carbon emissions. Despite some institutions’ efforts in this regard, multiple studies suggest that progress could be expedited through digital technology, leaving room for improvement. Numerous Higher Educational Institutions still need sustainable practices within their building infrastructure. Hence, this research project was developed to create an intelligent model for monitoring the carbon footprint of buildings within Higher Educational Institutions. The study focused on the Bandung Institute of Technology facilities, which encountered similar challenges stemming from various aspects contributing to the overall carbon footprint. This research effectively managed energy consumption by implementing design thinking, encompassing electricity and water usage, and reducing emissions. Furthermore, the application of this model provided valuable insights into both current and projected energy consumption and emission production. It also assessed the sustainability status of these buildings and enhanced the efficiency of information dissemination in energy reporting processes. This, in turn, facilitated the implementation of proactive measures for emission management not only at the Bandung Institute of Technology but also in other Higher Educational Institution buildings sharing similar characteristics.",
    "abstract_processed": "recent research shed light integr cut edg technolog variou organis support daili oper digit age howev implement result undesir consequ notabl contribut global warm climat chang primarili due uncheck carbon emiss higher educ institut expect lead exampl reduc global carbon emiss despit institutions’ effort regard multipl studi suggest progress could expedit digit technolog leav room improv numer higher educ institut still need sustain practic within build infrastructur henc research project develop creat intellig model monitor carbon footprint build within higher educ institut studi focus bandung institut technolog facil encount similar challeng stem variou aspect contribut overal carbon footprint research effect manag energi consumpt implement design think encompass electr water usag reduc emiss furthermor applic model provid valuabl insight current project energi consumpt emiss product also assess sustain statu build enhanc effici inform dissemin energi report process turn facilit implement proactiv measur emiss manag bandung institut technolog also higher educ institut build share similar characterist"
  },
  {
    "doc_id": "10320351",
    "abstract_original": "Identifying defects at different scales is a challenge in industrial defect detection. To solve this problem, many multi-scale feature fusion networks have been proposed to improve multi-scale target detection accuracy by fusing fine-grained information from shallow networks and semantic information from deep networks. This approach requires the introduction of extraÂ parameters. Thinking from another perspective, can the accuracy of multi-scale target detection be improved by fusing the feature information under different receptive fields? For this purpose, we designed a three-layer network structure called Trident-LK Net. our model uses convolutional kernels of different sizes (31, 25, 1) in the feature extraction phase and establishes cross-fusion connections. This omits the feature fusion part and greatly reduces the network parameters while obtaining a good detection accuracy. Finally we perform experiments on the neu-det dataset and the gc10 dataset to verify the feasibility of our idea. While keeping the number of parameters to a minimum, our model achieves competitive detection results on the neu-det dataset (76.9% mAP) and optimal on the gc10 dataset (63.55% mAP). Our code will be publicly available at https://github.com/syyang2022/Trident-LK-Net.",
    "abstract_processed": "identifi defect differ scale challeng industri defect detect solv problem mani multi scale featur fusion network propos improv multi scale target detect accuraci fuse fine grain inform shallow network semant inform deep network approach requir introduct extraâ paramet think anoth perspect accuraci multi scale target detect improv fuse featur inform differ recept field purpos design three layer network structur call trident lk net model use convolut kernel differ size featur extract phase establish cross fusion connect omit featur fusion part greatli reduc network paramet obtain good detect accuraci final perform experi neu det dataset gc dataset verifi feasibl idea keep number paramet minimum model achiev competit detect result neu det dataset map optim gc dataset map code publicli avail http github com syyang trident lk net"
  },
  {
    "doc_id": "10323527",
    "abstract_original": "Dexterous robotic grasping gains great benefits from tactile sensation, but delicate object exploration by tactile information is challenged by difficulty in rich and efficient data production. In this letter, we propose a tactile-based in-hand object perception approach, empowered by a sim-to-real approach toward a data-efficient learning process. A high-fidelity tactile input, measured by a pair of vision-based tactile sensors, was represented as a point cloud facilitating dual functionality of object classification and the associated pose estimation. For the classification, we constructed PoinTacNet, a variation of PointNet to fit into tactile data processing. A reliable simulation methodology on tactile input was employed for the pretraining of the model, transferred to the fine-tuning process facing real tactile data. Taking inspiration from human behaviors, a re-grasping strategy was imparted by means of conditional accumulation of class likelihood distribution. The result of the framework facilitates a high object classification accuracy of 83.89$\\%$ on the ten objects from McMaster-Carr's CAD models, which is significantly improved by the re-grasping. In addition, a set of benchmarks displays the computational efficiency in the sim-to-real transfer. In line with the successful classification, the posture of in-hand objects is estimated using point cloud registration algorithms, achieving an average angular and translational RMSE of 5.03$^\\circ$ and 2.41 mm, respectively. The proposed approach has the potential to enable robots to attain human-like haptic exploration skills for perceiving unstructured environments.",
    "abstract_processed": "dexter robot grasp gain great benefit tactil sensat delic object explor tactil inform challeng difficulti rich effici data product letter propos tactil base hand object percept approach empow sim real approach toward data effici learn process high fidel tactil input measur pair vision base tactil sensor repres point cloud facilit dual function object classif associ pose estim classif construct pointacnet variat pointnet fit tactil data process reliabl simul methodolog tactil input employ pretrain model transfer fine tune process face real tactil data take inspir human behavior grasp strategi impart mean condit accumul class likelihood distribut result framework facilit high object classif accuraci \\ ten object mcmaster carr cad model significantli improv grasp addit set benchmark display comput effici sim real transfer line success classif postur hand object estim use point cloud registr algorithm achiev averag angular translat rmse \\circ mm respect propos approach potenti enabl robot attain human like haptic explor skill perceiv unstructur environ"
  },
  {
    "doc_id": "10323987",
    "abstract_original": "There has recently been considerable interest in automatic detection strategies for recognising application layer security threats such as Hypertext Transfer Protocol (HTTP) Slow Denial of-Service (Slow DoS) attacks in Internet of Things (IoT) networks. Most existing approaches however, fail to take cognisance of the substantial resource constraints imposed upon IoT environments, which limits the applicability and deployment of many Slow DoS detection mechanisms. This paper addresses this significant security threat for resource scarce IoT nodes and networks in proposing an accurate and computationally efficient approach to packet-based intrusion detection of HTTP Slow DoS activity. The paper both critically analyses and measures the impact of applying network attribute filtering and packet sampling to reduce the computational overheads on the resource constrained IoT Slow DoS detection node. The unique solution proposed uses a dataset synthesised from a live IoT environment comprising both legitimate and malicious network events in the form of legitimate HTTP traffic and Slow DoS attacks. Experimental results corroborate that combining filtering at the Border Router of only in-bound packets containing no TCP payload with a systematic packet sampling scheme at a sampling ratio of up to 1:64, the processing overheads on the detection node are significantly reduced. The novel contribution presented is a resource efficient solution, garnered by employing systematic sampling to seamlessly and accurately support selective attribute-based intrusion detection of HTTP Slow DoS attacks in IoT networks.",
    "abstract_processed": "recent consider interest automat detect strategi recognis applic layer secur threat hypertext transfer protocol http slow denial servic slow do attack internet thing iot network exist approach howev fail take cognis substanti resourc constraint impos upon iot environ limit applic deploy mani slow do detect mechan paper address signific secur threat resourc scarc iot node network propos accur comput effici approach packet base intrus detect http slow do activ paper critic analys measur impact appli network attribut filter packet sampl reduc comput overhead resourc constrain iot slow do detect node uniqu solut propos use dataset synthesis live iot environ compris legitim malici network event form legitim http traffic slow do attack experiment result corrobor combin filter border router bound packet contain tcp payload systemat packet sampl scheme sampl ratio process overhead detect node significantli reduc novel contribut present resourc effici solut garner employ systemat sampl seamlessli accur support select attribut base intrus detect http slow do attack iot network"
  },
  {
    "doc_id": "10324104",
    "abstract_original": "This research goes into the intricate interplay of linguistic and psychological aspects in Doris Lessing’s fiction by conducting a computational analysis of verba sentiendi, or verbs of thinking. Drawing on applied linguistics, computational analysis, text, and discourse inquiry, we unravel the portrayal of characters’ thoughts/mental events through three categories of verba sentiendi: Thoughts and Opinions, Senses and Perceptions, Feelings and Emotions. By quantitatively examining the frequency values and interpreting descriptive statistics data, we shed light on the psychological dimensions that underlie Lessing’s fictional tapestry. Using cutting-edge tools such as Voyant and R/R Studio, we process vast volumes of textual data to quantify the prevalence of verba sentiendi across different categories, offering insights into their quantitative significance. Descriptive statistics provide further nuance by revealing central tendencies, variations, and quartiles within the three main categories under study.",
    "abstract_processed": "research goe intric interplay linguist psycholog aspect dori lessing’ fiction conduct comput analysi verba sentiendi verb think draw appli linguist comput analysi text discours inquiri unravel portray characters’ thought mental event three categori verba sentiendi thought opinion sens percept feel emot quantit examin frequenc valu interpret descript statist data shed light psycholog dimens underli lessing’ fiction tapestri use cut edg tool voyant r r studio process vast volum textual data quantifi preval verba sentiendi across differ categori offer insight quantit signific descript statist provid nuanc reveal central tendenc variat quartil within three main categori studi"
  },
  {
    "doc_id": "10325513",
    "abstract_original": "The computing world is rapidly evolving and advancing, with new ground-breaking technologies emerging. Quantum Computing and Quantum Machine Learning have opened up new possibilities, providing unprecedented computational power and problem-solving capabilities while offering a deeper understanding of complex systems. Our research proposes new variational methods based on a deep learning system based on an optical quantum neural network applied to Machine Learning models for point classification. As a case study, we considered the binary classification of points belonging to a certain geometric pattern (the Two-Moons Classification problem) on a plane. We think it is reasonable to expect benefits from using hybrid deep learning systems (classical + quantum), not just in terms of accelerating computation but also in understanding the underlying phenomena and mechanisms. This will result in the development of new machine-learning paradigms and a significant advancement in the field of quantum computation. The selected dataset is a set of 2D points creating two interleaved semicircles and is based on a 2D binary classification generator, which aids in evaluating the performance of particular methods. The two coordinates of each unique point,  $x_{1}$  and  $x_{2}$ , serve as the features since they present two disparate data sets in a two-dimensional representation space. The goal was to create a quantum deep neural network that could recognise and categorise points accurately with the fewest trainable parameters possible.",
    "abstract_processed": "comput world rapidli evolv advanc new ground break technolog emerg quantum comput quantum machin learn open new possibl provid unpreced comput power problem solv capabl offer deeper understand complex system research propos new variat method base deep learn system base optic quantum neural network appli machin learn model point classif case studi consid binari classif point belong certain geometr pattern two moon classif problem plane think reason expect benefit use hybrid deep learn system classic quantum term acceler comput also understand underli phenomena mechan result develop new machin learn paradigm signific advanc field quantum comput select dataset set point creat two interleav semicircl base binari classif gener aid evalu perform particular method two coordin uniqu point x x serv featur sinc present two dispar data set two dimension represent space goal creat quantum deep neural network could recognis categoris point accur fewest trainabl paramet possibl"
  },
  {
    "doc_id": "10325927",
    "abstract_original": "Methods of data mining are developed for many scientific areas and therefore contain different patter of the specifics of these disciplines. Moreover, these methods are currently widely used in different industry areas. The data mining algorithms can generate different solutions for the same data, which motivates scientists to improve it. The main goal of mining methods is to search for existing structures, patterns, and features in the collected data. Historical data from various sources make it possible to model complex processes in energy generation in renewable energy sources such as solar helio collectors and biogas plants, automate the process of interpreting geophysical data, and assess soil salinity using remote sensing data.",
    "abstract_processed": "method data mine develop mani scientif area therefor contain differ patter specif disciplin moreov method current wide use differ industri area data mine algorithm gener differ solut data motiv scientist improv main goal mine method search exist structur pattern featur collect data histor data variou sourc make possibl model complex process energi gener renew energi sourc solar helio collector bioga plant autom process interpret geophys data assess soil salin use remot sens data"
  },
  {
    "doc_id": "10326311",
    "abstract_original": "Lately, deep learning has become increasingly popular in resolving issues across multiple domains, including medical image analysis. This research introduces a process based on deep convolutional neural networks to diagnose Alzheimer's disease and its various stages by utilizing magnetic resonance imaging (MRI) scans. Identifying Alzheimer's disease (AD) in elderly individuals can be quite difficult. This is because it harms the brain cells related to memory and thinking abilities, and it's hard to tell apart from normal brain patterns in scans. Detecting it needs a special way to represent features for sorting it out. Deep learning methods can acquire such representations from the MRI data. In this paper, five different transfer learning models are trained in 15 binary classifiers, each of them can classify two of Alzheimer's disease, Mild Cognitive Impairment (MCI), and Cognitively Normal (CN) classes. This method finds the best transfer learning model for classifying each binary comparison. The proposed technique results in best accuracy of 92% for the AD vs. CN classifier, 94% for the AD vs. MCI classifier, and 72% for the MCI vs. CN classifier, which shows the effectiveness of transfer learning in distinguishing the AD vs. CN and the AD vs. MCI cases.",
    "abstract_processed": "late deep learn becom increasingli popular resolv issu across multipl domain includ medic imag analysi research introduc process base deep convolut neural network diagnos alzheim diseas variou stage util magnet reson imag mri scan identifi alzheim diseas ad elderli individu quit difficult harm brain cell relat memori think abil hard tell apart normal brain pattern scan detect need special way repres featur sort deep learn method acquir represent mri data paper five differ transfer learn model train binari classifi classifi two alzheim diseas mild cognit impair mci cognit normal cn class method find best transfer learn model classifi binari comparison propos techniqu result best accuraci ad vs cn classifi ad vs mci classifi mci vs cn classifi show effect transfer learn distinguish ad vs cn ad vs mci case"
  },
  {
    "doc_id": "10327734",
    "abstract_original": "Computational thinking is one barrier to enculturating as a professional engineer. We created the Engineering Computational Thinking Diagnostic (ECTD) as an instructional tool that can identify at-risk first-year engineering students. The purpose of this study is to provide construct validity, internal consistency reliability, item characteristics, and criterion validity evidence for this diagnostic. From fall 2020 to fall 2021, 469 students from three institutions in the United States took the diagnostic. The data from 152 students at one institution was used to provide evidence of predictive validity. Exploratory and confirmatory factor analyses resulted in 20 items loading onto one factor in a good model fit range, with the internal consistency reliability coefficient, Cronbach  $\\alpha $  of 0.86. From item analyses based on classical test theory, the diagnostic items on average tended to be slightly easy but had sufficient discrimination power. The correlation matrix for criterion validity evidence indicated that the diagnostic functions well to differentiate students’ computational thinking ability by prior computer science course experience as well as by first-generation status. Predictive validity evidence from regression analyses revealed the statistically significant effect of students’ diagnostic scores assessed at the beginning of the first semester on predicting their end of semester course grades. The ECTD can have a broad impact because it provides a tool to gauge the entry-level skills of students, enabling early curriculum interventions to help retention and persistence to graduation. We make the case that the ECTD could contribute to the development of a more diverse workforce in engineering.",
    "abstract_processed": "comput think one barrier encultur profession engin creat engin comput think diagnost ectd instruct tool identifi risk first year engin student purpos studi provid construct valid intern consist reliabl item characterist criterion valid evid diagnost fall fall student three institut unit state took diagnost data student one institut use provid evid predict valid exploratori confirmatori factor analys result item load onto one factor good model fit rang intern consist reliabl coeffici cronbach \\alpha item analys base classic test theori diagnost item averag tend slightli easi suffici discrimin power correl matrix criterion valid evid indic diagnost function well differenti students’ comput think abil prior comput scienc cours experi well first gener statu predict valid evid regress analys reveal statist signific effect students’ diagnost score assess begin first semest predict end semest cours grade ectd broad impact provid tool gaug entri level skill student enabl earli curriculum intervent help retent persist graduat make case ectd could contribut develop divers workforc engin"
  },
  {
    "doc_id": "10329809",
    "abstract_original": "The article refers to interdisciplinary scientific research in philosophy, information theory and the theory of algorithms. This article presents the results of theoretical studies on the formalization of human intellectual activity in relation to the field of cognitive sciences. The subject of the study is the concept of sense. The relevance of the study is conditioned by the development of artificial intelligence, in which the category of sense plays one of the leading roles. For humans, the concept of sense is relevant, both from a world outlook point of view and from the standpoint of cognitive science. However, the problem lies in the fact that sense is an axiomatic concept and therefore is difficult to formalize. There are various formulations of the sense at a qualitative level, but to solve practical problems in the field of cognitive science, a quantitative definition is required, that is, a description of the sense from a mathematical standpoint. The purpose of the study is to mathematically substantiate the concept of sense using the theory of algorithms and, as a consequence, to prove the possibility of calculating the sense. This paper uses the philosophical concept of the relationship of participation (author S. E. Yachin) and the Kolmogorov Complexity of Algorithms (author A. N. Kolmogorov). The principle of relativization, laid down in the formulation of the relationship of participation, served as the foundation for the development of an algorithmic approach to the calculation of sense. At a hypothetical level, an assumption is made that the additive constant accompanying the algorithmic calculations of information can serve as a measure of the amount of sense. To confirm the proposed hypothesis, a theorem on the computability of sense has been formulated and proved. The results obtained may be of interest to researchers and developers of artificial intelligence and other areas of cognitive science.",
    "abstract_processed": "articl refer interdisciplinari scientif research philosophi inform theori theori algorithm articl present result theoret studi formal human intellectu activ relat field cognit scienc subject studi concept sens relev studi condit develop artifici intellig categori sens play one lead role human concept sens relev world outlook point view standpoint cognit scienc howev problem lie fact sens axiomat concept therefor difficult formal variou formul sens qualit level solv practic problem field cognit scienc quantit definit requir descript sens mathemat standpoint purpos studi mathemat substanti concept sens use theori algorithm consequ prove possibl calcul sens paper use philosoph concept relationship particip author e yachin kolmogorov complex algorithm author n kolmogorov principl relativ laid formul relationship particip serv foundat develop algorithm approach calcul sens hypothet level assumpt made addit constant accompani algorithm calcul inform serv measur amount sens confirm propos hypothesi theorem comput sens formul prove result obtain may interest research develop artifici intellig area cognit scienc"
  },
  {
    "doc_id": "10329827",
    "abstract_original": "In the course of creating and analyzing music content, artificial intelligence systems are widely used, and according to the forecasts of analysts, their use in the field of music will grow steadily. Modern artificial intelligence systems successfully solve problems that cause difficulties for humans. However, these systems lack the ability to create and evaluate the semantics of musical works the same way as humans do. The problem of creating musical artificial intelligence with the creative abilities of the human mind is one of the most topical and complex problems in the music industry. The solution to this problem in the first place lies in studying and understanding the essence of the term “Musical Sense”. The purpose of the study is to develop a concept for the probabilistic assessment of the musical texts' semantics based on the concepts of information theory and information technologies. To achieve the goal, a convergent approach to the study of the problem of musical meaning, proposed by Professor A. B. Kayak, was used. As a result of the completed study, the main conceptual provisions of the theory of probabilistic evaluation of musical senses have been developed. The article is of a theoretical nature. However, the materials of the article may be of practical interest for researchers of the problem of sense and developers of artificial intelligence in the music industry.",
    "abstract_processed": "cours creat analyz music content artifici intellig system wide use accord forecast analyst use field music grow steadili modern artifici intellig system success solv problem caus difficulti human howev system lack abil creat evalu semant music work way human problem creat music artifici intellig creativ abil human mind one topic complex problem music industri solut problem first place lie studi understand essenc term “music sense” purpos studi develop concept probabilist assess music text semant base concept inform theori inform technolog achiev goal converg approach studi problem music mean propos professor b kayak use result complet studi main conceptu provis theori probabilist evalu music sens develop articl theoret natur howev materi articl may practic interest research problem sens develop artifici intellig music industri"
  },
  {
    "doc_id": "10330580",
    "abstract_original": "Entering the 5G era, the mobile network operators (MNO) are facing greater challenges in providing services cost effectively than any other previous generations. The potential solutions to this are lying on the emerging trend of deep convergence of information technology (IT), communication technology (CT) and data technology (DT). In particular, the O-RAN technology, the representation of such ICDT convergence and proposed by the O-RAN ALLIANCE in 2018, is transforming Radio Access Networks towards a new paradigm featuring openness, cloudification and intelligence. O-RAN has gained huge attention from both industry and academia since its inception. In this paper, we presented the recent endeavors from China Mobile, including our deployment scenarios, various test results from open fronthaul, cloud platform to the intelligent controller. Our rich and comprehensive tests have demonstrated the viability and superiority of current O-RAN technologies. Furthermore, we also provide our deep thinking on the O-RAN future evolution in order to better serve the emerging applications such as Metaverse, cloud extended-reality (XR), extensive enterprise private 5G verticals and so on.",
    "abstract_processed": "enter g era mobil network oper mno face greater challeng provid servic cost effect previou gener potenti solut lie emerg trend deep converg inform technolog commun technolog ct data technolog dt particular ran technolog represent icdt converg propos ran allianc transform radio access network toward new paradigm featur open cloudif intellig ran gain huge attent industri academia sinc incept paper present recent endeavor china mobil includ deploy scenario variou test result open fronthaul cloud platform intellig control rich comprehens test demonstr viabil superior current ran technolog furthermor also provid deep think ran futur evolut order better serv emerg applic metavers cloud extend realiti xr extens enterpris privat g vertic"
  },
  {
    "doc_id": "10331169",
    "abstract_original": "The development of science in the field of technology has accelerated due to the global need for society 5.0 which emphasizes creativity, critical thinking, communication, and collaboration to solve existing problems. One of its applications is to collaborate to create a smart robot using computer vision that can recognize a person's face and verify its authenticity. face recognition uses the identification and classification of faces by comparing matrix values between models and new inputs. Face liveness detection on the robot uses the mediapipe and the CNN algorithm. Facial recognition results get an accuracy value of 92% with an optimal distance of 100 cm.",
    "abstract_processed": "develop scienc field technolog acceler due global need societi emphas creativ critic think commun collabor solv exist problem one applic collabor creat smart robot use comput vision recogn person face verifi authent face recognit use identif classif face compar matrix valu model new input face live detect robot use mediapip cnn algorithm facial recognit result get accuraci valu optim distanc cm"
  },
  {
    "doc_id": "10332733",
    "abstract_original": "Cultivating students’ ability to use emerging technologies for innovation is important for the reform of new business education. Technological change needs the thinking revolution essentially so the big data system is of great significance for the construction of talent training programs, implementation of competency requirements, and curriculum teaching design. This study was carried out to identify the main enablers of the big data computation (BTC) in improving the innovation capability of students majoring in business and developing a model based on the contextual relationship among the identified enablers. Initially, a systematic literature review was conducted to identify the enablers of BTC. Then, total interpretive structural modeling (TISM) was used to evolve mutual relationships among the identified 17 enablers for developing a hierarchical model. Five key driving enablers, namely data consciousness, system thinking, statistical thinking, model thinking, and analytical thinking were identified as main enablers. Image thinking played an important role in the process of data analysis and application. Suggestions were made to cultivate the student’s BTC from the following three aspects: adding system science courses in the big data specialty, increasing training opportunities for students in using tools and methods of big data management, and improving students' data literacy.",
    "abstract_processed": "cultiv students’ abil use emerg technolog innov import reform new busi educ technolog chang need think revolut essenti big data system great signific construct talent train program implement compet requir curriculum teach design studi carri identifi main enabl big data comput btc improv innov capabl student major busi develop model base contextu relationship among identifi enabl initi systemat literatur review conduct identifi enabl btc total interpret structur model tism use evolv mutual relationship among identifi enabl develop hierarch model five key drive enabl name data conscious system think statist think model think analyt think identifi main enabl imag think play import role process data analysi applic suggest made cultiv student’ btc follow three aspect ad system scienc cours big data specialti increas train opportun student use tool method big data manag improv student data literaci"
  },
  {
    "doc_id": "10332926",
    "abstract_original": "Educational Robotics provides a dynamic and effective platform for fostering diverse skills and competencies. In this context, this paper explores creating and implementing a robotics club in a high school. The proposed methodology emphasizes the educational tripod: teaching, research, and extension. Therefore, the paper outlines the club’s conception, the sources of inspiration, and the achieved outcomes within the school and local community. It also highlights the activities and small projects developed by the students and the active participation of the club members in the Brazilian National Robotics Olympics. Furthermore, through student reports and an internal survey, the paper emphasizes the remarkable development of desired competencies, including creativity, teamwork, problem-solving, and computational thinking.",
    "abstract_processed": "educ robot provid dynam effect platform foster divers skill compet context paper explor creat implement robot club high school propos methodolog emphas educ tripod teach research extens therefor paper outlin club’ concept sourc inspir achiev outcom within school local commun also highlight activ small project develop student activ particip club member brazilian nation robot olymp furthermor student report intern survey paper emphas remark develop desir compet includ creativ teamwork problem solv comput think"
  },
  {
    "doc_id": "10332974",
    "abstract_original": "This article describes the experience of an Intro-duction to Programming and Robotics course offered to the community since 2016 for elementary school students with no prior exposure to programming. The objective of the course is to foster logical and computational reasoning and creativity and attract potential talents to the field of computer science. The course was designed to be a blended methodology aimed at developing active methodologies such as flipped classrooms, maker culture, and gamification from a Freirean perspective. It seeks to promote critical thinking, student empowerment, and meaningful learning experiences. The achieved results of the course encompass student education, skill development, scientific dissemination, and integration between the school and the community.",
    "abstract_processed": "articl describ experi intro duction program robot cours offer commun sinc elementari school student prior exposur program object cours foster logic comput reason creativ attract potenti talent field comput scienc cours design blend methodolog aim develop activ methodolog flip classroom maker cultur gamif freirean perspect seek promot critic think student empower meaning learn experi achiev result cours encompass student educ skill develop scientif dissemin integr school commun"
  },
  {
    "doc_id": "10332983",
    "abstract_original": "Educational robotics is a practice that has been disseminated in Brazil and in the world, allowing the inclusion of technology in the school environment through stimulating pedagogical activities for students, making them practice teamwork, fine motor coordination, and computational thinking, among other benefits. For the educational robotics classes to be executed in the most effective way, the teacher must be trained to use this tool, and from there propose and/or execute classes that use the technology to help in the teaching of curricular subjects in basic education. However, many teachers do not realize what can be possible with robotics in the classroom, and this often causes them not to choose to learn more about this technology. In this work, we developed a web system called Repo-Educ in which a teacher can access information about robotics lessons created by other teachers, generating ideas about how to apply robotics in their classroom. Using this system, it is possible to transform robotics education by combining knowledge. Even teachers who have never had contact with robotics can start using this technology in the classroom by replicating lessons that are proven to work by other teachers. The system is in the final stages of development to be made available to the educational robotics community.",
    "abstract_processed": "educ robot practic dissemin brazil world allow inclus technolog school environ stimul pedagog activ student make practic teamwork fine motor coordin comput think among benefit educ robot class execut effect way teacher must train use tool propos execut class use technolog help teach curricular subject basic educ howev mani teacher realiz possibl robot classroom often caus choos learn technolog work develop web system call repo educ teacher access inform robot lesson creat teacher gener idea appli robot classroom use system possibl transform robot educ combin knowledg even teacher never contact robot start use technolog classroom replic lesson proven work teacher system final stage develop made avail educ robot commun"
  },
  {
    "doc_id": "10335310",
    "abstract_original": "This article delves into the theory of Generative art has emerged as a prominent form of digital creative expression, and a thorough understanding of its creative trajectory within the framework of complex systems is crucial. This paper delves into the creative path of generative art by examining its definition, motivation, and positioning within complex scientific systems. It investigates generative art as a complex scientific system, focusing on its characteristics of high order, high disorder, and complexity. Notably, the study introduces fractals in complex systems, living systems, and neural networks as influential factors in generative art production. Through this comprehensive analysis, the paper unveils the distinctive key features that differentiate generative art from other creative practices. Furthermore, the article explores the future potential and development of generative art, emphasizing its promising prospects for growth and progress. By presenting these insights, this study contributes to a deeper understanding of generative art's evolutionary path and its unique position in the realm of creative expression.",
    "abstract_processed": "articl delv theori gener art emerg promin form digit creativ express thorough understand creativ trajectori within framework complex system crucial paper delv creativ path gener art examin definit motiv posit within complex scientif system investig gener art complex scientif system focus characterist high order high disord complex notabl studi introduc fractal complex system live system neural network influenti factor gener art product comprehens analysi paper unveil distinct key featur differenti gener art creativ practic furthermor articl explor futur potenti develop gener art emphas promis prospect growth progress present insight studi contribut deeper understand gener art evolutionari path uniqu posit realm creativ express"
  },
  {
    "doc_id": "10335478",
    "abstract_original": "The aim of this paper is to understand the human mind functions such that we can simulate them into a computational model for making cognitive systems more intelligent. We then present this model with formulae using a top-down approach. We propose that the human thought process, which is the fundamental unit for the human mind and all the different emotions coming from it, can be implemented as a mathematical formula to a reasonable extent. Furthermore, we argue that our model has the ability to derive mind functions such as dreams and thinking. The model utilizes a top-down approach for understanding the factors involved in the thought process while explaining the factors involved. The authors are intending to make continuous improvements in the formulae as more scientific advances happen in the understanding of the human cognitive functions.",
    "abstract_processed": "aim paper understand human mind function simul comput model make cognit system intellig present model formula use top approach propos human thought process fundament unit human mind differ emot come implement mathemat formula reason extent furthermor argu model abil deriv mind function dream think model util top approach understand factor involv thought process explain factor involv author intend make continu improv formula scientif advanc happen understand human cognit function"
  },
  {
    "doc_id": "10335814",
    "abstract_original": "Collaboration performance is often enriched by the interaction of a diversity of personalities and opinions in a team. There is little research on discussion-assistance systems to monitor and control the state of diversity and cohesion of opinions. This study proposes a system that guides participants to concentrate on differences in their opinions and to reach a decision with more satisfied agreement by encouraging cognitive empathy (i.e., understanding others’ thoughts). The system evaluates the similarity of opinions among participants, then it provides feedback on the similarity score to them. Receiving the feedback, participants can determine the necessity of the exchange of opinions to converge the discussion (not debate). We prepared a team-building task in which two participants alternately presented their opinions based on individual thoughts and emotions; then, they checked the similarity between their opinions and discussed cooperatively them to reach an agreement. We show that the feedback of opinion similarity score increases cognitive empathy, which is also objectively validated by observation of brain activities. Particularly, we observed the strong phase-synchronicity of theta wave between the discussion participants’ left lateral prefrontal cortexes. Satisfaction of participants with the result of the discussion marginally increased and the similarity score of their opinions significantly increased along with the task process. In conclusion, the feedback system during the team task promoted positively the consideration of their own and their partner’s emotions and thoughts. This study also contributes to hyperscanning studies in real-life situations because it used a simple electroencephalographic device and experimental design in communication.",
    "abstract_processed": "collabor perform often enrich interact divers person opinion team littl research discuss assist system monitor control state divers cohes opinion studi propos system guid particip concentr differ opinion reach decis satisfi agreement encourag cognit empathi e understand others’ thought system evalu similar opinion among particip provid feedback similar score receiv feedback particip determin necess exchang opinion converg discuss debat prepar team build task two particip altern present opinion base individu thought emot check similar opinion discuss cooper reach agreement show feedback opinion similar score increas cognit empathi also object valid observ brain activ particularli observ strong phase synchron theta wave discuss participants’ left later prefront cortex satisfact particip result discuss margin increas similar score opinion significantli increas along task process conclus feedback system team task promot posit consider partner’ emot thought studi also contribut hyperscan studi real life situat use simpl electroencephalograph devic experiment design commun"
  },
  {
    "doc_id": "10337301",
    "abstract_original": "This tutorial provides an overview of a human-centered design approach called a design sprint. The main structure of the tutorial includes a review of the literature and motivation for conducting a design sprint, the step-by-step process of a traditional design sprint and alternative approaches relevant to research environments. The tutorial will incorporate tools for planning and preparing the research environment and research team, interactive technological tools for collaboration, guided instruction on conducting a data analysis, and research-related challenges and solutions to be considered. We use two examples from the literature including one from our team’s design of a software to facilitate the review of genetic test offerings, and one of others that designed a diabetes patient portal. This tutorial is intended for participants interested in human-centered design and learning how to utilize state-of-the-art tools and resources to apply a modified design sprint methodology in a research setting.",
    "abstract_processed": "tutori provid overview human center design approach call design sprint main structur tutori includ review literatur motiv conduct design sprint step step process tradit design sprint altern approach relev research environ tutori incorpor tool plan prepar research environ research team interact technolog tool collabor guid instruct conduct data analysi research relat challeng solut consid use two exampl literatur includ one team’ design softwar facilit review genet test offer one other design diabet patient portal tutori intend particip interest human center design learn util state art tool resourc appli modifi design sprint methodolog research set"
  },
  {
    "doc_id": "10337481",
    "abstract_original": "The results of enormous climate change and other industrial carbon emissions have been driven by the rise of nonrenewable traditional energy sources. The scientific community is looking at unconventional renewable techniques that can harvest energy in the external atmosphere. This research article provides a critical analysis of the growth in the field of piezoelectric energy harvesting. Recent advances in bio-inspired piezo-smart equipment are critically analyzed. A comprehensive overview of harvesting power from mechanical vibrations and its renewable sources, such as human body movements, flowing fluid, and circuitry arrangements of structures with piezoelectric materials have been discussed. Capturing and converting mechanical energy into useful electric power is the easiest and most prevalent way to harness the massive amounts of ambient energy around us. With the help of piezoelectric materials, vibrations induced by mechanical sources can convert into electrical energy. Various industries, including transportation, construction, aeronautical, smart systems, micro-fluids, biomedical devices, and implantable electronics, employ piezoelectric energy generating at the micro level. Piezoelectric energy generating technique’s applications along with their achievements, and future possibilities are critically analyzed. This overview concisely presents the extensive range of piezoelectric materials for wireless electronic devices that use eco-friendly, renewable, and sustainable energy harvesting sources.",
    "abstract_processed": "result enorm climat chang industri carbon emiss driven rise nonrenew tradit energi sourc scientif commun look unconvent renew techniqu harvest energi extern atmospher research articl provid critic analysi growth field piezoelectr energi harvest recent advanc bio inspir piezo smart equip critic analyz comprehens overview harvest power mechan vibrat renew sourc human bodi movement flow fluid circuitri arrang structur piezoelectr materi discuss captur convert mechan energi use electr power easiest preval way har massiv amount ambient energi around us help piezoelectr materi vibrat induc mechan sourc convert electr energi variou industri includ transport construct aeronaut smart system micro fluid biomed devic implant electron employ piezoelectr energi gener micro level piezoelectr energi gener technique’ applic along achiev futur possibl critic analyz overview concis present extens rang piezoelectr materi wireless electron devic use eco friendli renew sustain energi harvest sourc"
  },
  {
    "doc_id": "10337505",
    "abstract_original": "We discuss the design and implementation of multi-faceted interactive intelligence instruction for exhibition design courses. Our intent is threefold: 1) adapting the new humanities and social sciences to the undergraduate training requirements of applied higher education institutions. 2) combining course characteristics, teaching processes and teaching objectives, and 3) developing a smart teaching model for the curriculum that use “Chaoxing Xuexitong” intelligent terminals. Because successful implementation requires both leadership from teachers and a collaborative effort from students, we review the development process of online teaching to identify the advantages of online teaching platform construction. We also consider how teaching organization and information, and the design perspective can be optimized using the Chaoxing classroom teaching platform. This mode of delivery yields benefits via the optimization of teaching effectiveness while providing a model that can be used to explore intelligent teaching of information technology in exhibition design courses.",
    "abstract_processed": "discuss design implement multi facet interact intellig instruct exhibit design cours intent threefold adapt new human social scienc undergradu train requir appli higher educ institut combin cours characterist teach process teach object develop smart teach model curriculum use “chaox xuexitong” intellig termin success implement requir leadership teacher collabor effort student review develop process onlin teach identifi advantag onlin teach platform construct also consid teach organ inform design perspect optim use chaox classroom teach platform mode deliveri yield benefit via optim teach effect provid model use explor intellig teach inform technolog exhibit design cours"
  },
  {
    "doc_id": "10337513",
    "abstract_original": "The national colleges and universities’ large-scale application of online education during the Covid-19. Academic dishonesty frequently occurs, leading to society’s attention to the problem of academic honesty. As a vital reserve force of academic talents, undergraduate students should pay more attention to their academic honesty. Nowadays, undergraduate students’ academic consciousness is weak, and their academic dishonesty is gradually showing new characteristics and problems under the large-scale application of online education. In the face of increasingly frequent and diverse academic dishonesty problems, various academic misconduct detection systems supported by computer technology have played a positive role in solving the problem of academic dishonesty among undergraduate students. We must study and think about improving undergraduate students’ academic honesty education with the development of online education combined with computer technology. This paper probes into the problems existing in undergraduate students’ academic honesty education under online education. Then it constructs the academic honesty education model from undergraduate students themselves, legal system, academic honesty training, and academic honesty supervision management mechanism, four aspects of standardizing undergraduate students’ academic behavior and forming an excellent academic moral atmosphere in colleges and universities.",
    "abstract_processed": "nation colleg universities’ larg scale applic onlin educ covid academ dishonesti frequent occur lead society’ attent problem academ honesti vital reserv forc academ talent undergradu student pay attent academ honesti nowaday undergradu students’ academ conscious weak academ dishonesti gradual show new characterist problem larg scale applic onlin educ face increasingli frequent divers academ dishonesti problem variou academ misconduct detect system support comput technolog play posit role solv problem academ dishonesti among undergradu student must studi think improv undergradu students’ academ honesti educ develop onlin educ combin comput technolog paper probe problem exist undergradu students’ academ honesti educ onlin educ construct academ honesti educ model undergradu student legal system academ honesti train academ honesti supervis manag mechan four aspect standard undergradu students’ academ behavior form excel academ moral atmospher colleg univers"
  },
  {
    "doc_id": "10340897",
    "abstract_original": "Dementia is the main cause of disability in elderly populations. It has been shown that the risk factors of dementia are a mixture of pathological, lifestyle and heritable factors, with some of those being provably modifiable. Early diagnosis of dementia and approaches to slow down its evolution are currently the most prominent management methodologies due to lack of a cure. For that reason, a plethora of home-based assistive technologies for dementia management do exist, with most of them focusing on the improvement of memory and thinking. The main objective of LETHE is prevention in the whole spectrum of cognitive decline in the elderly population at risk reaching from asymptomatic to subjective or mild cognitive impairment to prodromal Dementia. LETHE will provide a Big Data collection platform and analysis system, that will allow prevention, personalized risk detection and intervention on cognitive decline. Through the subsequent 2-year clinical trial, the LETHE system, as well as the respective knowledge gained will be evaluated and validated. The scope of the current paper is to introduce the LETHE study and its respective novel platform as a holistic approach to multidomain lifestyle intervention trial studies. The present work depicts the architectural perspective and extends beyond state-of-the-art guidelines and approaches to health management systems and cloud platform development.Clinical Relevance — Patient Management Systems as well as lifestyle management platforms have significant clinical relevance as they allow for remote and continuous monitoring of patients' health status. LETHE aims to improve patient outcomes by providing predictive models for cognitive decline and patient adherence to the multimodal lifestyle intervention, enabling prompt and appropriate medical decisions.",
    "abstract_processed": "dementia main caus disabl elderli popul shown risk factor dementia mixtur patholog lifestyl herit factor provabl modifi earli diagnosi dementia approach slow evolut current promin manag methodolog due lack cure reason plethora home base assist technolog dementia manag exist focus improv memori think main object leth prevent whole spectrum cognit declin elderli popul risk reach asymptomat subject mild cognit impair prodrom dementia leth provid big data collect platform analysi system allow prevent person risk detect intervent cognit declin subsequ year clinic trial leth system well respect knowledg gain evalu valid scope current paper introduc leth studi respect novel platform holist approach multidomain lifestyl intervent trial studi present work depict architectur perspect extend beyond state art guidelin approach health manag system cloud platform develop clinic relev — patient manag system well lifestyl manag platform signific clinic relev allow remot continu monitor patient health statu leth aim improv patient outcom provid predict model cognit declin patient adher multimod lifestyl intervent enabl prompt appropri medic decis"
  },
  {
    "doc_id": "10341230",
    "abstract_original": "Planarity of crisp graphs is a well-established field, whereas planarity within a fuzzy framework has seen recent development and extensive exploration. In an  $m$ -polar fuzzy graph ( $m$ PFG), each node and edge is associated with  $m$ -components, connected through minimal relationships. However, if one desires to incorporate maximum, average, or other intermediate relationships between nodes and edges, the  $m$ PFG concept becomes inadequate as in the  $m$ -polar fuzzy model, only minimum relation is considered. To address this limitation, a generalized model of  $m$ PFG is introduced in this article, allowing for a broader range of relationships to be considered simultaneously. This paper also discusses the properties of generalized  $m$ -polar fuzzy environments and generalized  $m$ -polar fuzzy graphs ( $\\text{G}m$ PFGs), highlighting their isomorphism. Several significant findings and insights are presented in this paper. The article delves into the properties and characteristics of generalized  $m$ -polar fuzzy planar graphs ( $\\text{G}m$ PFPGs) and explores various intriguing aspects related to them. Additionally, a novel concept of a generalized  $m$ -polar fuzzy dual graph ( $\\text{G}m$ PFDG) is introduced, derived from  $\\text{G}m$ PFPGs. The paper establishes a relationship between the dual of a  $\\text{G}m$ PFG and  $\\text{G}m$ PFG, examining their properties in the context of dual  $\\text{G}m$ PFPGs. Lastly, the article discusses an illustrative example of a social group network problem assessing the group’s activity based on attributes such as cooperation, team spirit, awareness, controlling power, good behaviour, and creativity.",
    "abstract_processed": "planar crisp graph well establish field wherea planar within fuzzi framework seen recent develop extens explor polar fuzzi graph pfg node edg associ compon connect minim relationship howev one desir incorpor maximum averag intermedi relationship node edg pfg concept becom inadequ polar fuzzi model minimum relat consid address limit gener model pfg introduc articl allow broader rang relationship consid simultan paper also discuss properti gener polar fuzzi environ gener polar fuzzi graph \\text g pfg highlight isomorph sever signific find insight present paper articl delv properti characterist gener polar fuzzi planar graph \\text g pfpg explor variou intrigu aspect relat addit novel concept gener polar fuzzi dual graph \\text g pfdg introduc deriv \\text g pfpg paper establish relationship dual \\text g pfg \\text g pfg examin properti context dual \\text g pfpg lastli articl discuss illustr exampl social group network problem assess group’ activ base attribut cooper team spirit awar control power good behaviour creativ"
  },
  {
    "doc_id": "10341425",
    "abstract_original": "Designing robots is a multiphase process aimed at solving a multi-criteria optimization problem to find the best possible detailed design. Generative design (GD) aims to accelerate the design process compared to manual design, since GD allows exploring and exploiting the vast design space more efficiently. In the field of robotics, however, relevant research focuses mostly on the generation of fully-actuated open chain kinematics, which is trivial in mechanical engineering perspective. Within this paper, we address the problem of generative design of closed-chain linkage mechanisms. A GD algorithm has to be able to generate meaningful mechanisms which satisfy conditions of existence. We propose an optimization-driven algorithm for generation of planar closed-chain linkages to follow a predefined trajectory. The algorithm creates an unlimited range of physically reproducible design alternatives that can be further tested in simulation. These tests could be done in order to find solutions that satisfy extra criteria, e.g., desired dynamic behavior or low energy consumption. The proposed algorithm is called “respawn” since it builds a new linkage after the ancestor has been tested in a virtual environment in pursuit for the optimal solution. To show that the algorithm is general enough, we show a set of generated linkages that can be used for a wide class of robots.",
    "abstract_processed": "design robot multiphas process aim solv multi criteria optim problem find best possibl detail design gener design gd aim acceler design process compar manual design sinc gd allow explor exploit vast design space effici field robot howev relev research focus mostli gener fulli actuat open chain kinemat trivial mechan engin perspect within paper address problem gener design close chain linkag mechan gd algorithm abl gener meaning mechan satisfi condit exist propos optim driven algorithm gener planar close chain linkag follow predefin trajectori algorithm creat unlimit rang physic reproduc design altern test simul test could done order find solut satisfi extra criteria e g desir dynam behavior low energi consumpt propos algorithm call “respawn” sinc build new linkag ancestor test virtual environ pursuit optim solut show algorithm gener enough show set gener linkag use wide class robot"
  },
  {
    "doc_id": "10341548",
    "abstract_original": "Deep neural networks using for real-world classification task require high reliability and robustness. However, the Softmax output by the last layer of network is often over-confident. We propose a novel confidence estimation method by considering model quality for deep classification models. Two metrics, MQ-Repres and MQ-Discri are developed accordingly to evaluate the model quality, and also provide a new confidence estimation called MQ-Conf for online inference. We demonstrate the capability of the proposed method by the $3D$ semantic segmentation tasks using three different deep networks. Through confusion analysis and feature visualization we show the rationality and reliability of the model quality quantification method.11This work is supported by the National Natural Science Foundation of China under Grant U22A2061 and High-performance Computing Platform of Peking University.",
    "abstract_processed": "deep neural network use real world classif task requir high reliabl robust howev softmax output last layer network often confid propos novel confid estim method consid model qualiti deep classif model two metric mq repr mq discri develop accordingli evalu model qualiti also provid new confid estim call mq conf onlin infer demonstr capabl propos method semant segment task use three differ deep network confus analysi featur visual show ration reliabl model qualiti quantif method work support nation natur scienc foundat china grant u high perform comput platform peke univers"
  },
  {
    "doc_id": "10342646",
    "abstract_original": "Teachers face challenges in teaching new subjects at the early primary level. The difficulties vary from subject to subject. Teachers' first challenge in Computer Science (CS) and Computational Thinking teaching is their technological literacy and competency challenges. Lack of confidence, time, and willingness are significant reasons for the challenge. One of the studies on mathematics teaching shows that teachers need more knowledge tools and models to facilitate the analysis during the teaching process. Researchers assert that educational practice has focused more on technology than on new pedagogies needed to truly use technology in a transformative way. Frameworks are designed to meet high-level objectives set by the authorities. Teachers are provided with teaching materials for developing the course contents. The frameworks act as a connection between high-level objectives and low-level teaching materials. In this paper, we present the elaboration of a framework for teaching CS at the early stages of education. The framework consists of three components based on modelling real-world problems into a machine-world context and then realising the machine solution in the real world. Moreover, the problem-solving component of the framework emphasizes the iterative process of learning that strengthens the previous concepts and provides a logical con-nection between the previous and new concepts. The framework was evaluated in the context of Saudi Arabia, where the teachers were interviewed individually and then provided with a guide for teaching grade-4 learners. The guide was developed using the material provided by the Saudi Ministry of Education. The teachers taught using this guide over a sequence of lessons. At the end of this time, a second individual teacher interview was conducted to determine teacher experience. The results show that teaching using the framework is effective, and it is not only easier for teachers to understand the teaching method but also for learners to learn the content quickly.",
    "abstract_processed": "teacher face challeng teach new subject earli primari level difficulti vari subject subject teacher first challeng comput scienc cs comput think teach technolog literaci compet challeng lack confid time willing signific reason challeng one studi mathemat teach show teacher need knowledg tool model facilit analysi teach process research assert educ practic focus technolog new pedagogi need truli use technolog transform way framework design meet high level object set author teacher provid teach materi develop cours content framework act connect high level object low level teach materi paper present elabor framework teach cs earli stage educ framework consist three compon base model real world problem machin world context realis machin solut real world moreov problem solv compon framework emphas iter process learn strengthen previou concept provid logic con nection previou new concept framework evalu context saudi arabia teacher interview individu provid guid teach grade learner guid develop use materi provid saudi ministri educ teacher taught use guid sequenc lesson end time second individu teacher interview conduct determin teacher experi result show teach use framework effect easier teacher understand teach method also learner learn content quickli"
  },
  {
    "doc_id": "10342890",
    "abstract_original": "This work-in-progress paper introduces an innovative approach that uses computational notebooks to teach Finite Element Analysis (FEA) in a Mechanical Engineering undergraduate course to aid the understanding of complex phenomena in Mechanics of Materials, and enhance students' computational thinking skills. Research indicates that students, irrespective of their educational level, face difficulties in grasping fundamental concepts in mechanics of materials. These challenges arise from the inherent complexity of concepts like stress, strain, torsion, and buckling, which are difficult to observe, hindering comprehension. Therefore, this work aims to leverage the synergy between mechanics of materials and computational principles to actively engage students in advanced topics such as structural strength, failure of structures, and sensitivity analysis, through the use of computational notebooks. To evaluate the effectiveness of this approach, we first asked students to analyze truss structures using hand calculations following the discrete stiffness method within a Finite Element Analysis framework. Subsequently, we implemented the same method as a simulation tool in a MATLAB Computational Notebook. Finally, we asked the students to reflect on: (1) the value of using computational methods to approach Finite Element Analysis when compared to hand calculations; (2) the difficulties they faced when implementing the activities in the MATLAB Computational Notebook; (3) the support they required to successfully complete these activities; and (4) the effectiveness of the simulation tool in understanding the effect of forces and stress distributions in structures. We anticipate that computational notebooks will provide an ideal platform for sharing lessons and tutorials, enhancing student engagement, and promoting active learning. Students have access to the complete source code, allowing them to develop computational skills. Early exposure to coding, modeling, and simulation techniques is crucial in preparing students for the computational demands of modern engineering workplaces.",
    "abstract_processed": "work progress paper introduc innov approach use comput notebook teach finit element analysi fea mechan engin undergradu cours aid understand complex phenomena mechan materi enhanc student comput think skill research indic student irrespect educ level face difficulti grasp fundament concept mechan materi challeng aris inher complex concept like stress strain torsion buckl difficult observ hinder comprehens therefor work aim leverag synergi mechan materi comput principl activ engag student advanc topic structur strength failur structur sensit analysi use comput notebook evalu effect approach first ask student analyz truss structur use hand calcul follow discret stiff method within finit element analysi framework subsequ implement method simul tool matlab comput notebook final ask student reflect valu use comput method approach finit element analysi compar hand calcul difficulti face implement activ matlab comput notebook support requir success complet activ effect simul tool understand effect forc stress distribut structur anticip comput notebook provid ideal platform share lesson tutori enhanc student engag promot activ learn student access complet sourc code allow develop comput skill earli exposur code model simul techniqu crucial prepar student comput demand modern engin workplac"
  },
  {
    "doc_id": "10342929",
    "abstract_original": "The importance of dialogue in questioning assumptions and bringing new options and perspectives to light is well established in various areas of decision-making; what potential does it hold to enrich students' critical thinking competencies in the context of ethics education? We examine student work in an ethics course for senior computer science and software engineering students. The course includes a series of exercises in critical ethical inquiry, implementing the iterative Ethical Cycle approach of van de Poel and Royakkers with reflection sessions where students exchange peer critiques. Through a qualitative analysis of two years of student work, we explore two questions: what kinds of critical issues do students acknowledge in peer dialogue, and how do students incorporate, or fail to incorporate, critical challenges into their work? We identify and categorize critical challenges that appear in student reflection statements, and we identify a number of patterns of critical engagement: ways in which student map the identifications of critical challenges to subsequent changes in later iterations. Our results indicate that dialogue with others is generally an enriching component of students' ethical inquiry, though not all students take advantage of it even when built into class exercises, and other students may adopt new ideas in a superficial way, failing to truly incorporate them into prior discussion. The results also suggest certain design changes of the ethical analysis exercises that can help students take greater advantage of insights from their peers: fostering greater interplay between peers through a single clearly identified topic; more defined scaffolding of peer discussions, prompting students to identify critical challenges from others; further scaffolding to remind students of the peer challenges raised earlier and ask them how (and whether) they wish to incorporate these new perspectives into their own work; and more discussion and modeling of how to truly incorporate new ideas in a robust way.",
    "abstract_processed": "import dialogu question assumpt bring new option perspect light well establish variou area decis make potenti hold enrich student critic think compet context ethic educ examin student work ethic cours senior comput scienc softwar engin student cours includ seri exercis critic ethic inquiri implement iter ethic cycl approach van de poel royakk reflect session student exchang peer critiqu qualit analysi two year student work explor two question kind critic issu student acknowledg peer dialogu student incorpor fail incorpor critic challeng work identifi categor critic challeng appear student reflect statement identifi number pattern critic engag way student map identif critic challeng subsequ chang later iter result indic dialogu other gener enrich compon student ethic inquiri though student take advantag even built class exercis student may adopt new idea superfici way fail truli incorpor prior discuss result also suggest certain design chang ethic analysi exercis help student take greater advantag insight peer foster greater interplay peer singl clearli identifi topic defin scaffold peer discuss prompt student identifi critic challeng other scaffold remind student peer challeng rais earlier ask whether wish incorpor new perspect work discuss model truli incorpor new idea robust way"
  },
  {
    "doc_id": "10342931",
    "abstract_original": "Game-based learning (GBL) can motivate learners and enable them to engage in their learning experience. Additionally, the popularity of GBL has grown in computer science and programming courses, where it can be used to develop computational thinking (CT) skills. CT is critical thinking used to apply fundamental concepts and reasoning derived from computing and computer science. Research has shown that digital GBL can improve critical thinking skills and help learners understand programming concepts, structures, and problem-solving strategies. Despite the popularity of digital GBL, analog card games and bingo games are still valuable and effective tools for learning. However, most studies on GBL that aim to train critical thinking skills have focused on digital approaches. This indicates a gap in the body of knowledge because few studies have explored the effectiveness of analog games for developing CT skills through GBL. The theoretical framework of this study is grounded in two learning theories. Constructivist theory frames learning as the construction of knowledge through a process of action, reflection, and construction. Constructionist learning theory calls for construction of artifacts, learner agency, authentic purpose, or authentic audience during the process. To investigate the design of GBL for developing CT skills and to generate discourse for its widespread adoption, the current study implemented design-based research (DBR) in an undergraduate computer science course for non-computer science majors. By addressing the gap in the literature on GBL for CT skill development, the study aimed to investigate complex learner experiences, including learner struggles and successes, alignment with learning theory principles, and design moves for future iterations of the project. The research question posed is: how can we optimize CT learning through GBL, based on learner experiences and learning theories? Prior to this study, the instructor used GBL in which learners played an analog, three-dimensional tic-tac-toe game with ping pong balls and then wrote a computer program that simulated that game. We chose to conduct DBR to strengthen the learning associated with this activity. DBR uses iterative designs to develop knowledge that improves educational practices. In the spring of 2023, we assessed the extent to which the non-digital game and programming the simulated game enhanced learners' CT skills by analyzing their experiences with CT. This involved collecting and analyzing learner surveys to gain insight into their learning experiences. Using network analysis and betweenness centrality measures, the data will be analyzed to identify learner struggles and successes. The results are expected to be available by August 2023. The contributions of this study include identifying effective design principles for GBL, optimizing CT learning, and generating discourse for the widespread adoption of GBL in computer science education.",
    "abstract_processed": "game base learn gbl motiv learner enabl engag learn experi addit popular gbl grown comput scienc program cours use develop comput think ct skill ct critic think use appli fundament concept reason deriv comput comput scienc research shown digit gbl improv critic think skill help learner understand program concept structur problem solv strategi despit popular digit gbl analog card game bingo game still valuabl effect tool learn howev studi gbl aim train critic think skill focus digit approach indic gap bodi knowledg studi explor effect analog game develop ct skill gbl theoret framework studi ground two learn theori constructivist theori frame learn construct knowledg process action reflect construct constructionist learn theori call construct artifact learner agenc authent purpos authent audienc process investig design gbl develop ct skill gener discours widespread adopt current studi implement design base research dbr undergradu comput scienc cours non comput scienc major address gap literatur gbl ct skill develop studi aim investig complex learner experi includ learner struggl success align learn theori principl design move futur iter project research question pose optim ct learn gbl base learner experi learn theori prior studi instructor use gbl learner play analog three dimension tic tac toe game ping pong ball wrote comput program simul game chose conduct dbr strengthen learn associ activ dbr use iter design develop knowledg improv educ practic spring assess extent non digit game program simul game enhanc learner ct skill analyz experi ct involv collect analyz learner survey gain insight learn experi use network analysi between central measur data analyz identifi learner struggl success result expect avail august contribut studi includ identifi effect design principl gbl optim ct learn gener discours widespread adopt gbl comput scienc educ"
  },
  {
    "doc_id": "10342942",
    "abstract_original": "This Research-to-Practice full paper presents an explorative study investigating the effects of flipped learning on the learning motivation of primary school students enrolled in a block-based programming course. Technology development has increased the importance of information technology-related competencies for the new generation. Programming skills are essential in various industries nowadays. Thus, programming education has become necessary to cultivate students' relevant abilities to meet the rapid pace of development. Programming learning encourages students to think logically and systematically, solve problems effectively, and develop computational thinking skills. However, learning programming is challenging for many students for different reasons, such as its inherent complexity, inadequate study methods, and pedagogical approaches unsuited to promote programming learning. Traditional teaching methods are often impersonalized and only suitable for some learning styles present in class. Moreover, the challenges encountered by the students as novice programmers are attributed to their low learning motivation. To learn to program, students must comprehend different syntactic conventions, complex instructions, and logical operators and actively engage in practical learning activities, often facing difficulties. This may reduce their learning motivation leading to failure and dropout. To accommodate different learning styles and increase students' motivation, this study employed the ARCS motivation model to design various innovative activities in a flipped classroom setting to increase students' motivation and improve teachers' teaching effectiveness. The study utilized a pretest-posttest method with two groups of grade five students to compare the effectiveness of teaching and learning between the flipped and traditional classroom students. The study's findings revealed that the flipped classroom experimental group showed significantly higher learning motivation than the students in the control group. Moreover, it was found that different flipped classroom activities, including the use of gamification, flipped videos, self-study, self-questioning, self-assessment, split programming tasks, group cooperation, and demonstration activities, had a positive influence on various sub-dimensions of the ARCS model, such as attention, relevance, confidence, and satisfaction.",
    "abstract_processed": "research practic full paper present explor studi investig effect flip learn learn motiv primari school student enrol block base program cours technolog develop increas import inform technolog relat compet new gener program skill essenti variou industri nowaday thu program educ becom necessari cultiv student relev abil meet rapid pace develop program learn encourag student think logic systemat solv problem effect develop comput think skill howev learn program challeng mani student differ reason inher complex inadequ studi method pedagog approach unsuit promot program learn tradit teach method often imperson suitabl learn style present class moreov challeng encount student novic programm attribut low learn motiv learn program student must comprehend differ syntact convent complex instruct logic oper activ engag practic learn activ often face difficulti may reduc learn motiv lead failur dropout accommod differ learn style increas student motiv studi employ arc motiv model design variou innov activ flip classroom set increas student motiv improv teacher teach effect studi util pretest posttest method two group grade five student compar effect teach learn flip tradit classroom student studi find reveal flip classroom experiment group show significantli higher learn motiv student control group moreov found differ flip classroom activ includ use gamif flip video self studi self question self assess split program task group cooper demonstr activ posit influenc variou sub dimens arc model attent relev confid satisfact"
  },
  {
    "doc_id": "10342945",
    "abstract_original": "This Innovative Practice Full Paper presents our design of teaching computer programming for middle and high school students during an one-week Summer camp for the past five years, with an interruption in the Summer of 2020 due to the Covid-19 pandemic. Many researchers believe that good Summer camps can improve many students' educational and career development outcomes. Teachers and administrators are increasingly promoting Summer camp opportunities for introducing programming skills to middle and high school students. The motivation of our program is to offer hands-on projects for middle and high school students to increase their interests and knowledge in computing to meet the growing demand. Like some Summer coding camps, we picked Scratch as the programming language (designed and offered for free by the Massachusetts Institute of Technology) for the students to learn important mathematical and computer programming concepts. In addition, the students learn how to think and reason creatively, reason systematically, and work collaboratively, while also having fun during the one-week Summer camp. For the students already familiar with Scratch, the instructor exposed students to basic concepts of Java programming language, such as Java virtual machine, computer memory, data representation, primitive data types, casting, arithmetic, and relational operators, as well as the assignment, selection and printing statements. This article presents our findings from Summer camps organized in 2018 and 2022. Our conclusion is that all students showed a better understanding of programming concepts and confidence in computing. In the upcoming paper sections, we will describe details about how we made one-week camps to be unique compared to other similar camps. One element of our own approach is to teach in an effective and innovative using an interactive teaching approach. For example, when we designed the lecture notes, we imagine that we are students taking for the first time a computer programming course. In addition, we designed simple programming exercises for the students to solve immediately. The instructors and Teaching Assistants promptly checked the solution and award the students with stars for completing the work. This environment was very well received because it was viewed as a student collegiate competition instead of a race against time. Besides learning about computer programming, we adopted during Summer camps several strategies like those enumerated earlier to enrich our camps, as well as social events, career and professional development, and academic exposure. Our findings indicate that these additional activities proved to be beneficial to our students attending the Summer camps.",
    "abstract_processed": "innov practic full paper present design teach comput program middl high school student one week summer camp past five year interrupt summer due covid pandem mani research believ good summer camp improv mani student educ career develop outcom teacher administr increasingli promot summer camp opportun introduc program skill middl high school student motiv program offer hand project middl high school student increas interest knowledg comput meet grow demand like summer code camp pick scratch program languag design offer free massachusett institut technolog student learn import mathemat comput program concept addit student learn think reason creativ reason systemat work collabor also fun one week summer camp student alreadi familiar scratch instructor expos student basic concept java program languag java virtual machin comput memori data represent primit data type cast arithmet relat oper well assign select print statement articl present find summer camp organ conclus student show better understand program concept confid comput upcom paper section describ detail made one week camp uniqu compar similar camp one element approach teach effect innov use interact teach approach exampl design lectur note imagin student take first time comput program cours addit design simpl program exercis student solv immedi instructor teach assist promptli check solut award student star complet work environ well receiv view student collegi competit instead race time besid learn comput program adopt summer camp sever strategi like enumer earlier enrich camp well social event career profession develop academ exposur find indic addit activ prove benefici student attend summer camp"
  },
  {
    "doc_id": "10342946",
    "abstract_original": "This Research to Practice Work-in-Progress paper discusses a next-generation learning system for K-12 students to educate them on scientific concepts surrounding the human body. Specifically, our gamified learning system is designed to make learning more fun, engaging, and effective through game and experiment elements that align with science and math learning standards. It will also increase systematic problem-solving and algorithmic reasoning for K-12 students. Since the human body can be thought of as a combination of interacting systems, the game also introduces students to computational thinking by introducing internal body functions. To achieve these goals, this project has two components. First, an educational virtual reality game will be built according to the natural human body structure. During the game process, students will experience the same as the human body functions, travel along the blood circulation, help with the heartbeat, and participate in oxygen exchange. While students are playing the game, our gamified adaptive learning system tracks and controls the student's learning progress. As the AI component collects student data and uses this information, our system adjusts game content and addresses possible learner issues to refine the learning curriculum for a faster and more effective learning experience. Second, a series of hands-on activities will be conducted based on the functions of the human body (e.g., developing an artificial heart and experiencing how the heart works). Through this project, an attractive and efficient next-generation learning system will be developed and used to expose K-12 students to this learning system. The education of students will be accomplished in different dimensions through games and hands-on practice, respectively. Additionally, compared to traditional learning methods, our learning system not only increases students' interest in learning but also makes it more personalized compared to the conventional learning process. Likewise, we will refer to the results of self-efficacy surveys administered to students and teachers separately to test their perceptions of their abilities and the new system.",
    "abstract_processed": "research practic work progress paper discuss next gener learn system k student educ scientif concept surround human bodi specif gamifi learn system design make learn fun engag effect game experi element align scienc math learn standard also increas systemat problem solv algorithm reason k student sinc human bodi thought combin interact system game also introduc student comput think introduc intern bodi function achiev goal project two compon first educ virtual realiti game built accord natur human bodi structur game process student experi human bodi function travel along blood circul help heartbeat particip oxygen exchang student play game gamifi adapt learn system track control student learn progress ai compon collect student data use inform system adjust game content address possibl learner issu refin learn curriculum faster effect learn experi second seri hand activ conduct base function human bodi e g develop artifici heart experienc heart work project attract effici next gener learn system develop use expos k student learn system educ student accomplish differ dimens game hand practic respect addit compar tradit learn method learn system increas student interest learn also make person compar convent learn process likewis refer result self efficaci survey administ student teacher separ test percept abil new system"
  },
  {
    "doc_id": "10343028",
    "abstract_original": "In this research to practice report, we present student perceptions of a new first-year engineering programming class that was designed by informed research practices. While the College of Engineering at the participating university saw a lot of major switching in the first year, there were not many students switching into computer science (CS). This could have been because other engineering major classes did not transfer well to CS or that students would be a year behind in the programming classes. In either case, the participating university felt that computational thinking and programming were an important part of first-year engineering exploration and believed that all 21st century engineering majors should learn to program in a general purpose language, such as Python or C++. Past research found that prior programming experience, knowledge organization, self-efficacy, and class size were factors impacting student performance in early programming courses, and learning about programming enhanced students' problem-solving skills and improved perceptions about CS. Many other research studies showed that the context in which programming material was presented to non-majors was important for their learning and interest, and themed, mixed-context courses with real-world engineering problems worked well. Therefore, in the spring 2022, we created 12, 100-person sections of a course titled “Engineering Computational and Algorithmic Thinking” for a new first-year engineering experience. Each section was taught by a different instructor representing a variety of disciplines and topics in the College of Engineering. This paper describes the research to practice and engineering student perceptions of the new, required programming class. We hypothesized that engineering students would say that the course should be required for all engineering majors, but we wanted to know why. We believed that student prior programming experience, engineering major, and other demographics would play a role in their responses. We thematically analyzed student justifications to identify emerging themes, and we used a mixed-method approach to correlate themes to different student demographics, engineering major interest, and prior programming experience. The majority of engineering students agreed that the first-year engineering course should be required, and prior programming experience and major played the largest role.",
    "abstract_processed": "research practic report present student percept new first year engin program class design inform research practic colleg engin particip univers saw lot major switch first year mani student switch comput scienc cs could engin major class transfer well cs student would year behind program class either case particip univers felt comput think program import part first year engin explor believ st centuri engin major learn program gener purpos languag python c past research found prior program experi knowledg organ self efficaci class size factor impact student perform earli program cours learn program enhanc student problem solv skill improv percept cs mani research studi show context program materi present non major import learn interest theme mix context cours real world engin problem work well therefor spring creat person section cours titl “engin comput algorithm thinking” new first year engin experi section taught differ instructor repres varieti disciplin topic colleg engin paper describ research practic engin student percept new requir program class hypothes engin student would say cours requir engin major want know believ student prior program experi engin major demograph would play role respons themat analyz student justif identifi emerg theme use mix method approach correl theme differ student demograph engin major interest prior program experi major engin student agre first year engin cours requir prior program experi major play largest role"
  },
  {
    "doc_id": "10343081",
    "abstract_original": "While governments, teacher educators, and teachers recognize the importance of introducing computer science (CS) in K-12, there is limited understanding about when the teacher preparation should start and how it needs to be done. Furthermore, with the rapid expansion of digital technology in our society and the way it affects our lives, new educational frameworks for better teacher preparation have been developed, such as TPACK and CTIntegration, that situate new technologies and their role in education to meet the new societal demands. There is a larger body of research in Mathematics on how on how to prepare teachers to teach than in CS. This study explores how graduate teaching candidates and undergraduate pre-service teachers engage with Math+CS modules differently. We were interested in the similarities and differences in the way senior-level pre-service teachers in a mathematics and technology class and graduate-level teacher candidates in a methods class interact with Math+CS integrated modules. Working with the concepts of variable, input, and output, we investigated which knowledge domains were leveraged among groups in different classes, what connections they make between the concepts in math and CS, and their uncertainty. The results indicated that there was a difference in the way the teaching candidates in their methods class approached the computational modules than the pre-service teachers. The pre-service teachers focused more on developing their CS content knowledge, and the teacher candidates were interested in making connections between their knowledge domains, reflecting on how their students would think about the concepts in math, expressing more concerns, and asking more questions to develop their TPACK.",
    "abstract_processed": "govern teacher educ teacher recogn import introduc comput scienc cs k limit understand teacher prepar start need done furthermor rapid expans digit technolog societi way affect live new educ framework better teacher prepar develop tpack ctintegr situat new technolog role educ meet new societ demand larger bodi research mathemat prepar teacher teach cs studi explor graduat teach candid undergradu pre servic teacher engag math cs modul differ interest similar differ way senior level pre servic teacher mathemat technolog class graduat level teacher candid method class interact math cs integr modul work concept variabl input output investig knowledg domain leverag among group differ class connect make concept math cs uncertainti result indic differ way teach candid method class approach comput modul pre servic teacher pre servic teacher focus develop cs content knowledg teacher candid interest make connect knowledg domain reflect student would think concept math express concern ask question develop tpack"
  },
  {
    "doc_id": "10343210",
    "abstract_original": "The goal of this research full paper is to provide insight into most recent findings of interviews with faculty members teaching digital skills in an integrated and innovative way embedded into courses on subject didactics of a teacher education program. Pre-studies analyzing students' perspectives regarding the inclusion of digital competences in the teacher education program of a large Central-European university revealed that less than half of the students who were at an advanced stage in their studies felt sufficiently prepared to impart digital competences in their daily teaching. Given the importance of being digitally competent in the modern, digital era, the question arises, how digital competences can be sustainably included in the curriculum of a teacher education program. This paper analyzes interviews with five faculty members successfully teaching digital skills in concert with subject didactics of Geography in order to identify best practices for the integration of digital competences. The first author asked our Interview Partners to provide insight into the content they mediated, the integration of digital competences and tools in their courses, how their teaching could be further improved, and what challenges they encounter. Eventually, we looked for best practices and collected instructors' thoughts on improvements on a curricular level and examples of transferring the good practices to other subjects, such that future students could benefit from a better integration of digital competences. For this paper, we analyzed the data with a mixture of narrative analysis and thematic analysis. Improving the mediating of digital skills and competences in a wider range of subjects at the university level should eventually help students, and ultimately their students, to implement digital know-how such as modern teaching tools into their courses, making teaching more effective and computational thinking as well as related fields of computing more accessible to academic as well as secondary and younger students. The research so far has shown promising results considering examples of tools that can be used on a broad spectrum of subjects and lead to a factor of learned new digital competences if used properly. On the other hand, lecturers also warned about relying too much on technology in specific tasks such as orientation on a map or analyzing statistical data. We conclude that combining existing approaches with new, more modern didactics can be the key to transferring the competencies required for our students' future.",
    "abstract_processed": "goal research full paper provid insight recent find interview faculti member teach digit skill integr innov way embed cours subject didact teacher educ program pre studi analyz student perspect regard inclus digit compet teacher educ program larg central european univers reveal less half student advanc stage studi felt suffici prepar impart digit compet daili teach given import digit compet modern digit era question aris digit compet sustain includ curriculum teacher educ program paper analyz interview five faculti member success teach digit skill concert subject didact geographi order identifi best practic integr digit compet first author ask interview partner provid insight content mediat integr digit compet tool cours teach could improv challeng encount eventu look best practic collect instructor thought improv curricular level exampl transfer good practic subject futur student could benefit better integr digit compet paper analyz data mixtur narr analysi themat analysi improv mediat digit skill compet wider rang subject univers level eventu help student ultim student implement digit know modern teach tool cours make teach effect comput think well relat field comput access academ well secondari younger student research far shown promis result consid exampl tool use broad spectrum subject lead factor learn new digit compet use properli hand lectur also warn reli much technolog specif task orient map analyz statist data conclud combin exist approach new modern didact key transfer compet requir student futur"
  },
  {
    "doc_id": "10343224",
    "abstract_original": "Computational thinking has become an essential skill nowadays. Many educational institutions around the world have adopted computational thinking as an elementary or complementary subject in their teaching schedules. One of the approaches that is efficient in teaching and learning computational thinking has been visual programming. However, like other applications used daily, visual programming tools can be a limiting factor for the blind in learning computational thinking. This work aims to present the iVProg4all, an accessible visual programming system based on forms. A preliminary study was carried out to test the usability of iVProg4all and accessibility with a blind user. The results show that, although some usability issues need to be fixed, the system proved accessible for blind people.",
    "abstract_processed": "comput think becom essenti skill nowaday mani educ institut around world adopt comput think elementari complementari subject teach schedul one approach effici teach learn comput think visual program howev like applic use daili visual program tool limit factor blind learn comput think work aim present ivprog access visual program system base form preliminari studi carri test usabl ivprog access blind user result show although usabl issu need fix system prove access blind peopl"
  },
  {
    "doc_id": "10343236",
    "abstract_original": "Learning progress is fascinating, especially in STEM fields. When learning novel concepts and principles, the learners will try to link and compare the newly learned contents with their existing knowledge system. If the newly learned knowledge matches the built-up ones, the learners will easily merge it into their long-term (permanent) knowledge structure. When the newly learned knowledge does not match their existing structure, the learners feel confused and hard to accept and digest. In many cases, the learners learned similar concepts and principles from middle school to post-college at different levels, in mathematics and engineering mechanics. Learners might notice that some of the concepts and principles at different levels looked similar and plausible, but the critical differences didn't catch enough attention, neither the concepts themselves nor the application conditions. Even though the students heard the explanation from the instructors in the class, it does not match their existing daily life experience, which makes it harder to accept and merge it into their knowledge system. In other words, a puzzle piece was put in the blank position where it does not fit. The present study is working on rebuilding the STEM knowledge structures and exploring the differences that existed among high school students (9th- 12th graders), first-year engineering undergraduates, higher-level engineering students, and professional engineers with designed quantitative and qualitative research methods. This research aims to explore the possibility of making the transition smoother from one learning stage to another and develop a novel curriculum that could merge the knowledge structures in a new way to reduce or eliminate the gaps between different levels of STEM learning. The author of the present project was working with 9th-12th grade students from local high schools, and college students in STEM majors at a public university, to rebuild and figure out the differences in their knowledge structures for STEM learning. The project includes preparation work as the development of concept inventories in STEM fields, structured survey questionnaires for both experimental groups. The topics the author chose are concepts shared and inherited from high school STEM education, such as force, velocity, acceleration, Newton's Second Law, etc. Currently, the study focused on the feedback of their scores completing the concept inventories, while the next phase of intervention will be applied.",
    "abstract_processed": "learn progress fascin especi stem field learn novel concept principl learner tri link compar newli learn content exist knowledg system newli learn knowledg match built one learner easili merg long term perman knowledg structur newli learn knowledg match exist structur learner feel confus hard accept digest mani case learner learn similar concept principl middl school post colleg differ level mathemat engin mechan learner might notic concept principl differ level look similar plausibl critic differ catch enough attent neither concept applic condit even though student heard explan instructor class match exist daili life experi make harder accept merg knowledg system word puzzl piec put blank posit fit present studi work rebuild stem knowledg structur explor differ exist among high school student th th grader first year engin undergradu higher level engin student profession engin design quantit qualit research method research aim explor possibl make transit smoother one learn stage anoth develop novel curriculum could merg knowledg structur new way reduc elimin gap differ level stem learn author present project work th th grade student local high school colleg student stem major public univers rebuild figur differ knowledg structur stem learn project includ prepar work develop concept inventori stem field structur survey questionnair experiment group topic author chose concept share inherit high school stem educ forc veloc acceler newton second law etc current studi focus feedback score complet concept inventori next phase intervent appli"
  },
  {
    "doc_id": "10343247",
    "abstract_original": "This paper proposes the implementation of Chat-GPT, a large language model, as a virtual peer for peer instruction in computer programming courses. The authors argue that AI tools, including ChatGPT, can bring benefits such as personalized learning, instant feedback, and active engagement to the classroom. An experiment was conducted with two groups of programming students: one receiving traditional instruction and the other utilizing the ChatGPT-based peer instruction model. Both groups were given the same programming assignments and assessments. The results indicated that the ChatGPT group outperformed the traditionally instructed group, demonstrating better programming skills and a deeper understanding of concepts. The ChatGPT group also reported higher engagement and satisfaction. However, some difficulties were observed when using ChatGPT for more abstract problems. Overall, the study highlights the effectiveness of using ChatGPT as a virtual peer to enhance active learning and student outcomes in computer programming courses, challenging biases regarding AI's potential benefits in education. The authors hope this study encourages educators to embrace AI tools in the classroom and overcome confirmation biases about their impact.",
    "abstract_processed": "paper propos implement chat gpt larg languag model virtual peer peer instruct comput program cours author argu ai tool includ chatgpt bring benefit person learn instant feedback activ engag classroom experi conduct two group program student one receiv tradit instruct util chatgpt base peer instruct model group given program assign assess result indic chatgpt group outperform tradit instruct group demonstr better program skill deeper understand concept chatgpt group also report higher engag satisfact howev difficulti observ use chatgpt abstract problem overal studi highlight effect use chatgpt virtual peer enhanc activ learn student outcom comput program cours challeng bias regard ai potenti benefit educ author hope studi encourag educ embrac ai tool classroom overcom confirm bias impact"
  },
  {
    "doc_id": "10343256",
    "abstract_original": "Enculturation to engineering is a topic of interest to professional organizations such as ASEE or IEEE. Enculturation can be understood as the process by which students are assimilated into the engineering culture. This culture involves the base knowledge, practices, and values shared by the community of practicing engineers. Both the culture and its assimilation are somewhat obscure and often attributed to role-modeling and hidden curriculum. Nevertheless, undergraduate students are expected to undergo this assimilation process, and by the end of a five-year program, they behave, talk, and do what engineers do. An approach to this process is the well-established model of engineering identity. This model of identity, however, limits its scope to the intrinsic process occurring in the student without paying much attention to the support systems expected to welcome and nurture students into the profession. Enculturation is a relatively new model that proposes both intrinsic and extrinsic factors affecting this assimilation of students. During the Spring of 2022, a team of researchers at a U.S. Southwest institution applied a survey to operationalize the extrinsic factors of a recently outlined engineering model of enculturation to understand the impact of COVID on engineering students. Eight Likert-based questions were asked to 534 engineering undergraduate students at different school year classifications (e.g., sophomore, junior, or senior). The model of enculturation tested eight extrinsic factors involving (1) engineering design, (2) teamwork, (3) engineering profession, (4) ethics, (5) engineering communications, (6) mathematical/physical modeling, (7) problem-solving, and (8) algorithmic/computational thinking. Additional Likert-based questions asked students about the perceived impact of COVID on their educational experience. The research questions guiding their investigation were: (a) How are the dimensions of enculturation to engineering changing across engineering undergraduate classifications?, and (b) How is enculturation associated with the COVID impact on students? Preliminary results show that six of the factors (namely 1–5 and 7) increase by students' school classification. This means that students in the lower years of their undergraduate program perceive their enculturation, as portrayed by factors 1–5 & 7, less than students at more advanced stages of their program. In terms of the perceived impact of COVID, only two factors showed negative correlations with this perceived impact The factors were ethics and algorithmic/computational thinking. In other words, the worse the student's perception of COVID's impact on their educational experience, the less they endorsed their enculturation in the impact of society of their technical solutions and their use of programming languages. While these results show encouraging applicability of the enculturation model, it can only be considered a first approach to a more fully developed model. The researchers expect to engage the FIE community in a discussion leading to a more refined enculturation model.",
    "abstract_processed": "encultur engin topic interest profession organ ase ieee encultur understood process student assimil engin cultur cultur involv base knowledg practic valu share commun practic engin cultur assimil somewhat obscur often attribut role model hidden curriculum nevertheless undergradu student expect undergo assimil process end five year program behav talk engin approach process well establish model engin ident model ident howev limit scope intrins process occur student without pay much attent support system expect welcom nurtur student profess encultur rel new model propos intrins extrins factor affect assimil student spring team research u southwest institut appli survey operation extrins factor recent outlin engin model encultur understand impact covid engin student eight likert base question ask engin undergradu student differ school year classif e g sophomor junior senior model encultur test eight extrins factor involv engin design teamwork engin profess ethic engin commun mathemat physic model problem solv algorithm comput think addit likert base question ask student perceiv impact covid educ experi research question guid investig dimens encultur engin chang across engin undergradu classif b encultur associ covid impact student preliminari result show six factor name – increas student school classif mean student lower year undergradu program perceiv encultur portray factor – less student advanc stage program term perceiv impact covid two factor show neg correl perceiv impact factor ethic algorithm comput think word wors student percept covid impact educ experi less endors encultur impact societi technic solut use program languag result show encourag applic encultur model consid first approach fulli develop model research expect engag fie commun discuss lead refin encultur model"
  },
  {
    "doc_id": "10343283",
    "abstract_original": "Personal health tracking devices and internet-based digital platforms with the capacity to collect, aggregate, and store data at massive scales are examples of tools that have broadened priorities in computing to include data science. In response, there has been growing attention in research and practice emphasizing pre-college groups. This is partly because of the growing recognition-reflected in initiatives like CS4ALL, Code.org, Bootstrap: Data Science, Exploring Computer Science-that learning experiences before college are consequential in sustaining a robust pipeline of computer scientists and engineers. Despite these inroads, there is justifiable concern that existing efforts might not fully support learner development in the necessary conceptual, epistemological, and heuristic styles needed to productively parse and understand “big data.” This is because computing-based curricula that include data science often involve data curated by others (rather than learners directly), which results in simulated versions of practice instead of engagement that is realistically discursive and messy. This is further complicated by the persistent shortage of K-12 computer science teachers in general and even fewer who can design and implement curricula that support authentic engagement with data science. To address these issues, we leverage culturally relevant and constructionist perspectives in a sandbox (i.e., open-ended) science where tools like Scratch and electronic textiles (E-textiles) have had success expanding possibilities in computing to also include activities where learners can engage broadly along varied pursuits-and encounter challenges that spur computational thinking and problem-solving. The literature suggests that learning activities framed in this way encourage knowledge construction, practice literacies, and seriously impact learner attitudes, interest, and perceptions of growth in the field. This latter set of self-concept measures represents a few of many related key predictors of long-term field participation and persistence. In this work-in-progress scholarship of discovery research, we co-develop, with youth and educators, “Coding Like a Data Miner” (CLDM)-a sandbox approach to computing-based data science wherein learners access a social media platform, Twitter, to mine, analyze, and understand quantitative and qualitative data sources. In this preliminary work, we assess affordances in co-developing a curriculum that leverages sandbox approaches to data science. Ultimately (and what will be presented in our final submission), we aim to study learning outcomes when high school students' access, analyze and make sense of “big data” sets of their own. We collaborated with high school teachers in a West Texas/Paso Del Norte region where computer science educators are exceptionally scarce and where there is an urgent and persistent need to support underrepresented learner access to burgeoning areas of computing. Using mixed-methodological approaches (e.g., quantitative analysis of learner pre- and post-survey responses along with qualitative assessments of semi-structured interview data), we address the following research questions: (1) What affordances exist using co-design approaches to develop sandbox data science for pre-college learners? (2) Which computational concepts do students learn when carrying out CLDM activities, (3) Which computational practices do high school students enact when mining, processing, and analyzing big data sets in CLDM? (4) How do learner knowledge and perceptions about data science shift after participating in CLDM? We use contemporary perspectives in computing education, constructionism, and equity to discuss how open-ended sandbox approaches to computing-based data science support learner computational thinking, practice literacies, and field perceptions.",
    "abstract_processed": "person health track devic internet base digit platform capac collect aggreg store data massiv scale exampl tool broaden prioriti comput includ data scienc respons grow attent research practic emphas pre colleg group partli grow recognit reflect initi like cs code org bootstrap data scienc explor comput scienc learn experi colleg consequenti sustain robust pipelin comput scientist engin despit inroad justifi concern exist effort might fulli support learner develop necessari conceptu epistemolog heurist style need product pars understand “big data ” comput base curricula includ data scienc often involv data curat other rather learner directli result simul version practic instead engag realist discurs messi complic persist shortag k comput scienc teacher gener even fewer design implement curricula support authent engag data scienc address issu leverag cultur relev constructionist perspect sandbox e open end scienc tool like scratch electron textil e textil success expand possibl comput also includ activ learner engag broadli along vari pursuit encount challeng spur comput think problem solv literatur suggest learn activ frame way encourag knowledg construct practic literaci serious impact learner attitud interest percept growth field latter set self concept measur repres mani relat key predictor long term field particip persist work progress scholarship discoveri research co develop youth educ “code like data miner” cldm sandbox approach comput base data scienc wherein learner access social media platform twitter mine analyz understand quantit qualit data sourc preliminari work assess afford co develop curriculum leverag sandbox approach data scienc ultim present final submiss aim studi learn outcom high school student access analyz make sens “big data” set collabor high school teacher west texa paso del nort region comput scienc educ except scarc urgent persist need support underrepres learner access burgeon area comput use mix methodolog approach e g quantit analysi learner pre post survey respons along qualit assess semi structur interview data address follow research question afford exist use co design approach develop sandbox data scienc pre colleg learner comput concept student learn carri cldm activ comput practic high school student enact mine process analyz big data set cldm learner knowledg percept data scienc shift particip cldm use contemporari perspect comput educ construction equiti discuss open end sandbox approach comput base data scienc support learner comput think practic literaci field percept"
  },
  {
    "doc_id": "10343349",
    "abstract_original": "High schools and undergraduate courses present several problems regarding teaching programming. In this perspective, several factors have led to the development of tools to support programming disciplines, including: (i) the persistent problems in teaching programming worldwide, (ii) the inclusion of computational thinking and programming practices in the new Basic Education Curriculum in Brazil, (iii) the need for a lightweight virtual tool that can be freely shared and used, as many available tools charge fees, and (iv) the practical application of knowledge by licentiate degree students in Computer Science, encompassing both learning theories and software development, through the evaluation of the tool. This research aims to develop and evaluate a lightweight web tool through a case study in the context of supporting feedback for programming activities in Brazilian higher education. Additionally, the study investigates whether the feedback is considered the main problem for first-year students in computer courses from the perspective of licentiate computer science students and whether their participation in the case study can improve their skills and abilities in analyzing educational tools. A total of 16 students and three professors from four disciplines participated in the case study, with an online questionnaire as the main instrument for data collection. The analysis was performed considering the collected responses' quantitative and qualitative aspects. We obtained quantitative responses through a Likert scale, while qualitative aspects were analyzed using the Discourse Unveiling Method (UDUM). Positive aspects were identified for both professors and students, providing initial evidence of the tool's potential. Moreover, the study highlighted important feedback from undergraduate Computer Science students, which provides an opportunity to apply their knowledge technically.",
    "abstract_processed": "high school undergradu cours present sever problem regard teach program perspect sever factor led develop tool support program disciplin includ persist problem teach program worldwid ii inclus comput think program practic new basic educ curriculum brazil iii need lightweight virtual tool freeli share use mani avail tool charg fee iv practic applic knowledg licenti degre student comput scienc encompass learn theori softwar develop evalu tool research aim develop evalu lightweight web tool case studi context support feedback program activ brazilian higher educ addit studi investig whether feedback consid main problem first year student comput cours perspect licenti comput scienc student whether particip case studi improv skill abil analyz educ tool total student three professor four disciplin particip case studi onlin questionnair main instrument data collect analysi perform consid collect respons quantit qualit aspect obtain quantit respons likert scale qualit aspect analyz use discours unveil method udum posit aspect identifi professor student provid initi evid tool potenti moreov studi highlight import feedback undergradu comput scienc student provid opportun appli knowledg technic"
  },
  {
    "doc_id": "10343392",
    "abstract_original": "There has been a limited number of studies in which a computing curriculum is designed and developed for students with Autism Spectrum Disorders (ASD), but no study has tested the effectiveness of an accessible computing curriculum for students with Autism Spectrum Disorder (ASD). Therefore, the objectives of this study are to evaluate the effectiveness of such a computing curriculum in improving the learning of computational thinking concepts (CTCs: flow control, data representation, abstraction, user-interactivity, synchronization, parallelism, and logic) by comparing computing projects developed by two groups of students (Potential Development Middle School (PDMS) and Rich Center for Autism (RCA)) of twenty-one students with ASD and by investigating the progressive improvement of a total of 312 computing projects developed by students (138 in PDMS and 174 in RCA) over 20 sessions. Students in both groups were equal in their knowledge of CTCs at the pretest, and RCA and PDMS groups were taught utilizing the accessible and original CT curriculums, respectively, in this experimental study. The results showed that the original CT curriculum was statistically significantly more effective in learning of logic. Additionally, when all seven CTCs as a single construct were examined, the original CT curriculum was statistically significantly more effective than the accessible one. Furthermore, an investigation of the gradual increase in students' computing project scores throughout 20 sessions showed that both curriculums were statistically significantly effective in progressively improving students' learning of data representation, abstraction, synchronization, parallelism, and all CTCs as a single construct. When the correlations between CTCs and sessions for individual groups (PDMS & RCA) were analyzed, both curriculums were statistically significantly effective in increasing scores of synchronization and all CTCs as a single construct. The accessible and the original CT curriculums were also statistically significantly effective in improving students' learning of data representation and abstraction, respectively.",
    "abstract_processed": "limit number studi comput curriculum design develop student autism spectrum disord asd studi test effect access comput curriculum student autism spectrum disord asd therefor object studi evalu effect comput curriculum improv learn comput think concept ctc flow control data represent abstract user interact synchron parallel logic compar comput project develop two group student potenti develop middl school pdm rich center autism rca twenti one student asd investig progress improv total comput project develop student pdm rca session student group equal knowledg ctc pretest rca pdm group taught util access origin ct curriculum respect experiment studi result show origin ct curriculum statist significantli effect learn logic addit seven ctc singl construct examin origin ct curriculum statist significantli effect access one furthermor investig gradual increas student comput project score throughout session show curriculum statist significantli effect progress improv student learn data represent abstract synchron parallel ctc singl construct correl ctc session individu group pdm rca analyz curriculum statist significantli effect increas score synchron ctc singl construct access origin ct curriculum also statist significantli effect improv student learn data represent abstract respect"
  },
  {
    "doc_id": "10343438",
    "abstract_original": "This innovative practice work in progress paper discusses the integration of Model-Eliciting Activities (MEA) into in software engineering (SE) classes, and the challenges faced in preparing and delivering these activities. The preparation and implementation of MEA in SE classes can be challenging, as it requires creating self-assessable MEA questions that simulate real-world problems, ensuring the integration of MEA in SE course topics, providing feedback, and analyzing learning outcomes. In this research, the authors address these challenges and gain practical experience in designing and implementing MEA in SE classes. The authors conducted experiments over two consecutive semesters in SE courses that cover topics such as requirement solicitation, design and implementation, software testing techniques, secure software, and software quality assurance. They incorporated MEA questions that simulate real-world problems into both face-to-face and online classes, ensuring the integration of MEA in SE course topics, providing feedback, and analyzing the learning gains. This paper contributes to the distribution of MEA application for SE courses. It presents the authors' experiences, challenges, reports evaluations, and findings in implementing MEA in SE courses. Overall, this paper provides insights into the effective integration of MEA into SE courses, and the benefits it can bring to students' learning outcomes.",
    "abstract_processed": "innov practic work progress paper discuss integr model elicit activ mea softwar engin se class challeng face prepar deliv activ prepar implement mea se class challeng requir creat self assess mea question simul real world problem ensur integr mea se cours topic provid feedback analyz learn outcom research author address challeng gain practic experi design implement mea se class author conduct experi two consecut semest se cours cover topic requir solicit design implement softwar test techniqu secur softwar softwar qualiti assur incorpor mea question simul real world problem face face onlin class ensur integr mea se cours topic provid feedback analyz learn gain paper contribut distribut mea applic se cours present author experi challeng report evalu find implement mea se cours overal paper provid insight effect integr mea se cours benefit bring student learn outcom"
  },
  {
    "doc_id": "10343467",
    "abstract_original": "Generative models are now capable of producing natural language text that is, in some cases, comparable in quality to the text produced by people. In the computing education context, these models are being used to generate code, code explanations, and programming exercises. The rapid adoption of these models has prompted multiple position papers and workshops which discuss the implications of these models for computing education, both positive and negative. This paper presents results from a series of semi-structured interviews with 12 students and 6 instructors about their awareness, experiences, and preferences regarding the use of tools powered by generative AI in computing classrooms. The results suggest that Generative AI (GAI) tools will play an increasingly significant role in computing education. However, students and instructors also raised numerous concerns about how these models should be integrated to best support the needs and learning goals of students. We also identified interesting tensions and alignments that emerged between how instructors and students prefer to engage with these models. We discuss these results and provide recommendations related to curriculum development, assessment methods, and pedagogical practice. As GAI tools become increasingly prevalent, it's important to understand educational stakeholders' preferences and values to ensure that these tools can be used for good and that potential harms can be mitigated.",
    "abstract_processed": "gener model capabl produc natur languag text case compar qualiti text produc peopl comput educ context model use gener code code explan program exercis rapid adopt model prompt multipl posit paper workshop discuss implic model comput educ posit neg paper present result seri semi structur interview student instructor awar experi prefer regard use tool power gener ai comput classroom result suggest gener ai gai tool play increasingli signific role comput educ howev student instructor also rais numer concern model integr best support need learn goal student also identifi interest tension align emerg instructor student prefer engag model discuss result provid recommend relat curriculum develop assess method pedagog practic gai tool becom increasingli preval import understand educ stakehold prefer valu ensur tool use good potenti harm mitig"
  },
  {
    "doc_id": "10343475",
    "abstract_original": "This work-in-progress paper will explore the effectiveness of topic modeling to support the analysis of Colombian teachers' conceptions of computational thinking (in Spanish) in an online professional development program. Computational thinking has become a form of literacy as it can help individuals to solve problems. Consequently, governments and bodies of accreditation worldwide have supported educational initiatives, primarily at the K-12 level. However, curricular changes are not enough. Teachers need to be prepared, so they develop the content knowledge associated with computational thinking concepts, practices, and applications in the classroom. To contribute to professional development opportunities geared toward the development of computational thinking pedagogical content knowledge, the Colombian National Academy of Exact, Physics, and Natural Sciences and the Global Center for Equitable Computer Science Education implemented an open online professional development program for Latin American early childhood and elementary educators. More than 100 teachers enrolled in a six-week online professional development program to integrate computational thinking activities from early childhood education. The program included two modules focused on conceptual understanding of computational thinking in early childhood and four more modules where the participants adapted, designed, implemented learning activities, and reflected on what happened during the implementation. As part of the participants' weekly interactions, the program included a Jamboard space, where the teachers answered a set of guiding questions, just like a discussion forum, but as a post-it wall, where they could access all their peers' contributions and questions in a single space.",
    "abstract_processed": "work progress paper explor effect topic model support analysi colombian teacher concept comput think spanish onlin profession develop program comput think becom form literaci help individu solv problem consequ govern bodi accredit worldwid support educ initi primarili k level howev curricular chang enough teacher need prepar develop content knowledg associ comput think concept practic applic classroom contribut profession develop opportun gear toward develop comput think pedagog content knowledg colombian nation academi exact physic natur scienc global center equit comput scienc educ implement open onlin profession develop program latin american earli childhood elementari educ teacher enrol six week onlin profession develop program integr comput think activ earli childhood educ program includ two modul focus conceptu understand comput think earli childhood four modul particip adapt design implement learn activ reflect happen implement part particip weekli interact program includ jamboard space teacher answer set guid question like discuss forum post wall could access peer contribut question singl space"
  },
  {
    "doc_id": "10343492",
    "abstract_original": "This study focused on a bachelor- university-level course that aims to design and implement a robotic-coding camp to train pre-service teachers. Seventeen pre-service teachers participated in this study conducted in the Computational Empowerment Lab at the Center of Teacher Education at the University of Vienna. The researchers aimed to identify specific improvement strategies for in-service and pre-service teachers to enhance their pedagogical practices in designing a robotic-coding camp by promoting student critical thinking, computational thinking, and problem-solving competencies. Additionally, the study proposed to identify the relevant features of the camp's design and implementation that can promote practitioners' engagement and address the challenges they face. The course was offered during the summer semester of 2023. For the procedure of the study, pre-service teachers thought about a problem or situation using the phenomena-based learning method and explained the problem using mediating tools, including educational robots, 3D printers, laser-cutting, and creative Lego boxes, among others. At the end of the course, students developed their project, designed a prototype of a robotic-coding camp, and created digital stories as real-world basis problem statements for their project. Students' assignments and group work interactions, including forum discussions in Moodle, reflection papers, and hands-on activities, were used as data sources. Data collected and analyzed by qualitatively. Participatory action research was used as a research method. The results provide guidelines for how to design and implement robotic coding camps and digital stories for teachers who might want to implement a robotic camp in their future careers. In addition, the results suggest improvement strategies for designing robotic coding activities, including four action steps: (1) phenomenon-based problem statement, (2) visualizing the problem as a digital story, (3) finding a pattern in the problem and (4) creating the learning environment and coding. The most challenging part was the third step, in which participant had difficulty finding a pattern within the problem.",
    "abstract_processed": "studi focus bachelor univers level cours aim design implement robot code camp train pre servic teacher seventeen pre servic teacher particip studi conduct comput empower lab center teacher educ univers vienna research aim identifi specif improv strategi servic pre servic teacher enhanc pedagog practic design robot code camp promot student critic think comput think problem solv compet addit studi propos identifi relev featur camp design implement promot practition engag address challeng face cours offer summer semest procedur studi pre servic teacher thought problem situat use phenomena base learn method explain problem use mediat tool includ educ robot printer laser cut creativ lego box among other end cours student develop project design prototyp robot code camp creat digit stori real world basi problem statement project student assign group work interact includ forum discuss moodl reflect paper hand activ use data sourc data collect analyz qualit participatori action research use research method result provid guidelin design implement robot code camp digit stori teacher might want implement robot camp futur career addit result suggest improv strategi design robot code activ includ four action step phenomenon base problem statement visual problem digit stori find pattern problem creat learn environ code challeng part third step particip difficulti find pattern within problem"
  },
  {
    "doc_id": "10343516",
    "abstract_original": "This practice work-in-progress paper describes an innovative laboratory course designed to introduce a heterogenous cohort of undergraduate students from various fields of engineering and science to the principles of designing and analyzing complex electronic systems. The course utilizes a self-developed drum machine as a visual and acoustic project with a gradually increasing level of complexity throughout the lab sessions. Through active participation students acquire an understanding of SPICE simulations, test & measurement equipment, and printed circuit board (PCB) assembly. The course is mandatory for students pursuing a bachelor's degree in electrical, mechatronic, biomedical, computational, and information system engineering, and is also attended as an optional module by computer science and physics students. In the winter term of 2022, the course returned to the lab after the COVID-19 pandemic and was attended by more than 200 students. The laboratory experiments are supported by complementary activities, such as SPICE simulations of the circuits as preparation, and lab reports written in LaTeX to introduce the students to scientific writing. Instructional videos and consultation hours are offered to assist with SPICE simulation and LaTeX. During the physical lab sessions, students work in groups of three in a traditional laboratory environment, with student tutors available to provide guidance offered in the form of minimal help. Overall, the presented lab course is an innovative and engaging method of teaching electronic systems. The self-developed drum machine provides a visually and audibly stimulating project, allowing students to learn practical skills and develop their theoretical knowledge.",
    "abstract_processed": "practic work progress paper describ innov laboratori cours design introduc heterogen cohort undergradu student variou field engin scienc principl design analyz complex electron system cours util self develop drum machin visual acoust project gradual increas level complex throughout lab session activ particip student acquir understand spice simul test measur equip print circuit board pcb assembl cours mandatori student pursu bachelor degre electr mechatron biomed comput inform system engin also attend option modul comput scienc physic student winter term cours return lab covid pandem attend student laboratori experi support complementari activ spice simul circuit prepar lab report written latex introduc student scientif write instruct video consult hour offer assist spice simul latex physic lab session student work group three tradit laboratori environ student tutor avail provid guidanc offer form minim help overal present lab cours innov engag method teach electron system self develop drum machin provid visual audibl stimul project allow student learn practic skill develop theoret knowledg"
  },
  {
    "doc_id": "10343639",
    "abstract_original": "The educational system's trajectory has shifted dramatically in recent years. The introduction of chatbots and artificial intelligence (AI) techniques has mostly pushed the trend. Fundamentally, these methods are intended to improve the culture and experience of teaching and learning. However, there are risks associated with these technologies. The risks of using AI chatbots in the education of future engineering graduates are severely examined in this systematic review. This review identifies and addresses pedagogical, ethical, technological, and socio-cultural dangers that may come from the widespread use of AI chatbots based on an intensive review of the available research. The findings provide useful insights for educators, institutions, and policymakers as they manage the hurdles of implementing AI chatbots in engineering education responsibly.",
    "abstract_processed": "educ system trajectori shift dramat recent year introduct chatbot artifici intellig ai techniqu mostli push trend fundament method intend improv cultur experi teach learn howev risk associ technolog risk use ai chatbot educ futur engin graduat sever examin systemat review review identifi address pedagog ethic technolog socio cultur danger may come widespread use ai chatbot base intens review avail research find provid use insight educ institut policymak manag hurdl implement ai chatbot engin educ respons"
  },
  {
    "doc_id": "10343685",
    "abstract_original": "First engineering and science formation units (blocks) of Tec21 competences-based model [1], defined by Tecnologico de Monterrey, include students solving a real challenge supported by knowledge obtained in modules on mathematics, physics, and computing. A new challenge \"Design, construction and modeling of a water-powered rocket\" was proposed for the F1007B \"Modeling in Engineering with Conservation Laws\" block. This challenge involves designing, modeling and construction of a rocket, powered by a jet of water due to the pressure of a hand pump. Students compete in teams to achieve the greatest distance with their rockets. The educational intention of this challenge is to enhance student learning experience by (1) Covering many more topics of Physics that can been applied by students (2) Improve students grades and professor evaluation, (3) Increasing the use of technology by incorporating the Tracker program for video analysis, (4) Enabling comparison of real results with those obtained through MATLAB modeling, and (5) Fostering enthusiasm among students by facilitating teams’ competition within the same class and even among different campuses. Considering the analysis made, it was observed that the water rocket contest helped most of the students to better understand the concepts of Physics included in this block and in the previous block, F1006B \"Modeling the Movement in Engineering\". The topics in this unit include the Principle of conservation of energy, the Principle of conservation of lineal momentum, Bernoulli’s Principle, Projectile motion and Air friction. A large percentage of students consider that this activity was good for using technological tools such as Matlab (72%) or Tracker (84%) and to compare theory with reality. A good number of students believe that this challenge helped them develop and implement solutions, demonstration of operation of engineering systems and devices, written language, and scientific thinking competences. It can be concluded that this rocket contest challenge is a good educational innovation since it incorporates a change in the materials, methods, contents and contexts involved in the formation unit.",
    "abstract_processed": "first engin scienc format unit block tec compet base model defin tecnologico de monterrey includ student solv real challeng support knowledg obtain modul mathemat physic comput new challeng design construct model water power rocket propos f b model engin conserv law block challeng involv design model construct rocket power jet water due pressur hand pump student compet team achiev greatest distanc rocket educ intent challeng enhanc student learn experi cover mani topic physic appli student improv student grade professor evalu increas use technolog incorpor tracker program video analysi enabl comparison real result obtain matlab model foster enthusiasm among student facilit teams’ competit within class even among differ campus consid analysi made observ water rocket contest help student better understand concept physic includ block previou block f b model movement engin topic unit includ principl conserv energi principl conserv lineal momentum bernoulli’ principl projectil motion air friction larg percentag student consid activ good use technolog tool matlab tracker compar theori realiti good number student believ challeng help develop implement solut demonstr oper engin system devic written languag scientif think compet conclud rocket contest challeng good educ innov sinc incorpor chang materi method content context involv format unit"
  },
  {
    "doc_id": "10343894",
    "abstract_original": "With the introduction of distance learning during the lockdown, teachers faced a number of problems on how to implement the teaching. Educational robotics was particularly negatively affected by this period. In our country, educational robotics is usually taught in informatics classes. However, in many schools, the teaching of informatics during the lockdown was very limited and often focused only on basic digital skills. As a similar situation occurred in several European countries, the idea of supporting teachers in such cases was proposed. Within an international project we are involved in, a methodology is being designed to develop computational thinking in students at all school levels through educational robotics in combination with a school arts subject. The methodology is based on the idea of project-based learning and should use blended learning methods. In this paper, we describe the planning and the course of an educational activity – a project – using the currently developed methodology. The results presented are from its pilot validation with lower-secondary students without previous experience with robotics. The project combined the theme of Greek myths with robotics using LEGO SPIKE Prime. During the validation, we focused primarily on students’ work with basic programming concepts. Our research problem was to validate the quality and potential of the proposed methodology and the computational thinking skills it can develop. The paper concludes with recommendations for further development of the methodology and also for the use of the selected robotic kit with respect to programming in informatics classes.",
    "abstract_processed": "introduct distanc learn lockdown teacher face number problem implement teach educ robot particularli neg affect period countri educ robot usual taught informat class howev mani school teach informat lockdown limit often focus basic digit skill similar situat occur sever european countri idea support teacher case propos within intern project involv methodolog design develop comput think student school level educ robot combin school art subject methodolog base idea project base learn use blend learn method paper describ plan cours educ activ – project – use current develop methodolog result present pilot valid lower secondari student without previou experi robot project combin theme greek myth robot use lego spike prime valid focus primarili students’ work basic program concept research problem valid qualiti potenti propos methodolog comput think skill develop paper conclud recommend develop methodolog also use select robot kit respect program informat class"
  },
  {
    "doc_id": "10343925",
    "abstract_original": "The push to develop low-stakes and personally meaningful computer science experiences is creating novel opportunities to broaden participation in CS. These opportunities have become increasingly present across contexts and have expanded the possibilities for introducing and sustaining student participation in computing. However, while these experiences tend to be effective ways for engaging new participants and new forms of participation, we must be careful to not overlook how ’high-stakes’ these experiences might be for learners. To explore this tension, this paper describes two case studies of students engaging in coding and computational thinking with Minecraft Education Edition. The first case study involves a 7-year-old Black and Latina girl who experiences significant frustration when her computer program destroys significant portions of her project. The second is from a Latino boy who avoids using the coding capabilities in Minecraft EDU out of fear that the code might not work properly. Building on these case studies, this paper suggests that the field take steps to ensure that the language and actions associated with low-stakes and high-stakes are reflective of learner perceptions, and that we design learning experiences that appropriately reflect this nuance.",
    "abstract_processed": "push develop low stake person meaning comput scienc experi creat novel opportun broaden particip cs opportun becom increasingli present across context expand possibl introduc sustain student particip comput howev experi tend effect way engag new particip new form particip must care overlook ’high stakes’ experi might learner explor tension paper describ two case studi student engag code comput think minecraft educ edit first case studi involv year old black latina girl experi signific frustrat comput program destroy signific portion project second latino boy avoid use code capabl minecraft edu fear code might work properli build case studi paper suggest field take step ensur languag action associ low stake high stake reflect learner percept design learn experi appropri reflect nuanc"
  },
  {
    "doc_id": "10344311",
    "abstract_original": "3D printing is a contemporary method of three-dimensional objects’ production. Prior to the printing, the object must be designed in the form of its 3D model - a virtual spatial body. The model is then transferred into a computer program which will control the printing process. Finally, the object is composed using a stepwise addition of micro-particles (grains).3D printing is very appropriate for the individualized production i.e. for fabricating unique objects or those done in small series. A typical lifecycle of these objects is \"Design it – Produce it – Make use of it\". A growing interest in this extent of production requires preparing enough 3D-printing specialists in a variety disciplines. In our presentation, we discuss what professionals are needed and what modifications of contemporary schooling would fulfil these requirements to a maximum degree.",
    "abstract_processed": "print contemporari method three dimension objects’ product prior print object must design form model virtual spatial bodi model transfer comput program control print process final object compos use stepwis addit micro particl grain print appropri individu product e fabric uniqu object done small seri typic lifecycl object design – produc – make use grow interest extent product requir prepar enough print specialist varieti disciplin present discuss profession need modif contemporari school would fulfil requir maximum degre"
  },
  {
    "doc_id": "10345555",
    "abstract_original": "While computational thinking arises as an essential skill worldwide, formal primary and secondary education in Latin America rarely incorporates mechanisms to develop it in their curricula. The extent to which students in the region acquire computational thinking skills remains largely unknown. To start addressing this void, this article presents findings from a cross sectional study that characterizes the computational thinking abilities of incoming students at a Chilean university with a strong emphasis on STEM disciplines. Based on more than 500 responses, this study provides evidence of significant inequalities in computational thinking across gender, type of school (private or no), and prior programming knowledge. The discussion offers insights into how these disparities relate to contextual factors of the country, such as a highly socio-economically segregated educational system, public policies focused mainly on technology access, and heavy reliance on voluntary initiatives, to develop computational thinking. The findings can enlighten upcoming research endeavors and formulate strategies to create a more equitable field for students entering STEM degrees in nations facing similar circumstances.",
    "abstract_processed": "comput think aris essenti skill worldwid formal primari secondari educ latin america rare incorpor mechan develop curricula extent student region acquir comput think skill remain larg unknown start address void articl present find cross section studi character comput think abil incom student chilean univers strong emphasi stem disciplin base respons studi provid evid signific inequ comput think across gender type school privat prior program knowledg discuss offer insight dispar relat contextu factor countri highli socio econom segreg educ system public polici focus mainli technolog access heavi relianc voluntari initi develop comput think find enlighten upcom research endeavor formul strategi creat equit field student enter stem degre nation face similar circumst"
  },
  {
    "doc_id": "10346668",
    "abstract_original": "The analysis of personality behavior has become important in many applications such as educational hypermedia systems, psychotherapy, and business recommendation systems. With the development of social media platforms (SMPs), people can express their feelings and opinions through their personal posts, comments and/or tweets. This study aims to analyze texts on SMPs to identify users' personalities according to the Myers-Briggs Type Indicator (MBTI) model. It also sought to enhance prediction accuracy and compare the findings with various deep learning techniques and previous literature. This study analyzes personality through a dataset that includes 8667 participants. Two deep learning techniques are implemented namely, long short-term memory (LSTM) and convolutional neural network (CNN). Unlike earlier literature, this research helps improve the prediction accuracy of users' personalities by building a multi-layer deep learning network and integrating the random search optimization approach. The results suggest that LSTM with the application of random search optimization outperformed previous findings. The average prediction accuracy of the four dimensions namely, Introversion-Extroversion (IE), Feeling-Thinking (FT), Intuition-Sensing (NS), and Judging-Perceiving (JP) is 85.02%.",
    "abstract_processed": "analysi person behavior becom import mani applic educ hypermedia system psychotherapi busi recommend system develop social media platform smp peopl express feel opinion person post comment tweet studi aim analyz text smp identifi user person accord myer brigg type indic mbti model also sought enhanc predict accuraci compar find variou deep learn techniqu previou literatur studi analyz person dataset includ particip two deep learn techniqu implement name long short term memori lstm convolut neural network cnn unlik earlier literatur research help improv predict accuraci user person build multi layer deep learn network integr random search optim approach result suggest lstm applic random search optim outperform previou find averag predict accuraci four dimens name introvers extrovers ie feel think ft intuit sens ns judg perceiv jp"
  },
  {
    "doc_id": "10346935",
    "abstract_original": "We intend to present a thorough analysis of the security concerns surrounding unmanned aerial vehicles and concepts that are addressed in this paper. The following is a summary of our significant contributions. We clarified the history of UAVs while emphasizing the key elements that define theUAV system. We offer the first thorough classification of UAV security concerns into four categories: sensor-related, hardware- related, software-related, and communication-related. We look into typical weaknesses, threats, assaults, and available counter-measures for each domain. We think that this categorization can provide a starting point for upcoming researchers looking into the security of UAVs. We stress the quantitative findings of the surveyed papers on the throughout our survey..",
    "abstract_processed": "intend present thorough analysi secur concern surround unman aerial vehicl concept address paper follow summari signific contribut clarifi histori uav emphas key element defin theuav system offer first thorough classif uav secur concern four categori sensor relat hardwar relat softwar relat commun relat look typic weak threat assault avail counter measur domain think categor provid start point upcom research look secur uav stress quantit find survey paper throughout survey"
  },
  {
    "doc_id": "10349017",
    "abstract_original": "The purpose of this study is to apply the Simplified Pivot Pairwise Relative Criteria Importance Assessment (PIPRECIA-S) weighting model with ranking criteria or priorities in determining Employee Performance Evaluation. The method used for the assessment of employee performance evaluation is the center of ranking and ranking order using Multi-Attribute Utility Theory (MAUT), so as to produce rankings that can be compared with the best alternative results with weighted values generated by each method. To apply the MAUT approach in decision support systems, the determination of employee performance evaluation assessment has the criteria of initiative, team working ability, communication skills, discipline, responsibility, creativity and innovation, customer service, and commitment to company values. This research aims at evaluating employee performance using MAUT and PIPRECIA-S in order to weight the criteria based on the assessment of decision makers more objectively. Based on the process of completing the application of the MAUT method using PIPRECIA-S weighting in the assessment of employee performance evaluation, among the 6 employees as the subjects of the research, the best performance was obtained by employee 4 with a final score of 0.435 as rank 1, and rank 2 was obtained by Employee 1 with a final score of 0.328, while rank 3 was obtained by Employee 3 with a final score of 0.251.",
    "abstract_processed": "purpos studi appli simplifi pivot pairwis rel criteria import assess piprecia weight model rank criteria prioriti determin employe perform evalu method use assess employe perform evalu center rank rank order use multi attribut util theori maut produc rank compar best altern result weight valu gener method appli maut approach decis support system determin employe perform evalu assess criteria initi team work abil commun skill disciplin respons creativ innov custom servic commit compani valu research aim evalu employe perform use maut piprecia order weight criteria base assess decis maker object base process complet applic maut method use piprecia weight assess employe perform evalu among employe subject research best perform obtain employe final score rank rank obtain employe final score rank obtain employe final score"
  },
  {
    "doc_id": "10350990",
    "abstract_original": "This paper introduces Qatent PatFig, a novel large-scale patent figure dataset comprising 30,000+ patent figures from over 11,000 European patent applications. For each figure, this dataset provides short and long captions, reference numerals, their corresponding terms, and the minimal claim set that describes the interactions between the components of the image. To assess the usability of the dataset, we finetune an LVLM model on Qatent PatFig to generate short and long descriptions, and we investigate the effects of incorporating various text-based cues at the prediction stage of the patent figure captioning process.",
    "abstract_processed": "paper introduc qatent patfig novel larg scale patent figur dataset compris patent figur european patent applic figur dataset provid short long caption refer numer correspond term minim claim set describ interact compon imag assess usabl dataset finetun lvlm model qatent patfig gener short long descript investig effect incorpor variou text base cue predict stage patent figur caption process"
  },
  {
    "doc_id": "10351197",
    "abstract_original": "Visible Light Communication (VLC) is a technology where light is used to transfer data. Just think of it, where light can be used as a medium of data communication and it is also a source of light (vision). How easy our work would be, the VLC technology is mostly used in indoor communication. The reason for this technology to evolve is the increasing number of crimes. In the present day, the number of internet users are more, there is no work done without the help of the internet. Due to this, the possibility of cyberattacks is more. Most of our personal data and confidential information is lost due to cyberattacks. The companies have faced a lot of financial losses because of it. The data transfer in VLC cannot be hacked easily. It is least prone for the attacks to take placeas communication is mostly indoors. In this paper, we have realized VLC in SISO and $\\mathbf{4}\\times \\mathbf{4}$ MIMO configurations. It is observed that the $\\mathbf{4}\\times \\mathbf{4}$ MIMO configuration outperforms SISO in terms of Bit error rate and Quality Factor.",
    "abstract_processed": "visibl light commun vlc technolog light use transfer data think light use medium data commun also sourc light vision easi work would vlc technolog mostli use indoor commun reason technolog evolv increas number crime present day number internet user work done without help internet due possibl cyberattack person data confidenti inform lost due cyberattack compani face lot financi loss data transfer vlc cannot hack easili least prone attack take placea commun mostli indoor paper realiz vlc siso \\mathbf \\time \\mathbf mimo configur observ \\mathbf \\time \\mathbf mimo configur outperform siso term bit error rate qualiti factor"
  },
  {
    "doc_id": "10351244",
    "abstract_original": "Sleep plays a parallel role in maintaining good health as diet and exercise. It not only improves the performance of our brain but also manages our mood swings and maintains our health. Not getting proper hours of sleep on a regular basis may become the reason for many disorders and diseases. Stress often impacts the sleep cycle of an individual resulting in a severe impact on their physical and mental health. Stress even affects the cognitive functioning of an individual, which refers to the mental processes involving memory management, decision thinking, etc. So, eventually, stress becomes a common factor for both. This study proposes an approach helping individuals to reduce stress by turning towards a proper sleep cycle eventually resulting in an increase in cognitive functioning. This paper uses the conventional method of machine learning through which it could be justified that as stress increases the number of hours slept by the person decreases. Furthermore, a correlation was established between sleep stress and cognitive functioning through which it could be concluded that sleep affects cognitive functioning. Previous research studies suggest that there is a link between video games and increased cognitive functioning, So, this study proposed the solution as a game named CANDY CRUSH which is much popular among middle age groups as it is easy to learn and can prove to be stress releaser for them eventually leading to better cognitive functioning.",
    "abstract_processed": "sleep play parallel role maintain good health diet exercis improv perform brain also manag mood swing maintain health get proper hour sleep regular basi may becom reason mani disord diseas stress often impact sleep cycl individu result sever impact physic mental health stress even affect cognit function individu refer mental process involv memori manag decis think etc eventu stress becom common factor studi propos approach help individu reduc stress turn toward proper sleep cycl eventu result increas cognit function paper use convent method machin learn could justifi stress increas number hour slept person decreas furthermor correl establish sleep stress cognit function could conclud sleep affect cognit function previou research studi suggest link video game increas cognit function studi propos solut game name candi crush much popular among middl age group easi learn prove stress releas eventu lead better cognit function"
  },
  {
    "doc_id": "10351292",
    "abstract_original": "The paper aims to present the real current situation of the state of education being provided by various schools in rural areas of the central Indian district of Yavatmal in the state of Maharashtra situated in India. Also, the paper is an attempt to analyze the data using simple analytical tools from an artificial intelligence perspective to predict various parameters indicating the future shape and direction of education is going to in these rural parts of mainland India. The study is based on real survey data collected by visiting numerous schools after receiving written permission from the Block Development Officer of Tehsil Yavatmal. The initial emphasis was on girl education but has been generalized to boys as well because of the coeducation system. The process involved talks on the state of the art of education and collection of data from respective heads of the school followed by interviews with schoolteachers, nonteaching staff, and students. The study is represented in the form of graphs, inferences, and observations on the complicated way ahead, for education to reach these deprived large chunks of people, who think that their future is their children and education is the only key responsible for new light to come to their lives. The paper includes the developmental stages Indian education passed through from pre-independence to recent times.",
    "abstract_processed": "paper aim present real current situat state educ provid variou school rural area central indian district yavatm state maharashtra situat india also paper attempt analyz data use simpl analyt tool artifici intellig perspect predict variou paramet indic futur shape direct educ go rural part mainland india studi base real survey data collect visit numer school receiv written permiss block develop offic tehsil yavatm initi emphasi girl educ gener boy well coeduc system process involv talk state art educ collect data respect head school follow interview schoolteach nonteach staff student studi repres form graph infer observ complic way ahead educ reach depriv larg chunk peopl think futur children educ key respons new light come live paper includ development stage indian educ pass pre independ recent time"
  },
  {
    "doc_id": "10351308",
    "abstract_original": "Humans frequently communicate effectively using their faces in addition to their words. The use of computer vision techniques to categorize face emotion has been extensively studied. Given the difficulties and restrictions of databases, such as the use of static data or facial capture in artificial contexts, these have had different degrees of success. As a result, we think that novel preprocessing methods are necessary to increase the precision of facial expression detection models. In this study, we suggest a novel, yet straightforward, approach to improving the precision of face emotion identification. Our research was done using the FER2013 dataset, which includes static facial photos of 7 basic emotions. Resizing and Normalization image preprocessing techniques were applied on the dataset prior to the splitting into train and test sets. The training images were split into train and test sets in the ratios of 75% and 25% respectively. The facial expressions in the photos were classified using Convolution Neural Networks [CNNs], with an accuracy of 76.75% on the test set.",
    "abstract_processed": "human frequent commun effect use face addit word use comput vision techniqu categor face emot extens studi given difficulti restrict databas use static data facial captur artifici context differ degre success result think novel preprocess method necessari increas precis facial express detect model studi suggest novel yet straightforward approach improv precis face emot identif research done use fer dataset includ static facial photo basic emot resiz normal imag preprocess techniqu appli dataset prior split train test set train imag split train test set ratio respect facial express photo classifi use convolut neural network cnn accuraci test set"
  },
  {
    "doc_id": "10351450",
    "abstract_original": "The relationship between artificial intelligence (AI) and mental health care, recognizing both its immense potential and associated challenges. It offers an in-depth analysis of AI tools tailored to establish personalized environments, aiding individuals in understanding their emotions, monitoring mental well-being, and accessing essential mental health support. Through the fusion of Natural Language Processing (NLP) and AI, the paper suggests a seamless merging of AI's core capabilities with the empathetic domain of mental health care. The integration of AI and mental health care revolves around providing individuals with virtual spaces that facilitate introspective self-analysis and effective emotional management. Empowered by advanced AI algorithms, these tools enable users to identify patterns and triggers influencing their mental health. The synergy of NLP and AI enriches this integration, allowing for the interpretation of textual and emotional cues, thereby fostering nuanced understanding and tailored assistance. The article underscores the importance of responsible development in AI-powered mental health tools. It advocates for collaborative partnerships between mental health experts and AI specialists, ensuring the infusion of ethical considerations, privacy safeguards, and clinical expertise into AI technologies. The overarching goal is to create AI-driven mental health solutions that not only demonstrate effectiveness and precision but also ensure reliability and security. In summary, the article highlights AI's transformative potential in reshaping mental health care, emphasizing the equilibrium between innovation and ethical accountability.",
    "abstract_processed": "relationship artifici intellig ai mental health care recogn immens potenti associ challeng offer depth analysi ai tool tailor establish person environ aid individu understand emot monitor mental well access essenti mental health support fusion natur languag process nlp ai paper suggest seamless merg ai core capabl empathet domain mental health care integr ai mental health care revolv around provid individu virtual space facilit introspect self analysi effect emot manag empow advanc ai algorithm tool enabl user identifi pattern trigger influenc mental health synergi nlp ai enrich integr allow interpret textual emot cue therebi foster nuanc understand tailor assist articl underscor import respons develop ai power mental health tool advoc collabor partnership mental health expert ai specialist ensur infus ethic consider privaci safeguard clinic expertis ai technolog overarch goal creat ai driven mental health solut demonstr effect precis also ensur reliabl secur summari articl highlight ai transform potenti reshap mental health care emphas equilibrium innov ethic account"
  },
  {
    "doc_id": "10351460",
    "abstract_original": "Artificial intelligence (AI), usually referred to as machine intelligence, is a scientific field that gives robots the ability to think like people. AI is a term used to describe a system that simulates human intellect using computer programming. AI is advancing quickly in many multidisciplinary fields, including ophthalmology, from healthcare to the accurate preventive measures, investigation, and treatment plans of illnesses. Because of the emphasis on imaging in the diagnosis of eye illnesses, optometry and ophthalmology is at the forefront of AI in medical field and medicine. Lately, the most prevalent illnesses that cause blindness and visual impairment, such as diabetic retinopathy (DR), have been subjected to deep learning-based AI screening and predictive algorithm models. Deep learning machine with algorithms are the computer models made up of several layers of simulated neurons, are largely responsible for the success of AI in medical field and medicine. These models are capable of learning how data is represented at various levels of abstraction. The trained AI system classified the various forms of DR on optical coherence tomography pictures with accuracy equivalent to that of human specialists. In this study, we focus on the core ideas of AI and how it is applied to the various forms of DR. We also go into further detail on how AI and DL are used in the future of ophthalmology.",
    "abstract_processed": "artifici intellig ai usual refer machin intellig scientif field give robot abil think like peopl ai term use describ system simul human intellect use comput program ai advanc quickli mani multidisciplinari field includ ophthalmolog healthcar accur prevent measur investig treatment plan ill emphasi imag diagnosi eye ill optometri ophthalmolog forefront ai medic field medicin late preval ill caus blind visual impair diabet retinopathi dr subject deep learn base ai screen predict algorithm model deep learn machin algorithm comput model made sever layer simul neuron larg respons success ai medic field medicin model capabl learn data repres variou level abstract train ai system classifi variou form dr optic coher tomographi pictur accuraci equival human specialist studi focu core idea ai appli variou form dr also go detail ai dl use futur ophthalmolog"
  },
  {
    "doc_id": "10355247",
    "abstract_original": "Bryan Johnson is on a quest for zeros. The enigmatic founder of Braintree, former CEO of Venmo, and founder of Kernel, which develops brain measurement and imaging systems, Johnson has made it his mission to discover the kinds of once-in-a-generation factors that radically alter the way we understand the world. He seeks &#x0022;zeros&#x0022;&#x2014;the discovery of fundamental building blocks, tenets, or rules that previously seemed impossible or beyond our vision.<superscript>1</superscript> They&#x0027;re the discovery of something that didn&#x0027;t exist in our limited minds, lingering in an alternate dimension until finally pulled out of the ether and into our field of perception. Albert Einstein&#x0027;s theory of relativity, for instance, set scientists on a new path of stunning breakthroughs in quantum mechanics, astrophysics, and cosmology, but none of those subsequent discoveries opened up the same step-change in scientific thinking as E=3Dmc<superscript>2</superscript>. As these types of life-altering building blocks get defined, new ways of thinking emerge. In the cognitive economy, powerful forms of computational intelligence will accelerate them. For example, the AlphaGo system&#x0027;s radically unexpected moves in its victories over Go world champion Lee Sedol hinted at how deep learning systems could offer other step-change departures from the forces, logic, and patterns we take as gospel.",
    "abstract_processed": "bryan johnson quest zero enigmat founder braintre former ceo venmo founder kernel develop brain measur imag system johnson made mission discov kind gener factor radic alter way understand world seek x zero x x discoveri fundament build block tenet rule previous seem imposs beyond vision superscript superscript x discoveri someth x exist limit mind linger altern dimens final pull ether field percept albert einstein x theori rel instanc set scientist new path stun breakthrough quantum mechan astrophys cosmolog none subsequ discoveri open step chang scientif think e dmc superscript superscript type life alter build block get defin new way think emerg cognit economi power form comput intellig acceler exampl alphago system x radic unexpect move victori go world champion lee sedol hint deep learn system could offer step chang departur forc logic pattern take gospel"
  },
  {
    "doc_id": "10355908",
    "abstract_original": "This article presents a systematic numerical investigation of a surface plasmon resonance (SPR) sensor based on photonic crystal fiber (PCF). The proposed design is modeled and simulated using the full-vectorial finite-element (FV-FEM) technique and sensing characteristics, such as confinement loss (CL) behaviors, phase matching, and sensitivity, which are investigated and presented. The plasmonic layer is made up of TiO2 and gold for improved sensitivity. The reported sensor exhibits an amplitude sensitivity of −374.062 RIU−1 and a wavelength sensitivity of 2000 nm/RIU for the refractive index (RI) sensing range of (1.39–1.44), according to the loss spectrum shift. The reported hoop-cut PCF-based SPR (HPCF-SPR) sensor is suitable for biosensing and chemical sensing applications because of its broad range (1.39–1.44) of analyte detection.",
    "abstract_processed": "articl present systemat numer investig surfac plasmon reson spr sensor base photon crystal fiber pcf propos design model simul use full vectori finit element fv fem techniqu sens characterist confin loss cl behavior phase match sensit investig present plasmon layer made tio gold improv sensit report sensor exhibit amplitud sensit − riu− wavelength sensit nm riu refract index ri sens rang – accord loss spectrum shift report hoop cut pcf base spr hpcf spr sensor suitabl biosens chemic sens applic broad rang – analyt detect"
  },
  {
    "doc_id": "10361064",
    "abstract_original": "Computational thinking (CT) has received increasing attention from educational researchers as a higher-order thinking skill. CT is a key factor that influences the learning process and facilitates the acquisition of knowledge and the improvement of students’ academic performance. However, the mechanisms of how CT affects students’ academic performance have yet to be explored in depth. Based on this, this study used a large-scale questionnaire to construct a model with problem-solving ability and learning anxiety as mediators with 8,134 Chinese elementary school students. The results showed that CT was a significant direct predictor of academic achievement; problem-solving ability and learning anxiety played significant mediator roles between CT and students’ academic achievement. CT can improve students’ problem-solving ability and reduce anxiety, which leads to better academic performance.",
    "abstract_processed": "comput think ct receiv increas attent educ research higher order think skill ct key factor influenc learn process facilit acquisit knowledg improv students’ academ perform howev mechan ct affect students’ academ perform yet explor depth base studi use larg scale questionnair construct model problem solv abil learn anxieti mediat chines elementari school student result show ct signific direct predictor academ achiev problem solv abil learn anxieti play signific mediat role ct students’ academ achiev ct improv students’ problem solv abil reduc anxieti lead better academ perform"
  },
  {
    "doc_id": "10361088",
    "abstract_original": "Computational thinking is advocated as a skill that everyone should possess, and stem content and background can be conducive to the learning of computational thinking. This study constructed a theoretical model of the impact of stem courses on students’ computational thinking, and measured the mediating effects of problem solving skills and stem attitudes on stem courses and students’ computational thinking. The study included a questionnaire of 1870 secondary school students and a descriptive, correlational and mediating analysis. The results show that stem courses can predict students’ computational thinking through students’ problem solving ability and students’ attitude towards stem. The results of this study have a positive reference value for discussing the factors affecting students’ computational thinking, implementing stem course education, improving students’ problem-solving ability and enhancing students’ attitude towards stem.",
    "abstract_processed": "comput think advoc skill everyon possess stem content background conduc learn comput think studi construct theoret model impact stem cours students’ comput think measur mediat effect problem solv skill stem attitud stem cours students’ comput think studi includ questionnair secondari school student descript correl mediat analysi result show stem cours predict students’ comput think students’ problem solv abil students’ attitud toward stem result studi posit refer valu discuss factor affect students’ comput think implement stem cours educ improv students’ problem solv abil enhanc students’ attitud toward stem"
  },
  {
    "doc_id": "10361116",
    "abstract_original": "This paper discusses the application of “Internet +” artificial intelligence in computer network technology. With the development of science and technology, human beings have entered the Internet era, which has changed the traditional way of learning and working, and largely promoted social development. At the same time, the rapid development of artificial intelligence technology, its use in computer network technology, can play an effective role. Firstly, we introduce the content related to artificial intelligence and big data technology, then analyze the advantages of applying it in computer network technology, and finally put forward effective strategies.",
    "abstract_processed": "paper discuss applic “internet ” artifici intellig comput network technolog develop scienc technolog human be enter internet era chang tradit way learn work larg promot social develop time rapid develop artifici intellig technolog use comput network technolog play effect role firstli introduc content relat artifici intellig big data technolog analyz advantag appli comput network technolog final put forward effect strategi"
  },
  {
    "doc_id": "10361211",
    "abstract_original": "AI (Artificial intelligence) has entered a new stage of development, approaching the level of human intelligence as never before in history, from academia to application, from specialty to generality. Natural language processing is one of the main application fields of AI, which has made significant progress in recent years. It combines the progress of language theory and statistics with hardware technology, which makes Machine translation technology have a new change. This paper discusses the Machine translation system based on the intelligent language model. First, the concepts of the intelligent language model and the Machine translation system are introduced respectively. Then, the operation performance of the Machine translation system based on the intelligent language model is verified through experiments. Finally, it shows that the Machine translation system based on the intelligent language model is more meaningful for research.",
    "abstract_processed": "ai artifici intellig enter new stage develop approach level human intellig never histori academia applic specialti gener natur languag process one main applic field ai made signific progress recent year combin progress languag theori statist hardwar technolog make machin translat technolog new chang paper discuss machin translat system base intellig languag model first concept intellig languag model machin translat system introduc respect oper perform machin translat system base intellig languag model verifi experi final show machin translat system base intellig languag model meaning research"
  },
  {
    "doc_id": "10361749",
    "abstract_original": "Interaction is a process in which two or more people exchange thoughts and feelings with each other, transmit information and influence both sides. Class interaction refers to the interaction between teachers, students and students in the special environment of classroom. IoT is a network that connects any goods with the Internet through various information sensing devices according to the agreed protocol, and carries out information exchange and communication, so as to realize intelligent identification, positioning, tracking, monitoring and management. Applying the conceptual model and thinking mode of the Internet of Things (IoT) to English Language Teaching (ELT) can also get good results, which leads to the change of ELT mode. This paper analyzes the shortcomings of the current IoT technology application process, and expounds the application of IoT optimization engine based on RETE algorithm in university ELT process. The simulation results show that the accuracy of IoT optimization engine based on RETE algorithm is higher than that of traditional algorithm. With the increase of the number of experiments, the accuracy of RETE algorithm is stable at about 95%, and the real-time wavelength tends to be stable. Therefore, applying the IoT optimization engine based on RETE algorithm to English interactive teaching can make IoT technology play a more active role in ELT in universities and achieve better implementation effect.",
    "abstract_processed": "interact process two peopl exchang thought feel transmit inform influenc side class interact refer interact teacher student student special environ classroom iot network connect good internet variou inform sens devic accord agre protocol carri inform exchang commun realiz intellig identif posit track monitor manag appli conceptu model think mode internet thing iot english languag teach elt also get good result lead chang elt mode paper analyz shortcom current iot technolog applic process expound applic iot optim engin base rete algorithm univers elt process simul result show accuraci iot optim engin base rete algorithm higher tradit algorithm increas number experi accuraci rete algorithm stabl real time wavelength tend stabl therefor appli iot optim engin base rete algorithm english interact teach make iot technolog play activ role elt univers achiev better implement effect"
  },
  {
    "doc_id": "10361777",
    "abstract_original": "Artificial neural network is an intelligent bionic model based on physiology, which simulates the thinking ability of human brain, and finds out regular things by studying, recalling, summarizing and sorting out a large number of cases. Because of the heterogeneity, distribution and dynamics of grid, traditional resource management methods are not suitable for grid environment. In view of the fact that the traditional resource management model can't meet the demand of service grid, this paper studies the resource management model based on the principles of computational economics and the characteristics of service grid environment, and proposes a resource management model based on computational economics. Most of the traditional economic models based on econometrics are linear models. Although such a model is a powerful economic analysis tool, it also has its own defects, that is, it can not reflect a large number of nonlinear relationships in the economic system. In this paper, an artificial neural network is used to establish a national economic forecasting model. In the process of modeling, immune particle swarm optimization algorithm is used to optimize the weights and thresholds of the neural network model, so that the predicted data of the model is closer to the actual data.",
    "abstract_processed": "artifici neural network intellig bionic model base physiolog simul think abil human brain find regular thing studi recal summar sort larg number case heterogen distribut dynam grid tradit resourc manag method suitabl grid environ view fact tradit resourc manag model meet demand servic grid paper studi resourc manag model base principl comput econom characterist servic grid environ propos resourc manag model base comput econom tradit econom model base econometr linear model although model power econom analysi tool also defect reflect larg number nonlinear relationship econom system paper artifici neural network use establish nation econom forecast model process model immun particl swarm optim algorithm use optim weight threshold neural network model predict data model closer actual data"
  },
  {
    "doc_id": "10361797",
    "abstract_original": "The Hierarchical Inheritance Algorithm (HGA) is an optimization technique inspired by biological principles of natural selection and heredity. This approach is versatile, finding applications in fields such as combinatorial optimization, machine learning, adaptive control, and more. It stands as a cornerstone in the realm of intelligent computing. This study bridges the gap between information technology and progressive management methodologies, aiming to adapt outdated financial management strategies to the demands of a digitalized environment, thereby pioneering a centralized financial management paradigm in the digital realm. The focus of this paper is to explore this digitally-centered financial management framework and propose a design tailored to the online ecosystem. Our findings indicate that the concept of smart finance goes beyond a mere blend of \"AI and finance.\" Implementing its technologies involves a unique methodology that thrives on \"closed-loop thinking.\" By gleaning insights from AI applications in diverse sectors, we've outlined the foundational pillars of smart finance application: digital transformation of specialized financial operations, algorithms rooted in financial logic that are fine-tuned through iterations, the fusion of data analytics within financial operations leading to product-centric solutions, and achieving a significant 90.00% platform integration for these smart financial solutions. As artificial intelligence technology continues to evolve, financial management will undoubtedly gravitate towards being instantaneous, user-centric, and intelligent. This will usher in heightened efficiency and benefits, heralding a new age in financial management.",
    "abstract_processed": "hierarch inherit algorithm hga optim techniqu inspir biolog principl natur select hered approach versatil find applic field combinatori optim machin learn adapt control stand cornerston realm intellig comput studi bridg gap inform technolog progress manag methodolog aim adapt outdat financi manag strategi demand digit environ therebi pioneer central financi manag paradigm digit realm focu paper explor digit center financi manag framework propos design tailor onlin ecosystem find indic concept smart financ goe beyond mere blend ai financ implement technolog involv uniqu methodolog thrive close loop think glean insight ai applic divers sector outlin foundat pillar smart financ applic digit transform special financi oper algorithm root financi logic fine tune iter fusion data analyt within financi oper lead product centric solut achiev signific platform integr smart financi solut artifici intellig technolog continu evolv financi manag undoubtedli gravit toward instantan user centric intellig usher heighten effici benefit herald new age financi manag"
  },
  {
    "doc_id": "10363466",
    "abstract_original": "Microservices have been making waves among forward-thinking application development organizations. In the realm of software development, software architecture holds paramount importance because it serves as a guiding force to shape the entire life cycle of a software system. Software architecture is a foundation for complex digital components built upon a software system. Within this domain, two prevalent paradigms, monolithic and service-oriented architecture (SOA), stand distinct. While monolithic simplifies development using its integrated structure, SOA reduces complexity through modular services. However, both paradigms suffer severe scalability, development cycle, and flexibility challenges. Subsequently, microservice architecture as a modern paradigm emerges to overcome these challenges. This paper presents an in-depth analysis of the paradigm shift from monolithic to microservice architecture. It begins with exploring the monolithic and SOA conceptual landscape and their pros and cons. After that, we delve into the microservice platform, including its basic architecture and implementation stages. Furthermore, we provide the trend of the paradigm shift that highlights the recent developments in the field and identifies the research challenges associated with it. Thus, the paper brings multiple research dimensions for the researchers and lets the software and application development teams improve resilience and expedite their time to market.",
    "abstract_processed": "microservic make wave among forward think applic develop organ realm softwar develop softwar architectur hold paramount import serv guid forc shape entir life cycl softwar system softwar architectur foundat complex digit compon built upon softwar system within domain two preval paradigm monolith servic orient architectur soa stand distinct monolith simplifi develop use integr structur soa reduc complex modular servic howev paradigm suffer sever scalabl develop cycl flexibl challeng subsequ microservic architectur modern paradigm emerg overcom challeng paper present depth analysi paradigm shift monolith microservic architectur begin explor monolith soa conceptu landscap pro con delv microservic platform includ basic architectur implement stage furthermor provid trend paradigm shift highlight recent develop field identifi research challeng associ thu paper bring multipl research dimens research let softwar applic develop team improv resili expedit time market"
  },
  {
    "doc_id": "10366259",
    "abstract_original": "The computing in the network (COIN) paradigm is a promising solution that leverages unused network resources to perform tasks to meet computation-demanding applications, such as the metaverse. In this vein, we consider the partial computation offloading problem in the metaverse for multiple subtasks in a COIN environment to minimize energy consumption and delay while dynamically adjusting the offloading policy based on the changing computational resource status. The problem is NP-hard, and we transform it into two subproblems: the task-splitting problem (TSP) on the user side and the task-offloading problem (TOP) on the COIN side. We model the TSP as an ordinal potential game and propose a decentralized algorithm to obtain its Nash equilibrium (NE). Then, we model the TOP as a Markov decision process and propose the double deep Q-network (DDQN) to solve for the optimal offloading policy. Unlike the conventional DDQN algorithm, where intelligent agents sample offloading decisions randomly within a certain probability, the COIN agent explores the NE of the TSP and the deep neural network. Finally, the simulation results reveal that the proposed model approach allows the COIN agent to update its policies and make more informed decisions, leading to improved performance over time compared to the traditional baseline.",
    "abstract_processed": "comput network coin paradigm promis solut leverag unus network resourc perform task meet comput demand applic metavers vein consid partial comput offload problem metavers multipl subtask coin environ minim energi consumpt delay dynam adjust offload polici base chang comput resourc statu problem np hard transform two subproblem task split problem tsp user side task offload problem top coin side model tsp ordin potenti game propos decentr algorithm obtain nash equilibrium ne model top markov decis process propos doubl deep q network ddqn solv optim offload polici unlik convent ddqn algorithm intellig agent sampl offload decis randomli within certain probabl coin agent explor ne tsp deep neural network final simul result reveal propos model approach allow coin agent updat polici make inform decis lead improv perform time compar tradit baselin"
  },
  {
    "doc_id": "10366351",
    "abstract_original": "The pandemic caused by Covid-19 – Coronavirus forced government authorities to take quick action against the virus, within the framework of these measures, borders, social distancing, confinement, cancellation of face-to-face attendance and implementation of teleworking were interrupted, and effective solutions were sought for the protection of physical health and care of life. However, mental health was neglected, triggering depression, anxiety, different types of violence, suicidal ideation, and action, among other factors. Directly affecting individuals in their environment, emotions, and perceptions. With the understanding of the demands in mental health care, the research team made an interdisciplinary proposal focused on the inhabitants of the department of Cauca, methodologically used a mixed research approach, applying qualitative instruments such as focus groups, debates with experts, discursive analysis; in quantitative, analysis of secondary sources, compilation, and review of reports. As a result, a technological platform was built to favor decision-making by state actors, a virtual learning object, a training process for 210 actors such as technical assistance, installed capacity in the 42 Municipalities of Cauca, a base document for the formulation of public policies in mental health and primary care for 60,000 people through face-to-face visits or teleorientation.",
    "abstract_processed": "pandem caus covid – coronaviru forc govern author take quick action viru within framework measur border social distanc confin cancel face face attend implement telework interrupt effect solut sought protect physic health care life howev mental health neglect trigger depress anxieti differ type violenc suicid ideat action among factor directli affect individu environ emot percept understand demand mental health care research team made interdisciplinari propos focus inhabit depart cauca methodolog use mix research approach appli qualit instrument focu group debat expert discurs analysi quantit analysi secondari sourc compil review report result technolog platform built favor decis make state actor virtual learn object train process actor technic assist instal capac municip cauca base document formul public polici mental health primari care peopl face face visit teleorient"
  },
  {
    "doc_id": "10369475",
    "abstract_original": "In current decades India has knowing a significant decline in land crop depiction generally due to the damaging belongings of feeling change accurate prognosis of crop yield before harvest is essential for laborers and policymakers to make conversant resolutions concerning marketing and depository this project aims to evolve an common prediction method original that allows farmers to estimate crop result before education bureaucracy will feature a user-friendly netting-located graphical interface and engage a machine intelligence invention anticipated effects will be determined to laborers empowering ruling class to create appropriate resolutions based on the news miscellaneous methods and algorithms including the usual chance forest invention will be promoted to resolve essential variables such as weather environments heat dampness rainfall and liquid for land result forecasting furthermore dossier excavating a comprehensive approach to resolving dossier from multiple outlooks will be used to extract valuable judgments random thicket a strong directed machine learning treasure worthy operating classification and reversion tasks builds an ensemble of conclusion trees all along preparation and generates prophecies established the fad of classes classification or the mean prognosis reversion from individual shrubs by integrating these methods this project aims to specify an direct solution for thinking crop yield in India portion of food to address the challenges formal by climate change in the land area",
    "abstract_processed": "current decad india know signific declin land crop depict gener due damag belong feel chang accur prognosi crop yield harvest essenti labor policymak make convers resolut concern market depositori project aim evolv common predict method origin allow farmer estim crop result educ bureaucraci featur user friendli net locat graphic interfac engag machin intellig invent anticip effect determin labor empow rule class creat appropri resolut base news miscellan method algorithm includ usual chanc forest invent promot resolv essenti variabl weather environ heat damp rainfal liquid land result forecast furthermor dossier excav comprehens approach resolv dossier multipl outlook use extract valuabl judgment random thicket strong direct machin learn treasur worthi oper classif revers task build ensembl conclus tree along prepar gener propheci establish fad class classif mean prognosi revers individu shrub integr method project aim specifi direct solut think crop yield india portion food address challeng formal climat chang land area"
  },
  {
    "doc_id": "10370853",
    "abstract_original": "Classifying foetal health is a crucial responsibility in healthcare, and innovative machine learning techniques can be utilised to help. In this instance, K-nearest neighbour, Nave Bayes, and Decision Tree classifiers are used to fine-tune an input picture dataset. The adjustment is done on these classifiers using methods like feature selection, cross-validation, and hyperparameter tweaking. Through the identification of the ideal parameters and feature combinations for your dataset, these strategies assist in improving the performance of the classifiers. To enhance the sustainable effectiveness of the classifier, you may also think about pre-processing methods like normalisation or dimensionality reduction. For the categorization of foetal health in this solution, three models are used and compared, with K-Nearest Neighbours, Naive Bayes classifier, and Decision Tree classifier showing 90%, 84.5%, and 93% accuracy, respectively when machine learning optimization techniques are applied using pre-trained model.",
    "abstract_processed": "classifi foetal health crucial respons healthcar innov machin learn techniqu utilis help instanc k nearest neighbour nave bay decis tree classifi use fine tune input pictur dataset adjust done classifi use method like featur select cross valid hyperparamet tweak identif ideal paramet featur combin dataset strategi assist improv perform classifi enhanc sustain effect classifi may also think pre process method like normalis dimension reduct categor foetal health solut three model use compar k nearest neighbour naiv bay classifi decis tree classifi show accuraci respect machin learn optim techniqu appli use pre train model"
  },
  {
    "doc_id": "10371611",
    "abstract_original": "This paper investigates how to provide meaningful scaffolding to bachelor humanities students, to enabled them to acquire Computational Thinking (CT) technical skills, and in particular basic programming competences. Two of the authors have been involved in the re-design, implementation and execution of a basic programming and CT course, offered to first-semester students as part of the Information science, IT and interaction design bachelor program, at the University of Southern Denmark (SDU). The central problem we faced in restructuring our introductory course, was finding a game genre that could support creative coding for beginners, be motivational and recognizable by the students, and would work with our use-modify-create learning approach. Our findings suggest that point-and-click games are an effective way to provide scaffolding and ease non-technical students into P5 programming. The genre has good expressive power, and the students were motivated because they recognized and could relate to the games they worked on. Future work will address students’ problems with scaling up the point-and-click games.",
    "abstract_processed": "paper investig provid meaning scaffold bachelor human student enabl acquir comput think ct technic skill particular basic program compet two author involv design implement execut basic program ct cours offer first semest student part inform scienc interact design bachelor program univers southern denmark sdu central problem face restructur introductori cours find game genr could support creativ code beginn motiv recogniz student would work use modifi creat learn approach find suggest point click game effect way provid scaffold eas non technic student p program genr good express power student motiv recogn could relat game work futur work address students’ problem scale point click game"
  },
  {
    "doc_id": "10371997",
    "abstract_original": "The surge of interest in artificial intelligence systems has sparked new directions of research in the realm of music data analysis. At the same time, the exploration and exploitation of intrinsic musical structures and sequences, a timeless endeavor, continue to captivate scholars and practitioners alike. In this context, the fusion of computational techniques with music analysis emerges as a natural progression. One of the pivotal crossroads in this convergence is the identification of musical phrase boundaries, pivotal demarcations that underpin the organizational fabric of a musical composition. This article pioneers an inventive approach to address the challenge of detecting these musical phrase boundaries, harnessing the power of artificial neural networks. However, the innovation does not stop there; the pinpointed phrase boundaries undergo a comprehensive dissection utilizing pattern mining techniques. The focus of this analysis is on unveiling recurrent motifs and classifying phrases into coherent clusters, predicated on the repetitions and similarities exposed through these neural network-driven techniques. This exploration was conducted using an extensive repository of folk songs, a treasure trove of foundational musical expressions that indelibly shape the stylistic contours of musical compositions. We claim that the presented approach not only opens avenues for penetrating and nuanced analysis, but also enriches our comprehension of the intricate interplay of musical components and their manifestations inspired by neural networks.",
    "abstract_processed": "surg interest artifici intellig system spark new direct research realm music data analysi time explor exploit intrins music structur sequenc timeless endeavor continu captiv scholar practition alik context fusion comput techniqu music analysi emerg natur progress one pivot crossroad converg identif music phrase boundari pivot demarc underpin organiz fabric music composit articl pioneer invent approach address challeng detect music phrase boundari har power artifici neural network howev innov stop pinpoint phrase boundari undergo comprehens dissect util pattern mine techniqu focu analysi unveil recurr motif classifi phrase coher cluster predic repetit similar expos neural network driven techniqu explor conduct use extens repositori folk song treasur trove foundat music express indel shape stylist contour music composit claim present approach open avenu penetr nuanc analysi also enrich comprehens intric interplay music compon manifest inspir neural network"
  },
  {
    "doc_id": "10372895",
    "abstract_original": "The current study aimed to assess the digital competence level among 41 mathematics teachers from the regular basic education sector in the public domain of the Lambayeque region. Utilizing the European Framework for the Digital Competence of Educators (DigCompEdu), key areas such as Professional Engagement, Teaching and Learning, and Open Education were scrutinized. Findings indicated a competent level in Professional Engagement, yet they revealed that teachers are still at initial stages regarding the integration of digital tools in teaching and the use of open educational resources. Although variables like gender, age, and academic background showed no significant differences, it was noted that both the technological infrastructure of institutions and support for professional development positively impact digital competences. This underlines the importance of reinforcing educational policies related to training and digital resources to promote a substantial improvement in mathematics teaching, as a key factor for the development of students’ critical and computational thinking.",
    "abstract_processed": "current studi aim assess digit compet level among mathemat teacher regular basic educ sector public domain lambayequ region util european framework digit compet educ digcompedu key area profession engag teach learn open educ scrutin find indic compet level profession engag yet reveal teacher still initi stage regard integr digit tool teach use open educ resourc although variabl like gender age academ background show signific differ note technolog infrastructur institut support profession develop posit impact digit compet underlin import reinforc educ polici relat train digit resourc promot substanti improv mathemat teach key factor develop students’ critic comput think"
  },
  {
    "doc_id": "10375936",
    "abstract_original": "The emergence of Large Language Models (LLMs) has renewed debate about whether Artificial Intelligence (AI) can be conscious or sentient. This paper identifies two approaches to the topic and argues: (1) A “Cartesian” approach treats consciousness, sentience, and personhood as very similar terms, and treats language use as evidence that an entity is conscious. This approach, which has been dominant in AI research, is primarily interested in what consciousness is, and whether an entity possesses it. (2) An alternative “Hobbesian” approach treats consciousness as a sociopolitical issue and is concerned with what the implications are for labeling something sentient or conscious. This both enables a political disambiguation of language, consciousness, and personhood and allows regulation to proceed in the face of intractable problems in deciding if something “really is” sentient. (3) AI systems should not be treated as conscious, for at least two reasons: (a) treating the system as an origin point tends to mask competing interests in creating it, at the expense of the most vulnerable people involved; and (b) it will tend to hinder efforts at holding someone accountable for the behavior of the systems. A major objective of this paper is accordingly to encourage a shift in thinking. In place of the Cartesian question—is AI sentient?—I propose that we confront the more Hobbesian one: Does it make sense to regulate developments in which AI systems behave as if they were sentient?",
    "abstract_processed": "emerg larg languag model llm renew debat whether artifici intellig ai consciou sentient paper identifi two approach topic argu “cartesian” approach treat conscious sentienc personhood similar term treat languag use evid entiti consciou approach domin ai research primarili interest conscious whether entiti possess altern “hobbesian” approach treat conscious sociopolit issu concern implic label someth sentient consciou enabl polit disambigu languag conscious personhood allow regul proceed face intract problem decid someth “realli is” sentient ai system treat consciou least two reason treat system origin point tend mask compet interest creat expens vulner peopl involv b tend hinder effort hold someon account behavior system major object paper accordingli encourag shift think place cartesian question—i ai sentient —i propos confront hobbesian one make sens regul develop ai system behav sentient"
  },
  {
    "doc_id": "10377698",
    "abstract_original": "We present a comprehensive study on a new task named image color aesthetics assessment (ICAA), which aims to assess color aesthetics based on human perception. ICAA is important for various applications such as imaging measurement and image analysis. However, due to the highly diverse aesthetic preferences and numerous color combinations, ICAA presents more challenges than conventional image quality assessment tasks. To advance ICAA research, 1) we propose a baseline model called the Delegate Transformer, which not only deploys deformable transformers to adaptively allocate interest points, but also learns human color space segmentation behavior by the dedicated module. 2) We elaborately build a color-oriented dataset, ICAA17K, containing 17K images, covering 30 popular color combinations, 80 devices and 50 scenes, with each image densely annotated by more than 1,500 people. Moreover, we develop a large-scale benchmark of 15 methods, the most comprehensive one thus far based on two datasets, SPAQ and ICAA17K. Our work, not only achieves state-of-the-art performance, but more importantly offers the community a roadmap to explore solutions for ICAA. Code and dataset are available in here.",
    "abstract_processed": "present comprehens studi new task name imag color aesthet assess icaa aim assess color aesthet base human percept icaa import variou applic imag measur imag analysi howev due highli divers aesthet prefer numer color combin icaa present challeng convent imag qualiti assess task advanc icaa research propos baselin model call deleg transform deploy deform transform adapt alloc interest point also learn human color space segment behavior dedic modul elabor build color orient dataset icaa k contain k imag cover popular color combin devic scene imag dens annot peopl moreov develop larg scale benchmark method comprehens one thu far base two dataset spaq icaa k work achiev state art perform importantli offer commun roadmap explor solut icaa code dataset avail"
  },
  {
    "doc_id": "10378642",
    "abstract_original": "Recently, various text-to-image generative models have been released, demonstrating their ability to generate high-quality synthesized images from text prompts. Despite these advancements, determining the appropriate text prompts to obtain desired images remains challenging. The quality of the synthesized images heavily depends on the user input, making it difficult to achieve consistent and satisfactory results. This limitation has sparked the need for an effective prompt optimization method to generate optimized text prompts automatically for text-to-image generative models. Thus, this study proposes a prompt optimization method that uses in-context few-shot learning in a pretrained language model. The proposed approach aims to generate optimized text prompts to guide the image synthesis process by leveraging the available contextual information in a few text examples. The results revealed that synthesized images using the proposed prompt optimization method achieved a higher performance, at 18% on average, based on an evaluation metric that measures the similarity between the generated images and prompts for generation. The significance of this research lies in its potential to provide a more efficient and automated approach to obtaining high-quality synthesized images. The findings indicate that prompt optimization may offer a promising pathway for text-to-image generative models.",
    "abstract_processed": "recent variou text imag gener model releas demonstr abil gener high qualiti synthes imag text prompt despit advanc determin appropri text prompt obtain desir imag remain challeng qualiti synthes imag heavili depend user input make difficult achiev consist satisfactori result limit spark need effect prompt optim method gener optim text prompt automat text imag gener model thu studi propos prompt optim method use context shot learn pretrain languag model propos approach aim gener optim text prompt guid imag synthesi process leverag avail contextu inform text exampl result reveal synthes imag use propos prompt optim method achiev higher perform averag base evalu metric measur similar gener imag prompt gener signific research lie potenti provid effici autom approach obtain high qualiti synthes imag find indic prompt optim may offer promis pathway text imag gener model"
  },
  {
    "doc_id": "10379489",
    "abstract_original": "The technological and online experiences of billions worldwide are dominated by a handful of companies known as “Big Tech.” Despite this being a cause for concern in governmental, economic, and ethical spheres, the literature lacks a study exploring the impact of public scandals on, and the global sentiment toward, Big Tech. Here, we quantify the power of Big Tech by analyzing their acquisitions, market capitalization, and number of monthly active users. Moreover, we utilize the synthetic control method to estimate the effect of public scandals on the stock price of two Big Tech companies, and find that they had no lasting effect. We also analyze the number of tweets mentioning these scandals, and find that they quickly fade from the spotlight. To explore public sentiment, we survey 5300 participants across 25 countries, and find that those from countries with lower digital literacy and more authoritarian regimes are more trusting of Big Tech. Furthermore, we find that one in three feels they lack control over the data collected about them, and one in four feels that Big Tech knows what they are thinking, knows more about them than their best friend, and may even be secretly listening to their conversations. Additionally, one in four feels addicted to Big Tech products, have no choice but to use them, and wishes there were more companies to choose from. These findings highlight the adverse effect of the oligopolistic nature of Big Tech on consumer choice and help inform policy-makers aiming to curb their dominance.",
    "abstract_processed": "technolog onlin experi billion worldwid domin hand compani known “big tech ” despit caus concern government econom ethic sphere literatur lack studi explor impact public scandal global sentiment toward big tech quantifi power big tech analyz acquisit market capit number monthli activ user moreov util synthet control method estim effect public scandal stock price two big tech compani find last effect also analyz number tweet mention scandal find quickli fade spotlight explor public sentiment survey particip across countri find countri lower digit literaci authoritarian regim trust big tech furthermor find one three feel lack control data collect one four feel big tech know think know best friend may even secretli listen convers addit one four feel addict big tech product choic use wish compani choos find highlight advers effect oligopolist natur big tech consum choic help inform polici maker aim curb domin"
  },
  {
    "doc_id": "10380594",
    "abstract_original": "At present, innovation courses for college students play a vital role in universities. It has also become an important teaching platform for cultivating superior talents. How to improve the level of innovative thinking of college students into high-quality national strategic talents has become a research topic of great concern. However, many university teachers still follow traditional instructional design. It is impossible to implement a customized approach to education. Responding to the deficiencies in the instructional design of innovative training for university students, the support vector machine and K-means clustering algorithms are combined to create a revolutionary network instructional system, which is then used in an undergraduate course. A virtual reality classroom, real-time chat features, and an evaluation system are just a few of the elements that make up this system. It makes it possible to personalize learning, share open data, have real-time debates, and participate in a variety of virtual learning activities. Through the use of conventional datasets, this integrated multi-algorithmic system’s dependability is illustrated. It can meet the diverse learning needs of college students and help solve the weaknesses of traditional instructional design. Since 2022, four evaluation techniques have been used to confirm the efficacy of this teaching strategy: student recognition analysis, final test passing rate, competition winning percentage, and classroom activity level assessment. The results support the following: Compared with the traditional teaching design, the novel network instructional system is more conducive to helping college students cultivate learning interests and enhance their innovative thinking level. The adoption and dissemination of this strategy will undoubtedly advance educational research and improve college students’ capacity for creative thought, fostering the development of top-notch creative talent and advancing sustainable societal development.",
    "abstract_processed": "present innov cours colleg student play vital role univers also becom import teach platform cultiv superior talent improv level innov think colleg student high qualiti nation strateg talent becom research topic great concern howev mani univers teacher still follow tradit instruct design imposs implement custom approach educ respond defici instruct design innov train univers student support vector machin k mean cluster algorithm combin creat revolutionari network instruct system use undergradu cours virtual realiti classroom real time chat featur evalu system element make system make possibl person learn share open data real time debat particip varieti virtual learn activ use convent dataset integr multi algorithm system’ depend illustr meet divers learn need colleg student help solv weak tradit instruct design sinc four evalu techniqu use confirm efficaci teach strategi student recognit analysi final test pass rate competit win percentag classroom activ level assess result support follow compar tradit teach design novel network instruct system conduc help colleg student cultiv learn interest enhanc innov think level adopt dissemin strategi undoubtedli advanc educ research improv colleg students’ capac creativ thought foster develop top notch creativ talent advanc sustain societ develop"
  },
  {
    "doc_id": "10381903",
    "abstract_original": "Complex networks can often be characterized by a fundamental structure that can be described by general principles. The same holds for social networks of partnership formations. Connections arose from the H2020 R& D funding program can also be analysed this way that is hugely affected by endogenous impacts. Nevertheless, self-organization occurs naturally that results high preferential points, near scale-free connection-network and significant inequalities among partners, EU member states and regions. Albeit the goal of such programs is not to increase regional cohesion but to remove obstacles from a borderless knowledge transfer, the two fields are not sharply separable. The aim of the present study is to shed light on regional connections within the H2020 social network and its time evolution via investigation of graph centrality measures. Since long-term regional development also necessitates strategical thinking regarding resource allocation on innovative fields, results could also be utilized by corresponding policymakers.",
    "abstract_processed": "complex network often character fundament structur describ gener principl hold social network partnership format connect aros h r fund program also analys way huge affect endogen impact nevertheless self organ occur natur result high preferenti point near scale free connect network signific inequ among partner eu member state region albeit goal program increas region cohes remov obstacl borderless knowledg transfer two field sharpli separ aim present studi shed light region connect within h social network time evolut via investig graph central measur sinc long term region develop also necessit strateg think regard resourc alloc innov field result could also util correspond policymak"
  },
  {
    "doc_id": "10381909",
    "abstract_original": "The agile method is a way of thinking and an approach that puts project collaboration on a new footing. The success of agile is hard to doubt, given the trends and fashions that have developed around it. However, understanding what makes agile projects successful, what factors influence it and how important they are to the participants is a much more complex issue. Agile places a strong emphasis on interaction and communication with each other, whether this is outside the team, but especially within the team, there are many different possibilities.",
    "abstract_processed": "agil method way think approach put project collabor new foot success agil hard doubt given trend fashion develop around howev understand make agil project success factor influenc import particip much complex issu agil place strong emphasi interact commun whether outsid team especi within team mani differ possibl"
  },
  {
    "doc_id": "10382007",
    "abstract_original": "TikTok has rapidly become the most popular social media application which offers creative and entertaining features. However, its excessive consumption carries the risk of addiction along with significant distraction. Multiple studies have found that the use of social media has also been linked to an increase in the risk of mental health problems such as depression, anxiety, loneliness, self-harm, and suicide ideation. The aim of this research is to identify and investigate the potential destructive impact of TikTok on society, specifically on the mental health and well-being of young people. This study quantitatively evaluates the data collected from an online survey distributed to a large number of young Tiktok users. The study explored the nature and extent of TikTok usage among young individuals and examined the potential impacts of TikTok usage on mental health outcomes. The researchers have found that gender differences linked to self-assessment, addiction and the fear of missing out (FOMO) could lead to more anxiety, depression and worsen self-esteem. However, pressure for higher visibility support creativity and skill development while longer TikTok usage leads to addiction as in the case of other social media platforms.",
    "abstract_processed": "tiktok rapidli becom popular social media applic offer creativ entertain featur howev excess consumpt carri risk addict along signific distract multipl studi found use social media also link increas risk mental health problem depress anxieti loneli self harm suicid ideat aim research identifi investig potenti destruct impact tiktok societi specif mental health well young peopl studi quantit evalu data collect onlin survey distribut larg number young tiktok user studi explor natur extent tiktok usag among young individu examin potenti impact tiktok usag mental health outcom research found gender differ link self assess addict fear miss fomo could lead anxieti depress worsen self esteem howev pressur higher visibl support creativ skill develop longer tiktok usag lead addict case social media platform"
  },
  {
    "doc_id": "10382029",
    "abstract_original": "This Neumann’s last publication marks the beginning of a comparison between artificial and natural information processing machines that has continued ever since, that is, the comparison of “The Computer and the Brain”. With a brief description of the book, we prepare the formulation of the new tasks of the comparison. In doing so, the revolutionary change that took place in the infosphere of humanity with the co-evolution of computing, networking and representing information, and which is still in intensive development, must be taken into account. The book contrasts the stored program architecture based on Neumann’s principle with the neural network architecture of the brain. The numerical comparison is based on differences in the performance, number, and density of the active elements. The comparison cannot be continued in this way, because we are not dealing with individual computers, but with a system of cooperating machines organized in the Internet. The worlds of the two kinds of machines jointly use the latest collection of artificially created information carriers, the Data Sphere, and together they form the active information processing component of the Humanity’s infosphere. The carriers of information provide the common, materially existing object of computation and thinking, which I call formation in the paper. The information event, introduced in the paper, associate formation with information. Formation means information when the observation or creation of the formation in an information event is connected to the meaning for its owner. While the information processing of computers is only the transformation of formations, the assignment of meaning is carried on in an information event both before and after the transformation. In the most important information event, the owner is the human mind. The separating barrier between the two worlds is the information event. Within the computer systems, there are no more information events, only formations are transformed, in which the activation of program formations enables the automatic execution of the computation.",
    "abstract_processed": "neumann’ last public mark begin comparison artifici natur inform process machin continu ever sinc comparison “the comput brain” brief descript book prepar formul new task comparison revolutionari chang took place infospher human co evolut comput network repres inform still intens develop must taken account book contrast store program architectur base neumann’ principl neural network architectur brain numer comparison base differ perform number densiti activ element comparison cannot continu way deal individu comput system cooper machin organ internet world two kind machin jointli use latest collect artifici creat inform carrier data sphere togeth form activ inform process compon humanity’ infospher carrier inform provid common materi exist object comput think call format paper inform event introduc paper associ format inform format mean inform observ creation format inform event connect mean owner inform process comput transform format assign mean carri inform event transform import inform event owner human mind separ barrier two world inform event within comput system inform event format transform activ program format enabl automat execut comput"
  },
  {
    "doc_id": "10385599",
    "abstract_original": "Accurate identification of cell types is a pivotal and intricate task in scRNA-seq data analysis. Recently, significant strides have been made in cell type annotation of scRNA-seq data using pre-trained language models (PLMs). This method has surmounted the constraints of conventional approaches regarding precision, robustness, and generalization. However, the fine-tuning process of large-scale pre-trained models incurs substantial computational expenses. To tackle this issue, a promising avenue of research has emerged, proposing parameter-efficient fine-tuning techniques for PLMs. These techniques concentrate on fine-tuning only a small portion of the model parameters while attaining comparable performance. In this study, we extensively research parameter-efficient fine-tuning methods for scRNA-seq cell type annotation, employing scBERT as the backbone. We scrutinize the performance and compatibility of various parameter-efficient fine-tuning methodologies across multiple datasets. Through comprehensive analysis, we demonstrate the remarkable performance of parameter-efficient fine-tuning methods in cell type annotation. Hopefully, this study can inspire new thinking in analyzing scRNA-seq data.",
    "abstract_processed": "accur identif cell type pivot intric task scrna seq data analysi recent signific stride made cell type annot scrna seq data use pre train languag model plm method surmount constraint convent approach regard precis robust gener howev fine tune process larg scale pre train model incur substanti comput expens tackl issu promis avenu research emerg propos paramet effici fine tune techniqu plm techniqu concentr fine tune small portion model paramet attain compar perform studi extens research paramet effici fine tune method scrna seq cell type annot employ scbert backbon scrutin perform compat variou paramet effici fine tune methodolog across multipl dataset comprehens analysi demonstr remark perform paramet effici fine tune method cell type annot hope studi inspir new think analyz scrna seq data"
  },
  {
    "doc_id": "10386092",
    "abstract_original": "In this paper, we call for computational archival studies to prioritize social justice and community-centeredness. Our initial research findings, as well as the work of community archives, provide evidence of the need to elevate and truly center the voices of those depicted (or underrepresented) in large-scale digital archives, leveraging the power of computational thinking with the transformative experience of seeing oneself represented (or representing oneself) in digital collections.",
    "abstract_processed": "paper call comput archiv studi priorit social justic commun centered initi research find well work commun archiv provid evid need elev truli center voic depict underrepres larg scale digit archiv leverag power comput think transform experi see oneself repres repres oneself digit collect"
  },
  {
    "doc_id": "10386409",
    "abstract_original": "There is a national need to increase the number of minority students entering STEM fields with essential computing skills. To increase minority students’ interest and engagement in computing, a researcher-practitioner partnership between the University of Texas at El Paso and the El Paso Independent School District, developed and implemented a culturally and linguistically responsive curriculum and pedagogy to introduce computational thinking (CT) in two middle schools across different subject areas in a borderland region. The curriculum leveraged the Sol y Agua game – a bilingual, culturally-responsive game designed to engage students of this region in CT. This paper describes the process and initial findings of this project. The quantitative data from in-game analyses show that students utilized the language change feature to switch from English to Spanish more frequently than the other way – highlighting the need for educational platforms relatable to students through language, environment, and cultural context. Analyses of the qualitative data indicate that while teachers/team members understood CT and translanguaging concepts and taught lesson units that provided opportunities to practice both, CT and translanguaging were largely implicit in the curriculum. In collaborative analyses of these patterns, teachers described additional supports that would help them to make CT instruction and translanguaging strategies more explicit in the content and pedagogy, highlighting the need for systematic, targeted integration of these concepts.",
    "abstract_processed": "nation need increas number minor student enter stem field essenti comput skill increas minor students’ interest engag comput research practition partnership univers texa el paso el paso independ school district develop implement cultur linguist respons curriculum pedagogi introduc comput think ct two middl school across differ subject area borderland region curriculum leverag sol agua game – bilingu cultur respons game design engag student region ct paper describ process initi find project quantit data game analys show student util languag chang featur switch english spanish frequent way – highlight need educ platform relat student languag environ cultur context analys qualit data indic teacher team member understood ct translanguag concept taught lesson unit provid opportun practic ct translanguag larg implicit curriculum collabor analys pattern teacher describ addit support would help make ct instruct translanguag strategi explicit content pedagogi highlight need systemat target integr concept"
  },
  {
    "doc_id": "10386566",
    "abstract_original": "Use of archival collections is accelerated by the presence of finding aids, which communicate the arrangement and description of collection contents. To arrive at the optimal arrangement of a collection, archivists rely on some item-level processing or knowledge gained by exploring and manipulating digital reproductions of the contents. In this paper we consider archival student and instructor perspectives from hands-on course experiences directly with two distinct collections: one pertaining to the development, 2017 transfer and launch, and ongoing maintenance of the International Research Portal for Records Related to Nazi-Era Cultural Property (IRP2), and one a selection of unclassified catalog entries about digitized nuclear science reports. Visualizing is a data practice that permits the discovery of key content patterns, identification of computational models to be carried out to aid further analysis, and query-resolution for subject experts with precise - and historically significant - research questions. While archival data visualizations have previously been implemented as an extension of descriptive work including finding aid element counts, here we connect visualization to the work of archival outreach and access. We study how visualizations generated by groups of students working with textual and numerical dataset portions can ultimately accelerate time-sensitive uses of collections.",
    "abstract_processed": "use archiv collect acceler presenc find aid commun arrang descript collect content arriv optim arrang collect archivist reli item level process knowledg gain explor manipul digit reproduct content paper consid archiv student instructor perspect hand cours experi directli two distinct collect one pertain develop transfer launch ongo mainten intern research portal record relat nazi era cultur properti irp one select unclassifi catalog entri digit nuclear scienc report visual data practic permit discoveri key content pattern identif comput model carri aid analysi queri resolut subject expert precis histor signific research question archiv data visual previous implement extens descript work includ find aid element count connect visual work archiv outreach access studi visual gener group student work textual numer dataset portion ultim acceler time sensit use collect"
  },
  {
    "doc_id": "10386773",
    "abstract_original": "Suicide is one of the major causes of death globally. Analysis of social media posts and in-depth insights show that some people have suicide ideas. In order to save more lives, it is crucial to comprehend the behavior of suicidal attempters. However, identifying and explaining suicidal thoughts poses a significant challenge in psychiatry. Additionally, analysing suicidal behavior is a complex procedure involving several variables based on the individual’s preferences and the data type. Although traditional methods have been utilized to identify clinical factors for suicide ideation detection (SID), these models often lack interpretability and understanding. Therefore, the primary aim of this research is to apply several deep learning (DL) and machine learning (ML) techniques such as BERT, LSTM, BiLSTM, RF, SVM, GaussianNB, LR, and KNeighbors blending with interpretable models such as LIME and SHAP to provide valuable insights into the importance of different features and make models more transparent in the SID process. The experiments were conducted on a publicly available dataset comprising 24,101 posts, categorized as either suicidal or non-suicidal. The implemented method brings about significant enhancements in performance in comparison. A comparison of all performance measures reveals that the LSTM model is particularly good at processing and classifying textual data, with higher accuracy, precision, recall, and AUC scores than the other models tested.",
    "abstract_processed": "suicid one major caus death global analysi social media post depth insight show peopl suicid idea order save live crucial comprehend behavior suicid attempt howev identifi explain suicid thought pose signific challeng psychiatri addit analys suicid behavior complex procedur involv sever variabl base individual’ prefer data type although tradit method util identifi clinic factor suicid ideat detect sid model often lack interpret understand therefor primari aim research appli sever deep learn dl machin learn ml techniqu bert lstm bilstm rf svm gaussiannb lr kneighbor blend interpret model lime shap provid valuabl insight import differ featur make model transpar sid process experi conduct publicli avail dataset compris post categor either suicid non suicid implement method bring signific enhanc perform comparison comparison perform measur reveal lstm model particularli good process classifi textual data higher accuraci precis recal auc score model test"
  },
  {
    "doc_id": "10386929",
    "abstract_original": "This paper describes an investigation of GPT-4’s knowledge in some areas of archival practice, and its ability to think computationally about archival tasks. It is demonstrated that GPT-4 has shown an understanding of ten among the twenty-two distinct forms of computational thinking. When GPT-4 is combined with plugins, it is able to apply some of these methods and tools to digital archival tasks.",
    "abstract_processed": "paper describ investig gpt ’s knowledg area archiv practic abil think comput archiv task demonstr gpt shown understand ten among twenti two distinct form comput think gpt combin plugin abl appli method tool digit archiv task"
  },
  {
    "doc_id": "10388119",
    "abstract_original": "This paper investigates the emotional reasoning abilities of the GPT family of large language models. We advocate a component perspective on evaluation that decomposes models into different aspects of emotional reasoning (appraisal derivation, affect/intensity derivation, and consequent derivation). We report two studies. A correlational study examines how the model reasons about autobiographical memories. An experimental study systematically varies aspects of situations in ways previously shown to impact emotion intensity and coping tendencies. Results demonstrate, even without prompt engineering, GPT predictions closely match human-provided appraisals and emotion labels, though GPT struggled to predict emotion intensity and coping responses. GPT-4 performed best on the first study but performed poorly on the second (though it yielded the best results following minor prompt engineering). The evaluation raises questions about how to utilize the strengths and mitigate the weaknesses of such models, including dealing with variability in responses. More fundamentally, these studies highlight the benefits of the componential perspective on model evaluation.",
    "abstract_processed": "paper investig emot reason abil gpt famili larg languag model advoc compon perspect evalu decompos model differ aspect emot reason apprais deriv affect intens deriv consequ deriv report two studi correl studi examin model reason autobiograph memori experiment studi systemat vari aspect situat way previous shown impact emot intens cope tendenc result demonstr even without prompt engin gpt predict close match human provid apprais emot label though gpt struggl predict emot intens cope respons gpt perform best first studi perform poorli second though yield best result follow minor prompt engin evalu rais question util strength mitig weak model includ deal variabl respons fundament studi highlight benefit componenti perspect model evalu"
  },
  {
    "doc_id": "10388185",
    "abstract_original": "Individual differences in personality determine our preferences, traits and values, which should similarly hold for the way we express ourselves. With current advancements and transformations of technology and society, text-based communication has become ordinary and often even surpasses natural voice conversations- with distinct challenges and opportunities. In this exploratory work, we investigate the impact of personality on the tendency how players of a team-based collaborative alternate reality game express themselves affectively. We collected chat logs from eleven players over two weeks, labeled them according to their affective state, and assessed the connection between them and the five-factor personality domains and facets. After applying multi-linear regression, we found a series of reasonable correlations between (combinations of) personality variables and expressed affect-as increased confusion could be predicted by lower self-competence (C1), personal annoyance by vulnerability to stress (N6) and expressing anger occured more often in players that are prone to anxiety (N1), less humble and modest (A5), think less carefully before they act (C6) and have higher neuroticism (N). Expanding the data set, sample size and input modalities in subsequent work, we aim to confirm these findings and reveal even more interesting connections that could inform affective computing and games user research equally.",
    "abstract_processed": "individu differ person determin prefer trait valu similarli hold way express current advanc transform technolog societi text base commun becom ordinari often even surpass natur voic convers distinct challeng opportun exploratori work investig impact person tendenc player team base collabor altern realiti game express affect collect chat log eleven player two week label accord affect state assess connect five factor person domain facet appli multi linear regress found seri reason correl combin person variabl express affect increas confus could predict lower self compet c person annoy vulner stress n express anger occur often player prone anxieti n less humbl modest think less care act c higher neurotic n expand data set sampl size input modal subsequ work aim confirm find reveal even interest connect could inform affect comput game user research equal"
  },
  {
    "doc_id": "10388201",
    "abstract_original": "Recently, the interest in robots capable of experiencing empathy and displaying emotions has grown. This trend can be attributed to the pervasive presence of robots in many environments, such as homes, offices, museums, and hospitals, that require more empathic and reliable human-machine relationships. Recent studies demonstrated that providing the robot with the ability to think aloud improves humans’ trust in machines, as they can understand the underlying reasoning of the artifact, what conclusions it can draw, and why and how. This work integrates a robot’s inner speech mechanism with Damasio’s theory of emotions to make the robot functionally conscious of its emotional experience, leading to a computational model of Extended Consciousness, SUSAN (Self-dialogue Utility in Simulating Artificial Emotions). Damasio claims that emotions originate within the body and precede and influence the reasoning processes that make the person aware of them. According to his theory, Extended Consciousness refers to the humans’ cognitive processes that make the humans themselves aware of the physiological experiences of emotions purged by an external stimulus. SUSAN models the bodily emotional experience and simulates the awareness of the emergent emotion by using inner speech. The model is presented, and the initial results related to a use case are discussed.",
    "abstract_processed": "recent interest robot capabl experienc empathi display emot grown trend attribut pervas presenc robot mani environ home offic museum hospit requir empath reliabl human machin relationship recent studi demonstr provid robot abil think aloud improv humans’ trust machin understand underli reason artifact conclus draw work integr robot’ inner speech mechan damasio’ theori emot make robot function consciou emot experi lead comput model extend conscious susan self dialogu util simul artifici emot damasio claim emot origin within bodi preced influenc reason process make person awar accord theori extend conscious refer humans’ cognit process make human awar physiolog experi emot purg extern stimulu susan model bodili emot experi simul awar emerg emot use inner speech model present initi result relat use case discuss"
  },
  {
    "doc_id": "10389248",
    "abstract_original": "Sound recognition refers to the technology or process of identifying and classifying different sounds or audio signals. This study aims to develop a sound recognition system using machine learning (ML) and deep learning (DL) techniques to classify and identify the gender of catfish based on their speech patterns. The study explores a range of supervised ML and DL algorithms, such as the Artificial Neural Network (ANN), Naïve Bayes (NB), and others, to predict the gender of catfish. The extracted features from the audio signals of the catfish serve as inputs to these algorithms, which produce binary predictions classifying the catfish samples as either male or female. This study further explores data analysis of the audio signals from the male and female catfish. The automated sound recognition system proves to be a more efficient and accurate approach compared to traditional methods, which rely on time-consuming visual observations. Evaluation metrics such as Accuracy, Sensitivity, and more, were employed to gauge the effectiveness of the algorithms in predicting the gender of catfish based on speech patterns. Among the employed algorithms, ANN and NB demonstrate the highest accuracy, achieving a score of 89.47%.",
    "abstract_processed": "sound recognit refer technolog process identifi classifi differ sound audio signal studi aim develop sound recognit system use machin learn ml deep learn dl techniqu classifi identifi gender catfish base speech pattern studi explor rang supervis ml dl algorithm artifici neural network ann naïv bay nb other predict gender catfish extract featur audio signal catfish serv input algorithm produc binari predict classifi catfish sampl either male femal studi explor data analysi audio signal male femal catfish autom sound recognit system prove effici accur approach compar tradit method reli time consum visual observ evalu metric accuraci sensit employ gaug effect algorithm predict gender catfish base speech pattern among employ algorithm ann nb demonstr highest accuraci achiev score"
  },
  {
    "doc_id": "10389487",
    "abstract_original": "Students, in the context of future workforce candidates, should be able to keep abreast of massive technological developments. This research aims to evaluate the effectiveness of student mentoring programs in creating online-based infographics to increase creativity in the digital era. Quantitative approach, with descriptive and Wilcoxon tests used in this study. The results showed that the level of student skills in making online-based infographics before and after the mentoring program had all increased. There are four indicators where after the mentoring activities the students are in the excellent category, while there are five indicators which are in the good category. This research can be used as a guide in seeking to improve student skills in the digital era.",
    "abstract_processed": "student context futur workforc candid abl keep abreast massiv technolog develop research aim evalu effect student mentor program creat onlin base infograph increas creativ digit era quantit approach descript wilcoxon test use studi result show level student skill make onlin base infograph mentor program increas four indic mentor activ student excel categori five indic good categori research use guid seek improv student skill digit era"
  },
  {
    "doc_id": "10389513",
    "abstract_original": "Health care is the improvement of health through the avoidance and cure of diseases. Chronic kidney disease (CKD) poses a substantial health issue, ranking as the eighth leading cause of death and the tenth leading cause of disability-adjusted life years for both genders. This research aims to utilize machine learning (ML) algorithms to accurately predict the presence of CKD, which affects people worldwide. Timely identification of CKD is crucial to prevent it from progressing to its final and most critical phase. Machine learning algorithms, such as Decision Tree (DT), Naïve Bayes (NB), and others, are used in this study for the prediction of CKD. Various health parameters such as age, albumin level, and more are used as input into each ML algorithm to predict the presence of CKD. Data preprocessing is carried out to improve the quality of the data for more accurate prediction. The data is analyzed to uncover the connections between CKD health parameters and their impact on the occurrence of CKD. This research further examines the influence of different train and test data ratios on the accuracy of the employed algorithms. Evaluation metrics such as accuracy, sensitivity, and more are employed to gauge the effectiveness of each algorithm in making predictions. Random Forest stood out as the most accurate algorithm, with a score of 96.25%. Naive Bayes and XGBoost demonstrated the highest sensitivity, achieving a perfect score of 100%.",
    "abstract_processed": "health care improv health avoid cure diseas chronic kidney diseas ckd pose substanti health issu rank eighth lead caus death tenth lead caus disabl adjust life year gender research aim util machin learn ml algorithm accur predict presenc ckd affect peopl worldwid time identif ckd crucial prevent progress final critic phase machin learn algorithm decis tree dt naïv bay nb other use studi predict ckd variou health paramet age albumin level use input ml algorithm predict presenc ckd data preprocess carri improv qualiti data accur predict data analyz uncov connect ckd health paramet impact occurr ckd research examin influenc differ train test data ratio accuraci employ algorithm evalu metric accuraci sensit employ gaug effect algorithm make predict random forest stood accur algorithm score naiv bay xgboost demonstr highest sensit achiev perfect score"
  },
  {
    "doc_id": "10390011",
    "abstract_original": "The advancement in technology related to artificial intelligence, or AI, has been a hot topic of debate in recent years. One concern is the possibility of job loss when machines with algorithms take over tasks that formerly required human labour. It analyses the implications of artificial intelligence technologies on the job market, paying particular attention to how it can decrease the demand for physical labour and perhaps oust employees from their professions. The distribution of wealth, salaries, efficiency, and job abilities are all areas where AI has the capability to have a significant impact. The paper also looks at the ethical implications of AI, such as how it will impact privacy, bias, and decision-making. The study outlines the potential dangers and benefits of AI on work and provides insights for policymakers and stakeholders to lessen adverse effects and realize the potential benefits of AI through a thorough analysis of the available literature and case studies. The study concludes that AI can change how work is done and that proactive steps must be taken to solve potential problems and take full advantage of the opportunities that AI presents. Overall, the present study provides an in-depth knowledge of how AI will impact the workplace, placing a strong focus on the potential for job displacement and creation, the impact on salaries and output, and the need for ethical considerations.",
    "abstract_processed": "advanc technolog relat artifici intellig ai hot topic debat recent year one concern possibl job loss machin algorithm take task formerli requir human labour analys implic artifici intellig technolog job market pay particular attent decreas demand physic labour perhap oust employe profess distribut wealth salari effici job abil area ai capabl signific impact paper also look ethic implic ai impact privaci bia decis make studi outlin potenti danger benefit ai work provid insight policymak stakehold lessen advers effect realiz potenti benefit ai thorough analysi avail literatur case studi studi conclud ai chang work done proactiv step must taken solv potenti problem take full advantag opportun ai present overal present studi provid depth knowledg ai impact workplac place strong focu potenti job displac creation impact salari output need ethic consider"
  },
  {
    "doc_id": "10390179",
    "abstract_original": "In recent years, there has been a remarkable increase in interest and challenges in image processing and pattern recognition, specifically in the context of air writing. This exciting research area has significant potential to advance automation processes and improve human-machine interfaces in various applications. The emergence of faster computers, affordable high-performance video cameras, and the need for automated analysis of videos has led to an increase in the popularity of object tracking, a critical task in computer vision. The process of video analysis typically encompasses object detection, tracking, and behavior analysis. Object tracking involves four main aspects choosing the suitable object representation, selecting features for tracking, detecting the object, and tracking the object. Object tracking algorithms find applications in different domains, including vehicle navigation, video indexing, and surveillance that are automated. The objective of the paper is to create a software application for smart wearable devices that utilizes computer vision to track finger gestures in the air, functioning as a motion-to-text converter for air-writing. The technology will facilitate communication for people by enabling them to generate text for multiple purposes, like sending emails and messages, through intermittent gestures. This is a productive means of communication that curbs the usage of laptops and mobiles, making it particularly beneficial for individuals who are deaf.",
    "abstract_processed": "recent year remark increas interest challeng imag process pattern recognit specif context air write excit research area signific potenti advanc autom process improv human machin interfac variou applic emerg faster comput afford high perform video camera need autom analysi video led increas popular object track critic task comput vision process video analysi typic encompass object detect track behavior analysi object track involv four main aspect choos suitabl object represent select featur track detect object track object object track algorithm find applic differ domain includ vehicl navig video index surveil autom object paper creat softwar applic smart wearabl devic util comput vision track finger gestur air function motion text convert air write technolog facilit commun peopl enabl gener text multipl purpos like send email messag intermitt gestur product mean commun curb usag laptop mobil make particularli benefici individu deaf"
  },
  {
    "doc_id": "10390463",
    "abstract_original": "Field-Programmable Gate Arrays (FPGAs) have become popular for their versatility and flexibility in implementing various digital circuits. An FPGA-VLSI processor's effectiveness is directly proportional to the speed with which its various digital signal processing operations may be carried out. The goal of this technique is to attain both a high level of accuracy and a high rate of speed. Approximate multipliers (AP) are among the fastest multipliers that are available and are used in FPGA-VLSI systems that are based on artificial intelligence (AI). A 64-bit multiplicator can be approximated with a 64-bit number thanks to the study that was suggested. We are employing the partial product or dada based multiplication technique to implement the suggested 64 bit digital approximate multiplier. This technique allows the 64 bit multiplication operation to be completed in the partial form. 64 bits multiplied by 32, 16, 8, 4, and 2 bits respectively after being broken up. We are thinking about performance characteristics like the area, the latency, and the PDP right now. The area is decreasing by up to 55%, and the latency and PDP are both decreasing by approximately up to 70% when compared to the present work. The multiplier under consideration achieves an accuracy of 99%. The virtex 7 family is represented by the FPGA integrated circuit that was used for the simulation.",
    "abstract_processed": "field programm gate array fpga becom popular versatil flexibl implement variou digit circuit fpga vlsi processor effect directli proport speed variou digit signal process oper may carri goal techniqu attain high level accuraci high rate speed approxim multipli ap among fastest multipli avail use fpga vlsi system base artifici intellig ai bit multipl approxim bit number thank studi suggest employ partial product dada base multipl techniqu implement suggest bit digit approxim multipli techniqu allow bit multipl oper complet partial form bit multipli bit respect broken think perform characterist like area latenc pdp right area decreas latenc pdp decreas approxim compar present work multipli consider achiev accuraci virtex famili repres fpga integr circuit use simul"
  },
  {
    "doc_id": "10390630",
    "abstract_original": "Micro-expression refers to facial expressions that last for an extremely short time, typically less than 0.5 seconds. It can reveal a person's true emotion, which is one of the powerful indicators to judge what a person actually thinks. However, the deployment of micro-expression recognition algorithms onto resource-constrained devices poses a challenge due to their high computational requirements. In this essay, we optimize the identification of microexpression algorithms by using pruning-based lightweight methods. By using unstructured pruning and structured pruning methods, the backbone Resnet-18 network model is subjected to local and global lightweight pruning, respectively, where the network structure is optimized to reduce the time and space costs required for micro-expression recognition algorithms. The experimental results demonstrate that the original algorithm's performance is enhanced following the pruning procedure with fewer parameters, and it exhibits superior performance on the CASMEII, SMIC, and SAMM datasets.",
    "abstract_processed": "micro express refer facial express last extrem short time typic less second reveal person true emot one power indic judg person actual think howev deploy micro express recognit algorithm onto resourc constrain devic pose challeng due high comput requir essay optim identif microexpress algorithm use prune base lightweight method use unstructur prune structur prune method backbon resnet network model subject local global lightweight prune respect network structur optim reduc time space cost requir micro express recognit algorithm experiment result demonstr origin algorithm perform enhanc follow prune procedur fewer paramet exhibit superior perform casmeii smic samm dataset"
  },
  {
    "doc_id": "10391228",
    "abstract_original": "Intelligent recommendation plays an important role in the field of intelligent education, among which arithmetic problem recommendation is an important research field. Geometry arithmetic problems are a major category of arithmetic problems which play a crucial role in nurturing students’ spatial perception, logical thinking, and computational skills. This paper proposes a scene-enhanced BERT model for recommending geometry arithmetic problems. Firstly, a multi-layer classification task of geometric knowledge was constructed for fine-tuning the BERT model. Secondly, this BERT model is used to vectorize the problem to be queried and the problem text in the database. Finally, the query questions are matched with questions under the same knowledge points using vector similarity calculations with diversity correction and recommended according to the score. Experimental results demonstrate that our proposed method has achieved good efficiency and accuracy in recommending geometric arithmetic problems. Overall, this research offers an effective recommendation approach for the geometry arithmetic problem task, providing valuable insights for intelligent education field and tutoring system.",
    "abstract_processed": "intellig recommend play import role field intellig educ among arithmet problem recommend import research field geometri arithmet problem major categori arithmet problem play crucial role nurtur students’ spatial percept logic think comput skill paper propos scene enhanc bert model recommend geometri arithmet problem firstli multi layer classif task geometr knowledg construct fine tune bert model secondli bert model use vector problem queri problem text databas final queri question match question knowledg point use vector similar calcul divers correct recommend accord score experiment result demonstr propos method achiev good effici accuraci recommend geometr arithmet problem overal research offer effect recommend approach geometri arithmet problem task provid valuabl insight intellig educ field tutor system"
  },
  {
    "doc_id": "10391815",
    "abstract_original": "\"The decision of the State Council on accelerating the development of modern vocational education\" defines the guiding ideology of speeding up the development of modern clothing education and implementing the \"integration of production and education and the characteristic of running a school\". Based on this, this paper combines the interactive technology of the computer network, namely the two sieving method, taking the three level inverted pendulum balance design as an example, and the teaching of the art design course is studied. First, the basic theory of the algorithm and the nonlinear characteristics of the art design system are analyzed. Secondly, the art interaction VR-GrHDP algorithm platform is constructed with the GrHDP algorithm designed. The art design course strategy, finally using the algorithm constructed in this paper to design a set of clothing display art Pendulum-inverted pendulum, the experiment shows that the interactive art design system based on GrHDP algorithm has good stability)",
    "abstract_processed": "decis state council acceler develop modern vocat educ defin guid ideolog speed develop modern cloth educ implement integr product educ characterist run school base paper combin interact technolog comput network name two siev method take three level invert pendulum balanc design exampl teach art design cours studi first basic theori algorithm nonlinear characterist art design system analyz secondli art interact vr grhdp algorithm platform construct grhdp algorithm design art design cours strategi final use algorithm construct paper design set cloth display art pendulum invert pendulum experi show interact art design system base grhdp algorithm good stabil"
  },
  {
    "doc_id": "1039192",
    "abstract_original": "Soft computing (SC) is an emerging collection of methodologies which aims to exploit tolerance for imprecision, uncertainty, and partial truth to achieve robustness, tractability, and low total cost. It differs from conventional hard computing (HC) in the sense that, unlike hard computing, it is strongly based on intuition or subjectivity. Therefore, soft computing provides an attractive opportunity to represent the ambiguity in human thinking with real life uncertainty. Fuzzy logic (FL), neural networks (NN), and genetic algorithms (GA) are the core methodologies of soft computing. However, FL, NN, and GA should not be viewed as competing with each other, but synergistic and complementary instead. Considering the number of available journal and conference papers on various combinations of these three methods, it is easy to conclude that the fusion of individual soft computing methodologies has already been advantageous in numerous applications. On the other hand, hard computing solutions are usually more straightforward to analyze; their behavior and stability are more predictable; and, the computational burden of algorithms is typically either low or moderate. These characteristics. are particularly important in real-time applications. Thus, it is natural to see SC and HC as potentially complementary methodologies. Novel combinations of different methods are needed when developing high-performance, cost-effective, and safe products for the demanding global market. We present an overview of applications in which the fusion of soft computing and hard computing has provided innovative solutions for challenging real-world problems. A carefully selected list of references is considered with evaluative discussions and conclusions.",
    "abstract_processed": "soft comput sc emerg collect methodolog aim exploit toler imprecis uncertainti partial truth achiev robust tractabl low total cost differ convent hard comput hc sens unlik hard comput strongli base intuit subject therefor soft comput provid attract opportun repres ambigu human think real life uncertainti fuzzi logic fl neural network nn genet algorithm ga core methodolog soft comput howev fl nn ga view compet synergist complementari instead consid number avail journal confer paper variou combin three method easi conclud fusion individu soft comput methodolog alreadi advantag numer applic hand hard comput solut usual straightforward analyz behavior stabil predict comput burden algorithm typic either low moder characterist particularli import real time applic thu natur see sc hc potenti complementari methodolog novel combin differ method need develop high perform cost effect safe product demand global market present overview applic fusion soft comput hard comput provid innov solut challeng real world problem care select list refer consid evalu discuss conclus"
  },
  {
    "doc_id": "10392805",
    "abstract_original": "Machine learning models, such as ChatGPT, are increasingly being used in creative writing. ChatGPT, a language model developed by OpenAI, can generate human-like writings in a variety of styles, including poetry and fiction. The purpose of this research is to investigate the possibilities of ChatGPT in creative writing and natural language text production. The study contains an in-depth examination of the elements considered by ChatGPT while generating poetry and fiction, as well as an exploration of different language models. The study also looks at the challenges and limitations of using ChatGPT in creative writing. The findings of this study have the potential to provide light on the use of machine learning in creative writing and natural language text generation.",
    "abstract_processed": "machin learn model chatgpt increasingli use creativ write chatgpt languag model develop openai gener human like write varieti style includ poetri fiction purpos research investig possibl chatgpt creativ write natur languag text product studi contain depth examin element consid chatgpt gener poetri fiction well explor differ languag model studi also look challeng limit use chatgpt creativ write find studi potenti provid light use machin learn creativ write natur languag text gener"
  },
  {
    "doc_id": "1039324",
    "abstract_original": "Domain experts think and reason at a high level of abstraction when they solve problems in their domain of expertise. We present the design and motivation behind a domain specific language (DSL), called /spl Phi/LOG, to enable biologists (domain experts) to program solutions to phylogenetic inference problems at a very high level of abstraction. The implementation infrastructure (interpreter, compiler, debugger) for the DSL is automatically obtained through a software engineering framework based on denotational semantics and logic programming.",
    "abstract_processed": "domain expert think reason high level abstract solv problem domain expertis present design motiv behind domain specif languag dsl call spl phi log enabl biologist domain expert program solut phylogenet infer problem high level abstract implement infrastructur interpret compil debugg dsl automat obtain softwar engin framework base denot semant logic program"
  },
  {
    "doc_id": "10396947",
    "abstract_original": "User Interface (UI) and User Experience (UX) design have a very important role in the development of digital products and services. UX quality is determined by the extent to which the UI developed can meet the needs of users. There are several factors that influence the quality of UX, one of which is its usability. Usability is one of the important concepts in UI/UX design, which aims to create products that are easy to use, effective, and satisfying for users. Lova.ID, a company that sells women's fashion, requires an E-Commerce website system to increase marketing and sales. To find out whether the UI/UX prototype can be used according to user needs, it is necessary to carry out a usability testing and analysis. This study aims to test the UI/UX prototype that has been made. Tests based on effectiveness, efficiency, and user usability use the time based efficiency method and the System Usability Scale (SUS). The results of this study note that users can complete all tasks properly to determine the effectiveness of the prototype with a percentage of 100%. In addition, the average time needed to do all tasks is included in the fast classification. And, the usability of the prototype is at level B, which means it is well accepted by users.",
    "abstract_processed": "user interfac ui user experi ux design import role develop digit product servic ux qualiti determin extent ui develop meet need user sever factor influenc qualiti ux one usabl usabl one import concept ui ux design aim creat product easi use effect satisfi user lova id compani sell women fashion requir e commerc websit system increas market sale find whether ui ux prototyp use accord user need necessari carri usabl test analysi studi aim test ui ux prototyp made test base effect effici user usabl use time base effici method system usabl scale su result studi note user complet task properli determin effect prototyp percentag addit averag time need task includ fast classif usabl prototyp level b mean well accept user"
  },
  {
    "doc_id": "10397000",
    "abstract_original": "The user interface is one of the aspects in the initial design of a website that acts as a link between the website and the user. The website created must have a solution to the problems experienced by users, so that later it will create a pleasant and easy experience in providing or obtaining information to users. This study aims to produce a user interface design for the bluesclues band website, which will later refer to the results of user interviews. The method used in this study is the design thinking method with five stages, namely emphatize, define, ideate, prototype, and the last is testing. Aspects of testing used in testing the design of this application namely effectiveness, efficiency, and satisfaction, by using the usability testing method with the system usability scale. based on the results of testing on related parties for the effectiveness aspect a value of 96% was obtained, for the efficiency aspect a time-based efficiency (TBE) value of 0.07 sec/goals was obtained. For the satisfaction aspect, a value of 83 is obtained, which is included in the grade B and acceptable category. From the test results it can be concluded that web design using the design thinking method can improve the user experience when using the website",
    "abstract_processed": "user interfac one aspect initi design websit act link websit user websit creat must solut problem experienc user later creat pleasant easi experi provid obtain inform user studi aim produc user interfac design bluesclu band websit later refer result user interview method use studi design think method five stage name emphat defin ideat prototyp last test aspect test use test design applic name effect effici satisfact use usabl test method system usabl scale base result test relat parti effect aspect valu obtain effici aspect time base effici tbe valu sec goal obtain satisfact aspect valu obtain includ grade b accept categori test result conclud web design use design think method improv user experi use websit"
  },
  {
    "doc_id": "10397668",
    "abstract_original": "It is fascinating to think about all the many ways in which information, intellect, and knowledge may be used in human existence. Because of the lightning-fast pace at which technology is advancing, it is now essential to amass a large quantity of data in order to forecast and investigate potential developments in the field of artificial intelligence. In order to identify new information inside databases, it is necessary to apply strategies and procedures taken from a variety of information systems specializations. The practice of data mining entails not only the finding of new information but also the extraction of information that may be put to beneficial use. In recent years, considerable advances have been made in decision-making abilities in a variety of contexts, including expert systems, artificial agent networks, and machine intelligence. These businesses include companies in the fields of commerce, education, architecture, and building construction, among others. The approach that was taken in this piece was derived from an analysis of the data mining strategies and developments that have seen the greatest amount of adoption across a variety of business sectors over the course of the last five years. These patterns and modes of operation were investigated. Throughout the course of this enquiry, the processes and patterns described above were scrutinized. The use of text mining as a tool for database analysis, the enhancement of worker productivity in the industrial sector, and the application of data mining for instructional practices are only a few instances of what has been learnt in the area of education. One other illustration of this would be the use of text mining as a technique for image recognition. It was also found in the fields of trade and industry.",
    "abstract_processed": "fascin think mani way inform intellect knowledg may use human exist lightn fast pace technolog advanc essenti amass larg quantiti data order forecast investig potenti develop field artifici intellig order identifi new inform insid databas necessari appli strategi procedur taken varieti inform system special practic data mine entail find new inform also extract inform may put benefici use recent year consider advanc made decis make abil varieti context includ expert system artifici agent network machin intellig busi includ compani field commerc educ architectur build construct among other approach taken piec deriv analysi data mine strategi develop seen greatest amount adopt across varieti busi sector cours last five year pattern mode oper investig throughout cours enquiri process pattern describ scrutin use text mine tool databas analysi enhanc worker product industri sector applic data mine instruct practic instanc learnt area educ one illustr would use text mine techniqu imag recognit also found field trade industri"
  },
  {
    "doc_id": "10397736",
    "abstract_original": "Occasionally, there may be a low impact on learning engagement between teachers and students due to, for example, poor internet connection or simply because students have lost their focus. One of the methods to improve learning engagement is through a research framework called Unified Theory Acceptance and Use of Technology (UTAUT). This paper adopted 17 UTAUT questions to compare with research variables (pre-post surveys and genders). The user acceptance and use of technology or UTAUT consisted of Likert scale (Strongly disagree to Strongly Agree) questions, computed to generate total scores for each participant. Then, the scores will be compared to each variable to investigate the relationships between these variables against the UTAUT. This study could be implemented via online learning, but in the end, the offline (unplugged) method was the only method to deliver the learning activities. There is limited evidence discussing UTAUT within the area of offline learning; hence, this paper will focus on another spectrum regarding the UTAUT study. Instead of mobile (online) learning engagement, this paper studies the relationship between unplugged learning with user acceptance and the use of technology. Spearman correlation indicated that the unplugged learning approach has a significant positive relationship with user acceptance and use of technology. It revealed that students may also demonstrate an interest in online learning engagement and be able to comprehensively accept the online learning approach. In contrast, Mann-Whitney U test analysis on genders revealed no significant difference. The findings could contribute to another noteworthy discussion regarding the validity of user acceptance and the use of technology against the unplugged learning approach.",
    "abstract_processed": "occasion may low impact learn engag teacher student due exampl poor internet connect simpli student lost focu one method improv learn engag research framework call unifi theori accept use technolog utaut paper adopt utaut question compar research variabl pre post survey gender user accept use technolog utaut consist likert scale strongli disagre strongli agre question comput gener total score particip score compar variabl investig relationship variabl utaut studi could implement via onlin learn end offlin unplug method method deliv learn activ limit evid discuss utaut within area offlin learn henc paper focu anoth spectrum regard utaut studi instead mobil onlin learn engag paper studi relationship unplug learn user accept use technolog spearman correl indic unplug learn approach signific posit relationship user accept use technolog reveal student may also demonstr interest onlin learn engag abl comprehens accept onlin learn approach contrast mann whitney u test analysi gender reveal signific differ find could contribut anoth noteworthi discuss regard valid user accept use technolog unplug learn approach"
  },
  {
    "doc_id": "10397791",
    "abstract_original": "Heart Complaint, alternately known as cardiovascular complaint, confines different terms that prompt the cardiovascular and is the rudimentary base of demise worldwide over the span of the once many lifetimes. It assorts numerous hazard facets in heart trouble and a desire of the moment to get factual, dependable, and discerning proffers to mould an ancient opinion to attain rapid-fire operation of the disease. In being work originally data balancing is done by using Synthetic Minority Oversampling fashion (SMOTE). Preprocessing is performed to homogenize the input data scale using min- maximum normalization system. Formerly get the regularized input data it sends for point selection grounded on Modified ditz Hunt Optimization (MCSO) system. Eventually heart complaint vaticination is reckoned grounded on Ensemble Improved Convolutional Neural Network (EICNN). Formerly get the dimensionality reduced features it'll be shoot for point selection using Mutation funk mass Optimization (MCSO). Eventually heart conditions Vaccination is performed by using Ensemble of colorful Convolutional Neural Network (EVCNN) models like VGG16, ResNet50, commencement-V3. Experimental results displays the effectiveness of the intended model in rapport of perfection, recall, delicacy and f-measure.",
    "abstract_processed": "heart complaint altern known cardiovascular complaint confin differ term prompt cardiovascular rudimentari base demis worldwid span mani lifetim assort numer hazard facet heart troubl desir moment get factual depend discern proffer mould ancient opinion attain rapid fire oper diseas work origin data balanc done use synthet minor oversampl fashion smote preprocess perform homogen input data scale use min maximum normal system formerli get regular input data send point select ground modifi ditz hunt optim mcso system eventu heart complaint vaticin reckon ground ensembl improv convolut neural network eicnn formerli get dimension reduc featur shoot point select use mutat funk mass optim mcso eventu heart condit vaccin perform use ensembl color convolut neural network evcnn model like vgg resnet commenc v experiment result display effect intend model rapport perfect recal delicaci f measur"
  },
  {
    "doc_id": "10398030",
    "abstract_original": "Image classification is a popular and important area of image processing research in today's society. For machine learning, SVM is a very good classification model. CNN is a type of convolution neural network that has an unpredictable development and uses convolution calculations. It is one of the most well-known deep learning algorithms. This review thinks about and inspects exemplary AI and profound learning picture classification procedures involving SVM and CNN as specific illustrations. Using a large sample mnist dataset, this study found that CNN has an accuracy of 0.97 and SVM has an accuracy of 0.89; SVM has an accuracy of 0.85 and CNN has an accuracy of 0.82 when working with a small sample ImageNet dataset. Tests in this review show that for little example informational collections, standard ML has an improved arrangement impact than deep learning structure does.",
    "abstract_processed": "imag classif popular import area imag process research today societi machin learn svm good classif model cnn type convolut neural network unpredict develop use convolut calcul one well known deep learn algorithm review think inspect exemplari ai profound learn pictur classif procedur involv svm cnn specif illustr use larg sampl mnist dataset studi found cnn accuraci svm accuraci svm accuraci cnn accuraci work small sampl imagenet dataset test review show littl exampl inform collect standard ml improv arrang impact deep learn structur"
  },
  {
    "doc_id": "10398148",
    "abstract_original": "The vast majority of email viruses propagate by ensuring that every address included in the address book of the victim is sent the malicious message or attachment. There are a variety of approaches that can be utilized in order to package and present these viruses. Some of them can be immediately identified as malicious based on the content of the body, the sender, who may or may not be trustworthy, and the subject lines, which are just unintelligible. It may be difficult for receivers to identify individual email messages that include malware since the malicious actor puts a lot of effort into making it appear as though the email message was sent from a respectable sender. Phishing is an attempt to steal sensitive information by impersonating a trustworthy entity, typically a business. Cybersecurity is an extremely important topic in the field of information technology. Information security is one of the most pressing problems facing our generation at the moment. When we think of cyber security, the first thing that comes to mind is cybercrime, which is expanding at an alarming rate. This is because cybercrime is the most common kind of online crime. In order to put an end to these cybercrimes, various governments and businesses are pursuing a variety of preventative measures. In spite of the many safeguards in place, a significant number of people continue to be anxious about the safety of their online activity. The difficulties surrounding the use of email viruses as a threat to cyber security are the primary focus of this article. From the point of view of email viruses, a unified approach for assessing the level of cyber security has been developed. In addition to this, it examines the most recent developments in the methods of cyber security, as well as the ethics and trends that are influencing the industry.",
    "abstract_processed": "vast major email virus propag ensur everi address includ address book victim sent malici messag attach varieti approach util order packag present virus immedi identifi malici base content bodi sender may may trustworthi subject line unintellig may difficult receiv identifi individu email messag includ malwar sinc malici actor put lot effort make appear though email messag sent respect sender phish attempt steal sensit inform imperson trustworthi entiti typic busi cybersecur extrem import topic field inform technolog inform secur one press problem face gener moment think cyber secur first thing come mind cybercrim expand alarm rate cybercrim common kind onlin crime order put end cybercrim variou govern busi pursu varieti prevent measur spite mani safeguard place signific number peopl continu anxiou safeti onlin activ difficulti surround use email virus threat cyber secur primari focu articl point view email virus unifi approach assess level cyber secur develop addit examin recent develop method cyber secur well ethic trend influenc industri"
  },
  {
    "doc_id": "10398308",
    "abstract_original": "While programming has been recognized as an engaging way to enhance students’ learning, implementing programming in K-12 education remains challenging, particularly when it requires access to digital devices or the internet. Therefore, it’s essential to consider more accessible methods for teaching crucial programming skills. Given this situation, we turned to unplugged computational thinking (CT) activities to foster interest and develop skills in programming. By introducing programming concepts through unplugged CT activities, this research significantly contributed to the growth of interest and the development of skills among secondary school students. Two hundred and thirty lower secondary school students volunteered to participate in the intervention using a designed unplugged CT activity framework. The CT activities framework consists of four components: puzzles, the Bebras Computing Challenge, problem-solving, and programming concepts. Four schools participated in three- to four-day interventions for four to five hours daily. Quantitative data collection was performed using pre- and post-surveys before and after the intervention phase. A paired sample t-test and Wilcoxon signed-rank tests indicated the p-value < 0.05 suggested a significant improvement in interest and programming skills. An overall findings implied that the unplugged CT activities enhanced students’ understanding of CT as well as improved their interest and programming skills.",
    "abstract_processed": "program recogn engag way enhanc students’ learn implement program k educ remain challeng particularli requir access digit devic internet therefor it’ essenti consid access method teach crucial program skill given situat turn unplug comput think ct activ foster interest develop skill program introduc program concept unplug ct activ research significantli contribut growth interest develop skill among secondari school student two hundr thirti lower secondari school student volunt particip intervent use design unplug ct activ framework ct activ framework consist four compon puzzl bebra comput challeng problem solv program concept four school particip three four day intervent four five hour daili quantit data collect perform use pre post survey intervent phase pair sampl test wilcoxon sign rank test indic p valu suggest signific improv interest program skill overal find impli unplug ct activ enhanc students’ understand ct well improv interest program skill"
  },
  {
    "doc_id": "10398325",
    "abstract_original": "This full paper presents the instillation of computational thinking (CT) in undergraduate students across multiple disciplines through an adaptive gamified e-learning platform. In today’s fast-paced digital age, possessing CT abilities is essential for effective critical thinking and problem-solving across various fields. To cultivate CT proficiency in students from diverse disciplines, we designed an innovative adaptive gamified e-learning platform called Computational Thinking Quest (CTQ). The eight key features of CTQ are (1) interactive storyline with customizable avatars, mini-games, and questions; (2) performance profiler; (3) comprehensive question bank with questions at three difficulty levels; (4) feedback and answer to each question; (5) additional learning resources via hyperlinks; (6) badges and leaderboard; (7) progress saving feature; and (8) integrated online feedback survey. The CTQ was introduced to recently enrolled first-year undergraduate students across all five discipline clusters at Singapore Institute of Technology. The learning performance and feedback of 135 students were gathered and examined. The student population comprised 33 Business, Communication and Design (BCD); 48 Health and Social Science (HSS); and 54 Infocomm Technology (ICT) undergraduates. Statistical results from the paired Student’s t-test reveal significant differences (p < 0.05) (i) between the pre-test and post-test scores for HSS, ICT, and all students combined; (ii) between the pre-test duration and post-test duration for all three clusters and all students combined; (iii) between the self-assessed knowledge score before CTQ and after completing CTQ for all three clusters and all students combined. Moreover, majority of the students commented that the CTQ generates interest in CT, is an engaging learning platform with enriching educational content, and has motivated their independent learning. Lastly, CTQ functions as an online preparatory course aimed at reducing the diversity in academic backgrounds and varying levels of prior knowledge of computer programming languages among students. This will help smoothly transition students into programming-relevant modules, and ultimately enhance the effectiveness of teaching and learning.",
    "abstract_processed": "full paper present instil comput think ct undergradu student across multipl disciplin adapt gamifi e learn platform today’ fast pace digit age possess ct abil essenti effect critic think problem solv across variou field cultiv ct profici student divers disciplin design innov adapt gamifi e learn platform call comput think quest ctq eight key featur ctq interact storylin customiz avatar mini game question perform profil comprehens question bank question three difficulti level feedback answer question addit learn resourc via hyperlink badg leaderboard progress save featur integr onlin feedback survey ctq introduc recent enrol first year undergradu student across five disciplin cluster singapor institut technolog learn perform feedback student gather examin student popul compris busi commun design bcd health social scienc hss infocomm technolog ict undergradu statist result pair student’ test reveal signific differ p pre test post test score hss ict student combin ii pre test durat post test durat three cluster student combin iii self assess knowledg score ctq complet ctq three cluster student combin moreov major student comment ctq gener interest ct engag learn platform enrich educ content motiv independ learn lastli ctq function onlin preparatori cours aim reduc divers academ background vari level prior knowledg comput program languag among student help smoothli transit student program relev modul ultim enhanc effect teach learn"
  },
  {
    "doc_id": "10398343",
    "abstract_original": "During the last two decades educational robotics became a popular tool for teaching STEM concepts to audiences of all levels. Yet, its use for teaching programming with university-level non-STEM audiences has not been researched so far. This work presents a new educational activity designed for teaching programming to non-STEM university-level audiences. The key aspect is a separation of teaching programming concepts and programming language and; therefore, complexity reduction in learning. The concepts are introduced using educational robotics and later on students learn how to use the concepts in the context of the Python programming language. Two teaching approaches, direct instruction and productive failure, along with a capstone challenge are deployed and their relationship to educational robotics is observed.",
    "abstract_processed": "last two decad educ robot becam popular tool teach stem concept audienc level yet use teach program univers level non stem audienc research far work present new educ activ design teach program non stem univers level audienc key aspect separ teach program concept program languag therefor complex reduct learn concept introduc use educ robot later student learn use concept context python program languag two teach approach direct instruct product failur along capston challeng deploy relationship educ robot observ"
  },
  {
    "doc_id": "10398358",
    "abstract_original": "Given the pervasive reliance on technology in modern society, teaching Computational Thinking (CT) abilities is becoming increasingly relevant. These abilities, such as modeling and coding, have become crucial for a larger audience of students, not only those who wish to become software engineers or computer scientists. Recent advances in Large Language Models (LLMs), such as ChatGPT, provide powerful assistance to complete computational tasks, by simplifying code generation and debugging, and potentially enhancing interactive learning. However, it is not clear if these advances make CT tasks more accessible and inclusive for all students, or if they further contribute to a digital skills divide, favoring the top students. To address this gap, we have created and evaluated a novel learning scenario for transversal CT skills that leveraged LLMs as assistants. We conducted an exploratory field study during the spring semester of 2022, to assess the effectiveness and user experience of LLM-augmented learning. Our results indicate that the usage of ChatGPT as a learning assistant improves learning outcomes. Furthermore, contrary to our predictions, the usage of ChatGPT by students does not depend on prior CT capabilities and as such does not seem to exacerbate prior inequalities.",
    "abstract_processed": "given pervas relianc technolog modern societi teach comput think ct abil becom increasingli relev abil model code becom crucial larger audienc student wish becom softwar engin comput scientist recent advanc larg languag model llm chatgpt provid power assist complet comput task simplifi code gener debug potenti enhanc interact learn howev clear advanc make ct task access inclus student contribut digit skill divid favor top student address gap creat evalu novel learn scenario transvers ct skill leverag llm assist conduct exploratori field studi spring semest assess effect user experi llm augment learn result indic usag chatgpt learn assist improv learn outcom furthermor contrari predict usag chatgpt student depend prior ct capabl seem exacerb prior inequ"
  },
  {
    "doc_id": "10399479",
    "abstract_original": "Scoliosis is a complicated spinal deformity, and millions of people are suffering from this disease worldwide. Early detection and accurate scoliosis assessment are vital for effective clinical management and patient outcomes. The Cobb Angle (CA) measurement is the most precise method for calculating scoliotic curvature, which plays an essential role in diagnosing and treating scoliosis. This letter has conducted a systematic review to analyze scoliosis detection by vertebra identification and CA estimation using the Preferred Reporting Item for Systematic Review and Meta-Analysis (PRISMA) guidelines. The major scientific databases such as Scopus, Web of Science (WoS), and IEEE Xplorer are explored, where 2017–2023 publications are considered. The article selection process is based on keywords like “Vertebra Identification,” “CA Estimation,” “Scoliosis Detection,” “Deep Learning (DL),” etc. After rigorous analysis, 413 articles are extracted, and 44 are identified for final consideration. Further, several investigations based on the previous work are discussed along with its Proposed Solutions (PS).",
    "abstract_processed": "scoliosi complic spinal deform million peopl suffer diseas worldwid earli detect accur scoliosi assess vital effect clinic manag patient outcom cobb angl ca measur precis method calcul scoliot curvatur play essenti role diagnos treat scoliosi letter conduct systemat review analyz scoliosi detect vertebra identif ca estim use prefer report item systemat review meta analysi prisma guidelin major scientif databas scopu web scienc wo ieee xplorer explor – public consid articl select process base keyword like “vertebra identif ” “ca estim ” “scoliosi detect ” “deep learn dl ” etc rigor analysi articl extract identifi final consider sever investig base previou work discuss along propos solut ps"
  },
  {
    "doc_id": "10399808",
    "abstract_original": "As the number of people using social networks increases, more people are using social media platforms to meet their news needs. Users think that it is easier to follow the agenda by accessing news, especially on Twitter, rather than newspaper news pages. However, fake news is increasingly appearing on social media, and it is not always possible for people to obtain correct news from partial news pages or short Twitter posts. Understanding whether the news shared on Twitter is true or not is an important problem. Detecting fake tweets is of great importance in Turkish as well as in any language. In this study, fake news obtained from verification platforms on Twitter and real news obtained from the Twitter accounts of mainstream newspapers were labeled and, preprocessed using the Zemberek natural language processing tool developed for the Turkish language, and a dataset named TR_FaRe_News was created. Then, the TR_FaRe_News dataset was explored using ensemble methods and BoW, TF-IDF, and Word2Vec vectorization methods for fake news detection. Then a pre-trained BERT deep learning model was fine-tuned, and variations of the model extended with Bi-LSTM and Convolutional Neural Network (CNN) layers with the frozen and unfrozen parameters methods were explored. The performance evaluation was conducted using seven comparable datasets, namely BuzzFeedNews, GossipCop, ISOT, LIAR, Twitter15, and Twitter16, including an LLM-generated fake news dataset. Analyzing Turkish tweets and using fake news datasets generated by LLM is considered an important contribution. Accuracy values between 90 and 94% were obtained with the BERT and BERTurk + CNN models with 94% accuracy.",
    "abstract_processed": "number peopl use social network increas peopl use social media platform meet news need user think easier follow agenda access news especi twitter rather newspap news page howev fake news increasingli appear social media alway possibl peopl obtain correct news partial news page short twitter post understand whether news share twitter true import problem detect fake tweet great import turkish well languag studi fake news obtain verif platform twitter real news obtain twitter account mainstream newspap label preprocess use zemberek natur languag process tool develop turkish languag dataset name tr fare news creat tr fare news dataset explor use ensembl method bow tf idf word vec vector method fake news detect pre train bert deep learn model fine tune variat model extend bi lstm convolut neural network cnn layer frozen unfrozen paramet method explor perform evalu conduct use seven compar dataset name buzzfeednew gossipcop isot liar twitter twitter includ llm gener fake news dataset analyz turkish tweet use fake news dataset gener llm consid import contribut accuraci valu obtain bert berturk cnn model accuraci"
  },
  {
    "doc_id": "10402125",
    "abstract_original": "As Virtual reality (VR) devices become more widespread, they are being recognized as efficient teaching tools for many subjects. In the 21st century, learners are expected to master important skills, which are difficult to teach in conventional lectures, such as computational thinking, critical thinking, creativity, and abstract reasoning. [1] Therefore, computer science or information technology courses often limit the discussion of recursion to calculating a factorial or a Fibonacci number, even though recursion is presented as an academic-type oddity in most cases. [2] To elucidate how VR can improve students’ computational thinking skills and abstract thinking associated with solving problems that require recursive algorithms, this paper examines the use of VR in computer science education to teach the abstract concept of recursion. The results of learners using VR Tower of Hanoi software are compared to those using the conventional Hanoi puzzle. Most learners show an improved understanding after experiencing the gameplay in the VR software, and some demonstrate a better understanding of recursion. In the post-survey, most participants acknowledge that the immersive environment is helpful when learning abstract subjects.",
    "abstract_processed": "virtual realiti vr devic becom widespread recogn effici teach tool mani subject st centuri learner expect master import skill difficult teach convent lectur comput think critic think creativ abstract reason therefor comput scienc inform technolog cours often limit discuss recurs calcul factori fibonacci number even though recurs present academ type odditi case elucid vr improv students’ comput think skill abstract think associ solv problem requir recurs algorithm paper examin use vr comput scienc educ teach abstract concept recurs result learner use vr tower hanoi softwar compar use convent hanoi puzzl learner show improv understand experienc gameplay vr softwar demonstr better understand recurs post survey particip acknowledg immers environ help learn abstract subject"
  },
  {
    "doc_id": "10402150",
    "abstract_original": "Learning programming language syntax is considered an obstacle in programming education. However, we believe it is an overlooked opportunity to exploit obvious synergies with Math. As evidenced around the world, middle and high school students know the syntax required to compute simple expressions, without previous exposure to programming languages. We make the case for an “expressions first” approach to facilitate the development of computational thinking. Our approach has the benefit of integrating directly with Math, which in turn reinforces the teaching of other STEM subjects as well as non-STEM ones. We report early results of an ongoing trial using a visual computing environment that supports this approach.",
    "abstract_processed": "learn program languag syntax consid obstacl program educ howev believ overlook opportun exploit obviou synergi math evidenc around world middl high school student know syntax requir comput simpl express without previou exposur program languag make case “express first” approach facilit develop comput think approach benefit integr directli math turn reinforc teach stem subject well non stem one report earli result ongo trial use visual comput environ support approach"
  },
  {
    "doc_id": "10402181",
    "abstract_original": "The development of computer science has led to an increase in programming education for younger people. Many countries have begun programming education in elementary schools. As is a relatively new subject in elementary education, the course design and textbooks for programming education remain under development. The growth trend in computational thinking (CT) is helpful for educators to teach suitable programming concepts to students. Scratch, which is mostly used as an introductory programming language for elementary school students, can be evaluated to reflect students’ CT. In this work-in-progress research, we conducted a data-driven analysis on fourth-grade students’ CT growth in their first 3 years of programming learning by evaluating their Scratch projects. A preliminary result shows that CT grows rapidly in the first 2 years and tends to be stable in the third year. The reasons for the difference in growth of specific CT concepts are discussed.",
    "abstract_processed": "develop comput scienc led increas program educ younger peopl mani countri begun program educ elementari school rel new subject elementari educ cours design textbook program educ remain develop growth trend comput think ct help educ teach suitabl program concept student scratch mostli use introductori program languag elementari school student evalu reflect students’ ct work progress research conduct data driven analysi fourth grade students’ ct growth first year program learn evalu scratch project preliminari result show ct grow rapidli first year tend stabl third year reason differ growth specif ct concept discuss"
  },
  {
    "doc_id": "10402296",
    "abstract_original": "Quantum mechanics is a fundamental, axiom-based physical theory that describes and explains phenomena that Classical Mechanics and Electrodynamics are unable to describe. It is considered a cross disciplinary STEM field, advancing the philosophy of Quantum Literacy (QL), which focuses on nature’s real complex problems. QL addresses the challenges of computing skills acquisition, through problem-based activities to offer powerful knowledge to a wide group of learners. Therefore, quantum technology knowledge should be accessible to students and teachers, in a more interactive way. In this paper, we propose contemporary and Problem based scenarios, in which students may acquire stronger mathematical, computational and modelling skills, working as real researchers. Thus, they acquire all necessary knowledge related to quantum principles, such as superposition, teleportation, entanglement, quantum gates and quantum information. The serious games we propose, relate to strategic games, within the computational thinking 2.0 framework. Certain Python libraries and packages are used and the didactic approach is based on game-based inquiry learning.",
    "abstract_processed": "quantum mechan fundament axiom base physic theori describ explain phenomena classic mechan electrodynam unabl describ consid cross disciplinari stem field advanc philosophi quantum literaci ql focus nature’ real complex problem ql address challeng comput skill acquisit problem base activ offer power knowledg wide group learner therefor quantum technolog knowledg access student teacher interact way paper propos contemporari problem base scenario student may acquir stronger mathemat comput model skill work real research thu acquir necessari knowledg relat quantum principl superposit teleport entangl quantum gate quantum inform seriou game propos relat strateg game within comput think framework certain python librari packag use didact approach base game base inquiri learn"
  },
  {
    "doc_id": "10403173",
    "abstract_original": "Dermoscopic image segmentation is a key step in computer-aided diagnosis of skin lesions. The current medical image segmentation model mainstream uses standard convolution and Transformers as the most important components of the model. However, standard convolution is unable to handle the problems of remote information interaction and long distance spatial dependence. Transformers is a hindrance to its application when dealing with medical clinical data, the insufficient amount of data and the large memory and time required for computation are hindering factors. Recently, HorNet, a high-order spatial interaction model that performs well in natural scenarios, has drawn our attention because the high-order interaction model has the common advantages of both convolution and Transformers. In this paper, we propose a new system that uses the HorNet model, which performs well in natural scenes, for medical image segmentation (skin lesion segmentation). To the best of our knowledge, we are the first to use a higher-order interaction model for medical image segmentation. We validate our system on three public datasets and do external validation on our own clinical dataset. The experimental results show that our system outperforms other current medical image segmentation models in several metrics. We think this is due to the higher spatial interaction capability and larger perceptual domain of gnconv in HorNet, which can fully and comprehensively capture the information of the overall medical image, which is crucial for medical image processing.",
    "abstract_processed": "dermoscop imag segment key step comput aid diagnosi skin lesion current medic imag segment model mainstream use standard convolut transform import compon model howev standard convolut unabl handl problem remot inform interact long distanc spatial depend transform hindranc applic deal medic clinic data insuffici amount data larg memori time requir comput hinder factor recent hornet high order spatial interact model perform well natur scenario drawn attent high order interact model common advantag convolut transform paper propos new system use hornet model perform well natur scene medic imag segment skin lesion segment best knowledg first use higher order interact model medic imag segment valid system three public dataset extern valid clinic dataset experiment result show system outperform current medic imag segment model sever metric think due higher spatial interact capabl larger perceptu domain gnconv hornet fulli comprehens captur inform overal medic imag crucial medic imag process"
  },
  {
    "doc_id": "10403882",
    "abstract_original": "The Internet of Things (IoT) infrastructure enables smart devices to learn, think, speak and perform. The facilities of the IoT devices can be enhanced to support an intelligent application through technologies like fog computing, smart networks, federated learning or explainable artificial intelligence infrastructures. In all these cases networking of IoT devices becomes inevitable. Whereever there exists a network, a threat to the network infrastructure is also possible. The proposed work classifies various attacks on the hosts with the support of proven machine learning (ML) algorithms. This work performs the comparative analysis of all these classification parameters of the machine learning algorithms with the use of fuzzy-based recommendation systems. This work also lists out various incidents of intrusions on the IoT hosts in appropriate layers of the interface and proposes an efficient algorithm and framework to overcome the occurrences of intrusions on the host side. In particular, we propose an effective security framework to deal with the intrusions that can deteriorate the host-based systems. The ranking of the algorithms is evaluated using fuzzy-based recommendation systems such as TOPSIS, VIKOR, MORA, WASPAS. The ensemble of machine learning algorithms such as Decision Tree, Lite Gradient Boost, Xtra Gradient Boost and Random Forest provide better values of accuracy (around 99%) with higher precision, re-call and F1-scores, thus proving their efficacy for intrusion detection in IoT networks.",
    "abstract_processed": "internet thing iot infrastructur enabl smart devic learn think speak perform facil iot devic enhanc support intellig applic technolog like fog comput smart network feder learn explain artifici intellig infrastructur case network iot devic becom inevit whereev exist network threat network infrastructur also possibl propos work classifi variou attack host support proven machin learn ml algorithm work perform compar analysi classif paramet machin learn algorithm use fuzzi base recommend system work also list variou incid intrus iot host appropri layer interfac propos effici algorithm framework overcom occurr intrus host side particular propos effect secur framework deal intrus deterior host base system rank algorithm evalu use fuzzi base recommend system topsi vikor mora waspa ensembl machin learn algorithm decis tree lite gradient boost xtra gradient boost random forest provid better valu accuraci around higher precis call f score thu prove efficaci intrus detect iot network"
  },
  {
    "doc_id": "10404103",
    "abstract_original": "This paper introduces a novel framework that melds the profound tenets of Indian philosophy with AI and ML. Our goal is to create models that replicate human cognition, paving the way for robots that think like us. Key concepts from Indian philosophy, including ”buddhi,” ”manas,” ”chit,” and ”ahamkar,” are woven into the framework, enhancing AI’s ability to understand and interact with the world in a more human-like way. The core of the framework consists of ”Buddhi” and ”Manas.” Buddhi, a discriminative AI component, adeptly navigates sensory data, making decisions aligned with human discernment. Complementing it, ”Manas” is a generative core, capable of crafting narratives and generating creative solutions. This synergy creates an iterative loop that encapsulates human thought, enabling machines to think, visualize, and even dream. In addition to advancing AI and ML research, we conducted an experiment using a modified News Aggregator dataset from the UCI repository. The experiment focused on word prediction, and our model, infused with Indian philosophy, outperformed RNN and LSTM models over 30 epochs. This framework has the potential to revolutionize AI and create more human-like machines, ushering in a new era of AI and robotics.",
    "abstract_processed": "paper introduc novel framework meld profound tenet indian philosophi ai ml goal creat model replic human cognit pave way robot think like us key concept indian philosophi includ ”buddhi ” ”mana ” ”chit ” ”ahamkar ” woven framework enhanc ai’ abil understand interact world human like way core framework consist ”buddhi” ”mana ” buddhi discrimin ai compon adeptli navig sensori data make decis align human discern complement ”manas” gener core capabl craft narr gener creativ solut synergi creat iter loop encapsul human thought enabl machin think visual even dream addit advanc ai ml research conduct experi use modifi news aggreg dataset uci repositori experi focus word predict model infus indian philosophi outperform rnn lstm model epoch framework potenti revolution ai creat human like machin usher new era ai robot"
  },
  {
    "doc_id": "10404881",
    "abstract_original": "Complex networks undergird everything from social media interactions to biological processes; therefore, uncovering their concealed patterns is more crucial than ever in today's digital world. The proposed work investigates graph mining techniques, emphasizing Frequent Subgraph Mining, to identify recurring themes and relationships in complex networks. The proposed study investigates in depth the relationship between graph representation, node and edge attributes, and network metrics, enabling analysts to evaluate a wide variety of data easily. Examining the applicability of Frequent Subgraph Mining in numerous contexts, ranging from social networks to biological systems, facilitates decision-making and inspires originality. The results demonstrate that these techniques are useful for identifying patterns and are computationally efficient, making them indispensable instruments for understanding the digital foundations of complex networks.",
    "abstract_processed": "complex network undergird everyth social media interact biolog process therefor uncov conceal pattern crucial ever today digit world propos work investig graph mine techniqu emphas frequent subgraph mine identifi recur theme relationship complex network propos studi investig depth relationship graph represent node edg attribut network metric enabl analyst evalu wide varieti data easili examin applic frequent subgraph mine numer context rang social network biolog system facilit decis make inspir origin result demonstr techniqu use identifi pattern comput effici make indispens instrument understand digit foundat complex network"
  },
  {
    "doc_id": "10405388",
    "abstract_original": "In recent years, there has been significant research conducted on the integration of game approach into education, particularly focusing on the utilization of Agent-based models (ABMs). These ABMs have gained prominence due to the advancement of computational technology, offering a flexible and creative approach to reshape science education. This study delves into the application of ABM technology within fundamental scientific learning games, aiming to explore the effects of incorporating ABMs into the game approach for learning of physics. Through this investigation, the potential transformational influence of ABMs on enhancing the game approach of physics education is examined.",
    "abstract_processed": "recent year signific research conduct integr game approach educ particularli focus util agent base model abm abm gain promin due advanc comput technolog offer flexibl creativ approach reshap scienc educ studi delv applic abm technolog within fundament scientif learn game aim explor effect incorpor abm game approach learn physic investig potenti transform influenc abm enhanc game approach physic educ examin"
  },
  {
    "doc_id": "10408402",
    "abstract_original": "Increased data availability has stimulated the interest in studying sports prediction problems via analytical approaches; in particular, with machine learning and simulation. We characterize several models that have been proposed in the literature, all of which suffer from the same drawback: they cannot incorporate rational decision-making and strategies from teams/players effectively. We tackle this issue by proposing hybrid simulation logic that incorporates teams as agents, generalizing the models/methodologies that have been proposed in the past. We perform a case study on the NBA with two goals: i) study the quality of predictions when using only one predictive variable, and ii) study how much historical data should be kept to maximize prediction accuracy. Results indicate that there is an optimal range of data quantity and that studying what data and variables to include is of extreme importance.",
    "abstract_processed": "increas data avail stimul interest studi sport predict problem via analyt approach particular machin learn simul character sever model propos literatur suffer drawback cannot incorpor ration decis make strategi team player effect tackl issu propos hybrid simul logic incorpor team agent gener model methodolog propos past perform case studi nba two goal studi qualiti predict use one predict variabl ii studi much histor data kept maxim predict accuraci result indic optim rang data quantiti studi data variabl includ extrem import"
  },
  {
    "doc_id": "10410382",
    "abstract_original": "Nowadays, online learning has been an important and effective auxiliary method for learning. Online reviews given by learners contain a ton of information. To reveal insight from the online reviews can enhance online course qualities. Sentiment analysis is proposed here to understand what learners think. Herein, this study focuses on model selection in sentiment analysis. Firstly, an explorative study was conducted to comprehend the review data. Next, different sentiment analysis models including rule-based and deep learning methods were utilized and their performance evaluated to find an optimal model. 7871 pieces of online reviews from Udemy paid courses collected from May 2017 to June 2023 were analyzed. The study finds that RoBERTa performed better on the educational review data. The results also illustrated common words with frequent occurrence given by paid online learners.",
    "abstract_processed": "nowaday onlin learn import effect auxiliari method learn onlin review given learner contain ton inform reveal insight onlin review enhanc onlin cours qualiti sentiment analysi propos understand learner think herein studi focus model select sentiment analysi firstli explor studi conduct comprehend review data next differ sentiment analysi model includ rule base deep learn method util perform evalu find optim model piec onlin review udemi paid cours collect may june analyz studi find roberta perform better educ review data result also illustr common word frequent occurr given paid onlin learner"
  },
  {
    "doc_id": "10410390",
    "abstract_original": "Poetry generation is a branch of text generation that demands a high level of linguistic proficiency and creativity. The Urdu language, renowned for its rich poetic tradition, encompasses a diverse collection of poets, each possessing a unique writing style. This research explores the automatic generation of Urdu poetry, specifically Urdu ghazals which hold a significant cultural value using natural language processing (NLP) techniques including deep learning. The dataset used consists of 17,609 couplets from the works of 15 renowned Urdu ghazal poets. We use three different approaches for poetry generation which include (a) the n-gram probabilistic model, (b) deep learning models such as LSTM and GRU, and (c) the state-of-the-art GPT-2 model. BLEU scores for each of these were (a) 0.5 for the n-gram model, (b) 0.1 for LSTM and GRU and, (c) 0.6 for the GPT-2 model, which was the highest overall score. In addition to the BLEU score, other metrics such as rhyming score and human evaluation were considered for evaluating the generated poetry. This research is the first to use transformer-based models for Urdu poetry generation, which enables aspiring poets to learn from and be inspired by the rich tradition of Urdu poetry.",
    "abstract_processed": "poetri gener branch text gener demand high level linguist profici creativ urdu languag renown rich poetic tradit encompass divers collect poet possess uniqu write style research explor automat gener urdu poetri specif urdu ghazal hold signific cultur valu use natur languag process nlp techniqu includ deep learn dataset use consist couplet work renown urdu ghazal poet use three differ approach poetri gener includ n gram probabilist model b deep learn model lstm gru c state art gpt model bleu score n gram model b lstm gru c gpt model highest overal score addit bleu score metric rhyme score human evalu consid evalu gener poetri research first use transform base model urdu poetri gener enabl aspir poet learn inspir rich tradit urdu poetri"
  },
  {
    "doc_id": "10410397",
    "abstract_original": "This study implemented the flipped classroom model in an education research methods course by means of Xue Xi Tong online learning platform and explored effective practices for enhancing students’ practical ability based on blended learning mode. The flipped classroom model for the course is primarily classified into three stages: pre-class, in-class, and after-class. In the pre-class stage, teachers used online learning platform and MOOC course materials as a tool to help students make due preparation for classroom. In the in-class stage, teachers organized active learning activities featured by experiential learning and collaborative peer work. In the afterclass stage, teachers design practice-oriented and problem-based assignment for students to reflect on the learning content. Meanwhile, it is important for instructors to provide detailed instructions on how to learn with the learning materials prior to class and focus on cultivating students’ higher order thinking skills in the teaching and learning process.",
    "abstract_processed": "studi implement flip classroom model educ research method cours mean xue xi tong onlin learn platform explor effect practic enhanc students’ practic abil base blend learn mode flip classroom model cours primarili classifi three stage pre class class class pre class stage teacher use onlin learn platform mooc cours materi tool help student make due prepar classroom class stage teacher organ activ learn activ featur experienti learn collabor peer work afterclass stage teacher design practic orient problem base assign student reflect learn content meanwhil import instructor provid detail instruct learn learn materi prior class focu cultiv students’ higher order think skill teach learn process"
  },
  {
    "doc_id": "10410406",
    "abstract_original": "Big data background is a prerequisite for precision teaching, and big data can bring scientific and perfect technical support for precision teaching. This study explores the process of combining precision teaching and data technology with the goal of optimising teaching quality. Teachers can use big data to efficiently collect students’ knowledge mastery, as well as being able to analyse the difficulty of test papers and count students’ performance, allowing teachers to make significant changes in their conception of teaching, the setting of teaching content and the use of teaching models, and big data makes teaching quality a strong guarantee.",
    "abstract_processed": "big data background prerequisit precis teach big data bring scientif perfect technic support precis teach studi explor process combin precis teach data technolog goal optimis teach qualiti teacher use big data effici collect students’ knowledg masteri well abl analys difficulti test paper count students’ perform allow teacher make signific chang concept teach set teach content use teach model big data make teach qualiti strong guarante"
  },
  {
    "doc_id": "10410841",
    "abstract_original": "This article presents a scientometric and literature analysis of current research on ChatGPT, a conversational AI technology developed by OpenAI. Using various databases, 103 relevant articles were retrieved and analyzed through scientometric, quantitative, and application-based approaches. A Google trend analysis and comparison with other generative AI and chatbot technologies were also carried out. The study provides insights into the distribution of ChatGPT publications across different countries and regions, the network of co-occurring keywords, authorship analysis, article typology, and publishing entities. The findings offer a comprehensive overview of the current state of ChatGPT research, highlighting key directions for future research. The study finds that ChatGPT has gained significant attention and interest in online platforms, particularly in technology, education, and healthcare, and highlights potential ethical and legal concerns related to its use. Its applications extend to several literary and text generation areas. We do note that the sample of extracted publications is lower than anticipated due to the niche area of investigation. The article is relevant to researchers, practitioners, and policymakers interested in the field of AI-powered language models, especially ChatGPT.",
    "abstract_processed": "articl present scientometr literatur analysi current research chatgpt convers ai technolog develop openai use variou databas relev articl retriev analyz scientometr quantit applic base approach googl trend analysi comparison gener ai chatbot technolog also carri studi provid insight distribut chatgpt public across differ countri region network co occur keyword authorship analysi articl typolog publish entiti find offer comprehens overview current state chatgpt research highlight key direct futur research studi find chatgpt gain signific attent interest onlin platform particularli technolog educ healthcar highlight potenti ethic legal concern relat use applic extend sever literari text gener area note sampl extract public lower anticip due nich area investig articl relev research practition policymak interest field ai power languag model especi chatgpt"
  },
  {
    "doc_id": "10412418",
    "abstract_original": "It is one of humanity’s greatest needs today to be able to transmit electric current using power lines from power plants to cities, Therefore, power generation companies are always thinking about improving power transmission lines. As a result of pollution sitting on electrical insulators and making them conductive, power lines lose most of their power. Therefore, we need more effective and newer methods to wash these pollutions from electrical insulators. In this article, the cleaning of electrical insulators using a fiber laser by a hexarotor has been investigated. The control of these systems is done either by a pilot at the ground station or by an autopilot. The steps involved in construction and the parts described. Solidworks flow simulatin was used to simulate the effect of wind at a height of 50 meters near the power tower using computational fluid dynamics (CFD).",
    "abstract_processed": "one humanity’ greatest need today abl transmit electr current use power line power plant citi therefor power gener compani alway think improv power transmiss line result pollut sit electr insul make conduct power line lose power therefor need effect newer method wash pollut electr insul articl clean electr insul use fiber laser hexarotor investig control system done either pilot ground station autopilot step involv construct part describ solidwork flow simulatin use simul effect wind height meter near power tower use comput fluid dynam cfd"
  },
  {
    "doc_id": "10413447",
    "abstract_original": "Suicidal ideation detection is a vital research area that holds great potential for improving mental health support systems. However, the sensitivity surrounding suicide-related data poses challenges in accessing large-scale, annotated datasets necessary for training effective machine learning models. To address this limitation, we introduce an innovative strategy that leverages the capabilities of generative AI models, such as ChatGPT, Flan-T5, and Llama, to create synthetic data for suicidal ideation detection. Our data generation approach is grounded in social factors extracted from psychology literature and aims to ensure coverage of essential information related to suicidal ideation. In our study, we benchmarked against state-of-the-art NLP classification models, specifically, those centered around the BERT family structures. When trained on the real-world dataset, UMD, these conventional models tend to yield F1-scores ranging from 0.75 to 0.87. Our synthetic data-driven method, informed by social factors, offers consistent F1-scores of 0.82 for both models, suggesting that the richness of topics in synthetic data can bridge the performance gap across different model complexities. Most impressively, when we combined a mere 30% of the UMD dataset with our synthetic data, we witnessed a substantial increase in performance, achieving an F1-score of 0.88 on the UMD test set. Such results underscore the cost-effectiveness and potential of our approach in confronting major challenges in the field, such as data scarcity and the quest for diversity in data representation.",
    "abstract_processed": "suicid ideat detect vital research area hold great potenti improv mental health support system howev sensit surround suicid relat data pose challeng access larg scale annot dataset necessari train effect machin learn model address limit introduc innov strategi leverag capabl gener ai model chatgpt flan llama creat synthet data suicid ideat detect data gener approach ground social factor extract psycholog literatur aim ensur coverag essenti inform relat suicid ideat studi benchmark state art nlp classif model specif center around bert famili structur train real world dataset umd convent model tend yield f score rang synthet data driven method inform social factor offer consist f score model suggest rich topic synthet data bridg perform gap across differ model complex impress combin mere umd dataset synthet data wit substanti increas perform achiev f score umd test set result underscor cost effect potenti approach confront major challeng field data scarciti quest divers data represent"
  },
  {
    "doc_id": "10415237",
    "abstract_original": "This article introduces a novel approach to remote laboratory instruction, specifically designed for teaching three-dimensional modeling using Blender software. The lab uses virtual machines to provide students with the necessary computational power to carry out the course activities, along with the correct version of the software. The flipped remote lab approach combines the elements of flipped classroom and peer assessment, making it suitable for face-to-face, totally online, or hybrid classes. Prior to each of the two lectures, students begin to practice by replicating the instructor's demonstrations in a set of concise tutorials. Upon completion of the assigned tasks, students carry out self-assessments of their own modeling, in addition to assessing two models created by their peers. A rubric comprising three questions facilitates the assessment process and allows providing feedback on each response. During the subsequent lecture, students work together with the instructor to address challenges encountered in their modeling, exploring also the advanced aspects of software usage that time constraints preclude in a traditional setting. The analysis of the flipped remote lab results reveals that student responses in peer-assessment activities are relevant to the posed questions. Moreover, the students who realized the models demonstrated a comparable level of rigor in self-assessment as their mates who reviewed their works. While students express a high degree of appreciation for the laboratory activities, a notable concern is the highlighted heavy workload. Increasing the allocated time for task completion can help mitigate the workload impact. The article concludes with insights gained from the implementation of the flipped remote lab approach.",
    "abstract_processed": "articl introduc novel approach remot laboratori instruct specif design teach three dimension model use blender softwar lab use virtual machin provid student necessari comput power carri cours activ along correct version softwar flip remot lab approach combin element flip classroom peer assess make suitabl face face total onlin hybrid class prior two lectur student begin practic replic instructor demonstr set concis tutori upon complet assign task student carri self assess model addit assess two model creat peer rubric compris three question facilit assess process allow provid feedback respons subsequ lectur student work togeth instructor address challeng encount model explor also advanc aspect softwar usag time constraint preclud tradit set analysi flip remot lab result reveal student respons peer assess activ relev pose question moreov student realiz model demonstr compar level rigor self assess mate review work student express high degre appreci laboratori activ notabl concern highlight heavi workload increas alloc time task complet help mitig workload impact articl conclud insight gain implement flip remot lab approach"
  },
  {
    "doc_id": "10417477",
    "abstract_original": "In recent years, the emergence of cooperative robots has been facilitated by technological advances, including the development of safety devices. Although these robots are considerably more flexible than conventional industrial robots, when confronted with a new task, the human operator is often left to address related problems unaided. The aim of this research is to develop a smart collaborative robot, where a rapid and accurate robot and a flexible human operator work synergistically to achieve a common objective. In the proposed system, humans and robots work together to tackle the same combinatorial optimization problem; the robot actively engages in problem-solving, while the human has the ability to override the robot's actions if disagreements arise, and to execute alternative actions. To facilitate this collaboration, this paper presents the development of a manipulator that enables two separate control centers the human brain and the robot's computational system to cooperate in solving complex, cognitive-motor tasks.",
    "abstract_processed": "recent year emerg cooper robot facilit technolog advanc includ develop safeti devic although robot consider flexibl convent industri robot confront new task human oper often left address relat problem unaid aim research develop smart collabor robot rapid accur robot flexibl human oper work synergist achiev common object propos system human robot work togeth tackl combinatori optim problem robot activ engag problem solv human abil overrid robot action disagr aris execut altern action facilit collabor paper present develop manipul enabl two separ control center human brain robot comput system cooper solv complex cognit motor task"
  },
  {
    "doc_id": "10418213",
    "abstract_original": "Smart spaces are physical environments equipped with sensors, actuators, and other computing devices to gather data and provide intelligent services to users. These spaces are made possible by ubiquitous computing, particularly context-aware computing. Although these systems are mainly implemented on mobile and other resource-constrained wearable devices, different techniques have been adopted for their implementation. Rule-based reasoning is a relatively easy-to-implement approach that can solve real-world problems. Rule-based systems rely on a set of assertions that constitute the working memory and a set of rules that govern what should be done with the set of assertions. Despite its relative simplicity, the working memory size is a critical factor in developing these systems, particularly for resource-constrained devices. In this paper, we propose techniques for efficiently calculating the working memory size. Our results show that all three techniques, DWM, APS, and SAPS, performed well in different ways. However, APS and SAPS consumed from 25% to 100% less memory than existing techniques.",
    "abstract_processed": "smart space physic environ equip sensor actuat comput devic gather data provid intellig servic user space made possibl ubiquit comput particularli context awar comput although system mainli implement mobil resourc constrain wearabl devic differ techniqu adopt implement rule base reason rel easi implement approach solv real world problem rule base system reli set assert constitut work memori set rule govern done set assert despit rel simplic work memori size critic factor develop system particularli resourc constrain devic paper propos techniqu effici calcul work memori size result show three techniqu dwm ap sap perform well differ way howev ap sap consum less memori exist techniqu"
  },
  {
    "doc_id": "10419197",
    "abstract_original": "Contribution: This research illuminates information entropy’s efficacy as a pivotal educational tool in programming, enabling the precise quantification of algorithmic complexity and student abstraction levels for solving P problems. This approach can provide students quantitative, comparative insights into the differences between optimal and student implemented solution, and allowing educators to offer targeted feedback, thereby optimizing the learning and abstraction processes in algorithm design through deliberate practice. Background: Abstraction is considered one of the most impor11 tant skills in problem solving. Many studies in programming have shown that higher abstraction capability can significantly simplify problems, reduce program complexity and improve efficiency. However, it is difficult to develop criteria to measure the level of abstraction, and there is still a lack of relevant systematic research. Research Questions: 1) How can students’ abstraction ability in programming be effectively measured? 2) How to develop programming education and training methods based on the measurement of abstraction ability? Methodology: Forty-six grade 10 students participated in the experiment, divided into two groups for programming train23 ing using information-entropy-based assessment and traditional learning methods. Their level of computational thinking, algo25 rithmic efficiency improvements, and test scores were used to measure performance and to analyze the effectiveness of the training methods. Findings: Through empirical research, this article finds that information-entropy-based assessment can reflect the differences in problem solving among students possessing varying capa31 bilities. Information entropy can be crucial for evaluating and improving students’ abstraction performance and algorithm efficiency.",
    "abstract_processed": "contribut research illumin inform entropy’ efficaci pivot educ tool program enabl precis quantif algorithm complex student abstract level solv p problem approach provid student quantit compar insight differ optim student implement solut allow educ offer target feedback therebi optim learn abstract process algorithm design deliber practic background abstract consid one impor tant skill problem solv mani studi program shown higher abstract capabl significantli simplifi problem reduc program complex improv effici howev difficult develop criteria measur level abstract still lack relev systemat research research question students’ abstract abil program effect measur develop program educ train method base measur abstract abil methodolog forti six grade student particip experi divid two group program train ing use inform entropi base assess tradit learn method level comput think algo rithmic effici improv test score use measur perform analyz effect train method find empir research articl find inform entropi base assess reflect differ problem solv among student possess vari capa biliti inform entropi crucial evalu improv students’ abstract perform algorithm effici"
  },
  {
    "doc_id": "10421076",
    "abstract_original": "In the digital era, the interaction between people and machines is constantly changing the way of interaction between people and between people and society, making people feel the unprecedented development of science and technology. In order to systematically study the influence of human-computer interaction on automatic recognition technology of print robot, the influence of human-computer interaction on human thinking mode, behavior mode and experience demand is analyzed. Secondly, from the perspective of media and its interaction, it describes the impact of human-computer interaction on machine recognition methods from four aspects: expanding the range of spatial information through multisource data, and improving the sensory experience through multi-channel interaction. Finally, under the background of new information technology, new interaction mode, intelligent feedback and new emotional factors, the dynamic response process is improved through real-time recording and feedback. The interaction between machines can create more opportunities for the automatic recognition technology of printing robots, and expand the research direction and the development of new designs.",
    "abstract_processed": "digit era interact peopl machin constantli chang way interact peopl peopl societi make peopl feel unpreced develop scienc technolog order systemat studi influenc human comput interact automat recognit technolog print robot influenc human comput interact human think mode behavior mode experi demand analyz secondli perspect media interact describ impact human comput interact machin recognit method four aspect expand rang spatial inform multisourc data improv sensori experi multi channel interact final background new inform technolog new interact mode intellig feedback new emot factor dynam respons process improv real time record feedback interact machin creat opportun automat recognit technolog print robot expand research direct develop new design"
  },
  {
    "doc_id": "10423676",
    "abstract_original": "This article presents a study carried out with two grade 1 classes, in the context of implementing the new Mathematics' curriculum. A sequence of tasks was carried out with the purpose of developing computational thinking, practices articulated with learning about the topic Numbers, and an attempt was made to identify the five practices of computational thinking in the students' activities. We ascertained that the students mobilized all the practices, the emergence of algorithmics coming to the fore and, at the same time, these practices allowed them to delve deeper into their mathematical knowledge in the content explored in the topic Numbers.",
    "abstract_processed": "articl present studi carri two grade class context implement new mathemat curriculum sequenc task carri purpos develop comput think practic articul learn topic number attempt made identifi five practic comput think student activ ascertain student mobil practic emerg algorithm come fore time practic allow delv deeper mathemat knowledg content explor topic number"
  },
  {
    "doc_id": "10423681",
    "abstract_original": "Large language models (LLMs) are being criticized for copyright infringement, inadvertent bias in training data, a danger to human innovation, the possibility of distributing incorrect or misleading information, and prejudice. Due to their popularity among students, the introduction of many comparable apps, and the inability to resist unfair and fraudulent student usage, their educational use needs to be adapted and harmonized. The incorporation of LLMs should be defined not only by pedagogues and educational institutions, but also by students who will actively utilize them to learn and prepare assignments. In order to find out what students from two universities think and suggest about LLMs use in education, they were asked to give their contribution by answering the survey that was conducted at the beginning of the spring semester of academic 2022/23. Their feedback was quantitatively and qualitatively analyzed, showing in a better light what students think about LLMs and how and why they would use them. Based on the analysis, the authors propose an original strategy for integrating LLMs into education. The proposed approach is also adapted for those students who are not interested in using LLMs and for those who prefer the hybrid mode by combining their own research with LLMs generated recommendations. The authors expect that by implementing the proposed strategy, schools will benefit from a better education in which research, creativity, academic honesty, recognition of false information, and the ability to improve knowledge will prevail.",
    "abstract_processed": "larg languag model llm critic copyright infring inadvert bia train data danger human innov possibl distribut incorrect mislead inform prejudic due popular among student introduct mani compar app inabl resist unfair fraudul student usag educ use need adapt harmon incorpor llm defin pedagogu educ institut also student activ util learn prepar assign order find student two univers think suggest llm use educ ask give contribut answer survey conduct begin spring semest academ feedback quantit qualit analyz show better light student think llm would use base analysi author propos origin strategi integr llm educ propos approach also adapt student interest use llm prefer hybrid mode combin research llm gener recommend author expect implement propos strategi school benefit better educ research creativ academ honesti recognit fals inform abil improv knowledg prevail"
  },
  {
    "doc_id": "10423693",
    "abstract_original": "The modern board game market (MBG) has been evolving gradually, and its mechanics appear to support concepts of Computational Thinking (CT). Seen as pedagogical resources applicable in the classroom context, this study analysed 10 MBGs with the aim of identifying aspects that can promote the development of CT, with a special focus on the modern board game 'Rossio.' Building upon the LM-TM model, an adapted version of the LM-GM model for board games, we propose a new framework that relates Computational Thinking learning mechanics (CTLM-TM) with tabletop game mechanisms.",
    "abstract_processed": "modern board game market mbg evolv gradual mechan appear support concept comput think ct seen pedagog resourc applic classroom context studi analys mbg aim identifi aspect promot develop ct special focu modern board game rossio build upon lm tm model adapt version lm gm model board game propos new framework relat comput think learn mechan ctlm tm tabletop game mechan"
  },
  {
    "doc_id": "10423707",
    "abstract_original": "This study presents the development of integrated computational thinking in mathematics lessons. The lessons were intended to support students' computational thinking while learning mathematics. To do so, we used the educational design research (EDR) methodology to develop the lessons. We collaborated with mathematics teachers and practitioners to improve the lessons. We also piloted the lessons for a few junior high school students in Indonesia. We collected data from online discussions with teachers and practitioners, GeoGebra files, and screen video recordings. We found that collaboration with teachers and practitioners helped us to refine the lessons. The pilot study showed the engagement of students in programming and debugging. Mostly students could solve the final task to create an inscribed polygon in a circle.",
    "abstract_processed": "studi present develop integr comput think mathemat lesson lesson intend support student comput think learn mathemat use educ design research edr methodolog develop lesson collabor mathemat teacher practition improv lesson also pilot lesson junior high school student indonesia collect data onlin discuss teacher practition geogebra file screen video record found collabor teacher practition help us refin lesson pilot studi show engag student program debug mostli student could solv final task creat inscrib polygon circl"
  },
  {
    "doc_id": "10423710",
    "abstract_original": "A Computational Thinking (CT) training program proposes a set of instruments to be used in the training, and also a set of recommendations on how to use them. To design such a program it is necessary to have a deep knowledge about the meaning of CT and its targets. Although CT skills are of paramount importance to all (since they bring numerous advantages for problem solving activities), in our context we see them as a pre-requisite for the learning of Computer Programming (CP). In order to design a CT training program supported by a rigorous framework, we decided to build an ontology that goes deeper into the underlying concepts and relates both domains, CT and CP. The outcome, OntoCnE (that stands for Ontologia para Computação na Escola in Portuguese), made clear what shall be trained in terms of reasoning to understand programming and being able to use it to solve problems using the computer. Moreover, OntoCnE also provides a clear insight on the concepts to be taught in each scholar year, as well as, on the instruments (hereafter called Learning Resources, LR) to be used in each moment for each specific purpose. This paper aims to introduce OntoCnE and demonstrates how to use it to classify LRs aiming to build a repository from where they can be picked up in a clear way. Finally, we demonstrate, through the PathIt resource, how the characterization of a concrete LR is performed in OntoCnE.",
    "abstract_processed": "comput think ct train program propos set instrument use train also set recommend use design program necessari deep knowledg mean ct target although ct skill paramount import sinc bring numer advantag problem solv activ context see pre requisit learn comput program cp order design ct train program support rigor framework decid build ontolog goe deeper underli concept relat domain ct cp outcom ontocn stand ontologia para computação na escola portugues made clear shall train term reason understand program abl use solv problem use comput moreov ontocn also provid clear insight concept taught scholar year well instrument hereaft call learn resourc lr use moment specif purpos paper aim introduc ontocn demonstr use classifi lr aim build repositori pick clear way final demonstr pathit resourc character concret lr perform ontocn"
  },
  {
    "doc_id": "10423763",
    "abstract_original": "This study aims to explore the integration of Internet of Things (IoT) technology and artificial intelligence (AI) in art education, assessing its impact on learners’ experiences and learning outcomes. The study first proposes a digital teaching system that enables the IoT and Generative Adversarial Networks (GANs) to play a role in art education by monitoring students’ creative state in real-time, providing immediate feedback, and facilitating the generation of creative works. The system framework includes sensor nodes, an IoT platform, a GAN model, and a user interface to build a real-time interactive environment. Sensor nodes constantly collect physiological, movement, and environmental data from students, and the GAN model receives student data from the IoT platform, combining creative input from students to generate artwork in real-time. The generated works are transmitted to the discriminator through the IoT platform, which evaluates their quality and provides real-time feedback. Students interact with the system through the user interface, observe the generated artwork, adjust generator parameters, and propose new ideas. These interactions influence further artistic creation. The WikiArt public art creation dataset is selected to establish the experimental foundation, and the experimental evaluation focuses on image generation quality, system performance, and student learning outcomes. It is compared with Deep Convolutional Generative Adversarial Network (DCGAN) and Variational Autoencoder (VAE) models. The research results indicate that the designed IoT and GANs integrated system remarkably outperforms DCGAN and VAE in image generation quality, with an Inception Score of 4.5, which is more diverse and recognizable than other models. Regarding system performance, the IoT and GANs integrated system is significantly ahead in image generation speed and user interaction, with a transmission speed of up to 200 Mbps. Regarding student learning outcomes, the system performs excellently in emotional feedback, learning outcomes, and creative work quality, achieving 80% satisfaction and 90% positive feedback. Overall, the research conclusion clearly points out that the integration of IoT and GANs has a significant and comprehensive effect on improving the quality of art education. This study expands the field of art education by integrating IoT and GANs, enhancing students’ creative experiences, and providing innovative methods for art teaching in the digital age.",
    "abstract_processed": "studi aim explor integr internet thing iot technolog artifici intellig ai art educ assess impact learners’ experi learn outcom studi first propos digit teach system enabl iot gener adversari network gan play role art educ monitor students’ creativ state real time provid immedi feedback facilit gener creativ work system framework includ sensor node iot platform gan model user interfac build real time interact environ sensor node constantli collect physiolog movement environment data student gan model receiv student data iot platform combin creativ input student gener artwork real time gener work transmit discrimin iot platform evalu qualiti provid real time feedback student interact system user interfac observ gener artwork adjust gener paramet propos new idea interact influenc artist creation wikiart public art creation dataset select establish experiment foundat experiment evalu focus imag gener qualiti system perform student learn outcom compar deep convolut gener adversari network dcgan variat autoencod vae model research result indic design iot gan integr system remark outperform dcgan vae imag gener qualiti incept score divers recogniz model regard system perform iot gan integr system significantli ahead imag gener speed user interact transmiss speed mbp regard student learn outcom system perform excel emot feedback learn outcom creativ work qualiti achiev satisfact posit feedback overal research conclus clearli point integr iot gan signific comprehens effect improv qualiti art educ studi expand field art educ integr iot gan enhanc students’ creativ experi provid innov method art teach digit age"
  },
  {
    "doc_id": "10424137",
    "abstract_original": "Collaborative learning in higher education, such as the emerging makerspaces, has contributed to research on innovation and participant expertise. However, there is little research on knowledge management in makerspaces or how learners transfer their individual tacit knowledge in the collaborative space. In addition, the functionality of maker education to promote individualized and personalized learning still needs to be explored. This study is based on Chinese STEM graduate students’ experiences with project-based learning in a Maker Education environment to test how AIGC tools help to acquire and transfer students’ individual tacit knowledge. The sample was formed from 266 MPhil students taking the \"Design Thinking and Effective Academic Communication\" course in their first academic year at the world’s first interdisciplinary university in southern China. The AIGC teaching intervention was based on the four-phase knowledge management model. In a cycle of socialization-externalization-combination-internalization,learners first explore expertise in a research area in project teams and formulate their research interest. Then, storytelling, analogy, and metaphor data were first used to assess students’ abilities to communicate their research topic in text and images on an A4 paper. The subsequent AIGC-supported instructional intervention consisted of 20-minute instructional Sprints with two instructors from Computational Media Arts and Academic Communication over two consecutive weeks. The students’ work shows that combining AIGC tools allows for a higher quality of visualization of tacit knowledge in the combination phase -.",
    "abstract_processed": "collabor learn higher educ emerg makerspac contribut research innov particip expertis howev littl research knowledg manag makerspac learner transfer individu tacit knowledg collabor space addit function maker educ promot individu person learn still need explor studi base chines stem graduat students’ experi project base learn maker educ environ test aigc tool help acquir transfer students’ individu tacit knowledg sampl form mphil student take design think effect academ commun cours first academ year world’ first interdisciplinari univers southern china aigc teach intervent base four phase knowledg manag model cycl social extern combin intern learner first explor expertis research area project team formul research interest storytel analog metaphor data first use assess students’ abil commun research topic text imag paper subsequ aigc support instruct intervent consist minut instruct sprint two instructor comput media art academ commun two consecut week students’ work show combin aigc tool allow higher qualiti visual tacit knowledg combin phase"
  },
  {
    "doc_id": "10427215",
    "abstract_original": "The rise of cybercrime is a daily challenge for individuals, organizations, and governments, especially when resources are scarce and cyberattacks are becoming more complex. These organizations often find it difficult to identify and stop such attacks, but they must investigate them to reduce the damage. This study aims to create a detailed model to help with the investigations of cybercrimes. To build this model, we reviewed existing research on cybercrime and investigative methods, and we used analytical techniques, studies, and logical reasoning. After examining different stages of investigations and the information needed, we created a model and put it to the test by investigating an insider attack. We think that this model could be the foundation for practical guidelines to investigate security breaches in organizations with either limited or ample resources.",
    "abstract_processed": "rise cybercrim daili challeng individu organ govern especi resourc scarc cyberattack becom complex organ often find difficult identifi stop attack must investig reduc damag studi aim creat detail model help investig cybercrim build model review exist research cybercrim investig method use analyt techniqu studi logic reason examin differ stage investig inform need creat model put test investig insid attack think model could foundat practic guidelin investig secur breach organ either limit ampl resourc"
  },
  {
    "doc_id": "10429782",
    "abstract_original": "Advancement in wireless transmission has enabled the communication among multiple devices all over the world, as well as expanding the frontiers of wireless Internet access. As a result of these advancement, numerous devices are questing for wireless connectivity thereby congesting the existing spectrum. If new measures are not taken to reduce depletion of the reserved radio resource, new allocations of wireless Internet access will be impossible, thereby risking the development of the entire wireless ecosystem. The demands for resourceful spectrum consumption have continually driven researchers and stakeholders in the wireless industry to search for spare radio spectrum to offer affordable and reliable wireless connectivity. The TV broadcasting is not fully utilizing the spectrum in some geographical zone. These TV unused spaces called TV White Spaces (TVWS), are well-thought-out to be the probable future resolutions for unavailability of spectrum. The low frequency band (470 to 694 MHz) of the unutilized TV channel has exceptional broadcast features over extensive distances and enables transmissions through high-rise buildings, trees, and mountains. These features allow the applications of TVWS in Internet of Things (IoT), wireless sensor network, wireless connectivity, wireless switching, smart grid and cities, automated transportation, and logistics as well as connectivity in cloud infrastructure. This paper presents a study on the advantages and benefits of television white space as an alternative to wireless broadband connectivity.",
    "abstract_processed": "advanc wireless transmiss enabl commun among multipl devic world well expand frontier wireless internet access result advanc numer devic quest wireless connect therebi congest exist spectrum new measur taken reduc deplet reserv radio resourc new alloc wireless internet access imposs therebi risk develop entir wireless ecosystem demand resourc spectrum consumpt continu driven research stakehold wireless industri search spare radio spectrum offer afford reliabl wireless connect tv broadcast fulli util spectrum geograph zone tv unus space call tv white space tvw well thought probabl futur resolut unavail spectrum low frequenc band mhz unutil tv channel except broadcast featur extens distanc enabl transmiss high rise build tree mountain featur allow applic tvw internet thing iot wireless sensor network wireless connect wireless switch smart grid citi autom transport logist well connect cloud infrastructur paper present studi advantag benefit televis white space altern wireless broadband connect"
  },
  {
    "doc_id": "10429999",
    "abstract_original": "This paper aims to solve the problem that achromatopsia cannot distinguish or perceive the energy of different colours. The problem of the previous study was to focus on the sound transforming into chladni's image patterns, which ignored the colours as more significant measurement in vision. The approach to filling the gap is standing by the creative computing approach, with the published brain colour response data, this research rebuilds the benchmark algorithm by combining the digital HSV (hue saturation brightness colour system in the computer) with the Chladni's Law and is supported by Ontology Philosophy. The result of this research proposes a novelty model to help achromatopsia to distinguish and to perceive the energy of different colours. Additionally, the design grounds on the filter-free sensor CMOS (metal-oxide-semiconductor) sensor technology, this paper proposed a sensor design plan for future model applications.",
    "abstract_processed": "paper aim solv problem achromatopsia cannot distinguish perceiv energi differ colour problem previou studi focu sound transform chladni imag pattern ignor colour signific measur vision approach fill gap stand creativ comput approach publish brain colour respons data research rebuild benchmark algorithm combin digit hsv hue satur bright colour system comput chladni law support ontolog philosophi result research propos novelti model help achromatopsia distinguish perceiv energi differ colour addit design ground filter free sensor cmo metal oxid semiconductor sensor technolog paper propos sensor design plan futur model applic"
  },
  {
    "doc_id": "10430192",
    "abstract_original": "The complex environmental influences often complicate the detection of longitudinal tears in conveyor belts, resulting in insufficient detection accuracy, overlooked detection, and elevated false detection rates. In this study, we propose a new depth learning method specifically designed for detecting longitudinal tears in conveyor belts. This method employs a linear Charge-Coupled Device (CCD) camera to capture images of the conveyor belt. These images are subsequently processed with a modified version of You Only Look Once (YOLO)v7 model to identify instances of longitudinal tearing. The modified YOLOv7 model features Efficient Intersection over Union (EIoU) loss function as a substitute for the original loss function. Furthermore, a Simple Parameter-Free Attention Module (SimAM) is introduced in the detection head to improve detection accuracy. In this method, we introduced the SimSPPFCSPC module as a new spatial pyramid pooling model. This module enhances detection speed while maintaining detection accuracy. Experiment results demonstrate the effectiveness of the proposed method, achieving an impressive precision of 94.6% and a detection speed of approximately 110 Frames Per Second (FPS). Such accuracy and speed meet the requirements for online detection of longitudinal tearing in belt conveyors.",
    "abstract_processed": "complex environment influenc often complic detect longitudin tear conveyor belt result insuffici detect accuraci overlook detect elev fals detect rate studi propos new depth learn method specif design detect longitudin tear conveyor belt method employ linear charg coupl devic ccd camera captur imag conveyor belt imag subsequ process modifi version look yolo v model identifi instanc longitudin tear modifi yolov model featur effici intersect union eiou loss function substitut origin loss function furthermor simpl paramet free attent modul simam introduc detect head improv detect accuraci method introduc simsppfcspc modul new spatial pyramid pool model modul enhanc detect speed maintain detect accuraci experi result demonstr effect propos method achiev impress precis detect speed approxim frame per second fp accuraci speed meet requir onlin detect longitudin tear belt conveyor"
  },
  {
    "doc_id": "10431870",
    "abstract_original": "The Covid-19 pandemic has been linked with significant deterioration of neuro-cognitive health. The forced abnormal isolation mandated by the lockdown has been associated with increased internal stressors, leading to early onset of mental health degeneration. The current challenge for the medical practitioners is to identify tools to help slow down such neurocognitive decline. In this project, we develop a model of sentiment manipulation using linguistic cues that can regulate the affective-motivational state of an individual to reduce triggers of neurocognitive degeneration. Based on the model insights, we build a user-friendly, low-cost Web App, customizable in many languages, to identify and score the primary sentiment of any audio or text to help reduce exposure to content that can potentially trigger internal stressors. In a randomized control experiment with 160 subjects, we find that participants in our target group who consumed content with positive or upbeat cues over a period of 60 days were 3.68 times less likely to report loneliness, 2.1 times less likely to report depressive thoughts and emotions and 1.75 times less likely to report forgetfulness than our control group, providing promising evidence of the potential of positive linguistic cues to prevent or slow down neuro-cognitive degeneration.",
    "abstract_processed": "covid pandem link signific deterior neuro cognit health forc abnorm isol mandat lockdown associ increas intern stressor lead earli onset mental health degener current challeng medic practition identifi tool help slow neurocognit declin project develop model sentiment manipul use linguist cue regul affect motiv state individu reduc trigger neurocognit degener base model insight build user friendli low cost web app customiz mani languag identifi score primari sentiment audio text help reduc exposur content potenti trigger intern stressor random control experi subject find particip target group consum content posit upbeat cue period day time less like report loneli time less like report depress thought emot time less like report forget control group provid promis evid potenti posit linguist cue prevent slow neuro cognit degener"
  },
  {
    "doc_id": "10433494",
    "abstract_original": "This study delves into the domain of dynamical systems, specifically the forecasting of dynamical time series defined through an evolution function. Traditional approaches in this area predict the future behavior of dynamical systems by inferring the evolution function. However, these methods may confront obstacles due to the presence of missing variables, which are usually attributed to challenges in measurement and a partial understanding of the system of interest. To overcome this obstacle, we introduce the autoregressive with slack time series (ARS) model, that simultaneously estimates the evolution function and imputes missing variables as a slack time series. Assuming time-invariance and linearity in the (underlying) entire dynamical time series, our experiments demonstrate the ARS model’s capability to forecast future time series. From a theoretical perspective, we prove that a 2-dimensional time-invariant and linear system can be reconstructed by utilizing observations from a single, partially observed dimension of the system.",
    "abstract_processed": "studi delv domain dynam system specif forecast dynam time seri defin evolut function tradit approach area predict futur behavior dynam system infer evolut function howev method may confront obstacl due presenc miss variabl usual attribut challeng measur partial understand system interest overcom obstacl introduc autoregress slack time seri ar model simultan estim evolut function imput miss variabl slack time seri assum time invari linear underli entir dynam time seri experi demonstr ar model’ capabl forecast futur time seri theoret perspect prove dimension time invari linear system reconstruct util observ singl partial observ dimens system"
  },
  {
    "doc_id": "10433950",
    "abstract_original": "Disease diagnosis in smart settings has been transformed by the fast development of technology, especially the Internet of Things (IoT) and Swarm Intelligence. Various health-related data may be continually monitored and collected in smart environments due to the abundance of sensors. However, this data's vast quantity and complexity complicates accurate illness diagnosis and early management. Inspired by the coordinated actions of flocks of birds and swarms of insects, Swarm Intelligence provides a novel paradigm for analyzing and understanding this mountain of data. Hence, this paper proposes a Swarm Intelligence-enabled Disease Diagnosis (SI-DD) in smart environments using IoT-based sensors. Smart systems use algorithms motivated by swarm behaviour to assess data from several sensors in concert, allowing for faster, more accurate illness diagnosis. As a shape of collective swarm intelligence, Ant Colony Optimization (ACO) enables make healthcare treatments more effective. As a result, sufferers get care tailor-made to their unique desires, thinking about their scientific history and the kingdom of the healthcare machine. This article examines the most distinguished makes use of the Internet of Things and Swarm Intelligence in healthcare. It highlights how those techniques have already shown their promise for higher contamination detection. With this in thoughts, it's clear that the usage of clever sensors prepared with Swarm Intelligence for infection detection in clever settings is a viable path toward enhancing healthcare results and the first-rate of existence for sufferers. This novel approach has the capability to revolutionize contamination surveillance, prognosis, and control, leading to greater cost-effective scientific services and higher results for sufferers.",
    "abstract_processed": "diseas diagnosi smart set transform fast develop technolog especi internet thing iot swarm intellig variou health relat data may continu monitor collect smart environ due abund sensor howev data vast quantiti complex complic accur ill diagnosi earli manag inspir coordin action flock bird swarm insect swarm intellig provid novel paradigm analyz understand mountain data henc paper propos swarm intellig enabl diseas diagnosi si dd smart environ use iot base sensor smart system use algorithm motiv swarm behaviour assess data sever sensor concert allow faster accur ill diagnosi shape collect swarm intellig ant coloni optim aco enabl make healthcar treatment effect result suffer get care tailor made uniqu desir think scientif histori kingdom healthcar machin articl examin distinguish make use internet thing swarm intellig healthcar highlight techniqu alreadi shown promis higher contamin detect thought clear usag clever sensor prepar swarm intellig infect detect clever set viabl path toward enhanc healthcar result first rate exist suffer novel approach capabl revolution contamin surveil prognosi control lead greater cost effect scientif servic higher result suffer"
  },
  {
    "doc_id": "10434098",
    "abstract_original": "Adolescent Brain Cognitive Development (ABCD) has been studied in ways never before possible because to breakthroughs in brain imaging technology. Indirectly, the accuracy and interpretability of findings affect our understanding of neurodevelopmental processes, highlighting the crucial necessity of dependable techniques. There are a wide variety of obstacles to overcome in this field, from the intricacies of researching developing brains to the subtle interplay of different cognitive processes. Overcoming these problems demands creative approaches and enhanced procedures that can capture the changing character of cognitive growth. The goal of this framework is to improve the accuracy and sensitivity of cognitive neuroscience studies, leading to a deeper comprehension of the complex mechanisms at play during brain development. In this study, there is a method called functional magnetic resonance-based tensor imaging (FMR-TI) that combines the strengths of both methods to provide more precise mapping of cognitive growth throughout time. As a bonus, the suggested method uses simulation analyses to verify its efficiency and resilience in capturing the nuances of cognitive development, making the results of the study more trustworthy. The proposed methodology can be used to a wide range of fields, such as educational neuroscience, clinical psychology, and developmental neuroscience. Understanding cognitive growth better has far-reaching effects on educational programs, diagnostic methods, and treatment plans. Moreover, this methodological improvement holds promise for unraveling the neurological foundations of neurodevelopmental diseases, helping to the development of focused therapies and tailored treatment strategies. The robustness of the processing, the flexibility of the paradigm, and the validity of the simulation are all taken into account during the investigation.",
    "abstract_processed": "adolesc brain cognit develop abcd studi way never possibl breakthrough brain imag technolog indirectli accuraci interpret find affect understand neurodevelopment process highlight crucial necess depend techniqu wide varieti obstacl overcom field intricaci research develop brain subtl interplay differ cognit process overcom problem demand creativ approach enhanc procedur captur chang charact cognit growth goal framework improv accuraci sensit cognit neurosci studi lead deeper comprehens complex mechan play brain develop studi method call function magnet reson base tensor imag fmr ti combin strength method provid precis map cognit growth throughout time bonu suggest method use simul analys verifi effici resili captur nuanc cognit develop make result studi trustworthi propos methodolog use wide rang field educ neurosci clinic psycholog development neurosci understand cognit growth better far reach effect educ program diagnost method treatment plan moreov methodolog improv hold promis unravel neurolog foundat neurodevelopment diseas help develop focus therapi tailor treatment strategi robust process flexibl paradigm valid simul taken account investig"
  },
  {
    "doc_id": "10434101",
    "abstract_original": "The term \"Modern Art Teaching and Evaluation Model\" describes the systematic incorporation of creative practices, methods, and experiences into traditional academic curricula in order to improve student achievement across the curriculum. The design thinking process and visual thinking tactics are two of the most popular methods. blockchain technology is up to the task of solving problems plaguing the higher education system and society as a whole. The blockchain's many benefits include less expensive transactions due to less time spent checking, controlling, and verifying data, as well as the presence of decentralized open data and the absence of forgeries and unsafe storing of information. The purpose of this study is to analyze the potential benefits and drawbacks of using blockchain technology in education, as well as the effects that this technology may have on the future of this sector. Although its rapid development, blockchain (BC) has not yet been widely included into the education of contemporary art. The purpose of this paper is to develop strategies for integrating BC into 21st-century art instruction. After examining how BC technologies are currently being utilized within the realm of contemporary art education, the writers assessed the issues associated with their utilization. As a result, three approaches to promoting BC facets of contemporary art learning were developed: bolstering the malleability of BC-based modern art learning, strengthening the innovative three education of art learning, and enhancing the recent art background and ambience of BC-based modern art learning. In this research, modern art education to be provided via a blockchain-based system (BC-MAT) is discussed to improve the student performance. Concurrently, a productivity analysis strategy using analytical hierarchical processing (AHP) and grey grouping was developed to assess BC's impact on today's art classrooms. The BC-MAT has numerous applications and can be used to determine how BC has affected modern art education. The simulation results demonstrate the system's superior performance in precision, accuracy, efficiency, productivity, learning score, and student performance score.",
    "abstract_processed": "term modern art teach evalu model describ systemat incorpor creativ practic method experi tradit academ curricula order improv student achiev across curriculum design think process visual think tactic two popular method blockchain technolog task solv problem plagu higher educ system societi whole blockchain mani benefit includ less expens transact due less time spent check control verifi data well presenc decentr open data absenc forgeri unsaf store inform purpos studi analyz potenti benefit drawback use blockchain technolog educ well effect technolog may futur sector although rapid develop blockchain bc yet wide includ educ contemporari art purpos paper develop strategi integr bc st centuri art instruct examin bc technolog current util within realm contemporari art educ writer assess issu associ util result three approach promot bc facet contemporari art learn develop bolster malleabl bc base modern art learn strengthen innov three educ art learn enhanc recent art background ambienc bc base modern art learn research modern art educ provid via blockchain base system bc mat discuss improv student perform concurr product analysi strategi use analyt hierarch process ahp grey group develop assess bc impact today art classroom bc mat numer applic use determin bc affect modern art educ simul result demonstr system superior perform precis accuraci effici product learn score student perform score"
  },
  {
    "doc_id": "10434104",
    "abstract_original": "The \"E-commerce for Artisans\" project aims to empower artisans and craftsmen by providing them with a digital platform to showcase and sell their handmade products to a global audience. Artisans play a pivotal role in preserving cultural heritage and fostering economic sustainability in many communities. However, they often face challenges in reaching wider markets and selling their unique creations. Our project offers a comprehensive e-commerce solution that bridges the gap between artisans and consumers. This platform provides artisans with the tools and resources needed to create online storefronts, manage their inventory, process orders, and receive payments securely. Customers can explore a diverse range of artisanal products, connect directly with the creators, and make informed purchases, thus supporting local craftsmanship and promoting sustainable consumption.",
    "abstract_processed": "e commerc artisan project aim empow artisan craftsmen provid digit platform showcas sell handmad product global audienc artisan play pivot role preserv cultur heritag foster econom sustain mani commun howev often face challeng reach wider market sell uniqu creation project offer comprehens e commerc solut bridg gap artisan consum platform provid artisan tool resourc need creat onlin storefront manag inventori process order receiv payment secur custom explor divers rang artisan product connect directli creator make inform purchas thu support local craftsmanship promot sustain consumpt"
  },
  {
    "doc_id": "10434108",
    "abstract_original": "This paper explores the intersection of historical exploration, gamification, and immersive technologies to enhance engagement and learning in history education. Traditional methods of historical inquiry often struggle to captivate learners' interest, particularly in an era dominated by digital experiences. Gamification, incorporating game elements into non-game contexts, has shown promise in fostering engagement and motivation. This study delves into the potential benefits of leveraging immersive gamification to create dynamic and captivating historical exploration experiences. The theoretical framework draws upon educational theories, game design principles, and the evolving landscape of immersive technologies such as virtual reality and augmented reality. We examine the limitations of traditional historical education methods and discuss how gamification can address these challenges by providing interactive and participatory learning experiences. Furthermore, the paper outlines fundamental design principles for creating immersive historical exploration scenarios, emphasising the importance of narrative structure, game mechanics, and user engagement. Through case studies, we highlight successful applications of immersive gamification in historical education, presenting outcomes and insights gained from these implementations. Challenges and considerations in integrating immersive gamification into historical exploration are also explored, including ethical considerations and accessibility issues. The paper concludes by proposing future directions for research in this emerging field, anticipating the continued evolution of technologies and pedagogical approaches.",
    "abstract_processed": "paper explor intersect histor explor gamif immers technolog enhanc engag learn histori educ tradit method histor inquiri often struggl captiv learner interest particularli era domin digit experi gamif incorpor game element non game context shown promis foster engag motiv studi delv potenti benefit leverag immers gamif creat dynam captiv histor explor experi theoret framework draw upon educ theori game design principl evolv landscap immers technolog virtual realiti augment realiti examin limit tradit histor educ method discuss gamif address challeng provid interact participatori learn experi furthermor paper outlin fundament design principl creat immers histor explor scenario emphasis import narr structur game mechan user engag case studi highlight success applic immers gamif histor educ present outcom insight gain implement challeng consider integr immers gamif histor explor also explor includ ethic consider access issu paper conclud propos futur direct research emerg field anticip continu evolut technolog pedagog approach"
  },
  {
    "doc_id": "10435122",
    "abstract_original": "An approximate parallel prefix adder is a type of circuit that can perform addition operations on binary numbers with extremely high speed, low latency, and much less power. Nowadays, thinking about fuzzy computing, that is, sacrificing computational expectations for computational efforts, has emerged as a promising graphical approach. Over the past decade, various research works have explored approximate computation at both the software level and the hardware abstraction level, with encouraging results. At the stage of hardware abstraction, adders (which are the most widely used and mandatory information operators in digital systems) have generated great interest in the approximation used in digital systems used in image processing applications. The approximate Brent-Kung adder (AxBK) is a variant of the simple Brent-Kung adder that introduces a degree of approximation into its operation. A new approximate BK adder is proposed with high-speed overall performance and low error cost. Its BK adder and AxBK adder are restricted to bits 8,16,32 using software called Xilinx Vivado and MATLAB.",
    "abstract_processed": "approxim parallel prefix adder type circuit perform addit oper binari number extrem high speed low latenc much less power nowaday think fuzzi comput sacrif comput expect comput effort emerg promis graphic approach past decad variou research work explor approxim comput softwar level hardwar abstract level encourag result stage hardwar abstract adder wide use mandatori inform oper digit system gener great interest approxim use digit system use imag process applic approxim brent kung adder axbk variant simpl brent kung adder introduc degre approxim oper new approxim bk adder propos high speed overal perform low error cost bk adder axbk adder restrict bit use softwar call xilinx vivado matlab"
  },
  {
    "doc_id": "10435201",
    "abstract_original": "This study aims to investigate students’ engagement in computational thinking skills through game-based learning in science classrooms. Data was gathered through observation and interviews with 30 secondary school students. Research data were analyzed qualitatively through six stages involving preparing and organizing data, exploring data, developing descriptions, representing results, interpreting findings, and validating the accuracy of findings. The study results show that game-based learning makes students engaged in computational thinking skills. Interaction with educational games trains students to find solutions more precisely and bravely in making decisions. Game-based learning can be a solution to introduce students’ computational thinking skills in a more enjoyable way. Teachers are expected to use this research to teach students computational thinking skills through game-based learning.",
    "abstract_processed": "studi aim investig students’ engag comput think skill game base learn scienc classroom data gather observ interview secondari school student research data analyz qualit six stage involv prepar organ data explor data develop descript repres result interpret find valid accuraci find studi result show game base learn make student engag comput think skill interact educ game train student find solut precis brave make decis game base learn solut introduc students’ comput think skill enjoy way teacher expect use research teach student comput think skill game base learn"
  },
  {
    "doc_id": "10436103",
    "abstract_original": "Contribution: A problem-solving approach (PSA) model derived from major computational thinking (CT) concepts. This model can be utilized to formulate solutions for different algorithmic problems and translate them into effective active learning methods. Background: Different teaching approaches for programming are widely available; however, being able to formulate an algorithmic solution computationally and then transform it into code is essential for students. Research Questions: What are the effective teaching approaches for fostering the development of problem-solving and programming skills? How do CT concepts contribute to the formulation of a PSA model for programming problems and its translation into an effective teaching method? How can an effective teaching method that utilizes the PSA model be identified and distinguished from other approaches? Methodology: A preliminary study pointed out the difficulties experienced when teaching programming, inspiring the formulation of a PSA model that used CT concepts. An experimental study on problem-based and game-based programming workshops that utilized the PSA model through sorting algorithms was performed on experimental groups consisting of 30 students each. A syntax-based programming workshop consisting of 30 students was used as the control group. All the participants were recruited through a pretest that incorporated basic programming questions. The participants had to answer a posttest after the workshop. Findings: The results showed that the participants exhibited no significant difference between the pretest and posttest for the syntax-based learning (SBL). However, there is a significant difference between the pretest and posttest of both the problem-based learning (PBL) and the game-based learning (GBL) workshops. There was no significant difference significant difference for the pretest scores of all three workshops. The analysis of the posttest further confirmed that the experimental groups (PBL and GBL) exhibited significant difference in the scores compared to the control group. However, the posttest results did not differ significantly between the experimental groups (PBL and GBL).",
    "abstract_processed": "contribut problem solv approach psa model deriv major comput think ct concept model util formul solut differ algorithm problem translat effect activ learn method background differ teach approach program wide avail howev abl formul algorithm solut comput transform code essenti student research question effect teach approach foster develop problem solv program skill ct concept contribut formul psa model program problem translat effect teach method effect teach method util psa model identifi distinguish approach methodolog preliminari studi point difficulti experienc teach program inspir formul psa model use ct concept experiment studi problem base game base program workshop util psa model sort algorithm perform experiment group consist student syntax base program workshop consist student use control group particip recruit pretest incorpor basic program question particip answer posttest workshop find result show particip exhibit signific differ pretest posttest syntax base learn sbl howev signific differ pretest posttest problem base learn pbl game base learn gbl workshop signific differ signific differ pretest score three workshop analysi posttest confirm experiment group pbl gbl exhibit signific differ score compar control group howev posttest result differ significantli experiment group pbl gbl"
  },
  {
    "doc_id": "10438861",
    "abstract_original": "RNA-binding proteins (RBPs) can regulate biological functions by interacting with specific RNAs, and play an important role in many life activities. Therefore, the rapid identification of RNA-protein binding sites is crucial for functional annotation and site-directed mutagenesis. In this work, a new parallel network that integrates the multi-head attention mechanism and the expectation pooling is proposed, named MAHyNet. The left-branch network of MAHyNet hybrids convolutional neural networks (CNNs) and gated recurrent neural network (GRU) to extract the features of one-hot. The right-branch network is a two-layer CNN network to analyze physicochemical properties of RNA base. Specifically, the multi-head attention mechanism is a computational collection of multiple independent layers of attention, which can extract feature information from multiple dimensions. The expectation pooling combines probabilistic thinking with global pooling. This approach helps to reduce model parameters and enhance the model performance. The combination of CNN and GRU enables further extraction of high-level features in sequences. In addition, the study shows that appropriate hyperparameters have a positive impact on the model performance. Physicochemical properties can be used to supplement characterization information to improving model performance. The experimental results show that MAHyNet has better performance than other models.",
    "abstract_processed": "rna bind protein rbp regul biolog function interact specif rna play import role mani life activ therefor rapid identif rna protein bind site crucial function annot site direct mutagenesi work new parallel network integr multi head attent mechan expect pool propos name mahynet left branch network mahynet hybrid convolut neural network cnn gate recurr neural network gru extract featur one hot right branch network two layer cnn network analyz physicochem properti rna base specif multi head attent mechan comput collect multipl independ layer attent extract featur inform multipl dimens expect pool combin probabilist think global pool approach help reduc model paramet enhanc model perform combin cnn gru enabl extract high level featur sequenc addit studi show appropri hyperparamet posit impact model perform physicochem properti use supplement character inform improv model perform experiment result show mahynet better perform model"
  },
  {
    "doc_id": "10439169",
    "abstract_original": "The increasing computational demands of Deep Reinforcement Learning (DRL) models, particularly for embedded systems in autonomous vehicles and drones, present significant challenges owing to their extensive neural network complexities. Previous DRL compression strategies predominantly focused on unstructured pruning, effective for reducing model size but requiring specialized hardware for computational acceleration. Conversely, DRL models with structured pruning applied can be accelerated on standard hardware, though they typically encounter performance issues at higher pruning rates due to structural constraints. In response to these challenges, this paper introduces an advanced structured pruning methodology, combined with scaled policy constraints (SPC) for DRL models. Our approach overcomes the performance limitations of conventional structured pruning, achieving high pruning rates while maintaining robust model performance. Enhanced performance restoration after pruning is achieved by fine-tuning with SPC and applying structural regularization, thus ensuring efficient decision-making with a minimal computational burden. Extensive evaluations on the D4RL benchmark and in a drone control simulation environment confirm the effectiveness of our method. Our approach maintains performance integrity even at high pruning rates, with less than a 2% decrease in normalized score at 90% pruning in D4RL and preserving cumulative reward at 87% pruning in drone control simulation. Significantly, our approach also enables considerable computational acceleration on standard hardware. We implemented our method on the NVIDIA Jetson Xavier NX board and achieved a 2.5-fold speed-up on devices with NVIDIA Volta GPUs and over double the speed-up on those with NVIDIA Carmel ARMv8.2 CPUs. These outcomes highlight our method’s suitability for real-time, resource-constrained applications, demonstrating its practicality and efficiency.",
    "abstract_processed": "increas comput demand deep reinforc learn drl model particularli embed system autonom vehicl drone present signific challeng owe extens neural network complex previou drl compress strategi predominantli focus unstructur prune effect reduc model size requir special hardwar comput acceler convers drl model structur prune appli acceler standard hardwar though typic encount perform issu higher prune rate due structur constraint respons challeng paper introduc advanc structur prune methodolog combin scale polici constraint spc drl model approach overcom perform limit convent structur prune achiev high prune rate maintain robust model perform enhanc perform restor prune achiev fine tune spc appli structur regular thu ensur effici decis make minim comput burden extens evalu rl benchmark drone control simul environ confirm effect method approach maintain perform integr even high prune rate less decreas normal score prune rl preserv cumul reward prune drone control simul significantli approach also enabl consider comput acceler standard hardwar implement method nvidia jetson xavier nx board achiev fold speed devic nvidia volta gpu doubl speed nvidia carmel armv cpu outcom highlight method’ suitabl real time resourc constrain applic demonstr practic effici"
  },
  {
    "doc_id": "10440725",
    "abstract_original": "Phishing, a prevalent cyber danger in contemporary times, involves the fraudulent impersonation of legitimate websites with the intention of deceiving users into divulging confidential information. The insufficiency of classic phishing detection tools has become apparent as fraudsters continue to develop new strategies; these approaches mostly depend on variables such as URL character sequences, site content, and visual resemblance. The present study highlights the “Zérosdetect” approach, a quantum-powered technique for detecting phishing URLs using zero-shot learning, a robust model that makes use of both the zero-shot learning’s adaptability and the computational advantageous nature of quantum computing, it mitigates the need for extensive previous knowledge of phishing URL attributes. In order to detect previously undiscovered phishing attacks, quantum neural network have been deployed to convert URL data into quantum spaces, therefore using the computational benefits of quantum systems. Quantum layers embedded inside Qnodes are a key part of the present system, calculating gradients at a faster pace, optimizing the network performance by rapidly calculating gradients, making the solution both efficient and forward-thinking. The present study lays the groundwork for future cybersecurity initiatives in the era of quantum computing, enhancing the potential to predict new cases of phishing.",
    "abstract_processed": "phish preval cyber danger contemporari time involv fraudul imperson legitim websit intent deceiv user divulg confidenti inform insuffici classic phish detect tool becom appar fraudster continu develop new strategi approach mostli depend variabl url charact sequenc site content visual resembl present studi highlight “zérosdetect” approach quantum power techniqu detect phish url use zero shot learn robust model make use zero shot learning’ adapt comput advantag natur quantum comput mitig need extens previou knowledg phish url attribut order detect previous undiscov phish attack quantum neural network deploy convert url data quantum space therefor use comput benefit quantum system quantum layer embed insid qnode key part present system calcul gradient faster pace optim network perform rapidli calcul gradient make solut effici forward think present studi lay groundwork futur cybersecur initi era quantum comput enhanc potenti predict new case phish"
  },
  {
    "doc_id": "1044182",
    "abstract_original": "Discusses a new approach to understanding how the brain organizes computation. Progress in understanding the brain function under constant interactions with the sensory environment is hampered by inadequate models and theories. Obviously, current models and theories of brain computing still appear irrelevant when they are confronted with real-world problems. We argue that architecture in the brain does not reflect the result of thinking, the ready-made algorithm for solving a problem. Rather it should reflect the control that generates the constraints to select a proper algorithm for a specific problem that is posed by the input-or to create a new one if the application of the previously acquired ones does not provide a sufficient solution. We propose that a value system (based on a genetically imprinted a priori knowledge on coarse behavioral evaluation of sensory input) and neocortical columnar architecture are crucial elements of future artificial neural systems that are expected to emulate the performance of the brain. This should be the case especially for those cognitive tasks that appear easy for animals in their everyday life but turn out to be hopelessly tricky for the current generation of computers. In order to advance beyond the well known paradigms of current computational theory, we need a more functional understanding of brain-type computation.",
    "abstract_processed": "discuss new approach understand brain organ comput progress understand brain function constant interact sensori environ hamper inadequ model theori obvious current model theori brain comput still appear irrelev confront real world problem argu architectur brain reflect result think readi made algorithm solv problem rather reflect control gener constraint select proper algorithm specif problem pose input creat new one applic previous acquir one provid suffici solut propos valu system base genet imprint priori knowledg coars behavior evalu sensori input neocort columnar architectur crucial element futur artifici neural system expect emul perform brain case especi cognit task appear easi anim everyday life turn hopelessli tricki current gener comput order advanc beyond well known paradigm current comput theori need function understand brain type comput"
  },
  {
    "doc_id": "10441858",
    "abstract_original": "With the progress of science and technology, quantum computing plays an increasingly important role in various fields, solving the traditional arithmetic bottleneck. In the financial field, credit scoring is the core of the lending industry and one of the most common risk management tools. Researchers are trying to find the best threshold-setting scheme to maximize revenue through quantum computing. This approach not only solves the optimization problem in the field of credit score cards, but also provides a new way of thinking about optimization problems in other fields. In this paper, three traditional computational models, one-fold credit card strategy, two-fold credit card combination strategy, and three-fold credit card combination strategy, are proposed, and the credit score card scheme that maximizes the final revenue is solved for each of the three models. The results show that under the one-fold credit card strategy, the final income is maximized at $54,087.2; under the two-fold credit card combination strategy, the final income is maximized at $41,106.3; and under the three-fold credit card combination strategy, the final income is maximized at $27,914.8. Secondly, this paper converts these three strategies to the QUBO model and obtains the maximum final income that is consistent with the maximum under the traditional model, with an accuracy of 96.3%, 92.7%, and 89.9% for the three combination strategies, respectively.",
    "abstract_processed": "progress scienc technolog quantum comput play increasingli import role variou field solv tradit arithmet bottleneck financi field credit score core lend industri one common risk manag tool research tri find best threshold set scheme maxim revenu quantum comput approach solv optim problem field credit score card also provid new way think optim problem field paper three tradit comput model one fold credit card strategi two fold credit card combin strategi three fold credit card combin strategi propos credit score card scheme maxim final revenu solv three model result show one fold credit card strategi final incom maxim two fold credit card combin strategi final incom maxim three fold credit card combin strategi final incom maxim secondli paper convert three strategi qubo model obtain maximum final incom consist maximum tradit model accuraci three combin strategi respect"
  },
  {
    "doc_id": "10442150",
    "abstract_original": "This paper applies the theory of granular computing to the load forecasting model of electric power systems. By constructing the electric load data as a fuzzy extension set, the concepts of detectors and sample spaces reconstructed in primitive form are proposed. The biological thinking of the complement system is used to optimize the dependent function, and a comprehensive forecasting model is established to evaluate and combine multiple forecasting results, achieving the complementary advantages of various models. The experiments show that the proposed forecasting model effectively improves the adaptability and accuracy of the electric power system, and has broad prospects for application in the field of load forecasting.",
    "abstract_processed": "paper appli theori granular comput load forecast model electr power system construct electr load data fuzzi extens set concept detector sampl space reconstruct primit form propos biolog think complement system use optim depend function comprehens forecast model establish evalu combin multipl forecast result achiev complementari advantag variou model experi show propos forecast model effect improv adapt accuraci electr power system broad prospect applic field load forecast"
  },
  {
    "doc_id": "10442275",
    "abstract_original": "Alzheimer's disease is a neurological condition that gradually affects memory, thinking, and reasoning abilities as well as daily functioning. The majority of people with this condition are elderly, particularly those over 65. The exact cause of this disease is still unknown, but it is now thought that it may be inherited, unintentional, or brought on by other factors. Actual assessment, CT examines, X-ray sweeps, and positron emission tomography, are a couple of techniques to analyze the disease, but X-ray checks are the most widely recognized one. Additionally, scanned images from MRI scans are used in this study. This study has established four groups for the condition: healthy, mildly demented, moderately demented, and very mildly demented. The most famous SVM technique is utilized in our proposed model along with a profound learning calculation because of its fast, trustworthy, and compelling activity. The dataset was obtained from Kaggle and uniformed through pre-processing. After the information was parted into preparing and testing datasets in a 80:20 proportion, tuner advancement was done to naturally pick various boundaries to improve the model. The ailment and its classification are then resolved utilizing the SVM grouping and the model's exactness is 99.4%. In order to diagnose the patient's condition and discover an appropriate course of treatment and therapy, it helps the doctors identify the disease and the degree of its dissemination.",
    "abstract_processed": "alzheim diseas neurolog condit gradual affect memori think reason abil well daili function major peopl condit elderli particularli exact caus diseas still unknown thought may inherit unintent brought factor actual assess ct examin x ray sweep positron emiss tomographi coupl techniqu analyz diseas x ray check wide recogn one addit scan imag mri scan use studi studi establish four group condit healthi mildli dement moder dement mildli dement famou svm techniqu util propos model along profound learn calcul fast trustworthi compel activ dataset obtain kaggl uniform pre process inform part prepar test dataset proport tuner advanc done natur pick variou boundari improv model ailment classif resolv util svm group model exact order diagnos patient condit discov appropri cours treatment therapi help doctor identifi diseas degre dissemin"
  },
  {
    "doc_id": "10442800",
    "abstract_original": "If Artificial Intelligence is powerful, then it would cover a wide spectrum of jobs that commonly is done by humans that might require a high level of abstraction and mathematical creation. In this paper, the possibility that Machine Learning through the criteria of Mitchell can produce original contribution at basic sciences, such for example at the theoretical physics, is investigated. Basically, it is shown that theoretical physics is essentially based in laws by which are employed mathematical apparatus based at differential equations, integrations, commutators of operators, closed-form algebra, etc. In this way, the Mitchell criteria might constitute an algorithm to generate new theoretical structures in physics. It is investigated if it is appropriate to claim that Artificial Intelligence is able to replace the human thinking to create new theoretical physics with relevance and with a solid prospectiveness.",
    "abstract_processed": "artifici intellig power would cover wide spectrum job commonli done human might requir high level abstract mathemat creation paper possibl machin learn criteria mitchel produc origin contribut basic scienc exampl theoret physic investig basic shown theoret physic essenti base law employ mathemat apparatu base differenti equat integr commut oper close form algebra etc way mitchel criteria might constitut algorithm gener new theoret structur physic investig appropri claim artifici intellig abl replac human think creat new theoret physic relev solid prospect"
  },
  {
    "doc_id": "10442827",
    "abstract_original": "Alzheimer's is a neurogenic disease which progress into neurological disorder that primarily affects cognitive function and memory. It's a Neurodegenerative (ND) disease, characterized by the gradual deterioration of cognitive function, memory, thinking, and behaviour. There are two most common diseases among neurodegenerative diseases: (a) Alzheimer's Disease and (b) Parkinson's Disease. We used 12 classifiers on the given dataset on UC Irvine Machine Learning Repository. The machine learning algorithms were engaged to identify Alzheimer Disease. Our research results showed that the XGB Model is the one that shows the best accuracy, of 100%, of all the 12 classifiers.",
    "abstract_processed": "alzheim neurogen diseas progress neurolog disord primarili affect cognit function memori neurodegen nd diseas character gradual deterior cognit function memori think behaviour two common diseas among neurodegen diseas alzheim diseas b parkinson diseas use classifi given dataset uc irvin machin learn repositori machin learn algorithm engag identifi alzheim diseas research result show xgb model one show best accuraci classifi"
  },
  {
    "doc_id": "10443445",
    "abstract_original": "To control an intelligent system in an unstructured environment, it is desirable to synergize human and machine intelligence to deal with changes and uncertainty cost-effectively. A shared control takes advantage of human and computer strengths in decision-making support, and this helps to improve the adaptability, agility, reliability, responsiveness, and resilience of the system. Since the decision spaces for human thinking and machine intelligence are quite different, challenges occur to fuse human intelligence and machine intelligence effectively. A brain–computer interface (BCI) can bridge human and machine intelligence; however, traditional BCIs are unidirectional that support interaction in one of two scenarios: first, human or machine takes effect at different control layers, and second, either human or machine takes effect at a time. There is an emerging need to close the loop of BCI-based control to alleviate the adverse effects of a machine's error or a human's mistake. In this article, available technologies for acquisition, processing, and mining of brain signals are reviewed, the needs of integrating human's capability to control unmanned aerial vehicles (UAV) are elaborated, and research challenges in advancing BCI for a shared human and machine control are discussed at the aspects of data acquisition, mapping of human's and machine's decision spaces, and the fusion of human's and machine's intelligence in automated controls. To address unsolved problems in the aforementioned aspects, we proposed a new platform of using BCI for human–machine interactions and three innovations are, first, an advanced BCI to acquire multimodal brain signals and extract features related to the intentions of motion and the quantified human's affection, second, an arbitrating mechanism in system control to determine the weight of human's decisions based on quantified human's affection, and finally, a decision support system that is capable of fusing human's and machine's decisions from different decision spaces seamlessly in controlling a UAV for real-time performance in application.",
    "abstract_processed": "control intellig system unstructur environ desir synerg human machin intellig deal chang uncertainti cost effect share control take advantag human comput strength decis make support help improv adapt agil reliabl respons resili system sinc decis space human think machin intellig quit differ challeng occur fuse human intellig machin intellig effect brain–comput interfac bci bridg human machin intellig howev tradit bci unidirect support interact one two scenario first human machin take effect differ control layer second either human machin take effect time emerg need close loop bci base control allevi advers effect machin error human mistak articl avail technolog acquisit process mine brain signal review need integr human capabl control unman aerial vehicl uav elabor research challeng advanc bci share human machin control discuss aspect data acquisit map human machin decis space fusion human machin intellig autom control address unsolv problem aforement aspect propos new platform use bci human–machin interact three innov first advanc bci acquir multimod brain signal extract featur relat intent motion quantifi human affect second arbitr mechan system control determin weight human decis base quantifi human affect final decis support system capabl fuse human machin decis differ decis space seamlessli control uav real time perform applic"
  },
  {
    "doc_id": "10443471",
    "abstract_original": "Recently, graph neural networks have achieved remarkable success in predicting molecular interactions. However, existing methodologies often fall short of comprehensively considering a pivotal factor influencing these interactions: the core subgraph within molecules, commonly represented by functional groups or atoms capable of engaging in interactions with other molecules. In this work, we propose a novel interaction prediction framework, called GIB-DS, which centers on the identification of the core subgraph in pairs of molecules to anticipate their interaction behavior. Guided by the principles of the Graph Information Bottleneck, our approach adeptly identifies two subgraphs within this pair of graphs that capture the essential information pertinent to the task at hand. We think that the dual-subgraph formulation could more faithfully capture the underlying nature of chemical reactions, where interactions between molecules and the interactions among specific atoms are inherently intertwined. Extensive experimentation across diverse datasets underscores the superiority of GIB-DS over state-of-the-art baselines, achieving an approximate 5% improvement. The GIB-DS code proposed can be found at https://github.com/LiLanQi/GIB_DS.",
    "abstract_processed": "recent graph neural network achiev remark success predict molecular interact howev exist methodolog often fall short comprehens consid pivot factor influenc interact core subgraph within molecul commonli repres function group atom capabl engag interact molecul work propos novel interact predict framework call gib ds center identif core subgraph pair molecul anticip interact behavior guid principl graph inform bottleneck approach adeptli identifi two subgraph within pair graph captur essenti inform pertin task hand think dual subgraph formul could faith captur underli natur chemic reaction interact molecul interact among specif atom inher intertwin extens experiment across divers dataset underscor superior gib ds state art baselin achiev approxim improv gib ds code propos found http github com lilanqi gib ds"
  },
  {
    "doc_id": "10443691",
    "abstract_original": "The significance of incorporating ethics education in engineering programs has grown considerably in recent times, especially within domains such as computer science, software engineering, data science, and artificial intelligence. In response to this demand, a pedagogical activity was developed and executed to facilitate students in applying ethical theories to occupational and societal challenges while enhancing their critical thinking abilities. This activity involves students participating in a debate where they are assigned a moral stance to uphold and must utilize one of the ethical theories explored in class to bolster their case. This paper offers an in-depth account of the conception and execution of this educational activity, as well as the encouraging results observed. Furthermore, the paper showcases the scenario utilized in the activity, which outlines a professional conundrum in the realm of Computer Engineering. The findings of this educational activity indicate its efficacy as a teaching instrument for ethics in engineering programs, with potential applicability to other engineering fields. By integrating such pedagogical activities into engineering programs, educators can empower students with essential ethical values and skills to tackle intricate ethical issues in their professional and social spheres while also fostering critical thinking and encouraging dialogue among students.",
    "abstract_processed": "signific incorpor ethic educ engin program grown consider recent time especi within domain comput scienc softwar engin data scienc artifici intellig respons demand pedagog activ develop execut facilit student appli ethic theori occup societ challeng enhanc critic think abil activ involv student particip debat assign moral stanc uphold must util one ethic theori explor class bolster case paper offer depth account concept execut educ activ well encourag result observ furthermor paper showcas scenario util activ outlin profession conundrum realm comput engin find educ activ indic efficaci teach instrument ethic engin program potenti applic engin field integr pedagog activ engin program educ empow student essenti ethic valu skill tackl intric ethic issu profession social sphere also foster critic think encourag dialogu among student"
  },
  {
    "doc_id": "10444104",
    "abstract_original": "Media bias has been extensively studied by both social and computational sciences. However, current work still has a large reliance on human input and subjective assessment to label biases. This is especially true for cable news, which has a continued presence in American media but a lack of text-based bias identification in research. To address these issues, we develop an unsupervised machine learning method to characterize the bias of cable news programs without any human input. This method relies on the analysis of what topics are mentioned through Named Entity Recognition and how those topics are discussed through Stance Analysis in order to cluster programs with similar biases together. Applying our method to 2020 cable news transcripts, we find that cable news programs tend to cluster together consistently over time and roughly correspond to the cable news network of the program. This method reveals the potential for future tools to more objectively assess media bias and characterize unfamiliar media environments, and the empirical results insight into the nature of bias in American cable news programs.",
    "abstract_processed": "media bia extens studi social comput scienc howev current work still larg relianc human input subject assess label bias especi true cabl news continu presenc american media lack text base bia identif research address issu develop unsupervis machin learn method character bia cabl news program without human input method reli analysi topic mention name entiti recognit topic discuss stanc analysi order cluster program similar bias togeth appli method cabl news transcript find cabl news program tend cluster togeth consist time roughli correspond cabl news network program method reveal potenti futur tool object assess media bia character unfamiliar media environ empir result insight natur bia american cabl news program"
  },
  {
    "doc_id": "10444509",
    "abstract_original": "In advance to the present study, the authors introduced a method which makes it possible to calculate the entropy of natural language digital texts, focusing on word-processed texts, presentations, and webpages. This entropy reveals that the more underdeveloped documents are, the more demanding their content-related modification becomes. It was also found that the time and data required to complete a modification task in an erroneous document is several times more than in its correct counterpart. This finding leads to the end-user paradox: the less trained end-users are, the more errors they make, and the modification of their documents requires more resources. To resolve these discrepancies, the present study defines the sustainability rate of natural language digital texts which calculates the losses – the waste of human resources, time, workspace, computers, energy, frustration, working in bees, losing data – generated by negligent text management. Furthermore, we present examples of how manual and enumerated lists behave to modifications in a 213-page long document and conclude from our investigations that while the waste of human and machine resources occurs repeatedly in erroneous documents, the sustainability rate remains low. To prove the necessity of correction, we cleared the sample document, which took approximately 67 hours of two experts of our research group ( $2\\times67$  hours). With this method, we found that the correction of errors can be extremely demanding, but uses resources only once, and further modifications in the now correct document need only the content-required amount of time, activities, entropy, and resources, in accordance with the expectations of the person intended to update the document. To correct documents, we present the Error Recognition Model, which is proved effective and efficient in digital education. All our findings indicate that both education and industry should adapt the presented approach (1) to develop students’ and end-users’ computational thinking skills, (2) to manage and take advantage of errors, (3) to recognize connections between the structure of the text and the complex word processing tools, (4) to pay attention to digital sustainability – beyond hardware and software development and recycling – with a focus on the human factor. Recently, the Error Recognition Model is a reactive problem-solving approach, whose effectiveness is justified. However, the near future is to run parallel the reactive and proactive uses of this approach, while if we look far into the future, the proactive use to digital born natural language texts should dominate.",
    "abstract_processed": "advanc present studi author introduc method make possibl calcul entropi natur languag digit text focus word process text present webpag entropi reveal underdevelop document demand content relat modif becom also found time data requir complet modif task erron document sever time correct counterpart find lead end user paradox less train end user error make modif document requir resourc resolv discrep present studi defin sustain rate natur languag digit text calcul loss – wast human resourc time workspac comput energi frustrat work bee lose data – gener neglig text manag furthermor present exampl manual enumer list behav modif page long document conclud investig wast human machin resourc occur repeatedli erron document sustain rate remain low prove necess correct clear sampl document took approxim hour two expert research group \\time hour method found correct error extrem demand use resourc modif correct document need content requir amount time activ entropi resourc accord expect person intend updat document correct document present error recognit model prove effect effici digit educ find indic educ industri adapt present approach develop students’ end users’ comput think skill manag take advantag error recogn connect structur text complex word process tool pay attent digit sustain – beyond hardwar softwar develop recycl – focu human factor recent error recognit model reactiv problem solv approach whose effect justifi howev near futur run parallel reactiv proactiv use approach look far futur proactiv use digit born natur languag text domin"
  },
  {
    "doc_id": "10445254",
    "abstract_original": "This study is devoted to exploring the strategy of automatic sketch generation and optimization of industrial design based on deep learning. By combining the Generative Adversarial Network (GAN) with the optimization algorithm, this paper proposes an innovative method to realize the automatic generation of high-quality and diverse industrial design sketches. In the experiment, this paper selects SketchyCAD and other public data sets, trains them through deep learning model, and introduces genetic algorithm(GA) and differential evolution algorithm to optimize the parameters. In terms of experimental results, we observed that the quality of generated sketches was significantly improved, and the design sketches generated by the mode (GAN+GA) were more realistic and innovative. The introduction of optimization strategy further improves the generation effect and intelligently adjusts the model parameters to adapt to different design styles. In this paper, the influence of hyperparameter tuning is analyzed in detail, and it is found that the adjustment of learning rate plays a key role in generating quality and diversity. However, the experiment also revealed some challenges and room for improvement. We noticed that the generated results may have the risk of over-fitting in the training process, and with the increase of training times, the diversity gradually decreased. This suggests that more complex model structure and richer data sets are needed to improve the generalization performance. Generally speaking, this study provides new ideas and methods for the integration of deep learning and industrial design. By innovatively combining generation model and optimization algorithm, this research has contributed beneficial research results to the development of industrial design automation. This research is of great significance to promote the intelligence and innovation in the field of industrial design.",
    "abstract_processed": "studi devot explor strategi automat sketch gener optim industri design base deep learn combin gener adversari network gan optim algorithm paper propos innov method realiz automat gener high qualiti divers industri design sketch experi paper select sketchycad public data set train deep learn model introduc genet algorithm ga differenti evolut algorithm optim paramet term experiment result observ qualiti gener sketch significantli improv design sketch gener mode gan ga realist innov introduct optim strategi improv gener effect intellig adjust model paramet adapt differ design style paper influenc hyperparamet tune analyz detail found adjust learn rate play key role gener qualiti divers howev experi also reveal challeng room improv notic gener result may risk fit train process increas train time divers gradual decreas suggest complex model structur richer data set need improv gener perform gener speak studi provid new idea method integr deep learn industri design innov combin gener model optim algorithm research contribut benefici research result develop industri design autom research great signific promot intellig innov field industri design"
  },
  {
    "doc_id": "10448542",
    "abstract_original": "In this article, the issue of human behavior learning (HBL) is addressed for a class of nonlinear human-in-the-loop (HiTL) systems where the human operator is viewed as a nonlinear optimal controller. Owing to its outstanding interpretability and strong nonlinear representation capability, the Takagi–Sugeno (T–S) fuzzy model is employed to represent the nonlinear HiTL control system and approximate the unknown human control law based on the parallel distributed compensation (PDC) scheme. A quadratic-like cost function with fuzzy weighting matrices is built to depict the human behavior, which conforms to human thinking and is unknown to the machine. The aim of the HBL is to retrieve the fuzzy weighting matrices such that the human control law will be optimal in the sense of minimizing the retrieved cost function. In the proposed HBL scheme, the state-dependent Riccati equation-based nonlinear optimal control technique plays an important role, which has a similar structure to the linear quadratic regulator theory and thus is of low computational complexity. With the help of the PDC-based fuzzy approximator for the unknown human control law, a two-step procedure is proposed for the HBL. First, a filter-based adaptive law is developed to learn the gain matrices of the fuzzy approximator using the system state data only. The convergence analysis of the adaptive estimator is also given. Then, a semidefinite programming problem with the quadratic objective function can be set up for determining the fuzzy weighting matrices of the cost function. The simulation study on a steering control system of the intelligent vehicle is given to show the effectiveness and applicability of the developed approach.",
    "abstract_processed": "articl issu human behavior learn hbl address class nonlinear human loop hitl system human oper view nonlinear optim control owe outstand interpret strong nonlinear represent capabl takagi–sugeno t– fuzzi model employ repres nonlinear hitl control system approxim unknown human control law base parallel distribut compens pdc scheme quadrat like cost function fuzzi weight matric built depict human behavior conform human think unknown machin aim hbl retriev fuzzi weight matric human control law optim sens minim retriev cost function propos hbl scheme state depend riccati equat base nonlinear optim control techniqu play import role similar structur linear quadrat regul theori thu low comput complex help pdc base fuzzi approxim unknown human control law two step procedur propos hbl first filter base adapt law develop learn gain matric fuzzi approxim use system state data converg analysi adapt estim also given semidefinit program problem quadrat object function set determin fuzzi weight matric cost function simul studi steer control system intellig vehicl given show effect applic develop approach"
  },
  {
    "doc_id": "10448961",
    "abstract_original": "As a vital risk to the public heath, suicide has been a hot topic for related research. Time perspectives (TPs) have attracted increasing attention in recent years in that making use of TPs can help gain insights into the real motives behind suicide ideation. TPs take into consideration how people think of or appraise their past, present, or future life would shape their behavior. Conventional TP-oriented studies on suicide tendency detection tend to rely on questionnaire surveys to help identify suicide thoughts or attempts. Such efforts suffer from weaknesses including low data collection efficiency and self-report bias. We proposed a TP-enhanced deep multitask model, TP-GloVe-GRU, in which TP is regarded as the synergy of both time and emotions. The model performance was evaluated against the CEASE dataset using a range of metrics. Results show that incorporating TP into the detection of suicide ideation leads to a better performance in most cases with an increase of 2.27% in the accuracy of suicide risk assessment.",
    "abstract_processed": "vital risk public heath suicid hot topic relat research time perspect tp attract increas attent recent year make use tp help gain insight real motiv behind suicid ideat tp take consider peopl think apprais past present futur life would shape behavior convent tp orient studi suicid tendenc detect tend reli questionnair survey help identifi suicid thought attempt effort suffer weak includ low data collect effici self report bia propos tp enhanc deep multitask model tp glove gru tp regard synergi time emot model perform evalu ceas dataset use rang metric result show incorpor tp detect suicid ideat lead better perform case increas accuraci suicid risk assess"
  },
  {
    "doc_id": "10448972",
    "abstract_original": "The Vehicle location is utilized to recognize the vehicles in any video or picture document. The course of recognition of vehicles incorporates the item location by thinking about the vehicles as the essential article. By taking the pictures structure elevated or even view and from street or stopping utilizing observation cameras, the location interaction can be started. Vehicle identification and order assumes critical part in rush hour gridlock checking and the executives. The use of vehicle recognition and order is exceptionally immense. Vehicle identification is utilized on streets, roadways, leaving or some other spot to distinguish or follow the quantity of vehicles present on the spot. This will assist the reconnaissance with passing judgment on the traffic vehicles, normal speed and classification of vehicle. There are number of item recognition methods are accessible to distinguish and arrange them.",
    "abstract_processed": "vehicl locat util recogn vehicl video pictur document cours recognit vehicl incorpor item locat think vehicl essenti articl take pictur structur elev even view street stop util observ camera locat interact start vehicl identif order assum critic part rush hour gridlock check execut use vehicl recognit order except immens vehicl identif util street roadway leav spot distinguish follow quantiti vehicl present spot assist reconnaiss pass judgment traffic vehicl normal speed classif vehicl number item recognit method access distinguish arrang"
  },
  {
    "doc_id": "10449552",
    "abstract_original": "The objective of this study is to determine if there exists a statistically significant distinction between high school pupils who get instruction in the topic of “Art” through the use of Artificial Intelligence (AI) and those who receive instruction through the integration of Science, Technology, Engineering, Arts, and Mathematics (STEAM). Creativity, particularly within the realm of art and design, is commonly perceived as the ability to think beyond conventional boundaries. The study posited an alternative perspective by equating computational thinking with creative thinking. A total of forty-two kids from a high school in Kazakhstan were chosen as case studies for the topic of Art. The objective is to facilitate the integration of STEM education and art-based education.",
    "abstract_processed": "object studi determin exist statist signific distinct high school pupil get instruct topic “art” use artifici intellig ai receiv instruct integr scienc technolog engin art mathemat steam creativ particularli within realm art design commonli perceiv abil think beyond convent boundari studi posit altern perspect equat comput think creativ think total forti two kid high school kazakhstan chosen case studi topic art object facilit integr stem educ art base educ"
  },
  {
    "doc_id": "10449582",
    "abstract_original": "Since some decades ago, cybercrimes have not only increased but it is also becoming more complex. The attackers are using more sophisticated techniques for data breaching. As humans take more time to understand the patterns of cyber-attacks, traditional methods of cyber security were not as much relevant. Henceforth, in the late 1980s the concept of artificial intelligence combined with cyber security, came into existence. Due to the machine learning and deep learning concepts humans teach the machine to detect the threats. By taking the help of big data machine learn the different patterns of attacks. By the concepts of deep learning the machine is able to learn from experiences, it can remember the patterns of different attacks. Neural networks make it possible for a machine to think like humans. Now when a threat arises the artificial intelligence is able to detect and take an action against it. It is true that the artificial intelligence has totally changed the world of cyber security but now also there are some questions in the human mind. This paper includes the basics of Artificial intelligence, Machine learning, Deep learning, AI in cyber security and many more collected through the survey of different papers.",
    "abstract_processed": "sinc decad ago cybercrim increas also becom complex attack use sophist techniqu data breach human take time understand pattern cyber attack tradit method cyber secur much relev henceforth late concept artifici intellig combin cyber secur came exist due machin learn deep learn concept human teach machin detect threat take help big data machin learn differ pattern attack concept deep learn machin abl learn experi rememb pattern differ attack neural network make possibl machin think like human threat aris artifici intellig abl detect take action true artifici intellig total chang world cyber secur also question human mind paper includ basic artifici intellig machin learn deep learn ai cyber secur mani collect survey differ paper"
  },
  {
    "doc_id": "10449604",
    "abstract_original": "In this study, we aimed to address issues related to students' slow writing skills by incorporating the “Out of Eden Walk” project using an AI model. Employing a project-based learning approach, our goal was to enhance students' writing abilities, particularly in the English subject. The research was conducted as a part of the classroom term-end assessment, following the model established by Nazarbayev Intellectual School of Chemistry and Biology, involving 42 students from Class 11. We utilized a qualitative descriptive method, employing both test and non-test instruments, including observation and data analysis in six cycles. The initial student completion rate was only 11.42%, while the experimental group showed a significant improvement to 85.71% by the end of the study. National Geographic's Out of Eden Walk, led by two-time Pulitzer Prize winner Paul Salopek, serves as an exemplary illustration of slow journalism. Over a seven-year, around-the-world journey, this article explores how Salopek's Walk not only embodies the essence of slow journalism but also significantly contributed to enhancing students' writing skills through the integration of an AI model.",
    "abstract_processed": "studi aim address issu relat student slow write skill incorpor “out eden walk” project use ai model employ project base learn approach goal enhanc student write abil particularli english subject research conduct part classroom term end assess follow model establish nazarbayev intellectu school chemistri biolog involv student class util qualit descript method employ test non test instrument includ observ data analysi six cycl initi student complet rate experiment group show signific improv end studi nation geograph eden walk led two time pulitz prize winner paul salopek serv exemplari illustr slow journal seven year around world journey articl explor salopek walk embodi essenc slow journal also significantli contribut enhanc student write skill integr ai model"
  },
  {
    "doc_id": "10449638",
    "abstract_original": "In the rapidly evolving landscape of education, the cultivation of computational skills and the enhancement of students' intellectual abilities remain of paramount importance. This research paper delves into the innovative approach of leveraging Multiple Intelligence (MI) theory to foster computational skills among high school students. The study specifically focuses on a group of 26 computer science high school students at N azarbayev Intellectual School in Shymkent, Kazakhstan. The research employs a comprehensive and structured methodology that integrates MI principles into the classroom environment. Over a designated timeframe, students participate in a variety of activities designed to engage and stimulate each of their unique intelligences. Language, mathematics, spatial perception, motor skills, music, personal, and intrapersonal communication intelligences are all encompassed in these pursuits., creating a holistic learning experience. Data collection encompasses a multitude of measures, including pre- and post-assessments, observations, and student feedback, to gauge demonstrate the significant improvement in students' computational abilities following the MI-enhanced curriculum. In particular, students displayed increased problem-solving skills, critical thinking, creativity, and adaptability when confronted with computational challenges. The conclusion of this study contribute significant analysis into the potential of MI theory to transform traditional computer science education. By providing a dynamic and inclusive learning environment that nurtures students' diverse intellectual strengths, educators can empower learners to excel in computational disciplines. This research paper encourages further exploration of MI- based strategies to enhance computational abilities and inspires a shift towards more personalized and inspires a shift towards more personalized and effective teaching methodologies.",
    "abstract_processed": "rapidli evolv landscap educ cultiv comput skill enhanc student intellectu abil remain paramount import research paper delv innov approach leverag multipl intellig mi theori foster comput skill among high school student studi specif focus group comput scienc high school student n azarbayev intellectu school shymkent kazakhstan research employ comprehens structur methodolog integr mi principl classroom environ design timefram student particip varieti activ design engag stimul uniqu intellig languag mathemat spatial percept motor skill music person intraperson commun intellig encompass pursuit creat holist learn experi data collect encompass multitud measur includ pre post assess observ student feedback gaug demonstr signific improv student comput abil follow mi enhanc curriculum particular student display increas problem solv skill critic think creativ adapt confront comput challeng conclus studi contribut signific analysi potenti mi theori transform tradit comput scienc educ provid dynam inclus learn environ nurtur student divers intellectu strength educ empow learner excel comput disciplin research paper encourag explor mi base strategi enhanc comput abil inspir shift toward person inspir shift toward person effect teach methodolog"
  },
  {
    "doc_id": "10449649",
    "abstract_original": "With the evolution of communication technologies, various substantial applications help the human community. Various real-time applications rely on the 5G era to fulfil the baseline service requirements. These 5G network communications deploy different cryptosystems to handle the security issues between homogeneous and heterogeneous systems. Here, a novel signcryption scheme is proposed over various public cryptosystems to secure communication among the 5G network model. The anticipated model establishes mutual communication among the certificate-less public key infra-structure environment. The proposed scheme works well against the chosen adaptive ciphertext attack under various computational random problems. A bilinear pairing-based signcryption (BPS) method is proposed and executed over the MATLAB 2020a simulation environment. This model is secure over the random model and establishes a better security trade-off among the prevailing approaches. Moreover, this model analyses and quantifies the scheme's performance with metrics like time comparison over a key generation, signcryption and unsigncryption. Therefore, the model attains superior security and efficiency.",
    "abstract_processed": "evolut commun technolog variou substanti applic help human commun variou real time applic reli g era fulfil baselin servic requir g network commun deploy differ cryptosystem handl secur issu homogen heterogen system novel signcrypt scheme propos variou public cryptosystem secur commun among g network model anticip model establish mutual commun among certif less public key infra structur environ propos scheme work well chosen adapt ciphertext attack variou comput random problem bilinear pair base signcrypt bp method propos execut matlab simul environ model secur random model establish better secur trade among prevail approach moreov model analys quantifi scheme perform metric like time comparison key gener signcrypt unsigncrypt therefor model attain superior secur effici"
  },
  {
    "doc_id": "10452115",
    "abstract_original": "Database is an important carrier to meet information overall management. With the continuous development of global information construction in recent years, the types and quantities of information stored in databases are increasing. Implementing high-speed query response to massive database storage resources through hardware-level optimization design has become an important research direction in related fields. Aiming at the key problems such as low efficiency and high delay existing in the process of performing aggregation operation in the current mainstream database, this paper thorough analysis the principles and key steps of database execution of aggregation queries, and a new FPGA-based database aggregation query accelerator is designed using heterogeneous thinking. The accelerator is designed according to the actual application scenario of relational database aggregation query, and implements the aggregation grouping strategy based on hash algorithm and five commonly used aggregation functions through FPGA; In order to maximize processing efficiency and fully utilize the excellent parallel processing capabilities of FPGA, this study also optimizes the existing aggregation query architecture and proposes a decentralized multi-core collaborative aggregation query architecture to meet the needs of single time period and multithreaded queries. The aggregation query experiments on ZNBase, an open source database platform, show that the proposed database aggregation query accelerator based on FPGA is 21.71 times more efficient than the traditional software algorithm to realize the aggregation query scheme.",
    "abstract_processed": "databas import carrier meet inform overal manag continu develop global inform construct recent year type quantiti inform store databas increas implement high speed queri respons massiv databas storag resourc hardwar level optim design becom import research direct relat field aim key problem low effici high delay exist process perform aggreg oper current mainstream databas paper thorough analysi principl key step databas execut aggreg queri new fpga base databas aggreg queri acceler design use heterogen think acceler design accord actual applic scenario relat databas aggreg queri implement aggreg group strategi base hash algorithm five commonli use aggreg function fpga order maxim process effici fulli util excel parallel process capabl fpga studi also optim exist aggreg queri architectur propos decentr multi core collabor aggreg queri architectur meet need singl time period multithread queri aggreg queri experi znbase open sourc databas platform show propos databas aggreg queri acceler base fpga time effici tradit softwar algorithm realiz aggreg queri scheme"
  },
  {
    "doc_id": "10455497",
    "abstract_original": "In the realm of computational physics education, enhancing student engagement remains a pivotal challenge. This research delved into the potential of Project-Based Learning (PBL), with a particular emphasis on the VBA Physics Simulation, to invigorate students’ learning engagement. By surveying undergraduate students’ perceptions in computational physics course, we observed a predominant positive response towards the PBL model. The findings underscore that students not only appreciate the structured learning experience PBL offers but also value the guidance from lecturers in this approach. Through the lens of PBL, students reported a marked improvement in various skills, including the 4C skills (Critical thinking, Communication, Collaboration, Creativity), problem-solving, and higher-order thinking skills. This study advocates for the broader integration of PBL in computational physics course, especially using tools like VBA Physics Simulation, as a means to deepen understanding and amplify student engagement. We also recommend future quantitative research to further solidify these findings.",
    "abstract_processed": "realm comput physic educ enhanc student engag remain pivot challeng research delv potenti project base learn pbl particular emphasi vba physic simul invigor students’ learn engag survey undergradu students’ percept comput physic cours observ predomin posit respons toward pbl model find underscor student appreci structur learn experi pbl offer also valu guidanc lectur approach len pbl student report mark improv variou skill includ c skill critic think commun collabor creativ problem solv higher order think skill studi advoc broader integr pbl comput physic cours especi use tool like vba physic simul mean deepen understand amplifi student engag also recommend futur quantit research solidifi find"
  },
  {
    "doc_id": "10455810",
    "abstract_original": "This research examines the impact of playing Multiplayer Online Battle Arena (MOBA) video games on computational thinking skills among Indonesian college students. Using a quantitative approach, structured and valid questionnaires were administered to collect data and explore the potential benefits of video games in education. The findings indicate that playing MOBA games is associated with enhanced computational thinking skills. Additionally, Participants recognized the positive influence of playing MOBA games on computational thinking, highlighting improved strategic thinking, decision-making, and team coordination as main benefits. These results contribute to the existing research on gaming and cognitive skills, underscoring the potential of MOBA games for fostering computational thinking abilities. Educators and program developers can utilize these insights to enhance teaching and learning methods by integrating video games.",
    "abstract_processed": "research examin impact play multiplay onlin battl arena moba video game comput think skill among indonesian colleg student use quantit approach structur valid questionnair administ collect data explor potenti benefit video game educ find indic play moba game associ enhanc comput think skill addit particip recogn posit influenc play moba game comput think highlight improv strateg think decis make team coordin main benefit result contribut exist research game cognit skill underscor potenti moba game foster comput think abil educ program develop util insight enhanc teach learn method integr video game"
  },
  {
    "doc_id": "1045878",
    "abstract_original": "This paper presents a prototype of a distributed training simulator for a surface-to-air missile system. Since the system requirement enforces us to choose an open standard platform, and we think that Java has matured enough to offer acceptable performance and reliability, we decide to implement it by Java. Basically, this training simulator is a distributed interactive application, and lots of messages are exchanged within it. For the performance reason, we use an IP-multicast-based Java message service (JMS) implementation as the communication infrastructure for delivering time-critical events. In this paper, we present how to exploit the capability of the JMS publish/subscribe paradigm to implement this training simulator. Besides, we also perform a set of experiments to test and verify whether the training simulator can meet the system requirement. We think the experience of this paper is a good case study of using Java and message-oriented middleware to build message-intensive distributed systems.",
    "abstract_processed": "paper present prototyp distribut train simul surfac air missil system sinc system requir enforc us choos open standard platform think java matur enough offer accept perform reliabl decid implement java basic train simul distribut interact applic lot messag exchang within perform reason use ip multicast base java messag servic jm implement commun infrastructur deliv time critic event paper present exploit capabl jm publish subscrib paradigm implement train simul besid also perform set experi test verifi whether train simul meet system requir think experi paper good case studi use java messag orient middlewar build messag intens distribut system"
  },
  {
    "doc_id": "10464618",
    "abstract_original": "We explore the potential of utilizing ChatGPT to automatically generate educational assessment questions. Despite the growing promise of ChatGPT across various natural language tasks, including question generation, there exists a challenge of producing content that is both reliable and desirable. This issue becomes particularly crucial in educational assessments, where the quality of the generated content and its alignment with the assessed material are paramount. This research examines questions produced by ChatGPT, focusing on their alignment with different levels of Bloom's Taxonomy and their overall fluency and coherence. To assess the quality of the generated questions, we establish several scenarios for generation and subsequently evaluate the questions using both automated metrics and manual examination. Our empirical analysis shows that ChatGPT tends to produce high-quality questions; however, these questions predominantly fall within the categories of Remember, Understand, and Apply in Bloom's Taxonomy. It exhibits limited capacity for generating questions that require higher-order reasoning. Further enhancements are therefore necessary to enhance the question quality of this model, particularly with regard to the diversity of question types based on Bloom's Taxonomy. This improvement is crucial to ensure the suitability of the generated questions for effective classroom assessments.",
    "abstract_processed": "explor potenti util chatgpt automat gener educ assess question despit grow promis chatgpt across variou natur languag task includ question gener exist challeng produc content reliabl desir issu becom particularli crucial educ assess qualiti gener content align assess materi paramount research examin question produc chatgpt focus align differ level bloom taxonomi overal fluenci coher assess qualiti gener question establish sever scenario gener subsequ evalu question use autom metric manual examin empir analysi show chatgpt tend produc high qualiti question howev question predominantli fall within categori rememb understand appli bloom taxonomi exhibit limit capac gener question requir higher order reason enhanc therefor necessari enhanc question qualiti model particularli regard divers question type base bloom taxonomi improv crucial ensur suitabl gener question effect classroom assess"
  },
  {
    "doc_id": "10465207",
    "abstract_original": "Schizophrenia is a serious mental disorder that affects a person's ability to think, feel, and behave clearly. Schizophrenia detection using Electroencephalography is an en-grossing area of neuroscience. There are several researches reported on designing effective models which can detect schizophre-nia accurately, however, existing models are either complex or use an extensive number of waves to process for detecting schizophre-nia accurately. Addressing the issues mentioned above, this work presents a lightweight Schizophrenia detection model with the help of Gamma wave extraction from the electroencephalogram brain waves. The proposed model has approximately 12500 parameters with an accuracy of 99.5 % which is much lighter than the previous state-of-the-art models that contain nearly 11 million parameters. We also presented a detailed comparative result analysis among all the state-of-the-art models with the proposed model which shows the effectiveness of our proposed model.",
    "abstract_processed": "schizophrenia seriou mental disord affect person abil think feel behav clearli schizophrenia detect use electroencephalographi en gross area neurosci sever research report design effect model detect schizophr nia accur howev exist model either complex use extens number wave process detect schizophr nia accur address issu mention work present lightweight schizophrenia detect model help gamma wave extract electroencephalogram brain wave propos model approxim paramet accuraci much lighter previou state art model contain nearli million paramet also present detail compar result analysi among state art model propos model show effect propos model"
  },
  {
    "doc_id": "10466457",
    "abstract_original": "I found a book under the Christmas tree with a curious title “The Shortcut”, by Nello Cristianini. The subtitle “Why Intelligent Machines Do Not Think Like Us” unveils that the book is about Artificial Intelligence (AI). What is the shortcut, then? As the author explains, there has been a change of paradigm associated with AI: From the original idea to create machines able to think as we do, to machines able to get trained by data-driven approaches based on statistics, and to make it so effectively as to give us the idea they are really thinking as we do. In a nutshell, machine learning (ML) has been our shortcut towards AI.",
    "abstract_processed": "found book christma tree curiou titl “the shortcut” nello cristianini subtitl “whi intellig machin think like us” unveil book artifici intellig ai shortcut author explain chang paradigm associ ai origin idea creat machin abl think machin abl get train data driven approach base statist make effect give us idea realli think nutshel machin learn ml shortcut toward ai"
  },
  {
    "doc_id": "10467426",
    "abstract_original": "Maize crops get hit hard by corn rust, a big disease that affects farming all over the world's food production. Traditional ways of finding diseases and putting them in groups are basic, but often limited by what people think about it. They don't work well when needed for a large number of cases. This study shows a new method using Multi-Layer Perceptron (MLP), which is deep learning (DL). It helps to correctly identify the degree of damage from corn rust disease. The study shows that the MLP model works well in finding and classifying disease stages using a set of 3500 and pictures from six levels. The MLP model was carefully made and taught to recognize small changes in disease levels. It puts importance on being right, exact, and remembering everything about it all the time. The machine reached 94.20% accuracy, showing it could be useful for people working with plants and those who farm. The MLP was faster, more scalable, and gave better results than other computer learning methods. It did a great job! This study aids the increasing mix of artificial intelligence and farming that's precise. It shows how DL can help solve tough agriculture problems. The results show that the MLP model can help manage crop diseases. It helps in quick and effective actions to stop these problems from causing more harm. For the future, we want to make the model stronger. We also plan on using it for other sicknesses and adding it to farming systems that check things in real-time right away. The research opens the door for better farming methods that are both green and save energy, driven by smart machines.",
    "abstract_processed": "maiz crop get hit hard corn rust big diseas affect farm world food product tradit way find diseas put group basic often limit peopl think work well need larg number case studi show new method use multi layer perceptron mlp deep learn dl help correctli identifi degre damag corn rust diseas studi show mlp model work well find classifi diseas stage use set pictur six level mlp model care made taught recogn small chang diseas level put import right exact rememb everyth time machin reach accuraci show could use peopl work plant farm mlp faster scalabl gave better result comput learn method great job studi aid increas mix artifici intellig farm precis show dl help solv tough agricultur problem result show mlp model help manag crop diseas help quick effect action stop problem caus harm futur want make model stronger also plan use sick ad farm system check thing real time right away research open door better farm method green save energi driven smart machin"
  },
  {
    "doc_id": "10467509",
    "abstract_original": "This article describes how quantum systems can be used to replicate complex physical occurrences, with emphasis on the use of new quantum algorithms and special data sets. First, let's talk about how quantum computers can handle big and complex data sets that are too hard for classical computers. The focus here is on the use of quantum computing methods. The main focus of our school assignment is on developing and executing quantum algorithms specifically designed to analyze and evaluate these datasets. These quantum algorithm allows us to model a complex system. Explain the basic of tool that can be used to quantum material properties. Instructions: Change the word ‘formulas’ into another Word and rephrase the sentence accordingly. The study proposes using quantum algorithms to handle large data collections. We explain how to transform classical data to quantum representation for clearer comprehension. Also illustrated is how this encoding may yield simulated outcomes. This approach ensures precise and reliable simulations. Unlike ordinary data storage and correction, quantum computing presents various problem-solving obstacles. To remove these challenges, the simulation is made painstakingly precise and dependable. Case studies may show how quantum systems can simulate complicated situations like astronomical object motions and subatomic particle activity under harsh conditions. These case studies show that quantum simulation can address issues traditional approaches can't. Our findings might affect future study, and quantum computing could transform our knowledge of complex physical events. We also discuss quantum computing and coding's pros and cons, encouraging creative thinking in this fascinating topic.",
    "abstract_processed": "articl describ quantum system use replic complex physic occurr emphasi use new quantum algorithm special data set first let talk quantum comput handl big complex data set hard classic comput focu use quantum comput method main focu school assign develop execut quantum algorithm specif design analyz evalu dataset quantum algorithm allow us model complex system explain basic tool use quantum materi properti instruct chang word ‘formulas’ anoth word rephras sentenc accordingli studi propos use quantum algorithm handl larg data collect explain transform classic data quantum represent clearer comprehens also illustr encod may yield simul outcom approach ensur precis reliabl simul unlik ordinari data storag correct quantum comput present variou problem solv obstacl remov challeng simul made painstakingli precis depend case studi may show quantum system simul complic situat like astronom object motion subatom particl activ harsh condit case studi show quantum simul address issu tradit approach find might affect futur studi quantum comput could transform knowledg complex physic event also discuss quantum comput code pro con encourag creativ think fascin topic"
  },
  {
    "doc_id": "10469197",
    "abstract_original": "The primary objective of this research was to investigate effective learning sequences starting with computational thinking, programming, or both. We experimented with and analyzed the learning sequence of students from the Department of Computer Engineering, Information Management, and Mechanical Engineering. The findings indicated that the students of the Department of Computer Engineering possessed prior experiences in programming or computational thinking. Their learning sequences limitedly impacted learning outcomes. Conversely, for the students of the Department of Information Management, learning computational thinking before programming did not result in better learning outcomes, emphasizing the need for coherence in courses. The students of the Department of Mechanical Engineering showed the practical value of computational thinking in non-IT disciplines, particularly in using specialized software such as MATLAB. For students with foundational knowledge, the learning sequence between learning computational thinking and programming was less significant. However, for beginners or those from non-IT backgrounds, effective learning required the coherence and integration of courses. Thus, it is required to maintain cross-course coherence and establish links between computational thinking and programming skills to offer a more in-depth learning experience.",
    "abstract_processed": "primari object research investig effect learn sequenc start comput think program experi analyz learn sequenc student depart comput engin inform manag mechan engin find indic student depart comput engin possess prior experi program comput think learn sequenc limitedli impact learn outcom convers student depart inform manag learn comput think program result better learn outcom emphas need coher cours student depart mechan engin show practic valu comput think non disciplin particularli use special softwar matlab student foundat knowledg learn sequenc learn comput think program less signific howev beginn non background effect learn requir coher integr cours thu requir maintain cross cours coher establish link comput think program skill offer depth learn experi"
  },
  {
    "doc_id": "10469561",
    "abstract_original": "Accompanied by the continuous progress of social science and technology, the hybrid teaching model and the intelligent classroom based on artificial intelligence (AI) technology in higher education institutions have become an innovative trend that has attracted much attention from the education sector. The purpose of this study was to delve into how to integrate hybrid teaching and AI technology in university education and create a smarter and more personalized classroom atmosphere. This study was carried out to build a smart classroom for a university image processing course with AI technology, using the book “Photoshop Basics” as an example. By integrating advanced technology in AI, the quality of classroom instruction was improved to help students learn image processing as a fundamental concept. The Smart Classroom program used adaptive learning systems, image recognition technology, and real-time feedback mechanisms to provide a personalized learning experience. By blending the foundational concepts of traditional Photoshop with the latest AI technologies, students understood the core concepts of image processing, thereby enhancing their creative and practical skills. AI-based blended teaching models in higher education continue to evolve as a powerful means of fostering students with innovative thinking and practical skills.",
    "abstract_processed": "accompani continu progress social scienc technolog hybrid teach model intellig classroom base artifici intellig ai technolog higher educ institut becom innov trend attract much attent educ sector purpos studi delv integr hybrid teach ai technolog univers educ creat smarter person classroom atmospher studi carri build smart classroom univers imag process cours ai technolog use book “photoshop basics” exampl integr advanc technolog ai qualiti classroom instruct improv help student learn imag process fundament concept smart classroom program use adapt learn system imag recognit technolog real time feedback mechan provid person learn experi blend foundat concept tradit photoshop latest ai technolog student understood core concept imag process therebi enhanc creativ practic skill ai base blend teach model higher educ continu evolv power mean foster student innov think practic skill"
  },
  {
    "doc_id": "10470584",
    "abstract_original": "This paper affords a hybrid forecasting scheme for time series prediction in head-primarily based aggregation clusters. The proposed version combines multiple individual predictors in a manner that permits each to capture heterogeneous characteristics of the time series and think of each of the temporal and spatial dimensions within the enter statistics. An aggregation step is also included to construct cluster distributions to enhance prediction accuracy. The model's performance is evaluated on actual datasets with recognition of each temporal and spatial dimension. Results display the effectiveness of the proposed technique in predicting destiny values of time collection with accuracy higher than individual predictions. Further, the model also can cope with minor adjustments within the shape of facts, allowing for excessive flexibility within the analysis and forecasting procedure. It explores the ability of hybrid predictions of time collection in head-based total aggregation clusters. It provides a complete time collection evaluation, forecasting the usage of an aggregate of records mining and device-getting-to-know techniques. The paper introduces the vital standards and techniques for an adequate time series forecasting version. A hybrid prediction model consisting of the Autoregressive included shifting standard (ARIMA) model and the Weighted Neighbourhood common (WNA) model is then explored. The efficacy of the version is statistically tested on an artificial dataset with constant natural and seasonal time series additives and on one actual-global dataset with a vast range of correlated time collection. Compared to classic forecasting fashions, the effects demonstrate that a hybrid prediction version produces drastically higher accuracy and offers an extra sensible representation of the device's behavior. The paper evaluates hybrid prediction fashions to alternative strategies and a few viable future development directions.",
    "abstract_processed": "paper afford hybrid forecast scheme time seri predict head primarili base aggreg cluster propos version combin multipl individu predictor manner permit captur heterogen characterist time seri think tempor spatial dimens within enter statist aggreg step also includ construct cluster distribut enhanc predict accuraci model perform evalu actual dataset recognit tempor spatial dimens result display effect propos techniqu predict destini valu time collect accuraci higher individu predict model also cope minor adjust within shape fact allow excess flexibl within analysi forecast procedur explor abil hybrid predict time collect head base total aggreg cluster provid complet time collect evalu forecast usag aggreg record mine devic get know techniqu paper introduc vital standard techniqu adequ time seri forecast version hybrid predict model consist autoregress includ shift standard arima model weight neighbourhood common wna model explor efficaci version statist test artifici dataset constant natur season time seri addit one actual global dataset vast rang correl time collect compar classic forecast fashion effect demonstr hybrid predict version produc drastic higher accuraci offer extra sensibl represent devic behavior paper evalu hybrid predict fashion altern strategi viabl futur develop direct"
  },
  {
    "doc_id": "10470788",
    "abstract_original": "The advancement in Microelectromechanical System (MEMS) technology resulted in accurate and high-performance miniature device systems. These devices are so tiny that they are not noticeable by the human eye and exhibit excellent feasibility in miniaturization sensors due to their small dimensions, low power consumption, and superior performance. The area of sci-ence and engineering where MEMS are developed (dimensions in the manometer scale) is called Nanotechnology. Nanotechnology is one of the fastest growing scientific research related to Industry 4.0. Nanotechnology may introduce industrial skills deficits as well as opportunities for new teaching practices in several subjects and educational frameworks. In the present work, we investigate the attitude of STEM (i.e. technology/engineering) and non STEM - related instructors, regarding the integration of Nanotechnology applications in Higher education curricula. Their opinions, concerning the applied teaching method, the learning content material and expected student skills, should always be taken in to account, as they may boost any reformations proposed. Moreover, we propose a repository platform, with which instructors may interact with 3D designs and MEMs mate-rial to built their didactic plans. This work's findings is critical for the design and innovative training material and computational thinking (CT) activities, which will prepare student with skills related to Industry 4.0 demand.",
    "abstract_processed": "advanc microelectromechan system mem technolog result accur high perform miniatur devic system devic tini notic human eye exhibit excel feasibl miniatur sensor due small dimens low power consumpt superior perform area sci enc engin mem develop dimens manomet scale call nanotechnolog nanotechnolog one fastest grow scientif research relat industri nanotechnolog may introduc industri skill deficit well opportun new teach practic sever subject educ framework present work investig attitud stem e technolog engin non stem relat instructor regard integr nanotechnolog applic higher educ curricula opinion concern appli teach method learn content materi expect student skill alway taken account may boost reform propos moreov propos repositori platform instructor may interact design mem mate rial built didact plan work find critic design innov train materi comput think ct activ prepar student skill relat industri demand"
  },
  {
    "doc_id": "10471714",
    "abstract_original": "In response to the current high psychological pressure among people in society, but the shortage of psychological professionals, many people are unable to seek help, this article designs a psychological stress assessment system based on big data analysis technology. This article introduces genetic algorithms to optimize neural networks, addressing their shortcomings and enabling the psychological stress assessment system to have superior performance. Through experimental testing, it is found that the psychological stress evaluation system designed in this paper has high evaluation efficiency, strong stability, and strong noise resistance, and can effectively evaluate the psychological stress.",
    "abstract_processed": "respons current high psycholog pressur among peopl societi shortag psycholog profession mani peopl unabl seek help articl design psycholog stress assess system base big data analysi technolog articl introduc genet algorithm optim neural network address shortcom enabl psycholog stress assess system superior perform experiment test found psycholog stress evalu system design paper high evalu effici strong stabil strong nois resist effect evalu psycholog stress"
  },
  {
    "doc_id": "10472096",
    "abstract_original": "Social networks are gaining importance as an important application landscape for machine learning techniques. Currently, it is prevalent thinking to introduce social networks into group decision-making research, despite exhibiting promising performance, there remain significant challenges, including 1) trust risk is often overlooked, and 2) group opinions are excessively relied upon. In this regard, this article introduces the trust risk test for group consensus (SN-TRT-GC) by using probabilistic linguistic preference relations under probabilistic linguistic term sets. The proposed method ensures that the expert's competence matches the discourse as much as possible by virtue of the trust risk value. Moreover, opinion evolution relies on the dual attributes of similarity and trust, which promote the exchange of opinions among experts and greatly accelerate the consensus reaching process. Empirical investigations of satisfaction surveys demonstrate the validity and superiority of the presented SN-TRT-GC technique.",
    "abstract_processed": "social network gain import import applic landscap machin learn techniqu current preval think introduc social network group decis make research despit exhibit promis perform remain signific challeng includ trust risk often overlook group opinion excess reli upon regard articl introduc trust risk test group consensu sn trt gc use probabilist linguist prefer relat probabilist linguist term set propos method ensur expert compet match discours much possibl virtu trust risk valu moreov opinion evolut reli dual attribut similar trust promot exchang opinion among expert greatli acceler consensu reach process empir investig satisfact survey demonstr valid superior present sn trt gc techniqu"
  },
  {
    "doc_id": "10475634",
    "abstract_original": "Gender bias creates inequalities in roles, expectations, and opportunities between males and females. When such biases are incorporated into artificial intelligence models, the corresponding technological solutions and products can further entrench the social biases. Herein, a new method for investigating the extent to which latent biases in text-based training data affect a language model is presented. Potential gender bias is identified by deriving values assigned to male/female words via inverse operations from embedded expressions to the original words using the approximate inverse model explanation (AIME). In particular, AIME constructs approximate generalized inverse operators for black-box models. A biased embedded representation used in machine learning models as an internal representation of word/sentence vectors likely introduces bias into the overall prediction results of such models. The OpenAI text-embedding-ada-002 large language model, which provides embedded expressions, is employed to determine the gender bias included in the proposed method. Experimental results show that the OpenAI textembedding-ada-002 model is partially gender-biased owing to the training text data. These results are expected to (i) contribute to the development of effective measures preventing gender bias during the design and training of language models, (ii) promote the identification and mitigation of gender bias in future language models, and (iii) provide insights into the effect of language models and their limitations from technical, social, and cultural perspectives.",
    "abstract_processed": "gender bia creat inequ role expect opportun male femal bias incorpor artifici intellig model correspond technolog solut product entrench social bias herein new method investig extent latent bias text base train data affect languag model present potenti gender bia identifi deriv valu assign male femal word via invers oper embed express origin word use approxim invers model explan aim particular aim construct approxim gener invers oper black box model bias embed represent use machin learn model intern represent word sentenc vector like introduc bia overal predict result model openai text embed ada larg languag model provid embed express employ determin gender bia includ propos method experiment result show openai textembed ada model partial gender bias owe train text data result expect contribut develop effect measur prevent gender bia design train languag model ii promot identif mitig gender bia futur languag model iii provid insight effect languag model limit technic social cultur perspect"
  },
  {
    "doc_id": "10476921",
    "abstract_original": "This paper studies spatial smoothing using sparse arrays in single-snapshot Direction of Arrival (DOA) estimation. We consider the application of automotive MIMO radar, which traditionally synthesizes a large uniform virtual array by appropriate waveform and physical array design. We explore deliberately introducing holes into this virtual array to leverage resolution gains provided by the increased aperture. The presence of these holes requires re-thinking DOA estimation, as conventional algorithms may no longer be easily applicable and alternative techniques, such as array interpolation, may be computationally expensive. Consequently, we study sparse array geometries that permit the direct application of spatial smoothing. We show that a sparse array geometry is amenable to spatial smoothing if it can be decomposed into the sum set of two subsets of suitable cardinality. Furthermore, we demonstrate that many such decompositions may exist-not all of them yielding equal identifiability or aperture. We derive necessary and sufficient conditions to guarantee identifiability of a given number of targets, which gives insight into choosing desirable decompositions for spatial smoothing. This provides uniform recovery guarantees and enables estimating DOAs at increased resolution and reduced computational complexity. 1",
    "abstract_processed": "paper studi spatial smooth use spars array singl snapshot direct arriv doa estim consid applic automot mimo radar tradit synthes larg uniform virtual array appropri waveform physic array design explor deliber introduc hole virtual array leverag resolut gain provid increas apertur presenc hole requir think doa estim convent algorithm may longer easili applic altern techniqu array interpol may comput expens consequ studi spars array geometri permit direct applic spatial smooth show spars array geometri amen spatial smooth decompos sum set two subset suitabl cardin furthermor demonstr mani decomposit may exist yield equal identifi apertur deriv necessari suffici condit guarante identifi given number target give insight choos desir decomposit spatial smooth provid uniform recoveri guarante enabl estim doa increas resolut reduc comput complex"
  },
  {
    "doc_id": "10479387",
    "abstract_original": "Computer science unplugged (CS unplugged) is a method of teaching computer science and computational thinking. The aim of our study is to illustrate program behavior and to prevent confusion about the program stack through visualization. To facilitate recognition, we used a toy consisting of a ball, pipes, and magnetic panels. The ball represents which line of code is executed, similar to the program counter. To demonstrate the feasibility of the proposed method, we present three examples based on the proposed method. The examples are necessity of loop to wait user input, necessity of loop to keep program running, and software testing. We conducted an experiment with nine participants to evaluate the effectiveness of the proposed method. The result suggested that the proposed method is expected to be effective.",
    "abstract_processed": "comput scienc unplug cs unplug method teach comput scienc comput think aim studi illustr program behavior prevent confus program stack visual facilit recognit use toy consist ball pipe magnet panel ball repres line code execut similar program counter demonstr feasibl propos method present three exampl base propos method exampl necess loop wait user input necess loop keep program run softwar test conduct experi nine particip evalu effect propos method result suggest propos method expect effect"
  },
  {
    "doc_id": "10480052",
    "abstract_original": "Programming has emerged as a crucial educational skill, as its acquisition correlates with the enhancement of students’ reading, writing, creative, computational, and problem-solving aptitudes. This significance is particularly pronounced in a global landscape transitioning into the 4.0 era, characterized by pervasive information technology integration into daily life. This research endeavors to explore the potential of utilizing board games for coding education, specifically targeting student demographics lacking access to modern technology and educational resources, such as ethnic groups or remote populations distanced from urban centers. The board game’s efficacy in augmenting programming comprehension was evaluated through testing and feedback solicited from students and teachers in schools across Chiang Rai Province. Moreover, insights from computer science educators were incorporated to refine gameplay and enrich knowledge components, ensuring adaptability and applicability for future educational contexts.",
    "abstract_processed": "program emerg crucial educ skill acquisit correl enhanc students’ read write creativ comput problem solv aptitud signific particularli pronounc global landscap transit era character pervas inform technolog integr daili life research endeavor explor potenti util board game code educ specif target student demograph lack access modern technolog educ resourc ethnic group remot popul distanc urban center board game’ efficaci augment program comprehens evalu test feedback solicit student teacher school across chiang rai provinc moreov insight comput scienc educ incorpor refin gameplay enrich knowledg compon ensur adapt applic futur educ context"
  },
  {
    "doc_id": "10480434",
    "abstract_original": "Alzheimer’s disease (AD) is a progressive neurodegenerative disorder that represents a significant and growing public health challenge. This work concisely summarizes AD, encompassing its pathophysiology, risk factors, clinical manifestations, diagnosis, treatment, and ongoing research. The main goal of managing AD is to reduce symptoms while improving the lives of those impacted. This letter has conducted a systematic review to analyze the prediction of AD using the Preferred Reporting Item for Systematic Review and Meta-Analysis (PRISMA) guidelines. The major scientific databases such as Scopus, Web of Science (WoS), and IEEE Xplorer are explored, where 2018–2023 publications are considered. The article selection process is based on keywords like “Alzheimer’s disease,” “Brain Images,” “Deep Learning (DL),” etc. After rigorous analysis, 946 articles were extracted, and 42 were identified for final consideration. Further, several investigations based on the previous work are discussed along with its Proposed Solutions (PS). Finally, a case study on AD detection using the Alzheimer’s Disease Neuroimaging Initiative (ADNI) dataset and AD Detection Network (ADD-NET) implementation is presented.",
    "abstract_processed": "alzheimer’ diseas ad progress neurodegen disord repres signific grow public health challeng work concis summar ad encompass pathophysiolog risk factor clinic manifest diagnosi treatment ongo research main goal manag ad reduc symptom improv live impact letter conduct systemat review analyz predict ad use prefer report item systemat review meta analysi prisma guidelin major scientif databas scopu web scienc wo ieee xplorer explor – public consid articl select process base keyword like “alzheimer’ diseas ” “brain imag ” “deep learn dl ” etc rigor analysi articl extract identifi final consider sever investig base previou work discuss along propos solut ps final case studi ad detect use alzheimer’ diseas neuroimag initi adni dataset ad detect network add net implement present"
  },
  {
    "doc_id": "10481204",
    "abstract_original": "Sustainability and circular economy are promoted by the UNSDGs. However, UNEP has suggested localization prior to development, and harmonization, to aggregate impacts across spatial scales and across different taxonomic groups, applicable to all resources, to address emergent crosscutting issues across regions and models. This study posits that based on design thinking, sustainable investing/asset management theory needs to be situated within societal needs, to cater to differentiated needs, diverse capability maturity levels, and different flavours of reuse. Thus, instantiating from the Knowledge-Requirements Engineering frameworks, this study aims to review, simplify and localize sustainable investing concepts. To cater to different scenarios, a Knowledge-Requirements Engineering-Lifecycle Thinking-Innovation Helixes framework is proposed; intertwining expansive framing and UNEP's intrinsic value, pivoting via instrumental values, localized to cultural values, analogical to online shopping drivers, to enhance absorptive/ multiplicative/ relational capacity/capability, transformative innovations, across SDGs. Hopefully, the framework can interconnect/recommend/transform metaverses/ (eco)systems/ ecologies/assets more reflectively, effectively and efficiently.",
    "abstract_processed": "sustain circular economi promot unsdg howev unep suggest local prior develop harmon aggreg impact across spatial scale across differ taxonom group applic resourc address emerg crosscut issu across region model studi posit base design think sustain invest asset manag theori need situat within societ need cater differenti need divers capabl matur level differ flavour reus thu instanti knowledg requir engin framework studi aim review simplifi local sustain invest concept cater differ scenario knowledg requir engin lifecycl think innov helix framework propos intertwin expans frame unep intrins valu pivot via instrument valu local cultur valu analog onlin shop driver enhanc absorpt multipl relat capac capabl transform innov across sdg hope framework interconnect recommend transform metavers eco system ecolog asset reflect effect effici"
  },
  {
    "doc_id": "10482207",
    "abstract_original": "The growing number of phishing attacks is one of the top concerns of cybersecurity researchers. Cryptographic methods are not reliable in stopping phishing attacks because they manipulate the users into thinking it is safe to access a web link. This results in compromise of sensitive information. Recent research has shown how machine learning methods are capable of detecting malicious websites. However, machine learning models can be computationally heavy to produce good accuracy. This paper focuses on reducing the computational cost while maintaining an effective prediction model. The experiment is conducted on a dataset of size (30, 10000), consisting of phishing and benign website links. The Isomap algorithm is implemented to reduce the input dimension while preserving correlation. Subsequently, a neural network is employed, utilizing simple activation and optimization functions to ensure efficient and rapid prediction. The model achieves an accuracy of 87% under 30 training epochs.",
    "abstract_processed": "grow number phish attack one top concern cybersecur research cryptograph method reliabl stop phish attack manipul user think safe access web link result compromis sensit inform recent research shown machin learn method capabl detect malici websit howev machin learn model comput heavi produc good accuraci paper focus reduc comput cost maintain effect predict model experi conduct dataset size consist phish benign websit link isomap algorithm implement reduc input dimens preserv correl subsequ neural network employ util simpl activ optim function ensur effici rapid predict model achiev accuraci train epoch"
  },
  {
    "doc_id": "10484055",
    "abstract_original": "Causal and temporal reasoning about video dynamics is a challenging problem. While neuro-symbolic models that combine symbolic reasoning with neural-based perception and prediction have shown promise, they exhibit limitations, especially in answering counterfactual questions. This paper introduces a method to enhance a neuro-symbolic model for counterfactual reasoning, leveraging symbolic reasoning about causal relations among events. We define the notion of a causal graph to represent such relations and use Answer Set Programming (ASP), a declarative logic programming method, to find how to coordinate perception and simulation modules. We validate the effectiveness of our approach on two benchmarks, CLEVRER and CRAFT. Our enhancement achieves state-of-the-art performance on the CLEVRER challenge, significantly outperforming existing models. In the case of the CRAFT benchmark, we leverage a large pre-trained language model, such as GPT-3.5 and GPT-4, as a proxy for a dynamics simulator. Our findings show that this method can further improve its performance on counterfactual questions by providing alternative prompts instructed by symbolic causal reasoning.",
    "abstract_processed": "causal tempor reason video dynam challeng problem neuro symbol model combin symbol reason neural base percept predict shown promis exhibit limit especi answer counterfactu question paper introduc method enhanc neuro symbol model counterfactu reason leverag symbol reason causal relat among event defin notion causal graph repres relat use answer set program asp declar logic program method find coordin percept simul modul valid effect approach two benchmark clevrer craft enhanc achiev state art perform clevrer challeng significantli outperform exist model case craft benchmark leverag larg pre train languag model gpt gpt proxi dynam simul find show method improv perform counterfactu question provid altern prompt instruct symbol causal reason"
  },
  {
    "doc_id": "10484127",
    "abstract_original": "In precision livestock farming, the individual identification of cattle is crucial to inform the decisions made to enhance animal welfare, health, and productivity. In literature, models exist that can read ear tags; however, they are not easily portable to real-world cattle production environments and make predictions mainly on still images. We propose a video-based cattle ear tag reading system, called ReadMyCow, which takes advantage of the temporal characteristics in videos to accurately detect, track, and read cattle ear tags at 25 FPS on edge devices. For each frame in a video, ReadMyCow functions in two steps. 1) Tag detection: a YOLOv5s Object Detection model and NVIDIA Deepstream Tracking Layer detect and track the tags present. 2) Tag reading: the novel WhenToRead module decides whether to read each tag, using a TRBA Scene Text Recognition model, or to use the reading from a previous frame. The system is implemented on an edge device, namely the NVIDIA Jetson AGX Orin or Xavier, making it portable to cattle production environments without external computational resources. To attain real-time speeds, ReadMyCow only reads the detected tag in the current frame if it thinks it will get a better reading when a decision metric is significantly improved in the current frame. Ideally, this means the best reading of a tag is found and stored throughout a tag’s presence in the video, even when the tag becomes occluded or blurry. While testing the system at a real Midwestern dairy farm housing 9,000 cows, 96.1% of printed ear tags were accurately read by the ReadMyCow system, demonstrating its real-world commercial potential. ReadMyCow opens opportunities for informed data-driven decision-making processes on commercial cattle farms.",
    "abstract_processed": "precis livestock farm individu identif cattl crucial inform decis made enhanc anim welfar health product literatur model exist read ear tag howev easili portabl real world cattl product environ make predict mainli still imag propos video base cattl ear tag read system call readmycow take advantag tempor characterist video accur detect track read cattl ear tag fp edg devic frame video readmycow function two step tag detect yolov object detect model nvidia deepstream track layer detect track tag present tag read novel whentoread modul decid whether read tag use trba scene text recognit model use read previou frame system implement edg devic name nvidia jetson agx orin xavier make portabl cattl product environ without extern comput resourc attain real time speed readmycow read detect tag current frame think get better read decis metric significantli improv current frame ideal mean best read tag found store throughout tag’ presenc video even tag becom occlud blurri test system real midwestern dairi farm hous cow print ear tag accur read readmycow system demonstr real world commerci potenti readmycow open opportun inform data driven decis make process commerci cattl farm"
  },
  {
    "doc_id": "10484173",
    "abstract_original": "In traditional teaching models, the role of teachers is relatively singular. Teachers are the controllers of the classroom, and students spend less than 10% of their time speaking English besides being asked to answer questions. Therefore, it is difficult for teachers to become promoters, facilitators, or coordinators of students' learning. Therefore, this article conducts research on the intelligent new mode design through the organic integration of computer networks and EL T (English Language Teaching) courses. When designing teaching activities, we should pursue the mutual promotion between the application of information technology and the transformation of teaching methods. Through the comprehensive application of information technology and various activity methods, information technology can not only support existing teaching methods, but also promote the transformation of teaching methods. Through the analysis of the research results indicating the weekly learning volume of EL T courses, it can be found that only a few students consider it easy, while the majority of students believe that the course volume is large, with an average proportion of up to 52.11 %. It can be seen that students can only engage in effective communication between students and teachers on the basis of self-learning and understanding, and their creative thinking can be effectively improved during the learning process.",
    "abstract_processed": "tradit teach model role teacher rel singular teacher control classroom student spend less time speak english besid ask answer question therefor difficult teacher becom promot facilit coordin student learn therefor articl conduct research intellig new mode design organ integr comput network el english languag teach cours design teach activ pursu mutual promot applic inform technolog transform teach method comprehens applic inform technolog variou activ method inform technolog support exist teach method also promot transform teach method analysi research result indic weekli learn volum el cours found student consid easi major student believ cours volum larg averag proport seen student engag effect commun student teacher basi self learn understand creativ think effect improv learn process"
  },
  {
    "doc_id": "10485136",
    "abstract_original": "Graph learning is becoming increasingly popular due to its superior performance in tackling many grand challenges. While quantization is widely used to accelerate Graph Neural Network (GNN) computation, quantized training faces remarkable roadblocks. Current quantized GNN training systems often experience longer training time than their full-precision counterparts for two reasons: (i) addressing the quantization accuracy challenge leads to excessive overhead, and (ii) the optimization potential exposed by quanti-zation is not adequately leveraged. This paper introduces Tango which re-thinks quantization challenges and opportunities for graph neural network training on GPUs with three contributions: Firstly, we introduce efficient rules to maintain accuracy during quantized GNN training. Secondly, we design and implement quantization-aware primitives and inter-primitive optimizations to speed up GNN training. Finally, we integrate Tango with the popular Deep Graph Library (DGL) system and demonstrate its superior performance over the state-of-the-art approaches on various GNN models and datasets.",
    "abstract_processed": "graph learn becom increasingli popular due superior perform tackl mani grand challeng quantiz wide use acceler graph neural network gnn comput quantiz train face remark roadblock current quantiz gnn train system often experi longer train time full precis counterpart two reason address quantiz accuraci challeng lead excess overhead ii optim potenti expos quanti zation adequ leverag paper introduc tango think quantiz challeng opportun graph neural network train gpu three contribut firstli introduc effici rule maintain accuraci quantiz gnn train secondli design implement quantiz awar primit inter primit optim speed gnn train final integr tango popular deep graph librari dgl system demonstr superior perform state art approach variou gnn model dataset"
  },
  {
    "doc_id": "10485664",
    "abstract_original": "This paper establishes an effective early-warning system framework of corporate financial risk. This paper discusses the early-warning model of financial risk. On this basis, Bayes-SVM algorithm is applied to the classification of financial crisis events. We timely detect and alarm the abnormal situation in the company's financial system. Finally, an example is given to prove that the proposed algorithm is correct. This model provides a new way of thinking for the early warning and prevention of enterprise financial risk.",
    "abstract_processed": "paper establish effect earli warn system framework corpor financi risk paper discuss earli warn model financi risk basi bay svm algorithm appli classif financi crisi event time detect alarm abnorm situat compani financi system final exampl given prove propos algorithm correct model provid new way think earli warn prevent enterpris financi risk"
  },
  {
    "doc_id": "10485933",
    "abstract_original": "Electroencephalogram (EEG) is a key resource for the study of brain function, and the interaction between computer and machine through EEG has become a new computer interaction mode. This project intends to study the EEG - computer interaction model based on facial expression. A neural cluster model based on neural network was used to model the mechanism of facial emotions-induced EEG. The EEG activity induced by facial emotion and its spectral characteristics were obtained. In order to improve the recognition accuracy of emotion-driven EEG, the analysis and recognition algorithm of EEG stimulated by expression is studied by combining wavelet with ANN model. The simulation results show that the correct rate of EEG recognition based on neural network is 88.69%. The recognition accuracy of BP neural network is 76.3%, and its convergence speed is also improved. The experimental results show that this method is an effective method for EEG recognition.",
    "abstract_processed": "electroencephalogram eeg key resourc studi brain function interact comput machin eeg becom new comput interact mode project intend studi eeg comput interact model base facial express neural cluster model base neural network use model mechan facial emot induc eeg eeg activ induc facial emot spectral characterist obtain order improv recognit accuraci emot driven eeg analysi recognit algorithm eeg stimul express studi combin wavelet ann model simul result show correct rate eeg recognit base neural network recognit accuraci bp neural network converg speed also improv experiment result show method effect method eeg recognit"
  },
  {
    "doc_id": "10487240",
    "abstract_original": "This paper describes a collaborative project that was conducted to promote Computer Science (CS) and Computational Thinking (CT) Education among pre-service and in-service teachers as well as Teacher Preparation Faculty. More than 40 pre-service and in-service teachers and 9 Education faculty members from three schools participated in a learning experience designed to address the K-12 Computer Science Framework [1] and Maryland's K-12 Computer Science Standards. The collaboration was designed to develop CS/CT knowledge, understanding, skills and application among participants. In phase one of the project, pre-service and in-service teachers explored CS educational hard/software platforms and used open-source sites such as Sphero Edu, Wonder Workshop, Scratch and Code.org. They envisioned how activities apply to K-8 classrooms, and they worked collaboratively to design a problem-based project for their own students. In phase two of the project, teacher preparation faculty were trained to integrate CS and CT into several preservice courses as well as build into the coursework sequence meaningful experiences that would expose future teachers to CS and CT knowledge and skills so that they could then incorporate these into their own K-8 lesson plans. Project evaluation included formative and summative assessments to examine changes in content and pedagogical knowledge. The feedback from the participants shows positive results.",
    "abstract_processed": "paper describ collabor project conduct promot comput scienc cs comput think ct educ among pre servic servic teacher well teacher prepar faculti pre servic servic teacher educ faculti member three school particip learn experi design address k comput scienc framework maryland k comput scienc standard collabor design develop cs ct knowledg understand skill applic among particip phase one project pre servic servic teacher explor cs educ hard softwar platform use open sourc site sphero edu wonder workshop scratch code org envis activ appli k classroom work collabor design problem base project student phase two project teacher prepar faculti train integr cs ct sever preservic cours well build coursework sequenc meaning experi would expos futur teacher cs ct knowledg skill could incorpor k lesson plan project evalu includ form summ assess examin chang content pedagog knowledg feedback particip show posit result"
  },
  {
    "doc_id": "10487429",
    "abstract_original": "Interpreting subjectively what makes a person persuasive in online videos is a complex and dynamic process that requires critical thinking and active engagement from the part of the observer. With the rapid expansion of online communication through social networking websites, more persuasive content is made available online in the form of video. The use of positive and/or negative opinions might affect how persuasive someone appears to be. Persuasiveness is at the core of everyday human-human interactions, such as defending a client in a court, seeking a patient's compliance with medical advice or convincing a customer to buy a product. This study is motivated by the argument that persuasive behavior changes with opinion polarity and whether a speaker is trying to persuade one in favor of or against something. Emotion plays a key role in persuasion both in verbal and non-verbal communication, therefore understanding the impact of opinion polarity (sentiment) on the persuasive messages becomes increasingly important. The study aims to explain the” emotion” behind the message as expressed in negative and positive opinions both persuasive and unpersuasive videos. The data used for the analysis is derived from Persuasive Opinion Multimedia (POM) dataset which is an online multimodal dataset with existing labels for persuasive and non-persuasive videos placed in two sentiment or opinion polarities (positive and negative). This research paper also introduced a new neuromarketing assessment method called NeuroMap's NeuroScoring tool, previously designed to evaluate persuasive messages through a neuromarketing perspective. The present study results align with the NeuroMap model's emphasis on the role of emotions in persuasion. The persuasion model suggests that emotions directly impact how people process and memorize information and how persuasive messages that evoke positive emotions are more likely to be effective. In the study, sentiment levels can be seen as indicators of emotional content conveyed in the video messages, and the positive relationship between sentiment levels and persuasiveness supports the view that emotional appeal plays a crucial role in influencing persuasion.",
    "abstract_processed": "interpret subject make person persuas onlin video complex dynam process requir critic think activ engag part observ rapid expans onlin commun social network websit persuas content made avail onlin form video use posit neg opinion might affect persuas someon appear persuas core everyday human human interact defend client court seek patient complianc medic advic convinc custom buy product studi motiv argument persuas behavior chang opinion polar whether speaker tri persuad one favor someth emot play key role persuas verbal non verbal commun therefor understand impact opinion polar sentiment persuas messag becom increasingli import studi aim explain the” emotion” behind messag express neg posit opinion persuas unpersuas video data use analysi deriv persuas opinion multimedia pom dataset onlin multimod dataset exist label persuas non persuas video place two sentiment opinion polar posit neg research paper also introduc new neuromarket assess method call neuromap neuroscor tool previous design evalu persuas messag neuromarket perspect present studi result align neuromap model emphasi role emot persuas persuas model suggest emot directli impact peopl process memor inform persuas messag evok posit emot like effect studi sentiment level seen indic emot content convey video messag posit relationship sentiment level persuas support view emot appeal play crucial role influenc persuas"
  },
  {
    "doc_id": "10487449",
    "abstract_original": "This article introduces an exploratory method for automatically grading programming exam questions using syntactic analysis. The target problem is the lack of a robust, scalable, and automated method to analyze computational thinking skills from source code written by elementary school students. The proposed method uses a variety of techniques to assess student responses, including analyzing the programming structure, programming correctness, and code execution based on certain parameters defined during the exercise specification. Analysis of the source code and evaluation of the answers to the exercises are carried out using high performance computing to improve the response time of the system. This preliminary work will contribute to a robust method for automated exam scoring, which is expected to assess and support the development of computational thinking among students.",
    "abstract_processed": "articl introduc exploratori method automat grade program exam question use syntact analysi target problem lack robust scalabl autom method analyz comput think skill sourc code written elementari school student propos method use varieti techniqu assess student respons includ analyz program structur program correct code execut base certain paramet defin exercis specif analysi sourc code evalu answer exercis carri use high perform comput improv respons time system preliminari work contribut robust method autom exam score expect assess support develop comput think among student"
  },
  {
    "doc_id": "10488238",
    "abstract_original": "This paper presents GraphLearner a neuromorphic sequence generator with similarities to Markov Chain Models. GraphLearner is proposed as an alternative to ‘black box’ deep neural network models which lack explainability and adaptability. Bloom Filters are used to simplify otherwise computationally expensive Markov chain probability calculations. It is demonstrated with Natural Language Processing tasks, generating sentences of remarkable quality.",
    "abstract_processed": "paper present graphlearn neuromorph sequenc gener similar markov chain model graphlearn propos altern ‘black box’ deep neural network model lack explain adapt bloom filter use simplifi otherwis comput expens markov chain probabl calcul demonstr natur languag process task gener sentenc remark qualiti"
  },
  {
    "doc_id": "10488363",
    "abstract_original": "This paper minimizes fake news, which has been a hot topic recently, using blockchain and artificial intelligence technology, and verifies it with blockchain. Also, using Artificial Intelligence technology, we want to create an algorithm that predicts how fake news will spread in the future. You can see various attempts at a news media platform based on Blockchain technology. However, the Blockchain news media platform is still not getting the market response we expected. It is questionable whether the reason is simply because it is a new technology, so it takes a long time to gain trust from consumers, whether consumers are not yet expecting an innovative news media platform, or whether the explosive growth of the Blockchain news media platform is difficult for other reasons. Research to answer this or direct research between Blockchain and media platforms is still lacking. In addition, the method of verifying fake news using artificial intelligence was verified, ANN, CBR, and MDA were changed, and the experiment was verified for progress. In addition, the use of 5-fold cross-validation as a comparative method was added as described above to more closely examine the possibility of its usefulness even in general situations. Also, through various fields of artificial intelligence and blockchain, verification work was done with blockchain, and fake news prediction was made using artificial intelligence. Various experiments were conducted and performance tests were performed, while the performance of about 5,000 TTPS was recorded through the third experiment. In the future, we think it is necessary to combine Artificial Intelligence and blockchain technology.",
    "abstract_processed": "paper minim fake news hot topic recent use blockchain artifici intellig technolog verifi blockchain also use artifici intellig technolog want creat algorithm predict fake news spread futur see variou attempt news media platform base blockchain technolog howev blockchain news media platform still get market respons expect question whether reason simpli new technolog take long time gain trust consum whether consum yet expect innov news media platform whether explos growth blockchain news media platform difficult reason research answer direct research blockchain media platform still lack addit method verifi fake news use artifici intellig verifi ann cbr mda chang experi verifi progress addit use fold cross valid compar method ad describ close examin possibl use even gener situat also variou field artifici intellig blockchain verif work done blockchain fake news predict made use artifici intellig variou experi conduct perform test perform perform ttp record third experi futur think necessari combin artifici intellig blockchain technolog"
  },
  {
    "doc_id": "10488629",
    "abstract_original": "Intelligence is a multifaceted concept that is generally defined as the ability of comprehending the environment, reasoning, planning, thinking, and learning. The Intelligence Quotient (IQ) is a well-known measure of cognitive abilities associated with intelligence. Recent neuroimaging studies have shown that brain structure and function are related to IQ, which varies from person to person. In this study, we investigated the potential of neuronal effective (directional) connectivity, computed using regression Dynamic Causal Modeling (rDCM) applied to resting-state fMRI data from 100 unrelated subjects in the HCP database, as a source of information for IQ estimation. We used permutation t-test and step-wise wrapper methods to select 24 significant features derived from directional connectivity and applied machine learning algorithms of Support Vector Regression (SVR) and Multi-Layer Perceptron (MLP) with 7-fold cross-validation to predict IQ. The results showed a reasonable IQ estimate, with a mean absolute error (MAE) of about 2 points and a prediction determination coefficient (R2) of about 70 percent. Our findings suggest that neuronal effective connectivity may provide valuable information for IQ estimation and support further investigation into its potential as a biomarker for intelligence.",
    "abstract_processed": "intellig multifacet concept gener defin abil comprehend environ reason plan think learn intellig quotient iq well known measur cognit abil associ intellig recent neuroimag studi shown brain structur function relat iq vari person person studi investig potenti neuron effect direct connect comput use regress dynam causal model rdcm appli rest state fmri data unrel subject hcp databas sourc inform iq estim use permut test step wise wrapper method select signific featur deriv direct connect appli machin learn algorithm support vector regress svr multi layer perceptron mlp fold cross valid predict iq result show reason iq estim mean absolut error mae point predict determin coeffici r percent find suggest neuron effect connect may provid valuabl inform iq estim support investig potenti biomark intellig"
  },
  {
    "doc_id": "10489623",
    "abstract_original": "In order to analyze Electrocardiograms (ECGs) in real time, this research is the first to integrate Recurrent Neural Networks (RNNs) into a cloud-based healthcare system. By utilizing sophisticated computational algorithms and an interpretivist perspective, the research seeks to transform cardiac diagnosis. Though extremely useful, traditional ECG analysis techniques have processing speed as well as scalability issues. The suggested method instantaneously interprets ECG waveforms by utilizing RNNs' temporal modeling capabilities. This paradigm change makes it possible to identify cardiac problems in a timely manner, potentially improving patient outcomes. Setting up a scalable cloud system for effective data processing is part of the study methodology. The RNN model is trained, verified, and then incorporated into the cloud system using secondary ECG data. The system's efficacy is confirmed by performance evaluation criteria like processing speed, sensitivity, and accuracy. Scalability, safety of data, and interpretability issues in models are highlighted via critical analysis. Techniques for improved model openness, strict data protection policies, and thorough scalability testing are all included in the recommendations.",
    "abstract_processed": "order analyz electrocardiogram ecg real time research first integr recurr neural network rnn cloud base healthcar system util sophist comput algorithm interpretivist perspect research seek transform cardiac diagnosi though extrem use tradit ecg analysi techniqu process speed well scalabl issu suggest method instantan interpret ecg waveform util rnn tempor model capabl paradigm chang make possibl identifi cardiac problem time manner potenti improv patient outcom set scalabl cloud system effect data process part studi methodolog rnn model train verifi incorpor cloud system use secondari ecg data system efficaci confirm perform evalu criteria like process speed sensit accuraci scalabl safeti data interpret issu model highlight via critic analysi techniqu improv model open strict data protect polici thorough scalabl test includ recommend"
  },
  {
    "doc_id": "10491869",
    "abstract_original": "This work aims to explore the innovative fusion of image style transfer technology and pattern derivative design, and seek new avenues for the integration of Artificial Intelligence (AI) technology with China's intangible cultural heritage. The batch processing and high efficiency characteristics of AI technology are adopted and derivative design is taken as a medium to effectively disseminate black copper patterns infused with silver. Generative Adversarial Network (GAN) models from deep learning are employed and tuned with appropriate parameters. The deep learning framework realizes the generation of black copper patterns infused with silver. Furthermore, by incorporating image style transfer algorithms, novel pattern aesthetics are designed while preserving the distinctive features of black copper patterns infused with silver. Expert assessments through questionnaire responses reveal that the average rating for the visual aesthetics of the images is 4 points, with a high score of 4.08 for style simulation effectiveness, and a presentation rating of 3.67 for Yunnan's cultural connotation. Expert reviews show approval for the migration results in the experiment, as the transferred pattern designs satisfy aesthetic preferences and meet the standards for simulating different styles. This work provides valuable insights for the preservation and inheritance of black copper patterns infused with silver, as well as for promoting their diversified applications.",
    "abstract_processed": "work aim explor innov fusion imag style transfer technolog pattern deriv design seek new avenu integr artifici intellig ai technolog china intang cultur heritag batch process high effici characterist ai technolog adopt deriv design taken medium effect dissemin black copper pattern infus silver gener adversari network gan model deep learn employ tune appropri paramet deep learn framework realiz gener black copper pattern infus silver furthermor incorpor imag style transfer algorithm novel pattern aesthet design preserv distinct featur black copper pattern infus silver expert assess questionnair respons reveal averag rate visual aesthet imag point high score style simul effect present rate yunnan cultur connot expert review show approv migrat result experi transfer pattern design satisfi aesthet prefer meet standard simul differ style work provid valuabl insight preserv inherit black copper pattern infus silver well promot diversifi applic"
  },
  {
    "doc_id": "10494256",
    "abstract_original": "In the context of digitalization, employing the dual-diamond model design thinking, we dissect the design of smart tourism systems to enhance user-centric experiences. Firstly, through a literature review, we delve into the concept and design process of the dual-diamond model while exploring the feasibility of digital technologies. Subsequently, harnessing the characteristics of the dual-diamond design thinking, we embark on the entire design process. During the exploration phase, we gather firsthand user pain points through user interviews, complemented by secondary data from the internet. This aids in constructing user journey maps and user models, defining user segments, and identifying design opportunities. Following this, we proceed with the functional reconstruction and interface prototyping of the smart tourism application, with a focus on features such as automated travel guides, visualized travel itineraries, panoramic guides, personalized travel companion searches, and intelligent user interactions. Conducting empirical design validation, we observed a high level of user satisfaction. Consequently, iterative design improvements were made, serving as a reference for future smart travel service promotion and development, thus advancing the growth of personalized tourism.",
    "abstract_processed": "context digit employ dual diamond model design think dissect design smart tourism system enhanc user centric experi firstli literatur review delv concept design process dual diamond model explor feasibl digit technolog subsequ har characterist dual diamond design think embark entir design process explor phase gather firsthand user pain point user interview complement secondari data internet aid construct user journey map user model defin user segment identifi design opportun follow proceed function reconstruct interfac prototyp smart tourism applic focu featur autom travel guid visual travel itinerari panoram guid person travel companion search intellig user interact conduct empir design valid observ high level user satisfact consequ iter design improv made serv refer futur smart travel servic promot develop thu advanc growth person tourism"
  },
  {
    "doc_id": "10494259",
    "abstract_original": "CAM mechanism is widely used in engineering, it can realize the arbitrary and complex motion curve of the follower [1]. The typical design method of CAM pitch curve is based on the principle of inversion [2], [3]. In the process of designing CAM, the author uses creative thinking [4] to raise the question whether the design steps based on the inversion principle can be applied \"in reverse\". Based on this problem, the author takes the plate CAM mechanism with translating knife-edge follower as an example and verifies the design results of CAM pitch curve through two different motion curves. The results show that the inverse application on the principle of the inversion method does not change the CAM pitch curve.",
    "abstract_processed": "cam mechan wide use engin realiz arbitrari complex motion curv follow typic design method cam pitch curv base principl invers process design cam author use creativ think rais question whether design step base invers principl appli revers base problem author take plate cam mechan translat knife edg follow exampl verifi design result cam pitch curv two differ motion curv result show invers applic principl invers method chang cam pitch curv"
  },
  {
    "doc_id": "10494260",
    "abstract_original": "Generative AI faces many challenges when entering the product design workflow, such as interface usability and interaction patterns. Therefore, based on design thinking and design process, we developed the DesignGPT multi-agent collaboration framework, which uses artificial intelligence agents to simulate the roles of different positions in the design company and allows human designers to collaborate with them in natural language. Experimental results show that compared with separate AI tools, DesignGPT improves the performance of designers, highlighting the potential of applying multi-agent systems that integrate design domain knowledge to product scheme design.",
    "abstract_processed": "gener ai face mani challeng enter product design workflow interfac usabl interact pattern therefor base design think design process develop designgpt multi agent collabor framework use artifici intellig agent simul role differ posit design compani allow human design collabor natur languag experiment result show compar separ ai tool designgpt improv perform design highlight potenti appli multi agent system integr design domain knowledg product scheme design"
  },
  {
    "doc_id": "10494274",
    "abstract_original": "With the rapid development of artificial intelligence technology, its functions have become increasingly powerful. Large Language Models such as ChatGPT have solved various tasks such as text creation and code debugging, and the impact in the field of education has caused close attention from many scholars. Therefore, by establishing an extended TAM, we conducted a questionnaire survey on 470 college students to explore their acceptance of using ChatGPT as an auxiliary learning tool. Structural equation modeling (SEM) was used to analyze the data. The results showed that trust, facilitating conditions, perceived usefulness, and perceived ease of use have a positive impact on college students' use intention of ChatGPT. Hence, by improving the credibility of generated content and providing appropriate auxiliary resources will help promote students' acceptance of ChatGPT. The research results provide suggestions and directions for future design.",
    "abstract_processed": "rapid develop artifici intellig technolog function becom increasingli power larg languag model chatgpt solv variou task text creation code debug impact field educ caus close attent mani scholar therefor establish extend tam conduct questionnair survey colleg student explor accept use chatgpt auxiliari learn tool structur equat model sem use analyz data result show trust facilit condit perceiv use perceiv eas use posit impact colleg student use intent chatgpt henc improv credibl gener content provid appropri auxiliari resourc help promot student accept chatgpt research result provid suggest direct futur design"
  },
  {
    "doc_id": "10494286",
    "abstract_original": "With the booming development of the photovoltaic (PV) industry, the cleaning of PV panels has become increasingly crucial. This study, framed under the double diamond model, utilized the large language model (LLM) GPT-4 to assist in designing a PV cleaning robot. Initially, the study involved in-depth market analysis and field investigations to identify consumer needs and design requirements. Subsequently, the Kano model was applied to effectively categorize and assess consumer needs, successfully pinpointing key design directions. GPT-4 proposed numerous innovative design ideas. We created the selected prototypes to test and chose the most promising one ultimately. The results indicate that the overall performance of the scheme met expectations, demonstrating the potential of LLMs in complex product design.",
    "abstract_processed": "boom develop photovolta pv industri clean pv panel becom increasingli crucial studi frame doubl diamond model util larg languag model llm gpt assist design pv clean robot initi studi involv depth market analysi field investig identifi consum need design requir subsequ kano model appli effect categor assess consum need success pinpoint key design direct gpt propos numer innov design idea creat select prototyp test chose promis one ultim result indic overal perform scheme met expect demonstr potenti llm complex product design"
  },
  {
    "doc_id": "10494302",
    "abstract_original": "In design, good ideas are the source of a designer’s creativity. With the development of artificial intelligence, large language models (LLMs) represented by ChatGPT shows excellent conversational and creative reasoning capabilities. However, we still know very little about the design ideation process and its performance in terms of productivity. In this paper, we propose a representation of the design ideation process based on NLP. On this basis, referring to LASSO and linkography method, we propose a DCLASSO model to calculate the interconnections between design moves in protocol analysis. In the subsequent experiment, we take the design protocols generated by ChatGPT as the experimental sample to verify the proposed model. Finally, with the generated linkographs, the characteristics of ChatGPT and human designers are analyzed and compared from aspects of design ideation process and design productivity.",
    "abstract_processed": "design good idea sourc designer’ creativ develop artifici intellig larg languag model llm repres chatgpt show excel convers creativ reason capabl howev still know littl design ideat process perform term product paper propos represent design ideat process base nlp basi refer lasso linkographi method propos dclasso model calcul interconnect design move protocol analysi subsequ experi take design protocol gener chatgpt experiment sampl verifi propos model final gener linkograph characterist chatgpt human design analyz compar aspect design ideat process design product"
  },
  {
    "doc_id": "10496041",
    "abstract_original": "In research aimed at determining the level of interest of high school students in enrolling in colleges, predictive analysis models and comparisons are rarely applied during the classification and processing of various data. All of this leads to significant fluctuations in college admissions, where certain schools are unable to admit a large number of students who show interest in a specific field. On the other hand, high school students lose interest in certain schools, leading to the discontinuation of specific directions essential for today's job market needs. Institutions largely fail to conduct a comparison and linkage of teaching and non-teaching activities when analyzing the talents and interests of high school students from different fields. The goal of this paper is to use programming language classifiers to predict student enrollments in colleges based on the results students demonstrate during regular attendance in high schools through participation in innovation fairs.",
    "abstract_processed": "research aim determin level interest high school student enrol colleg predict analysi model comparison rare appli classif process variou data lead signific fluctuat colleg admiss certain school unabl admit larg number student show interest specif field hand high school student lose interest certain school lead discontinu specif direct essenti today job market need institut larg fail conduct comparison linkag teach non teach activ analyz talent interest high school student differ field goal paper use program languag classifi predict student enrol colleg base result student demonstr regular attend high school particip innov fair"
  },
  {
    "doc_id": "10496935",
    "abstract_original": "Computational thinking (CT) assessment indicator assignment is an important strategy for optimizing assessment and an effective method for exploring differences in the importance of assessment indicators. However, the objectivity of the previous methods for assigning assessment indicators of CT is insufficient. Therefore, the paper proposed to use the XGBoost machine learning model to fit the assessment data, fully explore the data features and realize the weighting of CT assessment indicators. The CT assessment indicators are used as the features of XGBoost model training and the assessment levels are used as the training labels to obtain the feature weights through XGBoost model training. The feature weights are used as the CT assessment indicator weights to realize the weighting of assessment indicators of CT in reverse. From the analysis of the CT assessment indicator assignment results, the analysis of the importance of the assessment indicators and the comparative analysis of the assessment results before and after the indicator assignment, it is found that the CT assessment after the indicator assignment has higher robustness and credibility.",
    "abstract_processed": "comput think ct assess indic assign import strategi optim assess effect method explor differ import assess indic howev object previou method assign assess indic ct insuffici therefor paper propos use xgboost machin learn model fit assess data fulli explor data featur realiz weight ct assess indic ct assess indic use featur xgboost model train assess level use train label obtain featur weight xgboost model train featur weight use ct assess indic weight realiz weight assess indic ct revers analysi ct assess indic assign result analysi import assess indic compar analysi assess result indic assign found ct assess indic assign higher robust credibl"
  },
  {
    "doc_id": "10496944",
    "abstract_original": "Computational thinking assessment is an important part of testing the effectiveness of computational thinking cultivation. However, the existing computational thinking assessments still suffer from the problem of insufficient examination of non-cognitive factors, leading to the lack of validity of its assessment results. Since the iceberg model can comprehensively and deeply explore individual characteristics, this paper draws on the division idea of the model and divides computational thinking into explicit computational thinking the basic knowledge required to solve problems using computational thinking and implicit computational thinking the internal psychological characteristics of individuals in the process of using computational thinking. A comprehensive assessment framework of computational thinking is constructed, which contains five dimensions: knowledge and skills, self-efficacy, internet attitude, learning motivation, and thinking style. Finally, its application in the hierarchical teaching of computational thinking and suggestions for personalized teaching programs are given in order to promote the development of personalized education in computational thinking.",
    "abstract_processed": "comput think assess import part test effect comput think cultiv howev exist comput think assess still suffer problem insuffici examin non cognit factor lead lack valid assess result sinc iceberg model comprehens deepli explor individu characterist paper draw divis idea model divid comput think explicit comput think basic knowledg requir solv problem use comput think implicit comput think intern psycholog characterist individu process use comput think comprehens assess framework comput think construct contain five dimens knowledg skill self efficaci internet attitud learn motiv think style final applic hierarch teach comput think suggest person teach program given order promot develop person educ comput think"
  },
  {
    "doc_id": "10496968",
    "abstract_original": "To better understand the impact of students' personality on their computational thinking (CT), this paper develops a CT evaluation tool for college students. Correlation analysis is used to explore the relationship between students' computational thinking skills (CTS) and their five personality traits: extraversion, agreeableness, conscientiousness, neuroticism, and openness. 219 college students completed the CT Assessment Test and the Big Five Personality Inventory. The results showed that there were statistically significant correlations between CTS and extraversion, conscientiousness, and openness, among which openness had the greatest impact on CTS, and extraversion and conscientiousness had moderate effects on CTS. These results are consistent with the conclusions of most related literatures, confirming the existence of non-cognitive influencing factors of CT. Based on these findings, this paper recommends that teachers can pay attention to the individual differences of students from the perspective of personality, and provide them with suitable education to comprehensively improve students' CTS.",
    "abstract_processed": "better understand impact student person comput think ct paper develop ct evalu tool colleg student correl analysi use explor relationship student comput think skill ct five person trait extravers agreeabl conscienti neurotic open colleg student complet ct assess test big five person inventori result show statist signific correl ct extravers conscienti open among open greatest impact ct extravers conscienti moder effect ct result consist conclus relat literatur confirm exist non cognit influenc factor ct base find paper recommend teacher pay attent individu differ student perspect person provid suitabl educ comprehens improv student ct"
  },
  {
    "doc_id": "10496983",
    "abstract_original": "Recently, metaverse have been used in education to improve learners' interest and engagement. In particular, there have been studied various educational models such as theory, practice, and project classes in SW education programs. In this study, we aim to verify whether the SW education program has a significant effect on computational thinking and communication skills by using the communication-centered model (C-UMC), which centers on ‘communication’ as one of the characteristics of the metaverse. The SW education program applied in this study targets 23 high school students and is conducted for 16 sessions (2 hours × 8 sessions). This study is an ongoing research, and we presented the design process for conducting the study, as well as the current classroom process and preliminary results. For further study, we will perform an effectiveness analysis on whether there was a significant difference in learners' computational thinking and communication skills.",
    "abstract_processed": "recent metavers use educ improv learner interest engag particular studi variou educ model theori practic project class sw educ program studi aim verifi whether sw educ program signific effect comput think commun skill use commun center model c umc center ‘communication’ one characterist metavers sw educ program appli studi target high school student conduct session hour × session studi ongo research present design process conduct studi well current classroom process preliminari result studi perform effect analysi whether signific differ learner comput think commun skill"
  },
  {
    "doc_id": "10499013",
    "abstract_original": "With many gaps and shortcomings in the field of IoT security, no matter how simple you think it is on your side what goes inside an intrusion detection system technique to detect attacks. This study explores the current state of IDS in IoT. The most important points of vulnerability are identified, and we examine ways to address them immediately. One key finding of the research is that interoperability problems between differing IoT devices and platforms loom as two big roadblocks. Besides, the lack of standardized evaluation standards or sets for intrusion detection models in IoT environments turns out to be an important gap between what is being researched currently and reality. The ambiguity of how to upscale in large IoT networks is cited as an issue left unresolved by the study. In addition, it points toward the crucial role intrusion detection plays in safeguarding IoT systems and also reveals existing areas of weakness with regard to adaptability, scalability and standardization..",
    "abstract_processed": "mani gap shortcom field iot secur matter simpl think side goe insid intrus detect system techniqu detect attack studi explor current state id iot import point vulner identifi examin way address immedi one key find research interoper problem differ iot devic platform loom two big roadblock besid lack standard evalu standard set intrus detect model iot environ turn import gap research current realiti ambigu upscal larg iot network cite issu left unresolv studi addit point toward crucial role intrus detect play safeguard iot system also reveal exist area weak regard adapt scalabl standard"
  },
  {
    "doc_id": "10499637",
    "abstract_original": "This study explores the full potential of burst photography, a method that captures brief moments in a flood of pictures. However, the beauty of these frames is typically obscured by undesired blemishes such as occlusions and reflections. We address these restrictions by combining deep convolutional neural networks (DCNNs) and adaptive neural splines, which surpass traditional image fusion and reveal the hidden brilliance inside. Acting like skilled artisans, the adaptive neural splines deftly separate and reweave the image's fabric. Their subtle touch safeguards every strand of visual information, ensuring the final result is a harmonious tapestry of enhanced clarity and preserved detail. This harmonic connection reveals itself in a transforming process that combines many frames into a single, stunning tapestry. Shadows reveal their secrets, the previously opaque depths now shining with clarity. Occlusions and reflections evaporate, leaving just a spotless canvas on which the scene's genuine brightness shines. The result is a symphony of increased clarity, with minute details emerging from darkness and textures dancing with unparalleled sharpness. The power of this invention is not just theoretical. Extensive comparisons to cutting-edge approaches demonstrate its revolutionary influence. Our model outperforms others in retaining fine detail, improving overall clarity, and maintaining visual integrity. These breakthroughs not only push the frontiers of computational photography but also serve as a catalyst for future advances in image processing and analysis. This study shows that creative thinking unleashes the power of visuals. We use deep learning and adaptive splines to turn burst photographs into everlasting masterpieces that uncover hidden brilliance.",
    "abstract_processed": "studi explor full potenti burst photographi method captur brief moment flood pictur howev beauti frame typic obscur undesir blemish occlus reflect address restrict combin deep convolut neural network dcnn adapt neural spline surpass tradit imag fusion reveal hidden brillianc insid act like skill artisan adapt neural spline deftli separ reweav imag fabric subtl touch safeguard everi strand visual inform ensur final result harmoni tapestri enhanc clariti preserv detail harmon connect reveal transform process combin mani frame singl stun tapestri shadow reveal secret previous opaqu depth shine clariti occlus reflect evapor leav spotless canva scene genuin bright shine result symphoni increas clariti minut detail emerg dark textur danc unparallel sharp power invent theoret extens comparison cut edg approach demonstr revolutionari influenc model outperform other retain fine detail improv overal clariti maintain visual integr breakthrough push frontier comput photographi also serv catalyst futur advanc imag process analysi studi show creativ think unleash power visual use deep learn adapt spline turn burst photograph everlast masterpiec uncov hidden brillianc"
  },
  {
    "doc_id": "10500041",
    "abstract_original": "Computational thinking is the systematic approach of defining a problem and crafting its solution. It employs computer programming algorithms to address scientific, engineering, and mathematical challenges using programming languages. Feedback plays a pivotal role in the learning journey of computational thinking. It is widely recognized that offering timely feedback to students on their computational endeavors significantly contributes to their achievement and overall satisfaction with the course. This research explores the implementation of an automated feedback system designed to evaluate and offer early feedback on computer engineering projects. The aim is to integrate best practices and software tools related to computational thinking into the thinking and learning processes within an engineering curriculum. Preliminary findings suggest that the automated feedback system enhances students' computational skills and improves their performance in the course. We anticipate that the insights gained from this research will inform the enhancement of curricula and course evaluations across different computational thinking tasks, disciplines, and courses.",
    "abstract_processed": "comput think systemat approach defin problem craft solut employ comput program algorithm address scientif engin mathemat challeng use program languag feedback play pivot role learn journey comput think wide recogn offer time feedback student comput endeavor significantli contribut achiev overal satisfact cours research explor implement autom feedback system design evalu offer earli feedback comput engin project aim integr best practic softwar tool relat comput think think learn process within engin curriculum preliminari find suggest autom feedback system enhanc student comput skill improv perform cours anticip insight gain research inform enhanc curricula cours evalu across differ comput think task disciplin cours"
  },
  {
    "doc_id": "10500458",
    "abstract_original": "Nurturing programming talent early is crucial in today's digital world, especially in K-12 education, underscored by the rise of programming competitions for younger students. However, with limited research in programming talent search, discovering programming talent in primary schools posed a significant challenge. Traditionally, various test-based talent search tools have been utilized for programming talent identification, including the Computer Talent Search Test (CTST) and the Beginners Computational Thinking Test (BCTt). Game-based platforms like CodeCombat offer an engaging alternative to overcome this challenge. CodeCombat integrates game-based learning with programming education, allowing students to apply their computational thinking skills in an enjoyable context for learning Python. The study revealed a significant correlation between CodeCombat, CTST, and BCTt outcomes. This highlighted that CodeCombat emerged as a valuable platform for talent search, aligning seamlessly with the objectives of the test-based tools and suggesting its effectiveness in boosting programming learning motivation in primary school.",
    "abstract_processed": "nurtur program talent earli crucial today digit world especi k educ underscor rise program competit younger student howev limit research program talent search discov program talent primari school pose signific challeng tradit variou test base talent search tool util program talent identif includ comput talent search test ctst beginn comput think test bctt game base platform like codecombat offer engag altern overcom challeng codecombat integr game base learn program educ allow student appli comput think skill enjoy context learn python studi reveal signific correl codecombat ctst bctt outcom highlight codecombat emerg valuabl platform talent search align seamlessli object test base tool suggest effect boost program learn motiv primari school"
  },
  {
    "doc_id": "10500601",
    "abstract_original": "According to UNESCO, the use of technology in education can enhance the quality of education and increase access to education worldwide. One of the technological devices that has gained popularity in education in recent years is the BBC micro:bit. This device has been used as an educational tool to teach programming and technology to students of all ages. This paper combines a scoping review and bibliometric analysis to map and analyze the literature on the implementation of the BBC micro:bit in primary and secondary education. A total of 274 authors have published 95 documents with an average of 2.88 co-authors per document. The integration of BBC micro:bit in education has allowed for the adoption of various teaching strategies and methodologies, enriching the learning experience of students. Overall, this study provides a better understanding of the literature on the BBC micro:bit and its research landscape in an educational context.",
    "abstract_processed": "accord unesco use technolog educ enhanc qualiti educ increas access educ worldwid one technolog devic gain popular educ recent year bbc micro bit devic use educ tool teach program technolog student age paper combin scope review bibliometr analysi map analyz literatur implement bbc micro bit primari secondari educ total author publish document averag co author per document integr bbc micro bit educ allow adopt variou teach strategi methodolog enrich learn experi student overal studi provid better understand literatur bbc micro bit research landscap educ context"
  },
  {
    "doc_id": "10502542",
    "abstract_original": "Space-time big data, represented by space-space integration, combines GIS, remote sensing, tilt photography, BIM and Internet of things, and is an important driving force for the development of highway information. However, at present, China’s highway design code still adopts two-dimensional drawings as the design and delivery standards. That leads to the lack of the information management technology for large-scale highway construction based on space-time big data. In order to solve the above problems, this paper expounds the technical framework of spatio-temporal big data, which is composed of geographical modeling, geographical design, geographical monitoring and geographical control, and puts forward some key technologies such as geographical information, BIM and tilt photography, etc., the paper also introduces the experience and thinking of the application of road information technology based on BIM in the design and construction of G30 project, the advantages of applying BIM and GIS to the field of highway engineering design and construction in our country are revealed. Compared with the current highway design and construction management methods, the advantages of the proposed method are the whole process of collaborative work and the efficient control of the whole process. This laid a foundation for the further development of highway information technology and application by combining remote sensing, tilt photography and other advanced technologies.",
    "abstract_processed": "space time big data repres space space integr combin gi remot sens tilt photographi bim internet thing import drive forc develop highway inform howev present china’ highway design code still adopt two dimension draw design deliveri standard lead lack inform manag technolog larg scale highway construct base space time big data order solv problem paper expound technic framework spatio tempor big data compos geograph model geograph design geograph monitor geograph control put forward key technolog geograph inform bim tilt photographi etc paper also introduc experi think applic road inform technolog base bim design construct g project advantag appli bim gi field highway engin design construct countri reveal compar current highway design construct manag method advantag propos method whole process collabor work effici control whole process laid foundat develop highway inform technolog applic combin remot sens tilt photographi advanc technolog"
  },
  {
    "doc_id": "10503402",
    "abstract_original": "Machine learning (ML) has developed at a superlative rate, accompanying requests spanning various fields. This research investigates the experience of strength data, exceptionally the request of machine learning (ML) algorithms to a Body Mass Index (BMI) dataset. The basic aim of searching out unwinds the dossier’s many linkages and patterns, eventually chief to more thorough information of the variables deciding BMI. The study starts accompanying an initiation to the subject within reach, understood by a thorough study of appropriate work, a complex mechanics division, and an itemized reason of the reached results. However, because of advances in Machine Learning, we immediately have the talent to handle this issue in a more excellent manner. We’ve built an advance dossier-study system that can think a patient has diabetes, a suggestion of correction, admitting for early mediation. This predicting plan uses dossier analysis methods to extractable intuitions from a big number of diabetes-accompanying facts. Its basic aim is to correctly determine a patient’s risk of diabetes. We’ve working categorization plans to a degree Decision Tree, Artificial Neural Networks (ANN), Naive Bayes, and Support Vector Machine (SVM) algorithms to cultivate the model. These outcomes show the influence of the subsystems in thinking diabetes risk admit a large size of veracity. This predictive finish can create a meaningful dissimilarity in labeling at-risk things early and providing bureaucracy with essential care and counseling before the ailment progresses. In summary, our machine intelligence-located scheme offers a natural still strong solution to call the risk of diabetes in subjects. By controlling the wherewithal of dossier reasoning and categorization algorithms, we can enhance early discovery and deterrent measures for this weighty affliction, eventually reconstructing patient consequences and reducing the burden of BMI-related complications.",
    "abstract_processed": "machin learn ml develop superl rate accompani request span variou field research investig experi strength data except request machin learn ml algorithm bodi mass index bmi dataset basic aim search unwind dossier’ mani linkag pattern eventu chief thorough inform variabl decid bmi studi start accompani initi subject within reach understood thorough studi appropri work complex mechan divis item reason reach result howev advanc machin learn immedi talent handl issu excel manner we’v built advanc dossier studi system think patient diabet suggest correct admit earli mediat predict plan use dossier analysi method extract intuit big number diabet accompani fact basic aim correctli determin patient’ risk diabet we’v work categor plan degre decis tree artifici neural network ann naiv bay support vector machin svm algorithm cultiv model outcom show influenc subsystem think diabet risk admit larg size verac predict finish creat meaning dissimilar label risk thing earli provid bureaucraci essenti care counsel ailment progress summari machin intellig locat scheme offer natur still strong solut call risk diabet subject control wherewith dossier reason categor algorithm enhanc earli discoveri deterr measur weighti afflict eventu reconstruct patient consequ reduc burden bmi relat complic"
  },
  {
    "doc_id": "10503756",
    "abstract_original": "ChatGPT is one of the most advanced research achievements in the field of natural language processing. In order to showcase the research technology and application value of the large language model ChatGPT, this article provides a comprehensive summary of its development history, research status, and key technologies. This paper focuses on key technologies such as large-scale corpus training, support for high computing power, the fundamental model architecture of the Transformer, and reinforcement learning from human feedback. Three types of features are analyzed: the ChatGPT model GPT-4 Turbo, custom ChatGPT, and the multimodal API. In light of the limitations of technology based on current deep neural networks, which rely on big data and extensive computing power, and the presence of illusory performance, several suggestions are being proposed. The revolutionary applications of ChatGPT in the fields of education, search engines, metaverse, and high-tech enterprises are summarized. Finally, the full text is summarized and prospected.",
    "abstract_processed": "chatgpt one advanc research achiev field natur languag process order showcas research technolog applic valu larg languag model chatgpt articl provid comprehens summari develop histori research statu key technolog paper focus key technolog larg scale corpu train support high comput power fundament model architectur transform reinforc learn human feedback three type featur analyz chatgpt model gpt turbo custom chatgpt multimod api light limit technolog base current deep neural network reli big data extens comput power presenc illusori perform sever suggest propos revolutionari applic chatgpt field educ search engin metavers high tech enterpris summar final full text summar prospect"
  },
  {
    "doc_id": "10505460",
    "abstract_original": "With the development of science and technology, the talents of high-quality composite New Engineering Subjects need strong engineering practice ability, innovation ability, and international competitiveness. The college students have not only basic skills in computer operation but also certain programming skills. Those who understand and practice computational thinking will solve various non-universal computing problems encountered in work and study in the contemporary information society. In order to support the teaching objectives and educational concepts of the new engineering discipline, teaching reforms have been carried out in terms of teaching objectives, teaching content, teaching models, teaching resources, and ideological and political education. We cultivate interdisciplinary and professional integration through advanced thinking methods. It integrates knowledge points into practical engineering applications and cultivates students' computational thinking ability. It also improves the practical application and problem-solving abilities of students. In addition, we integrate ideological and political elements into the teaching process. It is a teaching method that combines moral education and professional courses.",
    "abstract_processed": "develop scienc technolog talent high qualiti composit new engin subject need strong engin practic abil innov abil intern competit colleg student basic skill comput oper also certain program skill understand practic comput think solv variou non univers comput problem encount work studi contemporari inform societi order support teach object educ concept new engin disciplin teach reform carri term teach object teach content teach model teach resourc ideolog polit educ cultiv interdisciplinari profession integr advanc think method integr knowledg point practic engin applic cultiv student comput think abil also improv practic applic problem solv abil student addit integr ideolog polit element teach process teach method combin moral educ profession cours"
  },
  {
    "doc_id": "10505486",
    "abstract_original": "Research purpose of the article is to explore new ideas for the reform of university computer basic courses. The proposed method starts with the background of the construction of new liberal arts and the demand for computational thinking and empowerment education. It aims at the current teaching status of college computer basic courses in application-oriented local undergraduate universities, and deeply analyzes the new situation faced by the reform of college computer basic courses. The result is to explore the path and methods of computer basic course reform in liberal arts universities from three aspects: setting course modules, reconstructing teaching content, and reforming teaching methods. The conclusion is a new idea for the reform of computer basic courses in universities.",
    "abstract_processed": "research purpos articl explor new idea reform univers comput basic cours propos method start background construct new liber art demand comput think empower educ aim current teach statu colleg comput basic cours applic orient local undergradu univers deepli analyz new situat face reform colleg comput basic cours result explor path method comput basic cours reform liber art univers three aspect set cours modul reconstruct teach content reform teach method conclus new idea reform comput basic cours univers"
  },
  {
    "doc_id": "10505497",
    "abstract_original": "With the rapid development of computer technology, computational thinking, as one of the core literacy elements of information technology majors, has been widely noticed, and at the same time, it has gradually become one of the core competencies cultivated by education and teaching. This paper uses CiteSpace to visualize and analyze the Chinese core papers related to computational thinking included in CNKI. By studying the current situation of domestic research on computational thinking and related hot keywords, it aims to explore the prospects for the application of computational thinking in secondary education, try to incorporate the educational model of C elements in STEM education, and provide research ideas for the cultivation of computational thinking ability of secondary students.",
    "abstract_processed": "rapid develop comput technolog comput think one core literaci element inform technolog major wide notic time gradual becom one core compet cultiv educ teach paper use citespac visual analyz chines core paper relat comput think includ cnki studi current situat domest research comput think relat hot keyword aim explor prospect applic comput think secondari educ tri incorpor educ model c element stem educ provid research idea cultiv comput think abil secondari student"
  },
  {
    "doc_id": "10506064",
    "abstract_original": "The remarkable achievements of ChatGPT and Generative Pre-trained Transformer 4 (GPT-4) have sparked a wave of interest and research in the field of large language models (LLMs) for artificial general intelligence (AGI). These models provide intelligent solutions that are closer to human thinking, enabling us to use general artificial intelligence (AI) to solve problems in various applications. However, in the field of remote sensing (RS), the scientific literature on the implementation of AGI remains relatively scant. Existing AI-related research in RS focuses primarily on visual-understanding tasks while neglecting the semantic understanding of the objects and their relationships. This is where vision-LMs (VLMs) excel as they enable reasoning about images and their associated textual descriptions, allowing for a deeper understanding of the underlying semantics. VLMs can go beyond visual recognition of RS images and can model semantic relationships as well as generate natural language descriptions of the image. This makes them better suited for tasks that require both visual and textual understanding, such as image captioning and visual question answering (VQA). This article provides a comprehensive review of the research on VLMs in RS, summarizing the latest progress, highlighting current challenges, and identifying potential research opportunities. Specifically, we review the application of VLMs in mainstream RS tasks, including image captioning, text-based image generation, text-based image retrieval (TBIR), VQA, scene classification, semantic segmentation, and object detection. For each task, we analyze representative works and discuss research progress. Finally, we summarize the limitations of existing works and provide possible directions for future development. This review aims to provide a comprehensive overview of the current research progress of VLMs in RS (see Figure 1), and to inspire further research in this exciting and promising field.",
    "abstract_processed": "remark achiev chatgpt gener pre train transform gpt spark wave interest research field larg languag model llm artifici gener intellig agi model provid intellig solut closer human think enabl us use gener artifici intellig ai solv problem variou applic howev field remot sens rs scientif literatur implement agi remain rel scant exist ai relat research rs focus primarili visual understand task neglect semant understand object relationship vision lm vlm excel enabl reason imag associ textual descript allow deeper understand underli semant vlm go beyond visual recognit rs imag model semant relationship well gener natur languag descript imag make better suit task requir visual textual understand imag caption visual question answer vqa articl provid comprehens review research vlm rs summar latest progress highlight current challeng identifi potenti research opportun specif review applic vlm mainstream rs task includ imag caption text base imag gener text base imag retriev tbir vqa scene classif semant segment object detect task analyz repres work discuss research progress final summar limit exist work provid possibl direct futur develop review aim provid comprehens overview current research progress vlm rs see figur inspir research excit promis field"
  },
  {
    "doc_id": "10506466",
    "abstract_original": "The solution of a typical programming task involves algorithmic thinking, pattern recognition, decomposition, and abstraction skills. These skills are basic pillars of Computational thinking (CT) and are essential for a computer programmer. Therefore, a programming teacher needs to take these skills into account for the evaluation of students. Existing methods for improving programming competency don’t consider the Computational Thinking of students and perform grading of students without taking these skills into account. Due to this limitation, deficiencies of these skills in students remain unrevealed, posing difficulties for educators to provide need-oriented feedback. The performance of programming students is thus hindered by a lack of interventions. This study proposes a method to evaluate programming students in terms of CT skill components and group them based on their skill set. In this study, 780 students of object-oriented programming (OOP) class were given programming assignments for assessment of programming competencies. These students were then given small programming tasks requiring different computational thinking skill components for their solutions. A machine learning approach was used to perform grouping of these students based on their scores. Six groups of programming students, each having its own set of skill deficiencies, were identified as a result of clustering. One of the groups had an empty set of skill deficiencies and consisted of students proficient in programming. Each of the other five groups had a non-empty set of skill deficiencies and comprised non-proficient programming students. A group-specific skill development plan was built for the groups having skill deficiencies. It was found that such feedback was very effective and improved the CT skill deficiencies of 82% of students.",
    "abstract_processed": "solut typic program task involv algorithm think pattern recognit decomposit abstract skill skill basic pillar comput think ct essenti comput programm therefor program teacher need take skill account evalu student exist method improv program compet don’t consid comput think student perform grade student without take skill account due limit defici skill student remain unrev pose difficulti educ provid need orient feedback perform program student thu hinder lack intervent studi propos method evalu program student term ct skill compon group base skill set studi student object orient program oop class given program assign assess program compet student given small program task requir differ comput think skill compon solut machin learn approach use perform group student base score six group program student set skill defici identifi result cluster one group empti set skill defici consist student profici program five group non empti set skill defici compris non profici program student group specif skill develop plan built group skill defici found feedback effect improv ct skill defici student"
  },
  {
    "doc_id": "10506479",
    "abstract_original": "The Internet of Things (IoT) is an emerging technology that allow smart devices to communicate through various heterogeneous channels (wired or wireless). However, for conventional networks, it has become a challenging task to efficiently control and manage the data flows of a huge number of devices. Software-defined networking (SDN) is a new way of thinking about networking. Because it is programmable, flexible, agile, and gives you a big picture of the network, it has tried to solve some IoT problems, like scalability, heterogeneity, and complexity. In large-scale SDN-IoT networks, there is a requirement for routing protocols that are both efficient and secure in order to ensure a superior level of quality of service (QoS) and quality of experience (QoE). To address the above stated challenges, a novel deep reinforcement learning (DRL) known as DQQS model is proposed. The aim is to achieve QoS and QoE while also ensuring the security of the SDN-IoT network. The proposed DQQS model dynamically extracts patterns from the past network history by interacting with the underlying network and generating optimized routing policies. This article employs three network metrics—throughput, latency, and the probability of avoiding malicious nodes—to measure the performance of DQQS. Simulations reveal that the proposed framework outperforms four state-of-the-art routing algorithms: OSPF, L-L Routing, Sailfish Routing, and RL-Routing in terms of both throughput and latency. For instance, in an attacked environment, the proposed DQQS model achieved the highest throughput value of 14.5 Mbps, surpassing OSPF at 8 Mbps, L-L at 8.2 Mbps, Sailfish at 9 Mbps, and RL at 9.5 Mbps. Similarly, this model exhibited superior performance in latency, recording the lowest latency value of 52 ms, compared to OSPF 88 ms, L-L 85 ms, Sailfish 72 ms, and RL 75 ms routing algorithms. The experimental results demonstrate that this new DQQS model is a pioneering deep reinforcement learning-based technique that optimally addresses secure routing in the SDN-IoT environment, ensuring enhanced quality of service and experience, and outperforming state-of-the art DL methodologies in both security and network performance metrics.",
    "abstract_processed": "internet thing iot emerg technolog allow smart devic commun variou heterogen channel wire wireless howev convent network becom challeng task effici control manag data flow huge number devic softwar defin network sdn new way think network programm flexibl agil give big pictur network tri solv iot problem like scalabl heterogen complex larg scale sdn iot network requir rout protocol effici secur order ensur superior level qualiti servic qo qualiti experi qoe address state challeng novel deep reinforc learn drl known dqq model propos aim achiev qo qoe also ensur secur sdn iot network propos dqq model dynam extract pattern past network histori interact underli network gener optim rout polici articl employ three network metrics—throughput latenc probabl avoid malici nodes—to measur perform dqq simul reveal propos framework outperform four state art rout algorithm ospf l l rout sailfish rout rl rout term throughput latenc instanc attack environ propos dqq model achiev highest throughput valu mbp surpass ospf mbp l l mbp sailfish mbp rl mbp similarli model exhibit superior perform latenc record lowest latenc valu ms compar ospf ms l l ms sailfish ms rl ms rout algorithm experiment result demonstr new dqq model pioneer deep reinforc learn base techniqu optim address secur rout sdn iot environ ensur enhanc qualiti servic experi outperform state art dl methodolog secur network perform metric"
  },
  {
    "doc_id": "10508043",
    "abstract_original": "Maximum power point tracking (MPPT) is a technique for continuously extracting the largest amount of energy that a source can provide under varying conditions, and it is indispensable for modern photovoltaic (PV) panels. Among several methods to achieve this, fuzzy logic controllers (FLCs) have been a popular choice over the years, incorporating human-like thinking into their design to promote flexibility, robustness, and reliability. In addition, due to its high performance, low power consumption, and high circuit density, a field-programmable gate array (FPGA) may be a suitable choice for implementing these controllers. This study aims to identify the applicability of FPGA-based FLCs for the MPPT of PV panels. A systematic literature review was conducted, focusing on five research questions. The methods proposed in the 14 selected studies were analyzed in terms of their advantages and limitations. Results demonstrate that FLCs are remarkably adequate for MPPT, although they are preferred when used in conjunction with other techniques. By employing FPGAs, fuzzy controllers may achieve significantly faster responses at an overall lower cost. However, this comes with increased complexity and resource usage. The findings highlight the suitability while acknowledging the limitations of FLCs and FPGAs for the MPPT in PV panels. Moreover, some aspects still require further research, such as methods for dealing with partial shading conditions, the analysis of modern techniques not yet explored in FPGAs, and the integration of FPGA-based technologies in large-scale grids.",
    "abstract_processed": "maximum power point track mppt techniqu continu extract largest amount energi sourc provid vari condit indispens modern photovolta pv panel among sever method achiev fuzzi logic control flc popular choic year incorpor human like think design promot flexibl robust reliabl addit due high perform low power consumpt high circuit densiti field programm gate array fpga may suitabl choic implement control studi aim identifi applic fpga base flc mppt pv panel systemat literatur review conduct focus five research question method propos select studi analyz term advantag limit result demonstr flc remark adequ mppt although prefer use conjunct techniqu employ fpga fuzzi control may achiev significantli faster respons overal lower cost howev come increas complex resourc usag find highlight suitabl acknowledg limit flc fpga mppt pv panel moreov aspect still requir research method deal partial shade condit analysi modern techniqu yet explor fpga integr fpga base technolog larg scale grid"
  },
  {
    "doc_id": "10508087",
    "abstract_original": "ChatGPT has received considerable attention in education, particularly in programming education because of its capabilities in automated code generation and program repairing and scoring. However, few empirical studies have investigated the use of ChatGPT to customize a learning system for scaffolding students’ computational thinking. Therefore, this article proposes an intelligent programming scaffolding system using ChatGPT following the theoretical framework of computational thinking and scaffolding. A mixed-method study was conducted to investigate the affordance of the scaffolding system using ChatGPT, and the findings show that most students had positive attitudes about the proposed system, and it was effective in improving their computational thinking generally but not their problem-solving skills. Therefore, more scaffolding strategies are discussed with the aim of improving student computational thinking, especially regarding problem-solving skills. The findings of this study are expected to guide future designs of generative artificial intelligence tools embedded in intelligent learning systems to foster students’ computational thinking and programming learning.",
    "abstract_processed": "chatgpt receiv consider attent educ particularli program educ capabl autom code gener program repair score howev empir studi investig use chatgpt custom learn system scaffold students’ comput think therefor articl propos intellig program scaffold system use chatgpt follow theoret framework comput think scaffold mix method studi conduct investig afford scaffold system use chatgpt find show student posit attitud propos system effect improv comput think gener problem solv skill therefor scaffold strategi discuss aim improv student comput think especi regard problem solv skill find studi expect guid futur design gener artifici intellig tool embed intellig learn system foster students’ comput think program learn"
  },
  {
    "doc_id": "10512888",
    "abstract_original": "Metaheuristics have been employed in solving several optimization and NP-hard problems owing to their ability to avoid local optima entrapment, flexibility and robustness, simplicity, and reasonable computational time. In this work, an empirical analysis is carried out on the application of metaheuristics in solving the protein structure prediction (PSP) problem. The PSP problem entails predicting a three-dimensional (3D) structure of proteins based on the amino acid sequences. This study employs the Ab Initio method, which relies on the thermodynamic properties of the proteins, such as the minimal free energy levels, bond angles, and torsional angles, in determining the protein structure. Five real protein sequences, namely 1CB3, 1BXL, 2H3S, 1TZ4, and 1CRN from the Protein Data Bank (PDB), and 11 metaheuristics including DE, GA, PSO, DSO, ACO, and HS were employed in the empirical analysis. Moreover, extensive Monte Carlo simulations were carried out to generate the results of the empirical analysis and these results were statistically tested using the Friedman test.",
    "abstract_processed": "metaheurist employ solv sever optim np hard problem owe abil avoid local optima entrap flexibl robust simplic reason comput time work empir analysi carri applic metaheurist solv protein structur predict psp problem psp problem entail predict three dimension structur protein base amino acid sequenc studi employ ab initio method reli thermodynam properti protein minim free energi level bond angl torsion angl determin protein structur five real protein sequenc name cb bxl h tz crn protein data bank pdb metaheurist includ de ga pso dso aco hs employ empir analysi moreov extens mont carlo simul carri gener result empir analysi result statist test use friedman test"
  },
  {
    "doc_id": "10513387",
    "abstract_original": "A series of unplugged programming courses based on game activities has been designed and developed to reduce the difficulty of programming courses in elementary school and to develop computational thinking skills in elementary school students. Four components were designed for the course: course objectives, course content, course activities, and course evaluation. A controlled experiment was performed to validate the course's influence on developing learners' computational thinking, and a questionnaire was employed to examine the experimental class learners' experience with the course. The results found that the level of computational thinking in the experimental class was also significantly different from the pretest, and the students in the experimental class rated each item of the course above 7 points. This indicates that this course has a significant effect on cultivating students' computational thinking, and the learners had a good learning experience and made gains from this course.",
    "abstract_processed": "seri unplug program cours base game activ design develop reduc difficulti program cours elementari school develop comput think skill elementari school student four compon design cours cours object cours content cours activ cours evalu control experi perform valid cours influenc develop learner comput think questionnair employ examin experiment class learner experi cours result found level comput think experiment class also significantli differ pretest student experiment class rate item cours point indic cours signific effect cultiv student comput think learner good learn experi made gain cours"
  },
  {
    "doc_id": "10515330",
    "abstract_original": "Repeated loan fraud threatens financial stability and drives away clients. Financial and banking institutions must immediately recognize network fraud. The banking sector in India and other countries is using AI-driven technology and machine learning algorithms to tackle fraud and unauthorized access. Innovative thinking, increased globalization, and technical developments are raising fraud detection costs. The suggested study would help banks identify credit application fraudsters. The study automated data preprocessing using Kaggle's K-Nearest Neighbor (KNN) algorithm. A one-dimensional convolutional neural network classified. Using the Vortex Search Algorithm (VSA) to fine-tune the classifier hyperparameters improved results. VSA determined the model's hyperparameter sweet spot. The suggested model outperforms other categorization methods with 98.62% accuracy. Better lending banking fraud detection may result from the proposed approach. The VSA-based 1DCNN model detects fraud faster and more precisely.",
    "abstract_processed": "repeat loan fraud threaten financi stabil drive away client financi bank institut must immedi recogn network fraud bank sector india countri use ai driven technolog machin learn algorithm tackl fraud unauthor access innov think increas global technic develop rais fraud detect cost suggest studi would help bank identifi credit applic fraudster studi autom data preprocess use kaggl k nearest neighbor knn algorithm one dimension convolut neural network classifi use vortex search algorithm vsa fine tune classifi hyperparamet improv result vsa determin model hyperparamet sweet spot suggest model outperform categor method accuraci better lend bank fraud detect may result propos approach vsa base dcnn model detect fraud faster precis"
  },
  {
    "doc_id": "10515759",
    "abstract_original": "Mobile learning is an inevitable result of technological progress, which is achieved through networks. Compared to traditional learning modes, using mobile phones for learning is not limited by geography or learning forms, and has great freedom in time and space. This is an informal remote teaching based on digitization and mobile computer devices. Autonomous learning breaks through the limitations of traditional learning models and enables learners to better utilize their fragmented time for learning. Based on the above issues, this article discussed how to build a mobile assisted language translation intelligent recommendation system using NPL (Natural Language Processing) technology. Finally, experimental data showed that the system designed in this article had the smallest parameter size but the shortest training time, with values of only 16M and 5.649min/epoch, respectively. This indicated that the language translation system designed in this article had strong advantages, which can reduce the size of model parameters and thus reduce the training time of the model. The experiment verified the superiority of the mobile assisted language translation system based on NPL.",
    "abstract_processed": "mobil learn inevit result technolog progress achiev network compar tradit learn mode use mobil phone learn limit geographi learn form great freedom time space inform remot teach base digit mobil comput devic autonom learn break limit tradit learn model enabl learner better util fragment time learn base issu articl discuss build mobil assist languag translat intellig recommend system use npl natur languag process technolog final experiment data show system design articl smallest paramet size shortest train time valu min epoch respect indic languag translat system design articl strong advantag reduc size model paramet thu reduc train time model experi verifi superior mobil assist languag translat system base npl"
  },
  {
    "doc_id": "10518044",
    "abstract_original": "The emerging Human-Centric Networks (HCN) paradigm shifts the passive role of individuals to an active one, intertwining the uncertainty of network resource usage with human dynamics, which are difficult to analyze and predict. This phenomenon implies an increase in reciprocal interactions between Cyber-Physical-Social Systems (CPSS) and human activities, presenting the challenge of efficiently allocating network resources while taking into account qualitative human uncertainty. In this study, we propose a conceptual model that addresses and quantifies such uncertainties. The proposed model is characterized by its adaptability to various CPSS applications, facilitating its integration into existing applications and future innovations. The adaptability of the model is based on the application of the sociological concept of Boundary Objects (BO), which allows for the structuring of system components and the generation of a reference architecture that facilitates systematic problem solving. To evaluate the model, we propose a use case related to a Vehicle for Hire (VFH) application operating within a 5G network slice. The integration of the proposed model with the OMNET++ simulation framework has allowed to demonstrate the effectiveness of the model in intricate computational environments and have shown its capacity to incorporate previously overlooked elements that are essential for the optimal allocation of resources in CPSS. This study proposes a methodology for comprehending and mitigating the consequences of human uncertainty, emphasizing the significance of a multidisciplinary approach to resource allocation in sophisticated technological systems.",
    "abstract_processed": "emerg human centric network hcn paradigm shift passiv role individu activ one intertwin uncertainti network resourc usag human dynam difficult analyz predict phenomenon impli increas reciproc interact cyber physic social system cpss human activ present challeng effici alloc network resourc take account qualit human uncertainti studi propos conceptu model address quantifi uncertainti propos model character adapt variou cpss applic facilit integr exist applic futur innov adapt model base applic sociolog concept boundari object bo allow structur system compon gener refer architectur facilit systemat problem solv evalu model propos use case relat vehicl hire vfh applic oper within g network slice integr propos model omnet simul framework allow demonstr effect model intric comput environ shown capac incorpor previous overlook element essenti optim alloc resourc cpss studi propos methodolog comprehend mitig consequ human uncertainti emphas signific multidisciplinari approach resourc alloc sophist technolog system"
  },
  {
    "doc_id": "10522260",
    "abstract_original": "When it comes to scene classification, the lack of labelled data is a significant obstacle that forces researchers to think about innovative solutions. This work presents a revolutionary method to strengthen scene classification models by combining transfer learning with AI-generated images. A key component of this project is the construction of a carefully curated dataset of 3672 augmented AI-generated photos in a total of 6 scenes. This database not only serves as a helpful resource for additional research but also makes a substantial contribution to this area of research. Using this dataset, a VGG16 model is trained, demonstrating the usefulness of synthetic data with a notable increase in accuracy. The model's performance is further improved through subsequent training using realistic photos through transfer learning, thereby surpassing the initial baseline. This work demonstrates the transformative effect of transfer learning on scene categorization accuracy and verifies its effectiveness using synthetic data through rigorous testing and evaluation. The results open the door for AI-generated photos to be used as an effective approach to address data scarcity issues in scene classification, which will help real-world applications improve.",
    "abstract_processed": "come scene classif lack label data signific obstacl forc research think innov solut work present revolutionari method strengthen scene classif model combin transfer learn ai gener imag key compon project construct care curat dataset augment ai gener photo total scene databas serv help resourc addit research also make substanti contribut area research use dataset vgg model train demonstr use synthet data notabl increas accuraci model perform improv subsequ train use realist photo transfer learn therebi surpass initi baselin work demonstr transform effect transfer learn scene categor accuraci verifi effect use synthet data rigor test evalu result open door ai gener photo use effect approach address data scarciti issu scene classif help real world applic improv"
  },
  {
    "doc_id": "10524473",
    "abstract_original": "Summary <p>This chapter deals with ways of evaluating the coupling that exists between disparate antennas that find themselves installed in each other's vicinity on vehicular platforms or indeed any platform. Clarity on a number of subtle ideas from electromagnetic theory greatly facilitates the understanding of the co&#x2010;sited antenna coupling problem. Study of the coupling between platform&#x2010;mounted antennas is in principle the same as studying coupling between the elements in an array antenna. The chapter describes antenna operation, and inter&#x2010;antenna coupling, in the way a full&#x2010;wave computational electromagnetics (CEM) model &#x201c;thinks&#x201d; about it. The rigorous formulations on which full&#x2010;wave CEM models are based argue as follows: the field generated by the impressed sources if all of the antenna structure were to be removed is the incident field and exists in all of space. Separate CEM models are in effect used to set up each of reduced complexity models for the antennas.</p>",
    "abstract_processed": "summari p chapter deal way evalu coupl exist dispar antenna find instal vicin vehicular platform inde platform clariti number subtl idea electromagnet theori greatli facilit understand co x site antenna coupl problem studi coupl platform x mount antenna principl studi coupl element array antenna chapter describ antenna oper inter x antenna coupl way full x wave comput electromagnet cem model x c think x rigor formul full x wave cem model base argu follow field gener impress sourc antenna structur remov incid field exist space separ cem model effect use set reduc complex model antenna p"
  },
  {
    "doc_id": "10526168",
    "abstract_original": "Digital With a growing global population comes a correspondingly higher need for food, making plant disease modernization in agricultural areas a top priority for all nations. Improving productivity is crucial to India’s economy. Consequently, the detection of disease in greeneries plays a key role in the development sector. The accuracy and precision of diagnosing diseases in plants and animals have also been enhanced by the increased use of expertise in modern times. One solution to the problem of classifying different populations is the prospect of grouping in AI techniques. We aim to provide insight into the present state of the illnesses and how to detect them rapidly using computational reasoning. The article suggests thinking about how to use AI techniques to automatically detect plant diseases. This research paper uses the O-RPN (Optimized District Proposition Network) to isolate and control the leaves in a complicated ecosystem. The O-RPN computation incorporates the signs component using Chan-Vese (CV) techniques. The district-based CV calculation yields encouraging results for noise- and weak-edge-free image segmentation. In addition, we compare CNN and SVM using a unique dataset related to plant illnesses.",
    "abstract_processed": "digit grow global popul come correspondingli higher need food make plant diseas modern agricultur area top prioriti nation improv product crucial india’ economi consequ detect diseas greeneri play key role develop sector accuraci precis diagnos diseas plant anim also enhanc increas use expertis modern time one solut problem classifi differ popul prospect group ai techniqu aim provid insight present state ill detect rapidli use comput reason articl suggest think use ai techniqu automat detect plant diseas research paper use rpn optim district proposit network isol control leav complic ecosystem rpn comput incorpor sign compon use chan vese cv techniqu district base cv calcul yield encourag result nois weak edg free imag segment addit compar cnn svm use uniqu dataset relat plant ill"
  },
  {
    "doc_id": "10529631",
    "abstract_original": "With the rapid development of modern wireless communication, communication has become more and more convenient and widely popular. However, due to the broadcast nature of the wireless channel, it is vulnerable to malicious attacks from third parties. During the establishment of UAV networks, given the limited computing power and storage resources of UAVs, traditional encryption methods may adversely affect their performance. Meanwhile, key distribution based on physical characteristics provides a new way of thinking. By utilizing the physical attributes of the channel to achieve key distribution, this method not only provides a high degree of security, but also greatly improves convenience. In addition, compared with traditional schemes, deep learning can automatically learn and integrate features at different levels, avoiding complex selection and combination of algorithms, thus possessing stronger generalization and robustness. Therefore, this paper proposes the use of deep learning techniques to extract channel features to increase the adaptability of key distribution. This approach is expected to provide strong support for the security and reliability of UAV networks.",
    "abstract_processed": "rapid develop modern wireless commun commun becom conveni wide popular howev due broadcast natur wireless channel vulner malici attack third parti establish uav network given limit comput power storag resourc uav tradit encrypt method may advers affect perform meanwhil key distribut base physic characterist provid new way think util physic attribut channel achiev key distribut method provid high degre secur also greatli improv conveni addit compar tradit scheme deep learn automat learn integr featur differ level avoid complex select combin algorithm thu possess stronger gener robust therefor paper propos use deep learn techniqu extract channel featur increas adapt key distribut approach expect provid strong support secur reliabl uav network"
  },
  {
    "doc_id": "10530940",
    "abstract_original": "Contribution: This article proposes a new theoretical model with a goal to develop future human computational thinking (CT) in foundational computer science (CS) education. The model blends six critical types of thinking, i.e., logical thinking, systems thinking, sustainable thinking, strategic thinking, creative thinking, and responsible thinking into the design of a first-year undergraduate programming course. The study describes a creative blended pedagogy that embeds the proposed model into the course plan. Background: The emergence of artificial intelligent systems such as large language models from a knowledge provider perspective, coupled with a gradual change in post-pandemic outlook of education challenge the relevance and raises concerns about the future of education. The 21st-century human CT requirements, viz., learning to code (skill) and thinking computationally (competency), will be inadequate in the future. Moreover, there is substantial evidence which shows that most introductory programming courses fail to integrate critical elements like ethics and responsibility as part of the course. Intended Outcomes: The authors anticipate experiential learning models such as this has immense potential to future-proof CS education, as well as make future software engineers responsible citizens. Application Design: The proposed model blends six types of thinking into the design and activities of the course. The underlying theoretical basis of these activities revolve around three key principles: 1) experiential learning; 2) self-reflection; and 3) peer learning. Findings: This case study from a liberal educational institution in India qualitatively shows evidence of students developing six critical elements of thinking that shapes their future CT ability.",
    "abstract_processed": "contribut articl propos new theoret model goal develop futur human comput think ct foundat comput scienc cs educ model blend six critic type think e logic think system think sustain think strateg think creativ think respons think design first year undergradu program cours studi describ creativ blend pedagogi emb propos model cours plan background emerg artifici intellig system larg languag model knowledg provid perspect coupl gradual chang post pandem outlook educ challeng relev rais concern futur educ st centuri human ct requir viz learn code skill think comput compet inadequ futur moreov substanti evid show introductori program cours fail integr critic element like ethic respons part cours intend outcom author anticip experienti learn model immens potenti futur proof cs educ well make futur softwar engin respons citizen applic design propos model blend six type think design activ cours underli theoret basi activ revolv around three key principl experienti learn self reflect peer learn find case studi liber educ institut india qualit show evid student develop six critic element think shape futur ct abil"
  },
  {
    "doc_id": "10531412",
    "abstract_original": "Cyber-physical systems (CPS) are ubiquitous in our modern world, from the cars we drive to the homes we live in. CPS are integrated systems that combine computational and physical components to perform complex tasks. As CPS become increasingly sophisticated and interconnected, it is important for students to have a basic understanding of how they work and how to use them safely and responsibly.In this work, the need for CPS education, the requirements from the teaching faculty and students, the course design methodology and its intent and a 20-hour lesson plan for CPS education is proposed along with a methodology to teach an introductory module on safety and security. CPS education in pre-university education should be comprehensive and hands-on, with an interdisciplinary approach, emphasis on safety and security, real-world applications, and integration of emerging technologies. This education will equip students with the knowledge and skills necessary to thrive in a rapidly evolving technological world while being aware of the trust, safety and security aspects in designing and using the CPS interface. The proposed method was implemented in an undergraduate program as an elective course and its observations are presented.",
    "abstract_processed": "cyber physic system cp ubiquit modern world car drive home live cp integr system combin comput physic compon perform complex task cp becom increasingli sophist interconnect import student basic understand work use safe respons work need cp educ requir teach faculti student cours design methodolog intent hour lesson plan cp educ propos along methodolog teach introductori modul safeti secur cp educ pre univers educ comprehens hand interdisciplinari approach emphasi safeti secur real world applic integr emerg technolog educ equip student knowledg skill necessari thrive rapidli evolv technolog world awar trust safeti secur aspect design use cp interfac propos method implement undergradu program elect cours observ present"
  },
  {
    "doc_id": "10531462",
    "abstract_original": "In the current scenario computing has become integral part of curriculum at all levels of education. It has transformed way of teaching and learning processes. However, it remains debatable about the content or curriculum of computing as a separate subject or as an integral part of all other subjects. A literature study reveals that most of the current high school education focuses on computer as a separate subject and less emphasis on computing and its integration with other subjects. The present work intends to propose a conceptual approach “Computing Implementation for High School Curriculum” with an objective of integrating computing as a part high school education with a multi-dimensional approach. It includes teaching & learning, emphasis on problem solving and supporting academic administration. This can help the stakeholders in the field of education to improve the overall development of our future generation.",
    "abstract_processed": "current scenario comput becom integr part curriculum level educ transform way teach learn process howev remain debat content curriculum comput separ subject integr part subject literatur studi reveal current high school educ focus comput separ subject less emphasi comput integr subject present work intend propos conceptu approach “comput implement high school curriculum” object integr comput part high school educ multi dimension approach includ teach learn emphasi problem solv support academ administr help stakehold field educ improv overal develop futur gener"
  },
  {
    "doc_id": "10531721",
    "abstract_original": "The incidence of depressive disorder in Korea is the highest among OECD countries. The proportion of patients in their 20s is the highest. However, social gaze and false perception are causing problems such as not visiting the hospital or delaying the visit. Accordingly, we suggest a Korean model for predicting depressive disorders using data from online communities widely used by people in their 20s. In many countries, including South Korea, depressive disorders are diagnosed using DSM-5 (Diagnostic and Statistical Manual of Mental Disorders, Fifth Edition) published by the American Psychiatric Association. We propose a model that predicts the probability of a user’s speech corresponding to nine criteria for diagnosing DSM-5 depressive disorder, following advice obtained through periodic meetings with a psychiatrist. The prediction performance was improved by using the correlation between each criterion in the model implementation stage.",
    "abstract_processed": "incid depress disord korea highest among oecd countri proport patient highest howev social gaze fals percept caus problem visit hospit delay visit accordingli suggest korean model predict depress disord use data onlin commun wide use peopl mani countri includ south korea depress disord diagnos use dsm diagnost statist manual mental disord fifth edit publish american psychiatr associ propos model predict probabl user’ speech correspond nine criteria diagnos dsm depress disord follow advic obtain period meet psychiatrist predict perform improv use correl criterion model implement stage"
  },
  {
    "doc_id": "10533093",
    "abstract_original": "The capstone projects for computing primary students require the embodiment of the skills and ideas learned by developing specific solutions to some existing challenges. This project must follow an organized and elaborate life cycle to reach the required solution. This task ends with the production of applicable software and a document showing the production stages of this work, which will be presented orally. During this scientific paper, we will evaluate all the forms and models of assessment used and their relevance to the student's level at the undergraduate level. (Abstract)",
    "abstract_processed": "capston project comput primari student requir embodi skill idea learn develop specif solut exist challeng project must follow organ elabor life cycl reach requir solut task end product applic softwar document show product stage work present oral scientif paper evalu form model assess use relev student level undergradu level abstract"
  },
  {
    "doc_id": "10534124",
    "abstract_original": "Summary <p>Critical Systems Thinking (CST) is a systems approach that aims to assist decision&#x2010;makers to better understand and address the complex issues they face. This chapter looks at the origins and early development of CST. A brief account of the state of Systems Thinking (ST) in the early 1980s is necessary to discern the reasons for the emergence of the approach. The development of CST is then traced to 1991. By that time, it had become formalised around a set of three commitments, to which it has largely remained true. The first, &#x2018;systemic critique&#x2019;, insists that all systems approaches are partial, and this leads to their different strengths and weaknesses. The second, &#x2018;systemic pluralism&#x2019;, suggests that the maximum benefit can be obtained by using systems methodologies in combination during an intervention. The third, &#x2018;systemic improvement&#x2019;, explains what improvement means in systems terms and how it can be pursued. The case is then made for CST to embrace a fourth commitment, to &#x2018;systemic pragmatism&#x2019;. It is argued that this can support the other three and take CST forward.</p>",
    "abstract_processed": "summari p critic system think cst system approach aim assist decis x maker better understand address complex issu face chapter look origin earli develop cst brief account state system think st earli necessari discern reason emerg approach develop cst trace time becom formalis around set three commit larg remain true first x system critiqu x insist system approach partial lead differ strength weak second x system plural x suggest maximum benefit obtain use system methodolog combin intervent third x system improv x explain improv mean system term pursu case made cst embrac fourth commit x system pragmat x argu support three take cst forward p"
  },
  {
    "doc_id": "10534769",
    "abstract_original": "Emotions are essential drivers of the learning process, influencing motivation, performance, and problem-solving abilities. In the field of Computer Science, students often struggle with negative emotions during programming activities, impacting their performance and project quality. To address this challenge, there is a growing need to introduce Computational Thinking skills at the pre-university level. This study focuses on understanding the emotions experienced by primary and secondary school students during Computational Thinking activities, involving both plugged and unplugged tools. A significant performance difference was observed between primary and secondary education levels, with the latter outperforming the former. The research identifies specific associations between concepts and emotions, highlighting age-related differences with younger students exhibiting more positive emotions. While gender-based disparities in Computer Science perception exist in secondary education, there are no corresponding distinctions in emotional responses. The study reveals a gender-based effect, with girls showing reduced emotional responses and lower Computational Thinking performance than boys. In summary, this research underscores the profound role of emotions in learning, providing essential insights for tailoring educational strategies considering gender-specific and programming concept-related factors. It also connects lower emotional reactions to inferior results, emphasizing the importance of heightened emotional engagement.",
    "abstract_processed": "emot essenti driver learn process influenc motiv perform problem solv abil field comput scienc student often struggl neg emot program activ impact perform project qualiti address challeng grow need introduc comput think skill pre univers level studi focus understand emot experienc primari secondari school student comput think activ involv plug unplug tool signific perform differ observ primari secondari educ level latter outperform former research identifi specif associ concept emot highlight age relat differ younger student exhibit posit emot gender base dispar comput scienc percept exist secondari educ correspond distinct emot respons studi reveal gender base effect girl show reduc emot respons lower comput think perform boy summari research underscor profound role emot learn provid essenti insight tailor educ strategi consid gender specif program concept relat factor also connect lower emot reaction inferior result emphas import heighten emot engag"
  },
  {
    "doc_id": "10535493",
    "abstract_original": "An improved think-globally-act-locally (ITGAL) method is proposed in this paper for the computation of a liveness enforcing/deadlock prevention supervisor containing of a set control places (CPs) for a Petri net (PN) model of a flexible manufacturing system (FMS) suffering from deadlocks. The proposed method is especially suitable for generalized PN classes containing weighted arcs such as S4R and S4PR. It leads to optimal or near-optimal liveness-enforcing supervisors without solving intractable integer linear programming problems. By using a recently proposed optimality test for CPs, the proposed ITGAL method provides improved behavioral permissiveness and/or reduced structural complexity of the CPs. The applicability of the proposed method is shown by means of a number of typical FMS examples.",
    "abstract_processed": "improv think global act local itgal method propos paper comput live enforc deadlock prevent supervisor contain set control place cp petri net pn model flexibl manufactur system fm suffer deadlock propos method especi suitabl gener pn class contain weight arc r pr lead optim near optim live enforc supervisor without solv intract integ linear program problem use recent propos optim test cp propos itgal method provid improv behavior permiss reduc structur complex cp applic propos method shown mean number typic fm exampl"
  },
  {
    "doc_id": "10536265",
    "abstract_original": "Creative design and applications based on Cultural Heritage (CH) content have gradually become a new way of communicating and interpreting cultural values. The proposed research aims to improve the CH experience using extended reality (XR) technologies by investigating the digital affordances of XR technologies that can support the design of playful CH experience, and exploring appropriate ways to enable user-generated content for participatory CH experience. This is an interdisciplinary project that sits at the intersection of human-computer interaction (HCI), XR, and CH. A practice-based approach will be adopted to conduct research in the wild, designing and developing novel XR interfaces and interaction techniques for CH experiences. The combined design thinking and computational approach will allow an in-depth understanding of playful and participatory CH experience using XR technologies, providing empirical, artifact, and theoretical contributions to the fields of HCI, XR, and CH.",
    "abstract_processed": "creativ design applic base cultur heritag ch content gradual becom new way commun interpret cultur valu propos research aim improv ch experi use extend realiti xr technolog investig digit afford xr technolog support design play ch experi explor appropri way enabl user gener content participatori ch experi interdisciplinari project sit intersect human comput interact hci xr ch practic base approach adopt conduct research wild design develop novel xr interfac interact techniqu ch experi combin design think comput approach allow depth understand play participatori ch experi use xr technolog provid empir artifact theoret contribut field hci xr ch"
  },
  {
    "doc_id": "10538326",
    "abstract_original": "The intersection of computer science and art has sparked a wave of innovation, particularly in digital visualizations and interactive installations. This abstract explores the symbiotic relationship between these disciplines, highlighting groundbreaking advancements and creative endeavors. Innovations in digital visualizations leverage algorithms and computational techniques to transform data into visually engaging representations. From intricate data sculptures to immersive virtual reality experiences, computer scientists and artists collaborate to push the boundaries of storytelling and communication. These visualizations not only convey complex information effectively but also evoke emotional responses, bridging the gap between technology and human perception. Interactive installations blur the lines between audience and artwork, inviting participation and engagement. Through sensors, augmented reality, and responsive environments, users become active participants in the creation of art, shaping and influencing their experiences in real-time. This dynamic interaction fosters new forms of expression and challenges traditional notions of artistic production. By exploring the intersection of computer science and art, this abstract underscores the transformative power of interdisciplinary collaboration. Through experimentation, exploration, and innovation, digital visualizations and interactive installations continue to redefine the possibilities of creative expression in the digital age.",
    "abstract_processed": "intersect comput scienc art spark wave innov particularli digit visual interact instal abstract explor symbiot relationship disciplin highlight groundbreak advanc creativ endeavor innov digit visual leverag algorithm comput techniqu transform data visual engag represent intric data sculptur immers virtual realiti experi comput scientist artist collabor push boundari storytel commun visual convey complex inform effect also evok emot respons bridg gap technolog human percept interact instal blur line audienc artwork invit particip engag sensor augment realiti respons environ user becom activ particip creation art shape influenc experi real time dynam interact foster new form express challeng tradit notion artist product explor intersect comput scienc art abstract underscor transform power interdisciplinari collabor experiment explor innov digit visual interact instal continu redefin possibl creativ express digit age"
  },
  {
    "doc_id": "10539509",
    "abstract_original": "World Wide Web is speeding up its pace into an intelligent and decentralized ecosystem, as seen in the campaign of Web 3.0 and forthcoming Web 4.0. Marked by the Europe Commission's latest mention of Web 4.0, a race towards strategic Web 4.0 success has started. Web 4.0 is committed to bringing the next technological transition with an open, secure, trustworthy fairness and digital ecosystem for individuals and businesses in private and public sectors. Despite overlapping scopes and objectives of Web 3.0 and Web 4.0 from academic and industrial perspectives, there are distinct and definitive features and gaps for the next generation of WWW. In this review, a brief introduction to WWW development unravels the entangled but consistent requirement of a more vivid web experience, enhancing human-centric experience in both societal and technical aspects. Moreover, the review brings a decentralized intelligence prospect of view on native AI entities for Web 4.0, envisioning sustainable, autonomous and decentralized AI services for the entire Web 4.0 environment, powering a self-sustainable Decentralized Physical and Software Infrastructure for Computing Force Network, Semantic Network, Virtual/Mixed Reality, and Privacy-preserving content presumption. The review aims to reveal that Web 4.0 offers native intelligence with focused thinking on utilizing decentralized physical infrastructure, in addition to sole requirements on decentralization, bridging the gap between Web 4.0 and Web 3.0 advances with the latest future-shaping blockchain-enabled computing and network routing protocols.",
    "abstract_processed": "world wide web speed pace intellig decentr ecosystem seen campaign web forthcom web mark europ commiss latest mention web race toward strateg web success start web commit bring next technolog transit open secur trustworthi fair digit ecosystem individu busi privat public sector despit overlap scope object web web academ industri perspect distinct definit featur gap next gener www review brief introduct www develop unravel entangl consist requir vivid web experi enhanc human centric experi societ technic aspect moreov review bring decentr intellig prospect view nativ ai entiti web envis sustain autonom decentr ai servic entir web environ power self sustain decentr physic softwar infrastructur comput forc network semant network virtual mix realiti privaci preserv content presumpt review aim reveal web offer nativ intellig focus think util decentr physic infrastructur addit sole requir decentr bridg gap web web advanc latest futur shape blockchain enabl comput network rout protocol"
  },
  {
    "doc_id": "10540133",
    "abstract_original": "Social media platforms are used widely by all people to express their feelings, opinions, and emotional states. Billions of people worldwide use them daily to share what they think and feel in their posts. Amongst all social media available platforms, Facebook only contains around three billion personal accounts. In this work Reddit dataset is used to automatically detect mental illness from social media posts. This study is not only limited to early detection of already existing mental illness or disorder like depression and anxiety from social posts, but also and most importantly the study is extended to predict successfully potential mental illness that would happen in future. This study deploys Nineteen different models to study the capability of them in detecting and predicting mental disorders from social media posts. Some of the deployed models are classical machine learning classifiers, some are ensemble learning models, and the rest are large language models (LLMs). Six machine learning classifiers were used in this work for the automatic detection and prediction of mental illness and logistic regression proved to be the best amongst other classifiers in this task. Nine Ensemble methods were also used and examined. Amongst the Nine ensemble learning models VC2, Light GBM, Bagging estimator, and XGBoost proved to be superior in this task. Four large language models were also used and examined for the same task. RoBERTa and OpenAI GPT proved to outperform the rest of models in this task. All those models were built, trained, tested, and compared with previous work in literature to get the best possible results. The study covers the main four mental disorders which are ADHD, Anxiety, Bipolar, and Depression. The work proposed in this paper succeeded in outperforming the results in literature in terms of number of addressed mental disorders, number of models used and tested, and dataset size used to validate results. The proposed work also outperformed the only attempt in literature that addressed all mental disorders in results of detection and prediction noticeably. This work achieved the detection of already existing mental disorders F1-score of 0.80 from clinical data and of 0.52 from non-clinical data, and it achieved a prediction of future mental disorder F1-score of 0.43 from non-clinical data.",
    "abstract_processed": "social media platform use wide peopl express feel opinion emot state billion peopl worldwid use daili share think feel post amongst social media avail platform facebook contain around three billion person account work reddit dataset use automat detect mental ill social media post studi limit earli detect alreadi exist mental ill disord like depress anxieti social post also importantli studi extend predict success potenti mental ill would happen futur studi deploy nineteen differ model studi capabl detect predict mental disord social media post deploy model classic machin learn classifi ensembl learn model rest larg languag model llm six machin learn classifi use work automat detect predict mental ill logist regress prove best amongst classifi task nine ensembl method also use examin amongst nine ensembl learn model vc light gbm bag estim xgboost prove superior task four larg languag model also use examin task roberta openai gpt prove outperform rest model task model built train test compar previou work literatur get best possibl result studi cover main four mental disord adhd anxieti bipolar depress work propos paper succeed outperform result literatur term number address mental disord number model use test dataset size use valid result propos work also outperform attempt literatur address mental disord result detect predict notic work achiev detect alreadi exist mental disord f score clinic data non clinic data achiev predict futur mental disord f score non clinic data"
  },
  {
    "doc_id": "10540721",
    "abstract_original": "Dull and abstract mechanical concepts, along with cumbersome formulas, often pose challenges for students in mechanical course learning. We propose an innovative approach that combines modeling, numerical computation, and E-learning software development to enhance students' learning enthusiasm. Focusing on the teaching knowledge point of “polar moment of inertia”, we examine the automotive transmission axle as a specific research case. By constructing a finite element model and conducting numerical calculations, we generated vivid visualization materials, including Mises stress and displacement cloud images. Leveraging the C# programming language, we developed E-learning software that incorporates the calculus derivation processes for axle torsion deformation. The results of our teaching experiment demonstrate the effectiveness of this teaching innovation, with a 90.63 % acceptance rate. Visualization materials, such as Mises stress cloud images, facilitate students' understanding of abstract concepts, garnering an 89.06% acceptance rate. Moreover, the E-learning software significantly increased students' learning enthusiasm, with an 85.91 % acceptance rate. The adoption of modeling and simulation to create digital materials for mechanical education provides a robust foundation for E-learning software development and classroom application. Digitalization and E-learning software are poised to be vital trends in future educational development, with ample opportunities for further exploration by scholars in the field.",
    "abstract_processed": "dull abstract mechan concept along cumbersom formula often pose challeng student mechan cours learn propos innov approach combin model numer comput e learn softwar develop enhanc student learn enthusiasm focus teach knowledg point “polar moment inertia” examin automot transmiss axl specif research case construct finit element model conduct numer calcul gener vivid visual materi includ mise stress displac cloud imag leverag c program languag develop e learn softwar incorpor calculu deriv process axl torsion deform result teach experi demonstr effect teach innov accept rate visual materi mise stress cloud imag facilit student understand abstract concept garner accept rate moreov e learn softwar significantli increas student learn enthusiasm accept rate adopt model simul creat digit materi mechan educ provid robust foundat e learn softwar develop classroom applic digit e learn softwar pois vital trend futur educ develop ampl opportun explor scholar field"
  },
  {
    "doc_id": "10541025",
    "abstract_original": "Computational thinking is a crucial skill for students to analyze and solve problems, and programming education serves as an important pathway to cultivate computational thinking. This study combines relevant literature and utilizes Scratch, a visual programming software, to construct a gamified teaching model for Scratch courses. A quasi-experimental research design was employed, involving two fifth-grade classes from a primary school in K city. The study employed methods such as analysis of student works, SPSS scale data analysis, and student interviews to investigate the impact of gamified teaching in Scratch courses on developing elementary students' computational thinking. The results indicate that gamified teaching in Scratch courses significantly enhances the computational thinking level of elementary students, particularly in the dimensions of critical thinking, problem-solving ability, and algorithmic thinking. Based on the research findings, it is recommended that gamified teaching in Scratch courses should involve appropriate teaching tools, incorporate game-based learning, emphasize problem-solving, encourage collaborative learning, and provide training for educators competent in programming education.",
    "abstract_processed": "comput think crucial skill student analyz solv problem program educ serv import pathway cultiv comput think studi combin relev literatur util scratch visual program softwar construct gamifi teach model scratch cours quasi experiment research design employ involv two fifth grade class primari school k citi studi employ method analysi student work spss scale data analysi student interview investig impact gamifi teach scratch cours develop elementari student comput think result indic gamifi teach scratch cours significantli enhanc comput think level elementari student particularli dimens critic think problem solv abil algorithm think base research find recommend gamifi teach scratch cours involv appropri teach tool incorpor game base learn emphas problem solv encourag collabor learn provid train educ compet program educ"
  },
  {
    "doc_id": "10541726",
    "abstract_original": "Cognitive Science is a complex mechanism of solving a problem based on the impact of behavior, analysis of interpretation, studying mental representations functioning of the neurons at the level of brain, perceiving and sensing an object: a living: nature & nurture, a deeper understanding of psychological aspects, relating mind to the brain, handling emotional sense with Intelligent quotient, a meta-analysis study of automation, handling the issues dealing with biasedness due to lack of optimal Hypothesis, correlating to develop ontological representations and illustrating the language of thought on empirical evidence, observational phenomena and applying technologies of Deep learning, machine learning, statistics subset to Artificial Intelligence for optimality. This comprehensive literature study navigates through the historical evolution and interdisciplinary dimensions of cognitive science, spanning from ancient Greek philosophy to its contemporary amalgamation with neuroscience, psychology, linguistics, and artificial intelligence. Examining theoretical paradigms like formal logic, rules, concepts, analogies, images, and connectionism, the study elucidates their pivotal roles in deciphering the mind's intricate representations and computations. Focused on the challenges encountered by cognitive science, the study underscores the integration of analytics, foundational concepts, and diverse methodologies such as statistical tools, machine learning, and prescriptive analytics. A Structured outlined working procedure showcases the application of cognitive science principles to enhance student performance, conducting and evaluating surveys, statistical analysis, machine learning models, and association rule mining. The methodology progresses systematically from data collection and persona analysis to prediction hypothesis formulation, mismatch analysis, marks prediction, rule-based classification, association rule mining, data analytics, and exploratory data analysis. Signifying the importance of big data, the study recommends cognitive computing concepts for intervention measures, encompassing cognitive behavioral therapy, gaming approaches, and neurological interventions, thereby contributing to the practical implementation of cognitive science in student performance analysis and intervention.",
    "abstract_processed": "cognit scienc complex mechan solv problem base impact behavior analysi interpret studi mental represent function neuron level brain perceiv sens object live natur nurtur deeper understand psycholog aspect relat mind brain handl emot sens intellig quotient meta analysi studi autom handl issu deal biased due lack optim hypothesi correl develop ontolog represent illustr languag thought empir evid observ phenomena appli technolog deep learn machin learn statist subset artifici intellig optim comprehens literatur studi navig histor evolut interdisciplinari dimens cognit scienc span ancient greek philosophi contemporari amalgam neurosci psycholog linguist artifici intellig examin theoret paradigm like formal logic rule concept analog imag connection studi elucid pivot role deciph mind intric represent comput focus challeng encount cognit scienc studi underscor integr analyt foundat concept divers methodolog statist tool machin learn prescript analyt structur outlin work procedur showcas applic cognit scienc principl enhanc student perform conduct evalu survey statist analysi machin learn model associ rule mine methodolog progress systemat data collect persona analysi predict hypothesi formul mismatch analysi mark predict rule base classif associ rule mine data analyt exploratori data analysi signifi import big data studi recommend cognit comput concept intervent measur encompass cognit behavior therapi game approach neurolog intervent therebi contribut practic implement cognit scienc student perform analysi intervent"
  },
  {
    "doc_id": "10541749",
    "abstract_original": "Cyborg Intelligence is a major component in replacing lost body part functions in the twenty-first century by incorporating cyborg technology; a human body will be able to function even if it loses one or more of its functioning parts, such as its arms or legs, which would significantly benefit society. The study of cyborgs and the creation of humanoid robots from them Cyborgs, as the title implies, are hybrids of humans and robots. The study examines cyborg technology that is cybernetic. An artificial intelligence is referred to as a cyborg in this context. Artificial intelligence, sometimes referred to as machine intelligence, is the ability of a computer to create software and act and think like a human. Cybernetics is a branch of science that focuses on the fundamentals of communication and control in both machines and biological things. The discussion of how cybernetics and artificial intelligence interact will be the main focus of this article. Additionally, this article will assess cyborg technology in the real world, examining its benefits and drawbacks as well as the ways in which cyborgs and robots are different. Cyborgs are conceivable in today’s world. A cyborg is a humanoid robot or, more accurately, a hybrid of humans and robots. Robots are mechanical humans that depend on the intellect offered by people. With the use of artificial intelligence, cyborgs may now create their own algorithms. The fusion of logic and technology is a key aspect in the creation of a cyborg.",
    "abstract_processed": "cyborg intellig major compon replac lost bodi part function twenti first centuri incorpor cyborg technolog human bodi abl function even lose one function part arm leg would significantli benefit societi studi cyborg creation humanoid robot cyborg titl impli hybrid human robot studi examin cyborg technolog cybernet artifici intellig refer cyborg context artifici intellig sometim refer machin intellig abil comput creat softwar act think like human cybernet branch scienc focus fundament commun control machin biolog thing discuss cybernet artifici intellig interact main focu articl addit articl assess cyborg technolog real world examin benefit drawback well way cyborg robot differ cyborg conceiv today’ world cyborg humanoid robot accur hybrid human robot robot mechan human depend intellect offer peopl use artifici intellig cyborg may creat algorithm fusion logic technolog key aspect creation cyborg"
  },
  {
    "doc_id": "10543845",
    "abstract_original": "Image captioning stands as a pivotal technique for providing contextual descriptions of visual content, promising substantial enhancement in the capabilities of conversational AI systems. This work delves into the integration of image captioning methodologies into ChatGPT, aiming to fortify its capacity in understanding and responding to visual information. The study extensively explores the application of deep learning models, encompassing ResNet50, LSTM, DenseNet121, MobileNet, and MobileNetv2, in the domain of image captioning. Specifically, a comprehensive investigation is conducted into a Recurrent Neural Network employing LSTM as a decoder and a Convolutional Neural Network utilizing ResNet as an encoder. These fusion harnesses vocabulary and image features to craft precise and meaningful descriptions of visual content. Furthermore, this study pioneers an approach to identify and relate at least two salient features within any given image, forming a coherent caption that binds the relationship between these identified features. This novel capability not only refines image captioning techniques but also empowers ChatGPT to comprehend complex visual contexts within conversational settings. The outcomes of this work offer profound insights into augmenting AI capabilities, facilitating a deeper understanding and more effective interaction with visual information across various domains, thereby advancing the field of conversational AI integration with visual context.",
    "abstract_processed": "imag caption stand pivot techniqu provid contextu descript visual content promis substanti enhanc capabl convers ai system work delv integr imag caption methodolog chatgpt aim fortifi capac understand respond visual inform studi extens explor applic deep learn model encompass resnet lstm densenet mobilenet mobilenetv domain imag caption specif comprehens investig conduct recurr neural network employ lstm decod convolut neural network util resnet encod fusion har vocabulari imag featur craft precis meaning descript visual content furthermor studi pioneer approach identifi relat least two salient featur within given imag form coher caption bind relationship identifi featur novel capabl refin imag caption techniqu also empow chatgpt comprehend complex visual context within convers set outcom work offer profound insight augment ai capabl facilit deeper understand effect interact visual inform across variou domain therebi advanc field convers ai integr visual context"
  },
  {
    "doc_id": "10544125",
    "abstract_original": "Neural Style Transfer (NST) currently leads the artistic creation field that combines artistry with technological innovation, well master the advanced of Convolution neural network (CNN) makes image manipulation easy and with creative flair. This paper suggests the optimized approach for NST which includes a dataset selection, choosing the type model architecture, learning strategies and, all-inclusive evaluation metrics. Through meticulous experimentation, we explore four distinct dimensions of NST applications: face painting, super-slow-motion, interactive, user-customization, real-time performance along online social media. In investigating superior style transfer our product highlights the highest perceptual matching, faithful style representation, and content preservation metrics ensuring the fulfillment of artistic style without deformation of the original content. Model efficiency is achieved by introducing optimized model architectures and fast training strategies, which, in turn, provide for responsive style transfer in real time with as little latency and resource consumption as possible. This is done by adapting models within a specific artistic domain through up-tuning models which will be the source of style transfer that can be tweaked in a manner that caters for any artistic domain. Therefore, the paper research is fundamental because of the management of the user’s experience by user-guided interaction, which has given interactive controls and real-time feedback that assist the users to customize stylization according to their likes and dislikes. Gratifying user scoring demonstrates the power of user-directed style transfer as a means of furthering users’ engagement and artistry.t.",
    "abstract_processed": "neural style transfer nst current lead artist creation field combin artistri technolog innov well master advanc convolut neural network cnn make imag manipul easi creativ flair paper suggest optim approach nst includ dataset select choos type model architectur learn strategi inclus evalu metric meticul experiment explor four distinct dimens nst applic face paint super slow motion interact user custom real time perform along onlin social media investig superior style transfer product highlight highest perceptu match faith style represent content preserv metric ensur fulfil artist style without deform origin content model effici achiev introduc optim model architectur fast train strategi turn provid respons style transfer real time littl latenc resourc consumpt possibl done adapt model within specif artist domain tune model sourc style transfer tweak manner cater artist domain therefor paper research fundament manag user’ experi user guid interact given interact control real time feedback assist user custom styliz accord like dislik gratifi user score demonstr power user direct style transfer mean further users’ engag artistri"
  },
  {
    "doc_id": "10544496",
    "abstract_original": "The recognition of unlimited signatures is an ongoing challenge for computer vision systems. Traditionally, in paragraph text recognition, two separate models are used for character splitting and text character recognition. In this regard, this study proposes an integrated end-to-end framework and a new hybrid thinking approach to address the existing challenge. The prototype is specifically intended to handle a splitting picture per align iteratively, with three different modules. Initially, the encoder creates maps of features derived from the whole passage picture. Then, a concept module produces typically a mask with weights, which enables focused analysis of current text line features, especially implicit line splitting Finally, the decoder module is used for performing spectrum detection in each text line feature, ending with comprehensive detection of the entire paragraph offers a new solution.",
    "abstract_processed": "recognit unlimit signatur ongo challeng comput vision system tradit paragraph text recognit two separ model use charact split text charact recognit regard studi propos integr end end framework new hybrid think approach address exist challeng prototyp specif intend handl split pictur per align iter three differ modul initi encod creat map featur deriv whole passag pictur concept modul produc typic mask weight enabl focus analysi current text line featur especi implicit line split final decod modul use perform spectrum detect text line featur end comprehens detect entir paragraph offer new solut"
  },
  {
    "doc_id": "10545100",
    "abstract_original": "The study aims to explore the pivotal moments that arise in early-stage startups. Early-stage startups encounter various obstacles and uncertainties while maneuvering through the competitive business environment. These obstacles frequently necessitate pivots to guarantee success and sustainability of the startup . The objective of this research paper is to identify and analyze the diverse elements that contribute to the process of pivot in early stage startups [23]. The study examined pertinent literature regarding the subject and identified several crucial elements that contribute to pivoting in early-stage startups via primary data gathering. Additionally, it assessed the influence of these key factors on early-stage startups by analyzing their effects on growth, performance, and overall success. The results of this investigation will offer valuable perspectives for entrepreneurs, investors, and policymakers engaged in early-stage startups.",
    "abstract_processed": "studi aim explor pivot moment aris earli stage startup earli stage startup encount variou obstacl uncertainti maneuv competit busi environ obstacl frequent necessit pivot guarante success sustain startup object research paper identifi analyz divers element contribut process pivot earli stage startup studi examin pertin literatur regard subject identifi sever crucial element contribut pivot earli stage startup via primari data gather addit assess influenc key factor earli stage startup analyz effect growth perform overal success result investig offer valuabl perspect entrepreneur investor policymak engag earli stage startup"
  },
  {
    "doc_id": "10545184",
    "abstract_original": "Unlike traditional computing, soft computing solves difficult real-world problems and works with approximation models. Soft computing is more forgiving of approximations, ambiguity, partial truth, and imprecision than hard computing. The human mind is, in a sense, the ideal model for soft computing. Techniques like fuzzy logic, machine learning, genetic algorithms, expert systems, and artificial neural networks are the foundation of soft computing. Even though soft computing theory and methods were initially presented in the 1980s, automatic control engineering currently uses them as a major area of research and study. Soft computing techniques are currently being successfully applied in a wide range of commercial, industrial, and household applications. Soft computing techniques and application areas are expected to grow further with the introduction of low-cost, outstanding-performance digital processing units and the falling cost of memory chips. The purpose of this paper is to discuss embracing uncertainties and approximation for intelligent problem-solving with the help of soft computing. First, the study has discussed various soft computing systems. Moreover, the concept of fuzzy logic has been illustrated along with a description of its applications. In terms of research methodology, this research paper has followed a qualitative research approach by gathering knowledge based on reviewing a wide range of different studies regarding the research topic. According to the findings of this research, as computer processing units get cheaper and more powerful, intelligent systems and soft computing techniques become more significant. Complex algorithms must be used by intelligent systems to make difficult judgments and select the optimal solution from a range of options.",
    "abstract_processed": "unlik tradit comput soft comput solv difficult real world problem work approxim model soft comput forgiv approxim ambigu partial truth imprecis hard comput human mind sens ideal model soft comput techniqu like fuzzi logic machin learn genet algorithm expert system artifici neural network foundat soft comput even though soft comput theori method initi present automat control engin current use major area research studi soft comput techniqu current success appli wide rang commerci industri household applic soft comput techniqu applic area expect grow introduct low cost outstand perform digit process unit fall cost memori chip purpos paper discuss embrac uncertainti approxim intellig problem solv help soft comput first studi discuss variou soft comput system moreov concept fuzzi logic illustr along descript applic term research methodolog research paper follow qualit research approach gather knowledg base review wide rang differ studi regard research topic accord find research comput process unit get cheaper power intellig system soft comput techniqu becom signific complex algorithm must use intellig system make difficult judgment select optim solut rang option"
  },
  {
    "doc_id": "10548705",
    "abstract_original": "The Internet of Things (IoT) is a network of interconnected appliances, sensors, and databases that aim to improve human life quality in various life fields. To enhance agricultural productivity quantitively and in terms of quality, farmers have adopted the emerging IoT and communication technologies to establish automated monitoring and control systems. This adoption of novel technologies enables farmers to deal with traditional practice problems. However, the solutions provided by this new concept reveal a wide range of research issues. Since security and privacy are the top concerns in IoT environments, it's important to think about potential attacks and develop countermeasures. In this paper, we present a simple security analysis in the IoT-based smart agriculture field. Then, considering the crucial role of authentication in IoT security, we reviewed the different classes of authentication in this field.",
    "abstract_processed": "internet thing iot network interconnect applianc sensor databas aim improv human life qualiti variou life field enhanc agricultur product quantit term qualiti farmer adopt emerg iot commun technolog establish autom monitor control system adopt novel technolog enabl farmer deal tradit practic problem howev solut provid new concept reveal wide rang research issu sinc secur privaci top concern iot environ import think potenti attack develop countermeasur paper present simpl secur analysi iot base smart agricultur field consid crucial role authent iot secur review differ class authent field"
  },
  {
    "doc_id": "10549033",
    "abstract_original": "With the continuous development and innovation of data mining technology and database technology, a large number of diversified data continue to show its due and unique business value, which directly impacts people's traditional way of thinking. If enterprises want to survive in the competition of big data era, they must reform the traditional marketing mode. For automobile marketing, accurately grasping the market situation and seizing the development opportunity can create greater development space and bring greater economic benefits for automobile enterprises. Through data mining, we can realize the market positioning of enterprises, the positioning of consumer groups, and help to formulate automobile marketing strategies. With the rapid development of data mining technology, diversified data show its important business value. Based on data mining technology, this paper analyzes how to change the automobile marketing mode, aiming to make the healthy development of China's automobile marketing mode, so as to make China continue to develop and expand the automobile sales market.",
    "abstract_processed": "continu develop innov data mine technolog databas technolog larg number diversifi data continu show due uniqu busi valu directli impact peopl tradit way think enterpris want surviv competit big data era must reform tradit market mode automobil market accur grasp market situat seiz develop opportun creat greater develop space bring greater econom benefit automobil enterpris data mine realiz market posit enterpris posit consum group help formul automobil market strategi rapid develop data mine technolog diversifi data show import busi valu base data mine technolog paper analyz chang automobil market mode aim make healthi develop china automobil market mode make china continu develop expand automobil sale market"
  },
  {
    "doc_id": "10549245",
    "abstract_original": "Implicit Sentiment Analysis (ISA) is a crucial research area in natural language processing. Inspired by the idea of large language model Chain of Thought(CoT), this paper intro - duces a Sentiment Analysis of Thinking (SAoT) framework. The framework first analyzes the implicit aspects and opinions in the text using common sense and thinking chain capabilities. Then, it reflects on the process of implicit sentiment analysis, and finally, it deduces the polarity of sentiment. The model is evaluated on the SemEval 2014 dataset, consisting of 1120 restaurant reviews and 638 laptop reviews. The experimental results demonstrate that the utilization of the ERNIE-Bot-4+SAoT model yields a notable performance improvement. Specifically, on the restaurant dataset, the F1 score reaches 75.27, accompanied by an ISA score of 66.29. Similarly, on the computer dataset, the F1 score achieves 76.50, while the ISA score amounts to 73.46. Comparatively, the ERNIE- Bot-4+SAoT model surpasses the BERTAsp +SCAPT baseline by an average margin of 47.99%.",
    "abstract_processed": "implicit sentiment analysi isa crucial research area natur languag process inspir idea larg languag model chain thought cot paper intro duce sentiment analysi think saot framework framework first analyz implicit aspect opinion text use common sens think chain capabl reflect process implicit sentiment analysi final deduc polar sentiment model evalu semev dataset consist restaur review laptop review experiment result demonstr util erni bot saot model yield notabl perform improv specif restaur dataset f score reach accompani isa score similarli comput dataset f score achiev isa score amount compar erni bot saot model surpass bertasp scapt baselin averag margin"
  },
  {
    "doc_id": "10549249",
    "abstract_original": "Digitization technology refers to the processing and storage of information by computer language, which includes words, graphics, colors, relationships, etc. The digitized information is stored and calculated, and displayed again in different forms. Most of the existing clothing design software is a subsystem of clothing CAD system, and its design method is mainly to use the mouse to replace the paintbrush or to use graphics processing software to process clothing photos, which lacks professional advantages and poor practicability. At present, in view of the disadvantages of most fashion design softwares, which focus on simple list of styles and interactive drawing functions, we put forward a digital fashion design system. The garment style can be automatically generated according to the user's requirements for garment style, material and color, and can be adjusted for style change, part increase or decrease, movement and part size modification. At present, the digitization of the garment field has participated in the whole process of garment industry production: anthropometry, garment fashion trend prediction, style design, model design, push version, code release, garment production, production management, process management, e-commerce, garment marketing, customer information management, etc.",
    "abstract_processed": "digit technolog refer process storag inform comput languag includ word graphic color relationship etc digit inform store calcul display differ form exist cloth design softwar subsystem cloth cad system design method mainli use mous replac paintbrush use graphic process softwar process cloth photo lack profession advantag poor practic present view disadvantag fashion design softwar focu simpl list style interact draw function put forward digit fashion design system garment style automat gener accord user requir garment style materi color adjust style chang part increas decreas movement part size modif present digit garment field particip whole process garment industri product anthropometri garment fashion trend predict style design model design push version code releas garment product product manag process manag e commerc garment market custom inform manag etc"
  },
  {
    "doc_id": "10549899",
    "abstract_original": "Accurate carbon price prediction can help save energy and reduce emissions worldwide. Thus, this paper proposes a model that combines swarm intelligence algorithms with deep learning to predict carbon prices. In this model, we collect news related to carbon trading, construct a dictionary of carbon financial sentiment, and determine the emotional value of the carbon news. Secondly, The Harris Hawks Optimization (HHO) algorithm is improved by updating the escape energy and introducing the inertia weight. Then, the LSTM is optimized using the improved Harris Hawks Optimization (IHHO) algorithm. Finally, technical and emotional data on carbon price as multiple source input values are integrated, and the MS-IHHO-LSTM prediction model is established. The results show that the MAPE of IHHO-LSTM is 1.89%, 30.48%, and 10.30% better than that of HHO-LSTM in Hubei, Shanghai, and Shenzhen Carbon Exchanges, respectively. Similarly, MS-IHHO-LSTM showed a lower MAPE than IHHO-LSTM by 27.79%, 29.82%, and 6.33% in the corresponding regions. The results of the experiment indicate that: 1) Using IHHO to optimize LSTM hyperparameters can avoid falling into local optimal and improve prediction accuracy; 2) Incorporating emotional values can further enhance the model’s performance. The MS-IHHO-LSTM prediction model facilitates low-carbon investment, technological innovation, and green production, enabling enterprises to support environmental sustainability.",
    "abstract_processed": "accur carbon price predict help save energi reduc emiss worldwid thu paper propos model combin swarm intellig algorithm deep learn predict carbon price model collect news relat carbon trade construct dictionari carbon financi sentiment determin emot valu carbon news secondli harri hawk optim hho algorithm improv updat escap energi introduc inertia weight lstm optim use improv harri hawk optim ihho algorithm final technic emot data carbon price multipl sourc input valu integr ms ihho lstm predict model establish result show mape ihho lstm better hho lstm hubei shanghai shenzhen carbon exchang respect similarli ms ihho lstm show lower mape ihho lstm correspond region result experi indic use ihho optim lstm hyperparamet avoid fall local optim improv predict accuraci incorpor emot valu enhanc model’ perform ms ihho lstm predict model facilit low carbon invest technolog innov green product enabl enterpris support environment sustain"
  },
  {
    "doc_id": "10550416",
    "abstract_original": "Autism Spectrum Disorder is a neuro-development behavioural disorder that is classified as a chronic disability leaving individuals unable to accurately grasp their environment and can lead to limited development of communication skills, thinking and other social skills. Prediction of ASD using video recordings is an open-ended critical problem in machine learning to facilitate the process of early intervention which requires high computational resources. This research aims to predict ASD in children using videos by extracting features and converting them into a binary classification problem thereby eliminating the need for high computational resources. This research postulates a study of machine learning techniques like Logistic Regression, Decision Trees and Neural Networks in comparison for the prediction of ASD as well as a novel approach to reduce the computational requirements for the analysis of videos. This research also addresses the lack of publically available video datasets for the analysis of Autism. The highest accuracy metric for the models was using the Neural Network architecture closely followed by the Decision Tree Classifier which yielded accuracies of 99.8% and 99.65% respectively. In this article, we offer an overview of predicting Autism Spectrum Disorder whilst focusing on the importance of video datasets.",
    "abstract_processed": "autism spectrum disord neuro develop behaviour disord classifi chronic disabl leav individu unabl accur grasp environ lead limit develop commun skill think social skill predict asd use video record open end critic problem machin learn facilit process earli intervent requir high comput resourc research aim predict asd children use video extract featur convert binari classif problem therebi elimin need high comput resourc research postul studi machin learn techniqu like logist regress decis tree neural network comparison predict asd well novel approach reduc comput requir analysi video research also address lack public avail video dataset analysi autism highest accuraci metric model use neural network architectur close follow decis tree classifi yield accuraci respect articl offer overview predict autism spectrum disord whilst focus import video dataset"
  },
  {
    "doc_id": "10550813",
    "abstract_original": "Sri Lanka has taken the initiative through its new education reforms to introduce Artificial Intelligence (AI) as a compulsory content in the ICT curriculum of lower secondary education from 2025. This national task focused on applying a more appropriate pedagogical approach to make a relatively complex subject like AI easier for students to understand. When the literature is examined, it is seen that different teaching approaches were used to teach AI worldwide, and authentic learning has been considered the most appropriate method. This study was conducted to assess the applicability of the learning module, which has been developed based on authentic learning techniques to teach AI to grade six school children in Sri Lanka. A qualitative study was conducted among six ICT school teachers who engage in teaching for lower secondary grades. Participants were selected purposefully to gather more important views on the research question. Key informants’ interviews were conducted using a qualitative guide, and all interviews were audio recorded following informed consent. All recordings were reviewed, and important areas were identified. Results revealed that our module provides more opportunities for the students to learn AI with their real-life experiences, moves students from passive receivers of information to active participants in their own discovery process, increases their motivation and retention to learn AI and helps to improve 21stcentury skills, i.e., learning skills, literacy skills and life skills, of the learners. The analysis of the results provided strong evidence to conclude that the developed learning module will be useful in teaching AI to grade six school children in Sri Lanka using an authentic learning approach. Similarly, it will enhance the knowledge and skills of students related to AI in a more sustainable manner to prepare them for the challenges and opportunities of the 21st century and the 4th industrial revolution.",
    "abstract_processed": "sri lanka taken initi new educ reform introduc artifici intellig ai compulsori content ict curriculum lower secondari educ nation task focus appli appropri pedagog approach make rel complex subject like ai easier student understand literatur examin seen differ teach approach use teach ai worldwid authent learn consid appropri method studi conduct assess applic learn modul develop base authent learn techniqu teach ai grade six school children sri lanka qualit studi conduct among six ict school teacher engag teach lower secondari grade particip select purpos gather import view research question key informants’ interview conduct use qualit guid interview audio record follow inform consent record review import area identifi result reveal modul provid opportun student learn ai real life experi move student passiv receiv inform activ particip discoveri process increas motiv retent learn ai help improv stcenturi skill e learn skill literaci skill life skill learner analysi result provid strong evid conclud develop learn modul use teach ai grade six school children sri lanka use authent learn approach similarli enhanc knowledg skill student relat ai sustain manner prepar challeng opportun st centuri th industri revolut"
  },
  {
    "doc_id": "10552015",
    "abstract_original": "School graduates of technology profiles classes are often seen as the most prepared potential applicants for engineering universities. Future engineers will need to apply modeling to solve problems that emerge in professional activities building on the school primary engineering learning. The construction of physical processes 3D models in computer environments can aid in the development of engineering thinking and digital training. This requires the electronic educational resources design and the development of suitable methods. The collaboration between pedagogical and engineering universities can facilitate the accomplishment of these tasks provided with methodical basis and a consolidation of the universities scientific and practical developments in the network interaction. One of the popular areas for training future engineers is distance project design where tasks are distributed among several performers. The issue of interdisciplinary design of electronic educational resources to ensure the quality of engineering training in technological profiles in schools is significant for the theory and practice of innovation in engineering education, pedagogical methodology and technology, and digital didactics. The proposed methods include computer modeling of physical processes in engineering (using materials science example), pedagogical design, and educational outcomes analysis. The paper describes the results of experimental work on organizing interdisciplinary projects for the development of electronic educational resources for school engineering learning by student teams. These teams consist of pedagogical university students, future teachers, and polytechnic university students, future engineers. It concludes that interdisciplinary training of students from pedagogical and engineering universities in the electronic educational resources design on computer modeling for school primary engineering learning is effectively feasible using distributed educational technologies. The outcome may be useful for early schoolchildren involvement in innovative engineering initiatives through participation in research projects and STEM Olympiads including multi-language educational events.",
    "abstract_processed": "school graduat technolog profil class often seen prepar potenti applic engin univers futur engin need appli model solv problem emerg profession activ build school primari engin learn construct physic process model comput environ aid develop engin think digit train requir electron educ resourc design develop suitabl method collabor pedagog engin univers facilit accomplish task provid method basi consolid univers scientif practic develop network interact one popular area train futur engin distanc project design task distribut among sever perform issu interdisciplinari design electron educ resourc ensur qualiti engin train technolog profil school signific theori practic innov engin educ pedagog methodolog technolog digit didact propos method includ comput model physic process engin use materi scienc exampl pedagog design educ outcom analysi paper describ result experiment work organ interdisciplinari project develop electron educ resourc school engin learn student team team consist pedagog univers student futur teacher polytechn univers student futur engin conclud interdisciplinari train student pedagog engin univers electron educ resourc design comput model school primari engin learn effect feasibl use distribut educ technolog outcom may use earli schoolchildren involv innov engin initi particip research project stem olympiad includ multi languag educ event"
  },
  {
    "doc_id": "10555849",
    "abstract_original": "This paper underlines the crucial role of transdisciplinary approaches in overcoming complex educational challenges to accelerate learning and meet semiconductor industry workforce needs by combining neurosciences, psychology, education, and engineering. It examines the brain’s learning processes, focusing on sensory and neuroendocrine pathways, and adopts a neuroscience approach from a Control Systems perspective to enhance personalized learning. Using an unconventional analogy between human learning and industrial processes, the study introduces the Psychophysiological-Based Hypermedia Adaptive Automation System (PHAS) model. Employing Model-Based Systems Engineering (MBSE) with Systems Modeling Language (SysML), it develops the Engineering Learning Analytic System (ELAS) framework, featuring a rigorous Verification and Validation (VV) process to align stakeholder needs with system capabilities. ELAS simulations offer predictive insights into soft skill development, facilitating targeted educational interventions. The study aims to develop comprehensive engineers with critical thinking, creativity, problem-solving, communication, and teamwork skills, aligning with initiatives such as the Chips for America by integrating Multidimensional Teaching/Learning Methods to create more effective, inclusive, and holistic educational systems.",
    "abstract_processed": "paper underlin crucial role transdisciplinari approach overcom complex educ challeng acceler learn meet semiconductor industri workforc need combin neurosci psycholog educ engin examin brain’ learn process focus sensori neuroendocrin pathway adopt neurosci approach control system perspect enhanc person learn use unconvent analog human learn industri process studi introduc psychophysiolog base hypermedia adapt autom system pha model employ model base system engin mbse system model languag sysml develop engin learn analyt system ela framework featur rigor verif valid vv process align stakehold need system capabl ela simul offer predict insight soft skill develop facilit target educ intervent studi aim develop comprehens engin critic think creativ problem solv commun teamwork skill align initi chip america integr multidimension teach learn method creat effect inclus holist educ system"
  },
  {
    "doc_id": "10558738",
    "abstract_original": "How did an “old dog” signal processing professor approach learning and teaching the “new tricks” of generative artificial intelligence (AI)? This article overviews my recent experience in preparing and delivering a new course called “Computational Creativity,” reflecting on the methods I adopted compared to a traditional equations-on-a-whiteboard course. The technical material is qualitatively different from traditional signal processing, and the types of students who took the class and their approach to learning were different too. I learned a lot from the experience but also came away with bigger questions about the role of educators in the age of generative AI.",
    "abstract_processed": "“old dog” signal process professor approach learn teach “new tricks” gener artifici intellig ai articl overview recent experi prepar deliv new cours call “comput creativ ” reflect method adopt compar tradit equat whiteboard cours technic materi qualit differ tradit signal process type student took class approach learn differ learn lot experi also came away bigger question role educ age gener ai"
  },
  {
    "doc_id": "10560373",
    "abstract_original": "Autism Spectrum Disorder (ASD) which is neurological and developmental condition. ASD can be detected by observing distinct patterns in an individual's learning, behaviour, communication, decision making ability and social interactions. The ability to anticipate emotions can prove beneficial in various situations, particularly when dealing with individuals across the autism spectrum with varying degrees of severity. Decision- making encompasses not only intelligence and perception but also emotions. Emotion Detection is helpful in Bio Feedback Therapy for ASD. Positive emotions, for example mostly tend to facilitate forward-thinking and successful decision-making while negative emotions often contribute to poor well-being or depression. A transformer model, a type of neural network architecture, possesses the capability to automatically convert one form of input into another form of output. This work intends to investigate various signals that may be useful in identifying emotions for the purpose of predicting autism as well as transformer model-based algorithms that may be useful in determining the Autism Severity Grading. Similar methods are used now to assist those who are autistic. There is also discussion of medical applications using minimal parameters and methods.",
    "abstract_processed": "autism spectrum disord asd neurolog development condit asd detect observ distinct pattern individu learn behaviour commun decis make abil social interact abil anticip emot prove benefici variou situat particularli deal individu across autism spectrum vari degre sever decis make encompass intellig percept also emot emot detect help bio feedback therapi asd posit emot exampl mostli tend facilit forward think success decis make neg emot often contribut poor well depress transform model type neural network architectur possess capabl automat convert one form input anoth form output work intend investig variou signal may use identifi emot purpos predict autism well transform model base algorithm may use determin autism sever grade similar method use assist autist also discuss medic applic use minim paramet method"
  },
  {
    "doc_id": "10560485",
    "abstract_original": "Distributed storage, which is one of the main functions of distributed computing, enables clients of cloud services to think of their data as being stored in the cloud and to share it with qualified customers. In distributed storage, stable deduplication has been widely researched because it can eliminate overt repetitiveness within scrambled data to reduce storage space significantly. In the field of safety and protection, many current continuous deduplication schemes highlight to a large extent the associated characteristics: information classification, label consistency, access control animal attack assaults. One technique for ensuring the accuracy of information in garage outsourcing is confirmed information possession. The article discusses the development of a green PDP scheme for a distributed cloud garage to facilitate provider migration scalability and statistics, where we keep in mind the lifecycle of multiple cloud service providers to maintain and maintain collaborative customer statistics. The cooperative scheme relies entirely on verifiable homomorphic reactions. Completeness, knowledge soundness, and zero-knowledge qualities may all be satisfied by our multi-proof zero-knowledge proof system, which strengthens the security of our system. The experiment shows that this solution has lower computational and communication overhead than non-cooperative approaches.",
    "abstract_processed": "distribut storag one main function distribut comput enabl client cloud servic think data store cloud share qualifi custom distribut storag stabl dedupl wide research elimin overt repetit within scrambl data reduc storag space significantli field safeti protect mani current continu dedupl scheme highlight larg extent associ characterist inform classif label consist access control anim attack assault one techniqu ensur accuraci inform garag outsourc confirm inform possess articl discuss develop green pdp scheme distribut cloud garag facilit provid migrat scalabl statist keep mind lifecycl multipl cloud servic provid maintain maintain collabor custom statist cooper scheme reli entir verifi homomorph reaction complet knowledg sound zero knowledg qualiti may satisfi multi proof zero knowledg proof system strengthen secur system experi show solut lower comput commun overhead non cooper approach"
  },
  {
    "doc_id": "10562294",
    "abstract_original": "Today, teaching faces several challenges, including students’ difficulty in understanding abstract concepts and lack of motivation. To address these problems, the use of virtual reality (VR) has been explored as an innovative and potentially effective educational tool. However, so far, the effectiveness of VR applications and the perception of their use lack a clear and effective approach to be used to support education. The importance of addressing this problem lies in the need to improve the quality of teaching using emerging technologies. It is for this reason that it is important to find new strategies to improve the effectiveness of teaching using VR. In this context, this research presents the results of the FreeDev application, previously validated with 20 teachers and with 80 engineering students from a private university. FreeDev is a VR application designed to support the teaching of basic programming, it is aimed as an educational tool to provide an immersive experience to students on how to get started in programming and computational thinking. FreeDev has been well accepted, and both teachers and engineering students see it as a tool that can be used to support education. It is hoped that this research will contribute to the advancement of knowledge in the field of education.",
    "abstract_processed": "today teach face sever challeng includ students’ difficulti understand abstract concept lack motiv address problem use virtual realiti vr explor innov potenti effect educ tool howev far effect vr applic percept use lack clear effect approach use support educ import address problem lie need improv qualiti teach use emerg technolog reason import find new strategi improv effect teach use vr context research present result freedev applic previous valid teacher engin student privat univers freedev vr applic design support teach basic program aim educ tool provid immers experi student get start program comput think freedev well accept teacher engin student see tool use support educ hope research contribut advanc knowledg field educ"
  },
  {
    "doc_id": "10563364",
    "abstract_original": "Although artificial intelligence (AI) is changing the world quickly, training AI models still requires a lot of money and time. This is so because training an AI model needs a lot of data and processing power. A website that allows users to promote their AI model to other users and pay them for sharing their computer resources to help train it is one suggested solution to this problem. A blockchain-based strategy can be used to do this, and it offers numerous advantages such as lower expenses, effective resource pooling, task automation, precise remuneration, and a decrease in administrative overhead. AI models will thereby become more effective, more reasonably priced, and available to a larger variety of individuals and institutions.",
    "abstract_processed": "although artifici intellig ai chang world quickli train ai model still requir lot money time train ai model need lot data process power websit allow user promot ai model user pay share comput resourc help train one suggest solut problem blockchain base strategi use offer numer advantag lower expens effect resourc pool task autom precis remuner decreas administr overhead ai model therebi becom effect reason price avail larger varieti individu institut"
  },
  {
    "doc_id": "10565656",
    "abstract_original": "The STEM methodology has been applied in different study approaches, covering different areas such as arts, internet of things, computational thinking, among others. In this paper, two necessary approaches are addressed for the implementation of a closed-loop control system. The first approach (programming) is directly related to the software implementation and the second approach addresses the hardware instrumentation part. Both approaches are developed in a practical teaching case, from a STEM Maker workshop which consisted of 15 sessions with duration 2 hours each one. Each session consisted of 4 stages: Stage 1 (Theoretical concepts), Stage 2 (Practical Example), Stage 3 (Practice) and Stage 4 (challenge). Through these four stages, the development of skills of the attendees in the areas of programming and electronics was encouraged, applying the STEM Maker strategy. From some evaluation instruments, data was collected about the development of skills of the assistants in the implementation of software and hardware instrumentation, acquired in the STEM Maker workshop. The results indicated that approximately 70% of the workshop attendees developed the necessary skills to propose solutions to problems in their current context where the application of programming and/or electronics intervenes. The product obtained from the practice is described as a temperature control which integrates a feedback signal, this system has a wide field of applications which allowed the students of the STEM Maker workshop to achieve a project related to the individual context of each one.",
    "abstract_processed": "stem methodolog appli differ studi approach cover differ area art internet thing comput think among other paper two necessari approach address implement close loop control system first approach program directli relat softwar implement second approach address hardwar instrument part approach develop practic teach case stem maker workshop consist session durat hour one session consist stage stage theoret concept stage practic exampl stage practic stage challeng four stage develop skill attende area program electron encourag appli stem maker strategi evalu instrument data collect develop skill assist implement softwar hardwar instrument acquir stem maker workshop result indic approxim workshop attende develop necessari skill propos solut problem current context applic program electron interven product obtain practic describ temperatur control integr feedback signal system wide field applic allow student stem maker workshop achiev project relat individu context one"
  },
  {
    "doc_id": "10565688",
    "abstract_original": "In this work we, study the self-efficacy of the use of the Choreographe software in block programming using the NAO robot in order to develop instructional videos in the classroom within the framework of Computational Thinking. The put forward objectives were three; (1) Evaluate the level of significance of self-efficacy and the applicability of CT concepts. (2) Measure the relationship between the applicability of CT concepts with the ease of use, usefulness, attitude and intention to work in the future with an instructional program. (3) Establish the percentages and means of the items of the variables concepts CT and self-efficacy. Thus, from a quantitative approach, we propose to create a questionnaire to measure self-efficacy and the level of knowledge acquired in block programming. 4 practical workshops of 2 hours each have been carried out with 28 initial training students between the ages of 23 and 27. The results yielded a positive correlation between the variables self-efficacy and computational thinking. Highlighting a positive acceptance of self-efficacy in the use of Choreographe software in the block programming experience and a growing ascendancy of interaction.",
    "abstract_processed": "work studi self efficaci use choreograph softwar block program use nao robot order develop instruct video classroom within framework comput think put forward object three evalu level signific self efficaci applic ct concept measur relationship applic ct concept eas use use attitud intent work futur instruct program establish percentag mean item variabl concept ct self efficaci thu quantit approach propos creat questionnair measur self efficaci level knowledg acquir block program practic workshop hour carri initi train student age result yield posit correl variabl self efficaci comput think highlight posit accept self efficaci use choreograph softwar block program experi grow ascend interact"
  },
  {
    "doc_id": "10568269",
    "abstract_original": "Many undergraduate students in software engineering have trouble developing computational thinking. Several tools have been reported in the literature to support the development of computational thinking. This paper reports a Systematic Literature Review to present the characteristics that have made successful web systems that support the development of computational thinking in recent years and the reported limitations. Eighteen primary studies were selected where the strategies used are usually learning through lessons, practicing with exercises, working through games, and using feedback. The systems found have been used at different elementary, middle, high school, and bachelor's degree levels. Finally, the main limitations reported in using these systems were mainly the difficulty of the topics, the previous knowledge that the students should have, the attitude that the students showed and the lack of motivation. Finally, we make some recommendations to software engineering curriculum planners and programming teachers about systems for developing computational thinking.",
    "abstract_processed": "mani undergradu student softwar engin troubl develop comput think sever tool report literatur support develop comput think paper report systemat literatur review present characterist made success web system support develop comput think recent year report limit eighteen primari studi select strategi use usual learn lesson practic exercis work game use feedback system found use differ elementari middl high school bachelor degre level final main limit report use system mainli difficulti topic previou knowledg student attitud student show lack motiv final make recommend softwar engin curriculum planner program teacher system develop comput think"
  },
  {
    "doc_id": "10568376",
    "abstract_original": "Cloud adoption in industrial sectors, such as process, manufacturing, health care, and finance, is steadily rising, but as it grows, the risk of targeted cyberattacks has increased. Hence, effectively defending against such attacks necessitates skilled cybersecurity professionals. Traditional human-based cyber-physical education is resource intensive and faces challenges in keeping pace with rapidly evolving technologies. This research focuses on the main advantages of incorporating large language models into cyber-physical education. The ChatGPT platform serves as an online tool to educate students on fundamentals, cyberattacks, and defense concepts, fostering the development of a new generation cybersecurity experts. The proposed learning approach adheres to the ChatGPT-assisted learn–apply–create model. Responding to prompts provided by the learners, the learning phase engages in conceptual learning, the applying phase involves mathematical modeling of various cyberattacks, and the creating phase develops MATLAB program to incorporate attacks into sensor measurements for the experiment and entails developing the necessary attack detection approaches. The effectiveness of the detection method developed by ChatGPT is assessed in both the simulation and real-time scenarios using a J-type thermocouple. The impact of the proposed learning platform over traditional learning methods is evaluated through an extensive comparative feedback analysis on the learner's foundational concepts, computational thinking, programming efficacy, and motivation. The study proved that integrating ChatGPT into engineering education enables students to swiftly learn cyber-physical fundamentals, comprehend and model cyberattacks, create new attack signatures, and contribute to developing detection algorithms. Such integration provides the learners with essential industrial skills crucial in modern industries.",
    "abstract_processed": "cloud adopt industri sector process manufactur health care financ steadili rise grow risk target cyberattack increas henc effect defend attack necessit skill cybersecur profession tradit human base cyber physic educ resourc intens face challeng keep pace rapidli evolv technolog research focus main advantag incorpor larg languag model cyber physic educ chatgpt platform serv onlin tool educ student fundament cyberattack defens concept foster develop new gener cybersecur expert propos learn approach adher chatgpt assist learn–apply–cr model respond prompt provid learner learn phase engag conceptu learn appli phase involv mathemat model variou cyberattack creat phase develop matlab program incorpor attack sensor measur experi entail develop necessari attack detect approach effect detect method develop chatgpt assess simul real time scenario use j type thermocoupl impact propos learn platform tradit learn method evalu extens compar feedback analysi learner foundat concept comput think program efficaci motiv studi prove integr chatgpt engin educ enabl student swiftli learn cyber physic fundament comprehend model cyberattack creat new attack signatur contribut develop detect algorithm integr provid learner essenti industri skill crucial modern industri"
  },
  {
    "doc_id": "10568728",
    "abstract_original": "Neural networks (NN) and machine learning (ML) techniques are gradually replacing true critical thinking. These methods surpass logical and quantitative approaches because they can handle massive boundaries in massive amounts of data and dynamic behavior over time. This article lays the groundwork for adaptive traffic control by proposing ML and DL calculations for crossing point traffic flow prediction. Adaptable traffic control can be accomplished by adjusting traffic light timing based on expected flow or by controlling traffic lights partially. That is why traffic flow prediction is the only focus here. The suggested ML and DL models are created, approved, and tested using two publicly available datasets. The first one gives a total of all cars analyzed by various sensors over a 56-day period, including clocks placed at six different crossroads. The ML and DL models used in this study were developed using four out of the six crossings. Subsequently, Multi-facet Perceptron Brain Organizations (MLP-NN) dealt with Irregular Backwoods, Direct Relapse, and Stochastic Inclination; MLP-NN required less preparation time but produced better results (R-Squared and EV score of 1.93) than Intermittent Brain Organizations (RNNs), which produced excellent measurement results but required more time overall. All ML and DL computations have excellent execution results, which makes them a good fit for intelligent traffic light management.",
    "abstract_processed": "neural network nn machin learn ml techniqu gradual replac true critic think method surpass logic quantit approach handl massiv boundari massiv amount data dynam behavior time articl lay groundwork adapt traffic control propos ml dl calcul cross point traffic flow predict adapt traffic control accomplish adjust traffic light time base expect flow control traffic light partial traffic flow predict focu suggest ml dl model creat approv test use two publicli avail dataset first one give total car analyz variou sensor day period includ clock place six differ crossroad ml dl model use studi develop use four six cross subsequ multi facet perceptron brain organ mlp nn dealt irregular backwood direct relaps stochast inclin mlp nn requir less prepar time produc better result r squar ev score intermitt brain organ rnn produc excel measur result requir time overal ml dl comput excel execut result make good fit intellig traffic light manag"
  },
  {
    "doc_id": "10568789",
    "abstract_original": "The use of social media, such as Facebook, Twitter, WhatsApp, WeChat, and others have grown exponentially over time with the growth of the Internet and has become the most influential networking platforms in the 21st century. They are well-known for their low-cost, quick, and effective communication. However, the enhancement of social connectivity often creates negative impacts on society that contributes to online abuse, harassment, cyberbullying, cyber flashing, cybercrime, and online trolling. In this paper, we are focusing on cyber-flashing, the unsolicited sending of nude or sexual images, which is a common practice but often met with negative reactions from receivers. During and after COVID lockdown, cyber-flashing has been a serious threat on WhatsApp recently. The majority of study, meanwhile, has focused on identifying instances of cyberbullying rather than the effects of cyber-flashing. Cyber-flashing is the act of sending an inappropriate photo or video to another person, as well as exposing oneself to another via live video. An essential step in the detection of cyber-flashing is evaluating the level of risk in terms of abusiveness in the provided picture, or video. Therefore, the goal of this research is to create and refine a method that can effectively identify abusive cyber-flashing content and prevent inappropriate content sharing within the social media platforms or public Wi-Fi network. As a result, we have proposed a unique technique, where we employ a multi- stage model for identifying cyber-flashing photos and the proposed YOLOv3-YCbCr performs best in terms of metrics, with 98.14% accuracy, 95.58% specificity, and 97.27% sensitivity. First, the YOLOv3 technique is used to detect human presence in the image. Then, the YCbCr model is used for the skin detection and analysis. In the context of intelligent systems, skin detection is a difficult topic that has drawn a lot of attention from specialists and experts from the research community; the lack of uniform testing methodologies and standard benchmarks have made it difficult to compare different approaches fairly. Based on our studies, YOLOv3-YCbCr performs far better for skin segmentation than any prior hand-crafted approach method.",
    "abstract_processed": "use social media facebook twitter whatsapp wechat other grown exponenti time growth internet becom influenti network platform st centuri well known low cost quick effect commun howev enhanc social connect often creat neg impact societi contribut onlin abus harass cyberbulli cyber flash cybercrim onlin troll paper focus cyber flash unsolicit send nude sexual imag common practic often met neg reaction receiv covid lockdown cyber flash seriou threat whatsapp recent major studi meanwhil focus identifi instanc cyberbulli rather effect cyber flash cyber flash act send inappropri photo video anoth person well expos oneself anoth via live video essenti step detect cyber flash evalu level risk term abus provid pictur video therefor goal research creat refin method effect identifi abus cyber flash content prevent inappropri content share within social media platform public wi fi network result propos uniqu techniqu employ multi stage model identifi cyber flash photo propos yolov ycbcr perform best term metric accuraci specif sensit first yolov techniqu use detect human presenc imag ycbcr model use skin detect analysi context intellig system skin detect difficult topic drawn lot attent specialist expert research commun lack uniform test methodolog standard benchmark made difficult compar differ approach fairli base studi yolov ycbcr perform far better skin segment prior hand craft approach method"
  },
  {
    "doc_id": "10569190",
    "abstract_original": "We propose a novel approach to Arabic story generation by fine-tuning a pre-trained Large Language Model (LLM). Our pipeline includes two stages: text generation and image generation. By fine-tuning the davinci-003 LLM on a dataset of 527 Arabic stories, we tailor the generated stories based on user preferences. For image generation, we utilize the Midjourney model. The results demonstrate the efficacy of fine-tuning a pre-trained image generation model on a limited dataset, as measured by the ROUGE score. Sarid's contributions include addressing the lack of Arabic story generation models, providing a comprehensive dataset of Arabic stories, and integrating text and image generation for a cohesive story generation pipeline.",
    "abstract_processed": "propos novel approach arab stori gener fine tune pre train larg languag model llm pipelin includ two stage text gener imag gener fine tune davinci llm dataset arab stori tailor gener stori base user prefer imag gener util midjourney model result demonstr efficaci fine tune pre train imag gener model limit dataset measur roug score sarid contribut includ address lack arab stori gener model provid comprehens dataset arab stori integr text imag gener cohes stori gener pipelin"
  },
  {
    "doc_id": "10569762",
    "abstract_original": "In this paper, we present a proposal for a series of STEAM activities developing students’ computational thinking, improving their health literacy, and consequently taking care of their own well-being. The implementation of these activities in the classroom requires not only the knowledge and skills of informatics and biology, but also the collaboration of teachers of both subjects. These activities are implemented in phases, starting in biology lesson and continuing in informatics lesson. The first activity tests the level of sensitivity of people to colour differences. The second activity trains human adaptation to psychological stress. The third activity is focused on creation of compensatory aid that compensates for colour perception disorder. The design and programming of students’ STEAM applications is a meaningful way to use informatics in problem solving. Using and experimenting with these applications helps students to better understand the biological content. STEAM approach strengthens students’ orientation towards interdisciplinary studies (e.g. bioinformatics) at the higher education level and helps them to be more employable in the labour market.",
    "abstract_processed": "paper present propos seri steam activ develop students’ comput think improv health literaci consequ take care well implement activ classroom requir knowledg skill informat biolog also collabor teacher subject activ implement phase start biolog lesson continu informat lesson first activ test level sensit peopl colour differ second activ train human adapt psycholog stress third activ focus creation compensatori aid compens colour percept disord design program students’ steam applic meaning way use informat problem solv use experi applic help student better understand biolog content steam approach strengthen students’ orient toward interdisciplinari studi e g bioinformat higher educ level help employ labour market"
  },
  {
    "doc_id": "10569858",
    "abstract_original": "The South African government continuously strives to work on the development of legislations that protect the confidentiality, integrity, and availability of its citizen's information in the digital space. The contagion of the Coronavirus (COVID-19) led to a global lockdown that put governments in emergency mode. Post-COVID-19, the benefits of digitization became more noticeable. During the lockdown era cloud computing proved its effectiveness and efficiency in helping employees continue working even outside of their workstations. The objective of this paper is to scrutinize the current state of cloud data protection in the public sector within South Africa. The emphasis is placed on the draft National policy for cloud and data storage. This paper also makes recommendations to further strengthen and improve the current state of South Africa's cloud and data storage. It goes further to review existing legislations such as POPI, ECT, and cyber law acts and their relevance to the draft National Data and Cloud Policy. A proposal for a model that incorporates the cloud-shared responsibility model is presented and briefly discussed.",
    "abstract_processed": "south african govern continu strive work develop legisl protect confidenti integr avail citizen inform digit space contagion coronaviru covid led global lockdown put govern emerg mode post covid benefit digit becam notic lockdown era cloud comput prove effect effici help employe continu work even outsid workstat object paper scrutin current state cloud data protect public sector within south africa emphasi place draft nation polici cloud data storag paper also make recommend strengthen improv current state south africa cloud data storag goe review exist legisl popi ect cyber law act relev draft nation data cloud polici propos model incorpor cloud share respons model present briefli discuss"
  },
  {
    "doc_id": "10569899",
    "abstract_original": "Advances in computer technology have expanded our capacity to solve problems on a scale never imagined, using strategies previously unavailable to us. Today’s \"digital natives\" have grown up in a world where technology is rapidly evolving, creating new fields of study, new types of jobs, and requiring new skill sets. Algorithmic and computational thinking are foundations for solving different problems from all domains and are not always closely related to computers and programming. They are currently primarily used in teaching computer science and STEM subjects but can be applied to all subjects and in all life situations. The paper presents the need to develop computational thinking in various subjects of primary education, with particular emphasis on combining digital (\"plugged\") and non-digital (\"unplugged\") activities, as well as on the development of algorithmic thinking. Four methodological scenarios with activities for the development of algorithmic thinking in primary education are presented.",
    "abstract_processed": "advanc comput technolog expand capac solv problem scale never imagin use strategi previous unavail us today’ digit nativ grown world technolog rapidli evolv creat new field studi new type job requir new skill set algorithm comput think foundat solv differ problem domain alway close relat comput program current primarili use teach comput scienc stem subject appli subject life situat paper present need develop comput think variou subject primari educ particular emphasi combin digit plug non digit unplug activ well develop algorithm think four methodolog scenario activ develop algorithm think primari educ present"
  },
  {
    "doc_id": "10571575",
    "abstract_original": "Factor graph, as a bipartite graphical model, offers a structured representation by revealing local connections among graph nodes. This study explores the utilization of factor graphs in modeling the autonomous racecar planning problem, presenting an alternate perspective to the traditional optimizationbased formulation. We model the planning problem as a probabilistic inference over a factor graph, with factor nodes capturing the joint distribution of motion objectives. By leveraging the duality between optimization and inference, a fast solution to the maximum a posteriori estimation of the factor graph is obtained via least-squares optimization. The localized design thinking inherent in this formulation ensures that motion objectives depend on a small subset of variables. We exploit the locality feature of the factor graph structure to integrate the minimum curvature path and local planning computations into a unified algorithm. This diverges from the conventional separation of global and local planning modules, where curvature minimization occurs at the global level. The evaluation of the proposed framework demonstrated superior performance for cumulative curvature and average speed across the racetrack. Furthermore, the results highlight the computational efficiency of our approach. While acknowledging the structural design advantages and computational efficiency of the proposed methodology, we also address its limitations and outline potential directions for future research.",
    "abstract_processed": "factor graph bipartit graphic model offer structur represent reveal local connect among graph node studi explor util factor graph model autonom racecar plan problem present altern perspect tradit optimizationbas formul model plan problem probabilist infer factor graph factor node captur joint distribut motion object leverag dualiti optim infer fast solut maximum posteriori estim factor graph obtain via least squar optim local design think inher formul ensur motion object depend small subset variabl exploit local featur factor graph structur integr minimum curvatur path local plan comput unifi algorithm diverg convent separ global local plan modul curvatur minim occur global level evalu propos framework demonstr superior perform cumul curvatur averag speed across racetrack furthermor result highlight comput effici approach acknowledg structur design advantag comput effici propos methodolog also address limit outlin potenti direct futur research"
  },
  {
    "doc_id": "10574406",
    "abstract_original": "In a previous “Games” column, I raised the question of whether OpenAI’s Sora could generate the complete Pixar animated film Toy Story. We discuss how to think about the computational requirements of such an endeavor.",
    "abstract_processed": "previou “games” column rais question whether openai’ sora could gener complet pixar anim film toy stori discuss think comput requir endeavor"
  },
  {
    "doc_id": "10575471",
    "abstract_original": "Neural Style Transfer (NST) is an influential technique in the field of deep learning that combines the content of one image with the style of another, resulting in visually impressive compositions. By utilizing Convolutional Neural Networks (CNNs) such as VGG19, a well-known pretrained model that excels at extracting advanced characteristics from images, NST algorithms may efficiently isolate and merge content and style representations. This project aims to create a user-friendly Neural Style Transfer (NST) application. The frontend of the program will be constructed using React, enabling users to easily upload their content and style images. Next, the user can initiate the process of neural style transfer by clicking on the style transfer button. The computational process of style transfer is managed by a backend system that utilizes Celery, a distributed task queue, and Redis, an in-memory data structure store. This architectural design allows for effective asynchronous execution of style transfer activities, assuring the ability to handle large workloads while maintaining scalability and responsiveness. Our NST application combines advanced deep learning algorithms with modern web development technology to make artistic creativity accessible to everyone. Users may effortlessly produce compelling visual compositions with just a few clicks. Our website provides a smooth and entertaining experience for both beginners and expert users, whether they want to turn regular photos into works of art resembling famous styles or explore innovative combinations. The proposed NST application combines state-of-the-art algorithms with a user-friendly interface, making powerful AI-driven creativity accessible to everyone.",
    "abstract_processed": "neural style transfer nst influenti techniqu field deep learn combin content one imag style anoth result visual impress composit util convolut neural network cnn vgg well known pretrain model excel extract advanc characterist imag nst algorithm may effici isol merg content style represent project aim creat user friendli neural style transfer nst applic frontend program construct use react enabl user easili upload content style imag next user initi process neural style transfer click style transfer button comput process style transfer manag backend system util celeri distribut task queue redi memori data structur store architectur design allow effect asynchron execut style transfer activ assur abil handl larg workload maintain scalabl respons nst applic combin advanc deep learn algorithm modern web develop technolog make artist creativ access everyon user may effortlessli produc compel visual composit click websit provid smooth entertain experi beginn expert user whether want turn regular photo work art resembl famou style explor innov combin propos nst applic combin state art algorithm user friendli interfac make power ai driven creativ access everyon"
  },
  {
    "doc_id": "10575903",
    "abstract_original": "IoT devices have changed into one of the mainstays in areas like houses, industry and education, resulting in a level of convenience and efficiency that has never been achieved before. Even though the most important advantage of the distributed network is raising the level of security, the problem of security vulnerabilities with the extended networks remains. This paper is devoted to a novel strategy of Federated Learning (FL) that could become an applied solution for enhancing the safety of the IoT. Therefore, based on its decentralized knowledge process, FL allows IoT devices to cooperate in achieving common purposes without endangering data pri vacy. The paper uses this thinking method to deal with scalability, model personalization, and non-IID data that aren’t IID distributing, suggesting solutions through model aggregation techniques or Artificial Intelligence (AI). Experimental evidence highlights that FL is very useful in enhancing IoT security irrespective of the diversity of its applications. To this end, residents of smart homes experienced a 17% increase in detecting the anomalies through the setting up of FL. This situation was replicated in the industrial Internet of Things, where the false positive rates were reduced from 20% to 5%, thus improving the system’s efficiency. Furthermore, in the FL context in healthcare IoT ecosystems, this blazes a trail for privacy-preserving data analytics, preserving patient confidentiality and systematic profiling of noteworthy health trends. These findings thus demonstrate that FL is a feasible way of dealing with the security challenges of IoT scalable, promptly and in a manner that maintains user privacy. The article takes part in a conversation about ways to strengthen the security of IoT networks. Such a framework is based on the computational power of IoT devices. It allows us to detect and prevent threats in time. Nonetheless, it urges extensive R&D attempts to be introduced to develop better security solutions in IoT. Without the involvement of different technologies, it won’t be easy to ensure safety and create some reliable IoT ecosystems.",
    "abstract_processed": "iot devic chang one mainstay area like hous industri educ result level conveni effici never achiev even though import advantag distribut network rais level secur problem secur vulner extend network remain paper devot novel strategi feder learn fl could becom appli solut enhanc safeti iot therefor base decentr knowledg process fl allow iot devic cooper achiev common purpos without endang data pri vaci paper use think method deal scalabl model person non iid data aren’t iid distribut suggest solut model aggreg techniqu artifici intellig ai experiment evid highlight fl use enhanc iot secur irrespect divers applic end resid smart home experienc increas detect anomali set fl situat replic industri internet thing fals posit rate reduc thu improv system’ effici furthermor fl context healthcar iot ecosystem blaze trail privaci preserv data analyt preserv patient confidenti systemat profil noteworthi health trend find thu demonstr fl feasibl way deal secur challeng iot scalabl promptli manner maintain user privaci articl take part convers way strengthen secur iot network framework base comput power iot devic allow us detect prevent threat time nonetheless urg extens r attempt introduc develop better secur solut iot without involv differ technolog won’t easi ensur safeti creat reliabl iot ecosystem"
  },
  {
    "doc_id": "10576494",
    "abstract_original": "Game-based learning (GBL) has been shown to enhance engagement, comprehension of course material, and academic achievements. This study aims to investigate previous studies on integrating computational thinking (CT) abilities in STEM education through GBL and propose a framework for integrating CT through the GBL framework. The proposed framework focuses on certain domains in creating mobile gaming content that facilitates the user's acquisition of knowledge about the advancement of CT in science, specifically within the STEM discipline. In addition, a comprehensive literature review was undertaken to identify a specific research need. In the proposed framework, this study emphasized more that CT is implemented as an approach to attract the involvement of students in STEM education through the framework. To foster more engagement, the development of CT should consider STEM-appropriate components of the framework by optimizing software and hardware functions.",
    "abstract_processed": "game base learn gbl shown enhanc engag comprehens cours materi academ achiev studi aim investig previou studi integr comput think ct abil stem educ gbl propos framework integr ct gbl framework propos framework focus certain domain creat mobil game content facilit user acquisit knowledg advanc ct scienc specif within stem disciplin addit comprehens literatur review undertaken identifi specif research need propos framework studi emphas ct implement approach attract involv student stem educ framework foster engag develop ct consid stem appropri compon framework optim softwar hardwar function"
  },
  {
    "doc_id": "10577151",
    "abstract_original": "This work contributes to the comprehension of Bayes’ theorem inclusive Bayesian probabilities and Bayesian inferencing within the framework of STEM (Science, Technology, Engineering, Arts, and Mathematics) and cognitive learning w.r.t Bloom’s taxonomy (BT). Bayes’ theorem is taken as a crucial statistical instrument employed in the development of intelligent systems and the management of risks, commonly utilized by engineers for tasks in machine learning and managerial decision-making. The fundamental concept behind Bayes’ theorem revolves around comprehending the degree of truth within the confines of an explicit perspective. This involves partitioning the entire sample space of possible evidence and utilizing the subset containing the relevant perspective to estimate the uncertainty of an event or the reliability of a model. However, it is often found difficult for students to understand Bayes’ theorem to the level of applying it to real-world problems. Considering this, the proposed learning method in this paper elucidated the acquisition of Bayes’ mathematical formulation by leveraging computational thinking, leading to the development of a computational model. The proposed model is named the Bayesian Computational Learning Model (BCLM). Subsequently, we have probed the utility of BCLM in the design and plan of learning activities, coherent to the STEM paradigm and BT cognitive learning hierarchy.",
    "abstract_processed": "work contribut comprehens bayes’ theorem inclus bayesian probabl bayesian inferenc within framework stem scienc technolog engin art mathemat cognit learn w r bloom’ taxonomi bt bayes’ theorem taken crucial statist instrument employ develop intellig system manag risk commonli util engin task machin learn manageri decis make fundament concept behind bayes’ theorem revolv around comprehend degre truth within confin explicit perspect involv partit entir sampl space possibl evid util subset contain relev perspect estim uncertainti event reliabl model howev often found difficult student understand bayes’ theorem level appli real world problem consid propos learn method paper elucid acquisit bayes’ mathemat formul leverag comput think lead develop comput model propos model name bayesian comput learn model bclm subsequ probe util bclm design plan learn activ coher stem paradigm bt cognit learn hierarchi"
  },
  {
    "doc_id": "10577164",
    "abstract_original": "In the dynamic landscape of contemporary education, the evolution of teaching strategies such as blended learning and flipped classrooms has highlighted the need for efficient and effective generation of multiple-choice questions (MCQs). To address this, we introduce MCQGen, a novel generative artificial intelligence framework designed for the automated creation of MCQs. MCQGen uniquely integrates a large language model (LLM) with retrieval-augmented generation and advanced prompt engineering techniques, drawing from an extensive external knowledge base. This integration significantly enhances the ability of the LLM to produce educationally relevant questions that align with both the goals of educators and the diverse learning needs of students. The framework employs innovative prompt engineering, combining chain-of-thought and self-refine prompting techniques, to enhance the performance of the LLM. This process leads to the generation of questions that are not only contextually relevant and challenging but also reflective of common student misconceptions, contributing effectively to personalized learning experiences and enhancing student engagement and understanding. Our extensive evaluations showcase the effectiveness of MCQGen in producing high-quality MCQs for various educational needs and learning styles. The framework demonstrates its potential to significantly reduce the time and expertise required for MCQ creation, marking its practical utility in modern education. In essence, MCQGen offers an innovative and robust solution for the automated generation of MCQs, enhancing personalized learning in the digital era.",
    "abstract_processed": "dynam landscap contemporari educ evolut teach strategi blend learn flip classroom highlight need effici effect gener multipl choic question mcq address introduc mcqgen novel gener artifici intellig framework design autom creation mcq mcqgen uniqu integr larg languag model llm retriev augment gener advanc prompt engin techniqu draw extens extern knowledg base integr significantli enhanc abil llm produc educ relev question align goal educ divers learn need student framework employ innov prompt engin combin chain thought self refin prompt techniqu enhanc perform llm process lead gener question contextu relev challeng also reflect common student misconcept contribut effect person learn experi enhanc student engag understand extens evalu showcas effect mcqgen produc high qualiti mcq variou educ need learn style framework demonstr potenti significantli reduc time expertis requir mcq creation mark practic util modern educ essenc mcqgen offer innov robust solut autom gener mcq enhanc person learn digit era"
  },
  {
    "doc_id": "10578593",
    "abstract_original": "A Virtual Reality (VR) ambiance can simulate real-world scenarios and problems, allowing students to apply their theoretical knowledge to practical situations. The design of the VR ambiance should align with the learning objectives and provide relevant challenges and tasks that require students to use their computer technology skills to solve problems. A well-designed VR ambiance can encourage exploration and creativity in computer technology students. By providing a virtual space that allows experimentation and innovation, students can explore different approaches, test ideas, and think creatively when solving problems. This paper studies how students and professors evaluated the development of competencies during an extracurricular project for the development of a virtual interactive environment for learning a process. Designing an interactive virtual environment will require the implementation of various interactive elements, such as 3D objects, user interfaces, and animations. Students can apply their programming skills to create the necessary functionality in the virtual environment. To create an attractive and easy-to-use virtual environment, students will need to consider UX design principles. In this case, the competencies to be measured were: Solving problems generating efficient computational algorithms under models and tools of computer science and developing software applying process and quality standards of Software Engineering. To assess compliance with the development of competencies, it was decided to develop an interactive virtual environment; this is a process that involves several stages, from conceptualization to implementation and testing. The objectives of the virtual environment were established. In this case, it was decided to develop an environment that would help the user learn how to change a flat tire. A plan was created detailing how users will interact with the virtual environment. Early results show that more than 50% of the students outstandingly developed problem-solving competence, additionally, if we add the students who obtained a solid evaluation, the percentage of students who developed the competence in a more than acceptable way would go up to 93%. These results, also show that more than 70% of the students outstandingly developed software development competence. In addition, if we add the students who obtained a solid evaluation, the percentage of students who developed competence in a more than acceptable way would rise to 92%.",
    "abstract_processed": "virtual realiti vr ambianc simul real world scenario problem allow student appli theoret knowledg practic situat design vr ambianc align learn object provid relev challeng task requir student use comput technolog skill solv problem well design vr ambianc encourag explor creativ comput technolog student provid virtual space allow experiment innov student explor differ approach test idea think creativ solv problem paper studi student professor evalu develop compet extracurricular project develop virtual interact environ learn process design interact virtual environ requir implement variou interact element object user interfac anim student appli program skill creat necessari function virtual environ creat attract easi use virtual environ student need consid ux design principl case compet measur solv problem gener effici comput algorithm model tool comput scienc develop softwar appli process qualiti standard softwar engin assess complianc develop compet decid develop interact virtual environ process involv sever stage conceptu implement test object virtual environ establish case decid develop environ would help user learn chang flat tire plan creat detail user interact virtual environ earli result show student outstandingli develop problem solv compet addit add student obtain solid evalu percentag student develop compet accept way would go result also show student outstandingli develop softwar develop compet addit add student obtain solid evalu percentag student develop compet accept way would rise"
  },
  {
    "doc_id": "10578599",
    "abstract_original": "Problem solving plays a central role in computer science classes, whereby the problems to be analyzed are often already available in encoded form. The initial process where the learners have to parse information into symbols using adequate representations, has hardly been considered systematically so far. However, encoding development is essential for the understanding of sign processes and for general education. This paper therefore presents the development and evaluation of a teaching unit called “Cup Song Encoding” designed to model information encoding using a percussion song as an example. It simultaneously imparts coding theory concepts and fosters Computational Thinking of students. The material of the teaching unit is available online. The teaching unit was successfully tested with over 200 students in different age groups in K-12 during which the students' solutions were recorded and examined. The outcomes of the unit demonstrate the potential for encoding modeling to be a valuable addition to K-12 computer science education. The results also show how Computational Thinking methods can be integrated in computer science classes.",
    "abstract_processed": "problem solv play central role comput scienc class wherebi problem analyz often alreadi avail encod form initi process learner pars inform symbol use adequ represent hardli consid systemat far howev encod develop essenti understand sign process gener educ paper therefor present develop evalu teach unit call “cup song encoding” design model inform encod use percuss song exampl simultan impart code theori concept foster comput think student materi teach unit avail onlin teach unit success test student differ age group k student solut record examin outcom unit demonstr potenti encod model valuabl addit k comput scienc educ result also show comput think method integr comput scienc class"
  },
  {
    "doc_id": "10578608",
    "abstract_original": "In the digital age, programming education has become increasingly important, even in primary schools. However, introducing programming at such an early stage presents unique challenges, given the need for students to grasp mathematical concepts, abstract thinking, and the intricacies of programming syntax. Educational Data Mining (EDM) offers a potential contribution by predicting learning performance, facilitating the optimization of the learning processes, and providing real-time guidance. A notable gap in the current literature about EDM in programming education is its predominant emphasis on the university level. Our research objectives were to identify features influencing primary school students' programming capabilities. A more comprehensive dataset was introduced, incorporating psychometric data and highlighting features such as learning motivation and attitude, computational thinking data, and other potentially influential variables, which set our study apart from previous studies. We found that the strongest predictor was academic performance in Information Technology, followed by psychometric data on students' learning attitudes and motivation. Computational thinking also emerged as a significant feature in predicting programming performance. It's worth highlighting that involvement in extra-curricular activities, like Olympic Mathematics training, showed a significant association, underscoring the importance of mathematical logic and reasoning in programming. This is further bolstered by the evident correlation with academic performance in Mathematics, confirming its pivotal role in shaping programming abilities. Interestingly, the correlation of academic performance in Chinese is also significant, indicating that the language medium of instruction can notably influence success.",
    "abstract_processed": "digit age program educ becom increasingli import even primari school howev introduc program earli stage present uniqu challeng given need student grasp mathemat concept abstract think intricaci program syntax educ data mine edm offer potenti contribut predict learn perform facilit optim learn process provid real time guidanc notabl gap current literatur edm program educ predomin emphasi univers level research object identifi featur influenc primari school student program capabl comprehens dataset introduc incorpor psychometr data highlight featur learn motiv attitud comput think data potenti influenti variabl set studi apart previou studi found strongest predictor academ perform inform technolog follow psychometr data student learn attitud motiv comput think also emerg signific featur predict program perform worth highlight involv extra curricular activ like olymp mathemat train show signific associ underscor import mathemat logic reason program bolster evid correl academ perform mathemat confirm pivot role shape program abil interestingli correl academ perform chines also signific indic languag medium instruct notabl influenc success"
  },
  {
    "doc_id": "10578626",
    "abstract_original": "There is a need to increase the number of students, especially women, choosing programming and STEM disciplines. We need innovative approaches in schools to better engage students and awake their interest in computer science. This paper addresses the need to create tools that effectively support the learning of programming and the development of computational thinking, highlighting why video games can be an effective educational tool for it and also attract new students to STEM. The Game4Coding Erasmus+ project proposes the design of a video game called CodeQuest, using a game genre that has not been frequently used before to address the teaching of programming, the monster tamer genre. We consider that video games have a number of benefits such as that stimulate active learning, are engaging for a wide range of students, and present information in a way that is attractive to learners. We want to explore this kind of game's effectiveness as a learning tool as well as its effect on the perception of STEM disciplines and programming to attract new public to coding (especially girls).",
    "abstract_processed": "need increas number student especi women choos program stem disciplin need innov approach school better engag student awak interest comput scienc paper address need creat tool effect support learn program develop comput think highlight video game effect educ tool also attract new student stem game code erasmu project propos design video game call codequest use game genr frequent use address teach program monster tamer genr consid video game number benefit stimul activ learn engag wide rang student present inform way attract learner want explor kind game effect learn tool well effect percept stem disciplin program attract new public code especi girl"
  },
  {
    "doc_id": "10578653",
    "abstract_original": "In recent years, educational research has emphasized the significance of computational thinking (CT) and mathematics knowledge acquisition for students' learning in engineering subjects. Pre-college education plays a crucial role in preparing students for future engineering learning. While the relationship between CT and mathematics has been extensively studied at the K-12 level, limited attention has been given to early childhood education (ECE) contexts. Our research aims to investigate the potential development of early CT through mathematics learning in a potentially reciprocal manner using developmentally appropriate educational tools and instructional approaches. To commence this exploration, our primary focus is to conduct a systematic review of existing empirical studies, synthesizing evidence to illuminate the interaction between CT and mathematics during early childhood. Using the seven powerful ideas from early CT proposed by Bers as the theoretical framework, our initial findings indicate that algorithms, hardware/software, and representation are the most studied CT competencies intersecting with early mathematics skills, including numerical and spatial knowledge, measurements, basic algebraical thinking, and data processing. The complex relationship between early CT and mathematics, in general, is also discussed. Overall, the findings of this study suggest that existing mathematics education in early childhood may foster the development of CT in young children. Although this study is preliminary, it serves as a valuable foundation for future research endeavors in uncovering the interdisciplinary nature of early CT within mathematics-integrated learning contexts, thus contributing to the advancement of this field.",
    "abstract_processed": "recent year educ research emphas signific comput think ct mathemat knowledg acquisit student learn engin subject pre colleg educ play crucial role prepar student futur engin learn relationship ct mathemat extens studi k level limit attent given earli childhood educ ece context research aim investig potenti develop earli ct mathemat learn potenti reciproc manner use development appropri educ tool instruct approach commenc explor primari focu conduct systemat review exist empir studi synthes evid illumin interact ct mathemat earli childhood use seven power idea earli ct propos ber theoret framework initi find indic algorithm hardwar softwar represent studi ct compet intersect earli mathemat skill includ numer spatial knowledg measur basic algebra think data process complex relationship earli ct mathemat gener also discuss overal find studi suggest exist mathemat educ earli childhood may foster develop ct young children although studi preliminari serv valuabl foundat futur research endeavor uncov interdisciplinari natur earli ct within mathemat integr learn context thu contribut advanc field"
  },
  {
    "doc_id": "10578675",
    "abstract_original": "New (interdisciplinary) Computer Science (CS) subjects in K-12 education have been introduced in recent years. Most of them have educational plans derived from CS Frame-works such as the K-12 CS Framework. To some extent the educational plans have the same core topic areas: data and coding (including data compression and data structures), algorithms (in-volving variables and software projects), computers and networks (covering topics like logic tables and data transmission) and information society and data security (consisting of collection and processing of personal data and asymmetric encryption). Various Computer Science assessment tests such as the SCS1, MG-CSCI, PSIv1 and the Fairy Assessment have been developed for different age groups. These tests mostly include computational thinking, programming or topics that could be categorized in the first two core topic areas data and coding and algorithms. Hence, the research desideratum was to develop a test specifically for measuring the four core topic areas. These core topic areas are part of the educational plan of the new interdisciplinary subject IMP (Informatics, Mathematics, Physics) for secondary schools in Germany. The test was piloted with 156 (m = 117, f = 37, o = 2) 10th grade students, approximately aged 16 at the end of the lower secondary level. We used the Item-Response-Theory (IRT) to validate the test. This work in progress paper presents translated items and the psychometric evaluation of the piloted test. The contribution for both researchers and educators in the CS education research field is the set of items of the research-based CS test in the four core topic areas for 10th grade students that includes item sets for the areas computers and networks and information society and data security.",
    "abstract_processed": "new interdisciplinari comput scienc cs subject k educ introduc recent year educ plan deriv cs frame work k cs framework extent educ plan core topic area data code includ data compress data structur algorithm volv variabl softwar project comput network cover topic like logic tabl data transmiss inform societi data secur consist collect process person data asymmetr encrypt variou comput scienc assess test sc mg csci psiv fairi assess develop differ age group test mostli includ comput think program topic could categor first two core topic area data code algorithm henc research desideratum develop test specif measur four core topic area core topic area part educ plan new interdisciplinari subject imp informat mathemat physic secondari school germani test pilot f th grade student approxim age end lower secondari level use item respons theori irt valid test work progress paper present translat item psychometr evalu pilot test contribut research educ cs educ research field set item research base cs test four core topic area th grade student includ item set area comput network inform societi data secur"
  },
  {
    "doc_id": "10578677",
    "abstract_original": "The Engineering Design Process (EDP) is contemporary teaching method, applicable within STEM framework, and consists of a series of steps that students – as future engineers – follow, in order to design a prototype artifact and find a solution to a complex engineering problem. These steps usually include problem – solving processes, such as defining the problem, background research, specifying requirements, brainstorming, evaluating, choosing the best solution, developing a prototype, testing the prototype and finally communicating the research results. During the process, students engage themselves with all Computational Thinking (CT) dimensions. In this research, we apply EDP, within the STEM and CT Epistemology framework, in order to design and develop an open – hardware, open – source, low – cost, easy and safe to use, drown, for educational activities, in Higher education. The purpose of this work is to highly engage University students, in developing solutions for complex Mechatronic course - related problems, and evaluate how they achieved their learning objectives. We also design a use case scenario, in which students form proper engineering teams to work with the design of the UAV, to program its behavior and to understand avionics. The simple design, safe use, economic cost, and open philosophy of this drone make it suitable not only for university courses, but also for educational robotics applications, and in STEM education in general, regardless of the educational level.",
    "abstract_processed": "engin design process edp contemporari teach method applic within stem framework consist seri step student – futur engin – follow order design prototyp artifact find solut complex engin problem step usual includ problem – solv process defin problem background research specifi requir brainstorm evalu choos best solut develop prototyp test prototyp final commun research result process student engag comput think ct dimens research appli edp within stem ct epistemolog framework order design develop open – hardwar open – sourc low – cost easi safe use drown educ activ higher educ purpos work highli engag univers student develop solut complex mechatron cours relat problem evalu achiev learn object also design use case scenario student form proper engin team work design uav program behavior understand avion simpl design safe use econom cost open philosophi drone make suitabl univers cours also educ robot applic stem educ gener regardless educ level"
  },
  {
    "doc_id": "10578701",
    "abstract_original": "Sorting is an algorithmic concept that is covered in every fundamental computer science and engineering course and included in most if not all programming competitions. It is an everyday task, self-taught and done naturally even by a small child. In spite of its ingenuousness, mastering sorting algorithms turns out to be not so simple for many first-time programmers. This happens because how humans perform sorting is far from being straightforwardly aligned with machine instructions. We have developed an unplugged game-based learning activity that aims not only to tackle this difficult dilemma but also to promote computational thinking practice. Our game robustly challenges audiences to complete a fun sorting task algorithmically and the building blocks of the exercise are methodologically grounded in the four cornerstones of computational thinking. Participants are gently guided through solving a problem by decomposing it, recognizing patterns, applying abstraction, writing step-by-step instructions, and finally arriving at a programmable solution. Our design is largely flexible. The game can be played in small groups or larger ones. It uses only common, readily accessible materials, and is easily adaptable to different levels of audiences, from the interested general public to secondary school students and teachers, to non-computer science undergraduates and those majoring in engineering or information technology related subjects. We have implemented this activity in our classrooms and conducted several workshops. Responses were markedly positive. Engaged from the beginning to the end, participants enjoyed the activity, having fun sorting. Appreciated the ideas, audiences were captivated by many surprising challenges. Most notably, they were able to comprehend the concepts of sorting algorithms and the computational steps behind them, and gain a better understanding of computational thinking.",
    "abstract_processed": "sort algorithm concept cover everi fundament comput scienc engin cours includ program competit everyday task self taught done natur even small child spite ingenu master sort algorithm turn simpl mani first time programm happen human perform sort far straightforwardli align machin instruct develop unplug game base learn activ aim tackl difficult dilemma also promot comput think practic game robustli challeng audienc complet fun sort task algorithm build block exercis methodolog ground four cornerston comput think particip gentli guid solv problem decompos recogn pattern appli abstract write step step instruct final arriv programm solut design larg flexibl game play small group larger one use common readili access materi easili adapt differ level audienc interest gener public secondari school student teacher non comput scienc undergradu major engin inform technolog relat subject implement activ classroom conduct sever workshop respons markedli posit engag begin end particip enjoy activ fun sort appreci idea audienc captiv mani surpris challeng notabl abl comprehend concept sort algorithm comput step behind gain better understand comput think"
  },
  {
    "doc_id": "10578742",
    "abstract_original": "In the field of education ChatGPT has sparked both admiration and controversy. This study explores students' perspectives, specifically focusing on those in computer science-related fields. We investigated their motivations, trust, perceptions of utility, and reliability of ChatGPT by conducting two surveys-one at the beginning and another at the end of the semester. During the semester, students were encouraged to engage with ChatGPT. Our findings highlight the tool's multifaceted use in an academic settings, establishing it as a valuable resource for a variety of learning tasks. Most students have incorporated ChatGPT into their regular academic activities and view it as a beneficial aid. They perceive it as a multi-task solver and anticipate significant advancements in its writing assistance features in the near future. Many, not only attribute high accuracy to it but think that it adheres to appropriate content and structural norms. Our results suggest that active confrontation with ChatGPT enhances understanding of its capabilities, limitations and autoregressive nature. Consequently, we recommend an approach of informed engagement that includes the distinction between language processing and genuine language understanding and a carefully crafted terminology.",
    "abstract_processed": "field educ chatgpt spark admir controversi studi explor student perspect specif focus comput scienc relat field investig motiv trust percept util reliabl chatgpt conduct two survey one begin anoth end semest semest student encourag engag chatgpt find highlight tool multifacet use academ set establish valuabl resourc varieti learn task student incorpor chatgpt regular academ activ view benefici aid perceiv multi task solver anticip signific advanc write assist featur near futur mani attribut high accuraci think adher appropri content structur norm result suggest activ confront chatgpt enhanc understand capabl limit autoregress natur consequ recommend approach inform engag includ distinct languag process genuin languag understand care craft terminolog"
  },
  {
    "doc_id": "10578762",
    "abstract_original": "STEM (Science, Technology, Engineering and Math-ematics) education is crucial, rising the demand for technological skills driven by the Industry 4.0 digital transformation, and fostering problem-solving, autonomy, computational thinking, creativity, innovation, and effective teamwork skills. To properly address the lack of structured materials in secondary schools, an Educational Design Research (EDR) project was developed to introduce young students to STEM, and particularly to electronics field. For this purpose, the developed approach combines instructionism and constructionism methods, through three educational projects and “Drops of knowledge” modules. The developed material was applied to 9th and 12th grades of a secondary school, with the achieved results showing that this immersive approach effectively provides students with the necessary competencies to tackle the initial technological challenges of electronics. The project was recognized by the Directorate General of Education of Portugal as a recommended practice of a digital initiative within secondary schools.",
    "abstract_processed": "stem scienc technolog engin math emat educ crucial rise demand technolog skill driven industri digit transform foster problem solv autonomi comput think creativ innov effect teamwork skill properli address lack structur materi secondari school educ design research edr project develop introduc young student stem particularli electron field purpos develop approach combin instruction construction method three educ project “drop knowledge” modul develop materi appli th th grade secondari school achiev result show immers approach effect provid student necessari compet tackl initi technolog challeng electron project recogn director gener educ portug recommend practic digit initi within secondari school"
  },
  {
    "doc_id": "10578766",
    "abstract_original": "In today's rapidly evolving technological landscape, marked by the proliferation of artificial intelligence and robotics, the role of engineering education stands as a cornerstone of sustainable progress. Recognizing this imperative, engineering curricula are increasingly incorporating a competency-based approach that reflects the complexities of the real world, for lifelong learning, using enabling and disruptive technologies such as humanoid robotics. We present a case study from the Tecnologico de Monterrey, Mexico City Campus, where NAO robots are used in social projects with immediate impact in the fields of health and education, addressing sustainable development objectives. This research shows projects that have had a significant social impact in different communities in Mexico, in the areas of education and health with innovative solutions that motivate and engage the attention of the audience. A group of students from different engineering careers design, develop and implement application scenarios for the accompaniment and social appropriation of challenges such as: the incorporation of girls in STEM areas, support for groups with intellectual disabilities, dissemination and knowledge of sign language and dissemination of the cultural heritage of Xochimilco as a cultural heritage of humanity. Preliminary results indicate that this pedagogical approach not only inculcates students with essential skills such as problem solving, critical thinking and teamwork, but also makes them more aware of the social implications of their engineering studies. Evidence and results of the involvement of undergraduate students in social scenarios are shown, showing that, by integrating these elements, engineering programs aspire to train professionals capable of harnessing their technical knowledge for the general good of society as well as the perception of the participants and audiences reached.",
    "abstract_processed": "today rapidli evolv technolog landscap mark prolifer artifici intellig robot role engin educ stand cornerston sustain progress recogn imper engin curricula increasingli incorpor compet base approach reflect complex real world lifelong learn use enabl disrupt technolog humanoid robot present case studi tecnologico de monterrey mexico citi campu nao robot use social project immedi impact field health educ address sustain develop object research show project signific social impact differ commun mexico area educ health innov solut motiv engag attent audienc group student differ engin career design develop implement applic scenario accompani social appropri challeng incorpor girl stem area support group intellectu disabl dissemin knowledg sign languag dissemin cultur heritag xochimilco cultur heritag human preliminari result indic pedagog approach inculc student essenti skill problem solv critic think teamwork also make awar social implic engin studi evid result involv undergradu student social scenario shown show integr element engin program aspir train profession capabl har technic knowledg gener good societi well percept particip audienc reach"
  },
  {
    "doc_id": "10578801",
    "abstract_original": "The CDIO Framework within engineering education is based on the idea that graduates should be capable of conceiving, designing, implementing, and operating (i.e., CDIO) complex systems within a team-based learning environment. As an approach to engineering education, it aims to create an active, experiential learning setting where product and process are considered fundamental to the curriculum. Modern pedagogical strategies and innovative teaching methods allow for the implementation of the CDIO approach, where students are supported to develop deep knowledge, manage the process of designing and exploiting new items and systems, and evaluate the impact of the scientific-technological process on society. This article will highlight aspects of this approach in the development of a practical quantum electronics session. In particular, it will focus on the developed principles of an innovative practice-targeted programme that can support the development of students' engineering thinking through the linkage of education and professional activities. As graduates, the students will need to be able to create innovative engineering systems as well as integrate their understanding of natural and technological sciences to generate novel concepts. They will also need to be proficient in professional ethics and have knowledge of business and entrepreneurship fundamentals. As such, this indicates the need for a strategically-focused curriculum that supports the development of a range of transversal skills required for industry. In this paper, the CDIO model is detailed as a means of transforming engineering education on a large scale. In order to develop the fundamental framework of creative awareness sessions for quantum technologies and their applications, this study attempted to further explore and provide more specific illustrations of the concepts relating to CIDO and to consider how they may be applied within an engineering context. The current work will present and evaluate the principles of an innovative teaching technique aimed at providing students with the opportunities to understand pioneering technologies for future applications.",
    "abstract_processed": "cdio framework within engin educ base idea graduat capabl conceiv design implement oper e cdio complex system within team base learn environ approach engin educ aim creat activ experienti learn set product process consid fundament curriculum modern pedagog strategi innov teach method allow implement cdio approach student support develop deep knowledg manag process design exploit new item system evalu impact scientif technolog process societi articl highlight aspect approach develop practic quantum electron session particular focu develop principl innov practic target programm support develop student engin think linkag educ profession activ graduat student need abl creat innov engin system well integr understand natur technolog scienc gener novel concept also need profici profession ethic knowledg busi entrepreneurship fundament indic need strateg focus curriculum support develop rang transvers skill requir industri paper cdio model detail mean transform engin educ larg scale order develop fundament framework creativ awar session quantum technolog applic studi attempt explor provid specif illustr concept relat cido consid may appli within engin context current work present evalu principl innov teach techniqu aim provid student opportun understand pioneer technolog futur applic"
  },
  {
    "doc_id": "10578887",
    "abstract_original": "Computational Thinking (CT) is vital in today's digital era, especially in Engineering Education. While no official policy or teaching framework on CT education has been established in the Netherlands, a Western European country, there have been various initiatives for the integration of CT into the curriculum. Recognizing the crucial role of teachers in CT integration, we surveyed the perceptions and intentions of teachers in tertiary education in the Netherlands. Our survey encompassed two aspects: (1) teachers' perceptions of CT, and (2) their intentions to integrate CT into pedagogical activities. 38 teachers, mostly in Engineering Education, from across the Netherlands completed the questionnaire based on the UTAUT framework. Regarding CT perceptions, our investigation reveals that teachers possess an inadequate understanding of the relationship between CT and Computer Science, have limited training experiences in CT, and hold differing opinions on when and which constructs of CT should be integrated into different domains. Concerning teachers' intentions to integrate CT, the results exhibited a strong positive correlation between performance expectancy, attitude towards CT, and behavioral intention to implement CT in learning activities. To foster the integration of CT in tertiary education, our findings suggest the need for further development of higher education teacher training programs focused on CT and its relation to CS. Additionally, there is a call for further exploration of how to enhance teachers' performance expectancy and effort expectancy.",
    "abstract_processed": "comput think ct vital today digit era especi engin educ offici polici teach framework ct educ establish netherland western european countri variou initi integr ct curriculum recogn crucial role teacher ct integr survey percept intent teacher tertiari educ netherland survey encompass two aspect teacher percept ct intent integr ct pedagog activ teacher mostli engin educ across netherland complet questionnair base utaut framework regard ct percept investig reveal teacher possess inadequ understand relationship ct comput scienc limit train experi ct hold differ opinion construct ct integr differ domain concern teacher intent integr ct result exhibit strong posit correl perform expect attitud toward ct behavior intent implement ct learn activ foster integr ct tertiari educ find suggest need develop higher educ teacher train program focus ct relat cs addit call explor enhanc teacher perform expect effort expect"
  },
  {
    "doc_id": "10578896",
    "abstract_original": "This paper presents a case study that explores the successful integration of project-based learning (PBL) in two courses, Biometry and Computer Vision, at the University of -DFBR-. The study emphasizes the positive impact of PBL not only on academic performance but also on student well-being, motivation, and self-regulated learning skills. In both courses, PBL was employed as a powerful tool to actively engage students in their learning process and enhance their understanding of complex subjects. The project developed by the students served as a vehicle to apply theoretical knowledge to a real-world scenario, ensuring the comprehensive coverage of the course topics. The outcome of this study revealed a positive impact of PBL methodology on student performance, which was indicated by their final grades and active participation during synchronous moments throughout the course duration. Moreover, the implementation of PBL has fostered a positive and motivating learning environment, as students embrace the opportunity to work on authentic, hands-on projects. The enhancement of self-regulated learning skills, including goal setting, time management, and re-flection, further contributes to students' overall academic growth. Furthermore, the transversal skills acquired by students in the PBL environment are relevant. Collaborative problem-solving, effective communication, critical thinking, and adaptability are just a few of the key skills that students develop through their active engagement in projects. This paper offers an exploration of the successful integration of PBL in engineering education. The study provides valuable insights into the transformative potential of PBL, not only in the referred courses but as a model for innovative engineering education practices. The experience at the University of -DFBR- illustrates how PBL can nurture a new generation of competent, motivated, and adaptable engineers, ready to tackle the challenges of an ever-changing world.",
    "abstract_processed": "paper present case studi explor success integr project base learn pbl two cours biometri comput vision univers dfbr studi emphas posit impact pbl academ perform also student well motiv self regul learn skill cours pbl employ power tool activ engag student learn process enhanc understand complex subject project develop student serv vehicl appli theoret knowledg real world scenario ensur comprehens coverag cours topic outcom studi reveal posit impact pbl methodolog student perform indic final grade activ particip synchron moment throughout cours durat moreov implement pbl foster posit motiv learn environ student embrac opportun work authent hand project enhanc self regul learn skill includ goal set time manag flection contribut student overal academ growth furthermor transvers skill acquir student pbl environ relev collabor problem solv effect commun critic think adapt key skill student develop activ engag project paper offer explor success integr pbl engin educ studi provid valuabl insight transform potenti pbl refer cours model innov engin educ practic experi univers dfbr illustr pbl nurtur new gener compet motiv adapt engin readi tackl challeng ever chang world"
  },
  {
    "doc_id": "10578899",
    "abstract_original": "The objective of this study is to develop and empirically evaluate an educational model that enhances algorithmic thinking - a key element of computational literacy - through the application with the concept of so called semantic waves for advancing K-12 students' digital proficiency. The concept of a semantic wave refers to the process of moving between abstract, theoretical knowledge and concrete, practical examples to create deeper understanding and learning. Considering this, our proposed model in the field of algorithmic thinking is intended to support pre-service computer science teachers and educators in designing instructional processes that are easy to implement and facilitate swift planning and reflection for K-12 computer science education. Initial results indicate promising outcomes but also suggested areas for enhancement. This research furthermore delves into refining the model through the incorporation of notional machines and the computational action approach for improving the training of future computer science teachers and students for the challenges of digital transformation.",
    "abstract_processed": "object studi develop empir evalu educ model enhanc algorithm think key element comput literaci applic concept call semant wave advanc k student digit profici concept semant wave refer process move abstract theoret knowledg concret practic exampl creat deeper understand learn consid propos model field algorithm think intend support pre servic comput scienc teacher educ design instruct process easi implement facilit swift plan reflect k comput scienc educ initi result indic promis outcom also suggest area enhanc research furthermor delv refin model incorpor notion machin comput action approach improv train futur comput scienc teacher student challeng digit transform"
  },
  {
    "doc_id": "10578905",
    "abstract_original": "Drones have emerged as powerful educational tools, offering students diverse ways to learn and develop critical thinking and problem-solving skills in STEM education. Drones are framed within real-world contexts, showcasing their applications in multiple industries. Drones offer the possibility to be used to teach programming and coding that promote computational and critical thinking. This research paper presents a pedagogical approach that combines the use of drones with inquiry-based learning to foster students' intellectual, creative, and technical abilities, enhancing their understanding of real-world scenarios and their capacity for critical thinking and problem-solving. The study was conducted in top-end schools in Northern Australia. The findings indicate that engaging in drone coding exercises within authentic bushfire scenarios offers an ideal environment for STEM education, enhancing students' critical thinking and problem-solving abilities.",
    "abstract_processed": "drone emerg power educ tool offer student divers way learn develop critic think problem solv skill stem educ drone frame within real world context showcas applic multipl industri drone offer possibl use teach program code promot comput critic think research paper present pedagog approach combin use drone inquiri base learn foster student intellectu creativ technic abil enhanc understand real world scenario capac critic think problem solv studi conduct top end school northern australia find indic engag drone code exercis within authent bushfir scenario offer ideal environ stem educ enhanc student critic think problem solv abil"
  },
  {
    "doc_id": "10578906",
    "abstract_original": "The kind of students that currently arrive in the classroom in this technological age require a learning model that promotes their motivation for learning and thus boosts their creative thinking skills to develop disciplinary and cross-cutting competencies in their courses. It is of utmost importance to provide the students with comprehensive training and improve their competitiveness in their professional field by enhancing the skills of future generations to develop both the transversal and disciplinary competencies required that will allow them to become professionals who face challenges and opportunities in their future lives. Disciplinary competencies are the minimum necessary set of knowledge, skills, and attitudes in their disciplinary field for students to perform successfully in different contexts. Traditionally, the evaluation of knowledge is used to evaluate the student's competencies in a course, and it does not usually reflect the degree of achievement of the student's competencies since these evaluations are based on specific topics and not on the acquisition of the competencies that the course should generate. The objective of this study is to design the evaluation criteria for the disciplinary competencies of Computer Science in students, as well as to measure their impact concerning the different subjects of their academic plan.",
    "abstract_processed": "kind student current arriv classroom technolog age requir learn model promot motiv learn thu boost creativ think skill develop disciplinari cross cut compet cours utmost import provid student comprehens train improv competit profession field enhanc skill futur gener develop transvers disciplinari compet requir allow becom profession face challeng opportun futur live disciplinari compet minimum necessari set knowledg skill attitud disciplinari field student perform success differ context tradit evalu knowledg use evalu student compet cours usual reflect degre achiev student compet sinc evalu base specif topic acquisit compet cours gener object studi design evalu criteria disciplinari compet comput scienc student well measur impact concern differ subject academ plan"
  },
  {
    "doc_id": "10578908",
    "abstract_original": "In the last decade, educational reforms introduced technologies and digital tools to a higher degree, serving as powerful catalysts in educational innovation for creating, managing, and delivering content in STEM education with a focus on computational and engineering subjects. However, in the small reality of the classroom, some discrepancies arise between policy objectives and everyday practice. The research community emphasises the importance of providing technology infusions based on educators' pedagogical beliefs as well as needs rooted in the authentic scholarly environment. Considering this perspective when orchestrating in-classroom technology can support educators in their daily experiences and enhance their digital competencies. To contribute to this aim, we propose a case study carried out via interviews with fellow primary and secondary teachers, tackling challenges in STEM (Science, Technology, Engineering, and Mathematics), including Computer Science (CS) and Computational thinking (CT) education delivery. Along with the teachers' perspectives, our study aims to obtain a detailed account of the classroom's internal dynamics as perceived by the teachers. The most prominent findings concern the disparity among educators' proficiency in technology endorsement, impacting the consistency in content delivery, the complexity of the assessment of students' learning process if it is digital-based, and the inclusivity and trustworthiness of online content. Finally, we suggest guidance for a further mindful in-school uptake of technology to support teachers in orchestrating content delivery with educational technologies and enhance their confidence in this aspect.",
    "abstract_processed": "last decad educ reform introduc technolog digit tool higher degre serv power catalyst educ innov creat manag deliv content stem educ focu comput engin subject howev small realiti classroom discrep aris polici object everyday practic research commun emphasis import provid technolog infus base educ pedagog belief well need root authent scholarli environ consid perspect orchestr classroom technolog support educ daili experi enhanc digit compet contribut aim propos case studi carri via interview fellow primari secondari teacher tackl challeng stem scienc technolog engin mathemat includ comput scienc cs comput think ct educ deliveri along teacher perspect studi aim obtain detail account classroom intern dynam perceiv teacher promin find concern dispar among educ profici technolog endors impact consist content deliveri complex assess student learn process digit base inclus trustworthi onlin content final suggest guidanc mind school uptak technolog support teacher orchestr content deliveri educ technolog enhanc confid aspect"
  },
  {
    "doc_id": "10578918",
    "abstract_original": "This work aims to explore the application of the physical and digital twin pair as a computational thinking instrument to support learning and exercise proportional reasoning at the ages at which pursuing STEM studies is decided. Diverse studies reveal that the initial decision about the vocation in studies is made towards the end of the primary education stage, also from 8–9 years old. The Digital Transformation Commission of the Engineering Associations of Catalonia is concerned about the low number of young people who decide to pursue STEM studies. STEM explorations in early childhood lay the foundation for lifelong learning. In addition, from age 5, children informally begin to practice proportional reasoning, and in the third year of primary school (8–9 years old), the subject is formally introduced into the Primary Education curriculum. The notion of proportionality is very transversal, and it is one of the fundamental concepts of the STEM field. The consequences of an incomplete understanding of it directly or indirectly affect the attitude of subjects toward mathematics and the STEM world. With the emergence of Industry 4.0, the digital twin concept is becoming one of the central instruments of Digital Transformation. In this paper, we propose using computational thinking to help the understanding of proportional thinking using a physical and digital twin pair. In 2022, computational thinking was introduced into the Spanish and Catalan educational system's early childhood, primary, and secondary education curricula. It includes programming with block languages such as Scratch or Snap!. A digital twin of the system has also been implemented in Snap!. Through the collaboration of a primary school, a workshop has been prepared in which they exercise the concepts of proportional reasoning, such as ratio, proportion, scale, or percentage. The approach followed has consisted of developing a physical system of a floating ball, controlling the electric motor's power with an electronic system based on low-cost elements from the maker world. We have designed a very easy-to-use system for any teacher, and its open-source nature ensures its transparency and documentation. The foam ball rises and remains floating at a height determined by the power supplied to the motor. The control of the system is carried out with Snap!. It will be assumed that the engine revolutions are proportional to the power setpoint. The physical system generates a high level of expectation and attention in the students, facilitating the process of its abstraction. The range of options of the developed system allows experimenting with the actual system and a schematic digital twin with sound effects. In all cases, the same computational thinking tools have been used to exercise the concepts and powerful ideas of proportional reasoning. At the end of the workshop, the understanding of the concepts exercised and the assessment of their personal experience were evaluated. This gave us helpful information to motivate students of these ages and below to maintain their STEM vocation.",
    "abstract_processed": "work aim explor applic physic digit twin pair comput think instrument support learn exercis proport reason age pursu stem studi decid divers studi reveal initi decis vocat studi made toward end primari educ stage also – year old digit transform commiss engin associ catalonia concern low number young peopl decid pursu stem studi stem explor earli childhood lay foundat lifelong learn addit age children inform begin practic proport reason third year primari school – year old subject formal introduc primari educ curriculum notion proportion transvers one fundament concept stem field consequ incomplet understand directli indirectli affect attitud subject toward mathemat stem world emerg industri digit twin concept becom one central instrument digit transform paper propos use comput think help understand proport think use physic digit twin pair comput think introduc spanish catalan educ system earli childhood primari secondari educ curricula includ program block languag scratch snap digit twin system also implement snap collabor primari school workshop prepar exercis concept proport reason ratio proport scale percentag approach follow consist develop physic system float ball control electr motor power electron system base low cost element maker world design easi use system teacher open sourc natur ensur transpar document foam ball rise remain float height determin power suppli motor control system carri snap assum engin revolut proport power setpoint physic system gener high level expect attent student facilit process abstract rang option develop system allow experi actual system schemat digit twin sound effect case comput think tool use exercis concept power idea proport reason end workshop understand concept exercis assess person experi evalu gave us help inform motiv student age maintain stem vocat"
  },
  {
    "doc_id": "10579547",
    "abstract_original": "In the ever-evolving field of technologies, the emergence of artificial general intelligence (AGI), often referred as strong artificial intelligence (AI), stands as a breakthrough in the realm of machine intelligence, promising to witness a new era of capabilities and possibilities. In particular, AGI ventures into human-level cognition, and expands to thinking, reasoning, and awareness. This imminent evolution is envisioned to be manifested through the embodiment of AI machines, allowing machines to transcend their purely computational nature and interact with the world through the different senses. Accordingly, AI agents will be grounded in the physical environment, going through subjective experiences and acquiring the needed knowledge that will lead to understanding and cognition. In our article, we explore the path toward realizing the true vision of AGI through AI embodiment, where we dig into the different types of thinking required to achieve knowledge, and hence, cognition and understanding. Furthermore, we look through the evolution of generative AI models, and shed light on the limitations of auto-regression in large language models (LLMs), with the aim to answer the question: is sensory grounding (through 6G) necessary, and enough, to achieve understanding in LLMs? Finally, we identify the main pillars of AGI and unveil how 6G networks will orchestrate the development of AGI systems.",
    "abstract_processed": "ever evolv field technolog emerg artifici gener intellig agi often refer strong artifici intellig ai stand breakthrough realm machin intellig promis wit new era capabl possibl particular agi ventur human level cognit expand think reason awar immin evolut envis manifest embodi ai machin allow machin transcend pure comput natur interact world differ sens accordingli ai agent ground physic environ go subject experi acquir need knowledg lead understand cognit articl explor path toward realiz true vision agi ai embodi dig differ type think requir achiev knowledg henc cognit understand furthermor look evolut gener ai model shed light limit auto regress larg languag model llm aim answer question sensori ground g necessari enough achiev understand llm final identifi main pillar agi unveil g network orchestr develop agi system"
  },
  {
    "doc_id": "10580977",
    "abstract_original": "The main content of this study is the human-machine collaborative design research, taking the car body design as the carrier. The research framework focused on two phases of car body design process, that of design ideation and evaluation. In the ideation stage, we trained an imperfect Deep Convolutional Generative Adversarial Network (DCGAN) model that just could generate blur automobile images as the blur design motherboards for the iterative sketching, which had design uncertainties and blanks, thus activating designers’ subjective initiative and aesthetic intuition to provide more creative deepen sketches. We leveraged motherboards to address uncertainty through sketching and aesthetic intuition, refining options and ultimately selecting an optimal design. In the evaluation phase, we initially constructed a parametric 3D model with 20 parameters based on the optimal design, and invited 32 designers conducting participatory design experiments, getting 1024 human-designed schemes. Following this, we administered an online survey to assess the aesthetic qualities of a total of 1024 design schemes. Leveraging the collected score data (The first round of surveys engaged 279 participants, while the second round involved 73 participants), we trained an Artificial Neural Network (ANN) model to serve as an aesthetic evaluation score predictor for unknown parameter configurations. The machine could evaluate designs autonomously, thus selecting best design from 20,000 schemes generated randomly by machine. We utilized the parametric design converting sketching images to the numeric parameters, switching the qualitative ideation to the quantitative evaluation, thus achieving aesthetic evaluation and optimization. This study explores the relationship between human cognitive intuition and machine intelligence and how they can collaborate with each other.",
    "abstract_processed": "main content studi human machin collabor design research take car bodi design carrier research framework focus two phase car bodi design process design ideat evalu ideat stage train imperfect deep convolut gener adversari network dcgan model could gener blur automobil imag blur design motherboard iter sketch design uncertainti blank thu activ designers’ subject initi aesthet intuit provid creativ deepen sketch leverag motherboard address uncertainti sketch aesthet intuit refin option ultim select optim design evalu phase initi construct parametr model paramet base optim design invit design conduct participatori design experi get human design scheme follow administ onlin survey assess aesthet qualiti total design scheme leverag collect score data first round survey engag particip second round involv particip train artifici neural network ann model serv aesthet evalu score predictor unknown paramet configur machin could evalu design autonom thu select best design scheme gener randomli machin util parametr design convert sketch imag numer paramet switch qualit ideat quantit evalu thu achiev aesthet evalu optim studi explor relationship human cognit intuit machin intellig collabor"
  },
  {
    "doc_id": "10581073",
    "abstract_original": "Natural Language Generation (NLG) acts as a bridge between input data and human communication. NLG systems are meant to generate human-understandable output making it a useful technique mainly in report generation, automatic replies to queries like Chatbots, and other domains that involve Natural Language Processing (NLP). NLG continues to evolve; embracing the latest trends like neural networks, large language models, personalized features, cognitive architectures, and emotional intelligence, but it still faces some challenges with its implementations and operations for cohesive integration. Therefore, this survey presents a brief introduction to some of the latest trends and challenges faced by NLG which are playing a dynamic role in shaping the evolution of NLG.",
    "abstract_processed": "natur languag gener nlg act bridg input data human commun nlg system meant gener human understand output make use techniqu mainli report gener automat repli queri like chatbot domain involv natur languag process nlp nlg continu evolv embrac latest trend like neural network larg languag model person featur cognit architectur emot intellig still face challeng implement oper cohes integr therefor survey present brief introduct latest trend challeng face nlg play dynam role shape evolut nlg"
  },
  {
    "doc_id": "10581081",
    "abstract_original": "Artificial intelligence is a part machine language. Both are the result of intelligence of human. In modern days, humans are creating lots of new machine and that help out time, save energy. First human think about the idea about AI and then as a result it comes out as a machine language. Computer knowledge is very important for that. This research is based on machine language and artificial intelligence and their effects on business. Upgrading both of this process and checking their security are also essential. Unemployment is a side effect of this good work. AI and MI can reduce human work and as it's costly for maintenance, most of the business is looking for less employee and more machines.",
    "abstract_processed": "artifici intellig part machin languag result intellig human modern day human creat lot new machin help time save energi first human think idea ai result come machin languag comput knowledg import research base machin languag artifici intellig effect busi upgrad process check secur also essenti unemploy side effect good work ai mi reduc human work costli mainten busi look less employe machin"
  },
  {
    "doc_id": "10581327",
    "abstract_original": "This research deals with the analysis and detection of current mental state including feelings, emotions and mental processes from body language signs, such as analysis of personality traits, psychological states, mental health monitoring, human-computer interaction and lie detection. In this study, we discovered this new approach to classify a person's current mental state through convolutional neural networks (CNN) based on the analysis of eye, mouth and hand positions. We use extensive data to train and evaluate our model, which includes video recordings and images that record various human activities and emotions. Pre-processing techniques including normalization and scaling are used to improve model reliability. We use a CNN architecture that is optimized for feature extraction from facial and hand movements and uses both spatial and temporal information from the input data. By extracting the main features of the eyes, mouth and hand positions and movements, we try to capture subtle clues that indicate different emotional states such as happiness, sadness etc., as well as cognitive processes such as thinking, imagining and creating. Experimental results show promising classification accuracy for detecting different mental states, with better performance than basic methods. Our approach provides valuable insights into the complex interplay between body language and mental states, contributing to the understanding of human behaviour. The proposed method has significant potential for real-world applications, including Psychological and behaviour analysis, mental health assessment, personal user interfaces etc. This proposed model is simply an artificial intelligence based psychologist.",
    "abstract_processed": "research deal analysi detect current mental state includ feel emot mental process bodi languag sign analysi person trait psycholog state mental health monitor human comput interact lie detect studi discov new approach classifi person current mental state convolut neural network cnn base analysi eye mouth hand posit use extens data train evalu model includ video record imag record variou human activ emot pre process techniqu includ normal scale use improv model reliabl use cnn architectur optim featur extract facial hand movement use spatial tempor inform input data extract main featur eye mouth hand posit movement tri captur subtl clue indic differ emot state happi sad etc well cognit process think imagin creat experiment result show promis classif accuraci detect differ mental state better perform basic method approach provid valuabl insight complex interplay bodi languag mental state contribut understand human behaviour propos method signific potenti real world applic includ psycholog behaviour analysi mental health assess person user interfac etc propos model simpli artifici intellig base psychologist"
  },
  {
    "doc_id": "10581394",
    "abstract_original": "The study focuses on discerning between human and AI-generated essays, highlighting the ethical implications of AI in academia. It employs various algorithms like logistic regression, Support Vector Machine (SVM), decision trees, random forests, KNN, and LSTM to develop models for essay classification. The TF-IDF technique (Term Frequency-Inverse Document Frequency) is applied to assess document word importance, with rigorous parameter tuning ensuring model accuracy. Findings revealed SVM's exceptional precision and recall, highlighting its robustness in accurately classifying essays, while decision trees offer simplicity but increased misclassification risk. KNN strikes a balance and random forests as well. LSTM excels in contextual understanding, albeit with higher computational demands. The research emphasizes the significance of algorithm selection in maintaining academic integrity and fostering genuine student creativity. SVM emerges as a robust and accurate choice for essay classification, ensuring fair assessment and upholding academic honesty.",
    "abstract_processed": "studi focus discern human ai gener essay highlight ethic implic ai academia employ variou algorithm like logist regress support vector machin svm decis tree random forest knn lstm develop model essay classif tf idf techniqu term frequenc invers document frequenc appli assess document word import rigor paramet tune ensur model accuraci find reveal svm except precis recal highlight robust accur classifi essay decis tree offer simplic increas misclassif risk knn strike balanc random forest well lstm excel contextu understand albeit higher comput demand research emphas signific algorithm select maintain academ integr foster genuin student creativ svm emerg robust accur choic essay classif ensur fair assess uphold academ honesti"
  },
  {
    "doc_id": "10581446",
    "abstract_original": "Machine learning models have achieved significant milestones in various domains, for example, computer vision models have an exceptional result in object recognition, and in natural language processing, where Large Language Models (LLM) like GPT can start a conversation with human-like proficiency. However, abstract reasoning remains a challenge for these models, “Can AI really thinking like a human?” still be a question yet to be answered. Raven's Progressive Matrices (RPM) is a metric designed to assess human reasoning capabilities. It presents a series of eight images as a problem set, where the participant should try to discover the underlying rules among these images and select the most appropriate image from eight possible options that best completes the sequence. This task always be used to test human reasoning abilities and IQ. Zhang et al proposed a dataset called RAVEN [12] which can be used to test Machine Learning model abstract reasoning ability. In this paper, we purposed Vision Transformer Contrastive Network which build on previous work with the Contrastive Perceptual Inference network (CoPiNet), which set a new benchmark for permutation-invariant models Raven's Progressive Matrices by incorporating “contrast effects” from psychology, cognition, and education, and extends this foundation by leveraging the cutting-edge Vision Transformer architecture. This integration aims to further refine the machine's ability to process and reason about spatial-temporal information from pixel-level inputs and global wise features on RAVEN dataset.",
    "abstract_processed": "machin learn model achiev signific mileston variou domain exampl comput vision model except result object recognit natur languag process larg languag model llm like gpt start convers human like profici howev abstract reason remain challeng model “can ai realli think like human ” still question yet answer raven progress matric rpm metric design assess human reason capabl present seri eight imag problem set particip tri discov underli rule among imag select appropri imag eight possibl option best complet sequenc task alway use test human reason abil iq zhang et al propos dataset call raven use test machin learn model abstract reason abil paper purpos vision transform contrast network build previou work contrast perceptu infer network copinet set new benchmark permut invari model raven progress matric incorpor “contrast effects” psycholog cognit educ extend foundat leverag cut edg vision transform architectur integr aim refin machin abil process reason spatial tempor inform pixel level input global wise featur raven dataset"
  },
  {
    "doc_id": "10581632",
    "abstract_original": "Math Word Problem, abbreviated as MWP, constitute a class of elementary mathematical application scenarios, commonly encountered within primary secondary educational curricula. Such problems are characterized by their presentation in natural language, eschewing the utilization of intricate mathematical symbols or formulas. The focal task of model geared towards addressing Math Word Problem is twofold: first, to discern and interpret the mathematical concepts encapsulated within the textual descriptions provided, and second, to formulate an appropriate mathematical expression or equation reflective of the problem's essence. Subsequently, these models proceed to compute the solution corresponding to the derived expression, thereby completing the problem-solving process. Currently, advancements in this domain primarily revolve around improvements to encoders and decoders within models, with a relatively narrow scope of thinking processes during model solving. Consequently, the efficacy of expression solving for complex semantic Math Word Problem remains to be enhanced. In contrast to the prevalent sequence-to-tree approach, humans often employ a top-down thinking process to solve Math Word Problem. We introduce a Math Word Problem solving model featuring a dual-thinking structure, comprising a top-down solver, a step-by-step anthropomorphic thinking solver, and a consistent comparison learning module. By aligning expressions derived from two distinct solvers at multiple granularities to maintain consistency, we aim to enhance reasoning correctness. Experimental results across multiple datasets demonstrate the superiority of our approach over existing baselines, particularly in achieving notable improvements in solving accuracy for complex problems.",
    "abstract_processed": "math word problem abbrevi mwp constitut class elementari mathemat applic scenario commonli encount within primari secondari educ curricula problem character present natur languag eschew util intric mathemat symbol formula focal task model gear toward address math word problem twofold first discern interpret mathemat concept encapsul within textual descript provid second formul appropri mathemat express equat reflect problem essenc subsequ model proceed comput solut correspond deriv express therebi complet problem solv process current advanc domain primarili revolv around improv encod decod within model rel narrow scope think process model solv consequ efficaci express solv complex semant math word problem remain enhanc contrast preval sequenc tree approach human often employ top think process solv math word problem introduc math word problem solv model featur dual think structur compris top solver step step anthropomorph think solver consist comparison learn modul align express deriv two distinct solver multipl granular maintain consist aim enhanc reason correct experiment result across multipl dataset demonstr superior approach exist baselin particularli achiev notabl improv solv accuraci complex problem"
  },
  {
    "doc_id": "10582950",
    "abstract_original": "The 2000s held many challenges for humanity. The 2008 mortgage crisis significantly redrawn our financial thinking and changed our attitudes towards financial products. The effects that thousands of people have suffered as a result of poorly made financial decisions have contributed to all these processes. The same characteristics could be said for businesses. Following the mortgage crisis, we became acquainted with a number of other financial crises during the 2000s, but a new level after all this was still the coronavirus epidemic escalated in 2020 and the ensuing crisis. The growing digitalisation challenge, the advancement of artificial intelligence, and the automation of processes are causing headaches for many small and medium-sized enterprises. Businesses around the world face these challenges, sometimes stronger and weaker. The aim of our study is to present the local, macroeconomic challenges and the assessment of those whose competitiveness is affected and influenced by the results of a questionnaire research conducted in Hungary. The research is part of an international survey, in our present study we want to present the effects in Hungary.",
    "abstract_processed": "held mani challeng human mortgag crisi significantli redrawn financi think chang attitud toward financi product effect thousand peopl suffer result poorli made financi decis contribut process characterist could said busi follow mortgag crisi becam acquaint number financi crise new level still coronaviru epidem escal ensu crisi grow digitalis challeng advanc artifici intellig autom process caus headach mani small medium size enterpris busi around world face challeng sometim stronger weaker aim studi present local macroeconom challeng assess whose competit affect influenc result questionnair research conduct hungari research part intern survey present studi want present effect hungari"
  },
  {
    "doc_id": "10582960",
    "abstract_original": "Agility - like the XXI. one of the fashionable concepts and leading approaches of the 20th century - it came into the spotlight after the 2000s. At first, as a new project management methodology, it was included in the thinking, which is able to eliminate the shortcomings and slowness of the classic waterfall model, thus making project management more efficient, directing them towards successful projects. Seeing the success of agile project management, more and more companies and businesses began to agileize their various organizational units as well, and finally the mindset spread to the whole organization. Today, we interpret the concept of agility not only at the organizational level, but also at the individual level. However, the willingness of individuals and employees to agility differs along a number of factors. It is influenced by an individual's age, generation affiliation, education, culture, which determines the extent to which he or she is able to embrace this new way of thinking. In our study, we look for the answer to what agility means as a term in the reading of respondents of each generation. The basis of our study is a questionnaire research carried out in Hungary, which was also part of an international research.",
    "abstract_processed": "agil like xxi one fashion concept lead approach th centuri came spotlight first new project manag methodolog includ think abl elimin shortcom slow classic waterfal model thu make project manag effici direct toward success project see success agil project manag compani busi began agil variou organiz unit well final mindset spread whole organ today interpret concept agil organiz level also individu level howev willing individu employe agil differ along number factor influenc individu age gener affili educ cultur determin extent abl embrac new way think studi look answer agil mean term read respond gener basi studi questionnair research carri hungari also part intern research"
  },
  {
    "doc_id": "10582976",
    "abstract_original": "Digitalisation is the defining concept of the 21st century. Today, there is no area of life that is not digitised, not connected to the internet in some way, not connected to an online platform where the actor or solution is available. Digitalisation cannot be excluded from the education system either. Higher education has long taken advantage of the opportunities offered by digitisation, which greatly facilitates the lives of individuals involved in education. It is an effective and good solution for the educators, but it is also an equally effective and good solution for the learners. In this study, we want to assess the impact of digitalisation on the competitiveness of education and the perceptions of those involved in education, students and learners. We want to assess how the competitiveness of education as a key area can be improved by moving part of education from the physical space to the digital space and how this is received by those involved in education. In this paper, we will present our findings and the context that determines and judges the current state of the art of this issue based on the results of a Hungarian primary research.",
    "abstract_processed": "digitalis defin concept st centuri today area life digitis connect internet way connect onlin platform actor solut avail digitalis cannot exclud educ system either higher educ long taken advantag opportun offer digitis greatli facilit live individu involv educ effect good solut educ also equal effect good solut learner studi want assess impact digitalis competit educ percept involv educ student learner want assess competit educ key area improv move part educ physic space digit space receiv involv educ paper present find context determin judg current state art issu base result hungarian primari research"
  },
  {
    "doc_id": "10583100",
    "abstract_original": "Job choice and retention are of paramount importance, especially in today's labour market conditions. Job selection criteria have changed significantly, further differentiated by generational differences and characteristics. Rather than standard solutions, employers need to think in terms of employer branding and HR strategies based on expectations tailored to individual career path needs. In this paper, we present the results of primary research conducted in a Chinese market, focusing specifically on Generation Z. With an international perspective, we analyse the perceptions of young Chinese people and evaluate the practical application of tools and methods to motivate them in HR and employer branding.",
    "abstract_processed": "job choic retent paramount import especi today labour market condit job select criteria chang significantli differenti gener differ characterist rather standard solut employ need think term employ brand hr strategi base expect tailor individu career path need paper present result primari research conduct chines market focus specif gener z intern perspect analys percept young chines peopl evalu practic applic tool method motiv hr employ brand"
  },
  {
    "doc_id": "10584380",
    "abstract_original": "Provides society information that may include news, reviews or technical notes that should be of interest to practitioners and researchers.",
    "abstract_processed": "provid societi inform may includ news review technic note interest practition research"
  },
  {
    "doc_id": "10585001",
    "abstract_original": "The fast advancement of machine learning (ML) techniques has brought about both innovative opportunities and unprecedented security challenges. In this paper, we consider the some important field of machine learning conduct a critical survey and analysis of machine language security and its importance, attacks and threats, aiming to provide a comprehensive understanding of the evolving landscape in cybersecurity. We begin by elucidating the fundamental concepts and terminologies associated with ML attacks, laying the groundwork for an in-depth exploration. Subsequently, we categorize and dissect various types of ML attacks, including adversarial attacks, data poisoning, model inversion, and membership inference, among others. Real-world case studies and examples across different domains, such as computer vision and natural language processing, are scrutinized to reveal the intricacies and implications of these attacks. Furthermore, we evaluate existing defense mechanisms and countermeasures, assessing their effectiveness against different attack scenarios. Finally, we discuss the broader societal impacts and ethical considerations surrounding the deployment of ML technologies in security-critical applications. this paper provides the tools to handle the machine language’s attacks and their solution using integration of academic research with real world examples.",
    "abstract_processed": "fast advanc machin learn ml techniqu brought innov opportun unpreced secur challeng paper consid import field machin learn conduct critic survey analysi machin languag secur import attack threat aim provid comprehens understand evolv landscap cybersecur begin elucid fundament concept terminolog associ ml attack lay groundwork depth explor subsequ categor dissect variou type ml attack includ adversari attack data poison model invers membership infer among other real world case studi exampl across differ domain comput vision natur languag process scrutin reveal intricaci implic attack furthermor evalu exist defens mechan countermeasur assess effect differ attack scenario final discuss broader societ impact ethic consider surround deploy ml technolog secur critic applic paper provid tool handl machin language’ attack solut use integr academ research real world exampl"
  },
  {
    "doc_id": "10585049",
    "abstract_original": "The human nervous system is the controlling mechanism for coordinating all body-related activities. In the cognitive world, it stimulates thinking capabilities. It prompts a reaction to a particular situation and allows body parts to move. In addition, it also regulates other physiological functions such as digestion and respiration. The nervous system consists of billions of cells which interpret information from sensory elements and translate it into coordinated action performed by various parts of the body. With the increase in age, the steady decline of these cells results in a loss of dopamine compounds. Parkinson's disease (PD) is caused by an unforeseen expansion of the movement of bodily extremities that results in this decline. Finding a cure for this disease is still an enormous challenge, and its progression can be slowed by early detection. The proposed work has been implemented with seven machine learning and deep-learning techniques, including decision tree (DT), random forest (RF), logistic regression, naive Bayes, k nearest neighbour, neural network model, and support vector machines for preemptively predicting PD. The model was implemented utilizing a dataset acquired from Kaggle. This included the normal cases as well as those with PD. The findings showed that the random forest model was superior to others, achieving an accuracy of 86.70%. In contrast, the naive Bayes model displayed the lowest accuracy of 71.50%. In addition, both the random forest and support vector machine models showed the highest accuracy levels of 85.90%. Various other performance metrics such as computational time, AUC (the Area Under the Curve), F1-score, ROC curve area, and recall rate were utilized to predict the effectiveness of each technique. Comparative analysis identified that the least performing models are the k-nearest neighbour and naive Bayes methods. In the future, this method can be refined further by using a large dataset and employing deep learning models for higher predictive outcomes.",
    "abstract_processed": "human nervou system control mechan coordin bodi relat activ cognit world stimul think capabl prompt reaction particular situat allow bodi part move addit also regul physiolog function digest respir nervou system consist billion cell interpret inform sensori element translat coordin action perform variou part bodi increas age steadi declin cell result loss dopamin compound parkinson diseas pd caus unforeseen expans movement bodili extrem result declin find cure diseas still enorm challeng progress slow earli detect propos work implement seven machin learn deep learn techniqu includ decis tree dt random forest rf logist regress naiv bay k nearest neighbour neural network model support vector machin preemptiv predict pd model implement util dataset acquir kaggl includ normal case well pd find show random forest model superior other achiev accuraci contrast naiv bay model display lowest accuraci addit random forest support vector machin model show highest accuraci level variou perform metric comput time auc area curv f score roc curv area recal rate util predict effect techniqu compar analysi identifi least perform model k nearest neighbour naiv bay method futur method refin use larg dataset employ deep learn model higher predict outcom"
  },
  {
    "doc_id": "10585562",
    "abstract_original": "As computational thinking (CT) emerges as a required skill in the modern educational and professional landscape, the use of games for learning programming has gained prominence. However, consideration for the user's needs and experiences is as important as the educational content itself, in order to ensure that the learner has an engaging experience. For this reason, this paper explores the integration of Empathic Design principles into the user experience (UX) evaluation of several popular programming genre games aimed at cultivating CT. The findings indicate a partial positive alignment with these principles, particularly in user-centric design, learning journey, and visual aspects. Learner-players feedback emphasized engaging experiences and visual appeal, while improvement suggestions centered on enhancing interface depth, providing clearer instructions, and addressing challenges for beginners and scalability issues.",
    "abstract_processed": "comput think ct emerg requir skill modern educ profession landscap use game learn program gain promin howev consider user need experi import educ content order ensur learner engag experi reason paper explor integr empath design principl user experi ux evalu sever popular program genr game aim cultiv ct find indic partial posit align principl particularli user centric design learn journey visual aspect learner player feedback emphas engag experi visual appeal improv suggest center enhanc interfac depth provid clearer instruct address challeng beginn scalabl issu"
  },
  {
    "doc_id": "10586672",
    "abstract_original": "Multimodal emotion recognition aims to recognize emotions through modal features such as acoustic, text, and visual modalities. Although existing multimodal emotion recognition algorithms have achieved good performance, in many tasks, features are extracted from the same video for acoustic, text, and visual modalities, which will lead to redundant information across modalities. To alleviate this issue, this paper proposes a multidimensional orthogonal fusion module, which orthogonalizes the input feature vectors to obtain pairwise orthogonal vectors, and concatenates the base vectors with the obtained orthogonal vectors to form fusion vectors. Experimental results demonstrate that the proposed algorithm outperforms mainstream multimodal emotion recognition algorithms. Ablation experiments show that the input sequence of modality affects the model's performance, with the model achieving optimal performance when the input sequence is visual features, speech features, text features, and personality features.",
    "abstract_processed": "multimod emot recognit aim recogn emot modal featur acoust text visual modal although exist multimod emot recognit algorithm achiev good perform mani task featur extract video acoust text visual modal lead redund inform across modal allevi issu paper propos multidimension orthogon fusion modul orthogon input featur vector obtain pairwis orthogon vector concaten base vector obtain orthogon vector form fusion vector experiment result demonstr propos algorithm outperform mainstream multimod emot recognit algorithm ablat experi show input sequenc modal affect model perform model achiev optim perform input sequenc visual featur speech featur text featur person featur"
  },
  {
    "doc_id": "10589932",
    "abstract_original": "The course “Computer Foundation of University” shoulders the mission of cultivating computational thinking and information literacy, and plays an important basic role in the general education curriculum system of undergraduate education. How to put computational thinking training into practice in teaching strategy design is problem worth researching. This paper gives an understanding of the nature, status and role of the course firstly. On this basis, instructional design research is carried out from the aspects of objective design, content design, teaching strategy design and evaluation design, etc. The purpose is to find feasible implementation strategies according to the characteristics and training objectives of the course, so as to realize the teaching objectives of the course and truly implement the training of computational thinking.",
    "abstract_processed": "cours “comput foundat university” shoulder mission cultiv comput think inform literaci play import basic role gener educ curriculum system undergradu educ put comput think train practic teach strategi design problem worth research paper give understand natur statu role cours firstli basi instruct design research carri aspect object design content design teach strategi design evalu design etc purpos find feasibl implement strategi accord characterist train object cours realiz teach object cours truli implement train comput think"
  },
  {
    "doc_id": "10589934",
    "abstract_original": "This paper focuses on the characteristics of computer science general course, specifically the emphasis on comprehension and practical application in “Python Language Programming”. Combining the contemporary Artificial Intelligence Generated Content (AIGC) technology with the teaching philosophy of Outcome-Based Education (OBE) and CDIO (Conceive, Design, Implement, Operate) in computer education, I propose the innovative AIGC-CDIO-OBE education model. Which can help students enhance computational thinking, design thinking, and programming skills in python language. Through teaching practices, the effectiveness and feasibility of this education model are demonstrated when compared to traditional teaching methods. Students have more interesting for learning, stronger motivation for coding, and stronger sense of achievement in their learning outcomes.",
    "abstract_processed": "paper focus characterist comput scienc gener cours specif emphasi comprehens practic applic “python languag programming” combin contemporari artifici intellig gener content aigc technolog teach philosophi outcom base educ obe cdio conceiv design implement oper comput educ propos innov aigc cdio obe educ model help student enhanc comput think design think program skill python languag teach practic effect feasibl educ model demonstr compar tradit teach method student interest learn stronger motiv code stronger sens achiev learn outcom"
  },
  {
    "doc_id": "10589958",
    "abstract_original": "As blended learning models gain popularity, analyzing the online learning behaviors of college students has emerged as a crucial approach to enhancing teaching effectiveness. The objective of this study is to conduct a comprehensive analysis of the learning behavior data from 44 students specializing in computer-related subjects on the online platform of the “Introduction to Computational Thinking” course, utilizing clustering algorithms. Subsequently, we utilized the Pearson correlation coefficient method to delve into the intricate relationship between diverse behavioral traits and academic performance. Our research has revealed that cluster analysis is adept at discerning behavioral disparities among students. Specifically, we identified four types of learning groups with different learning characteristics. Furthermore, a notable correlation was observed between homework scores and key evaluation metrics, including academic performance. Based on these findings, this study proposes targeted learning strategies and teaching suggestions, aiming to help educators better guide students in learning and improve the effectiveness of blended learning.",
    "abstract_processed": "blend learn model gain popular analyz onlin learn behavior colleg student emerg crucial approach enhanc teach effect object studi conduct comprehens analysi learn behavior data student special comput relat subject onlin platform “introduct comput thinking” cours util cluster algorithm subsequ util pearson correl coeffici method delv intric relationship divers behavior trait academ perform research reveal cluster analysi adept discern behavior dispar among student specif identifi four type learn group differ learn characterist furthermor notabl correl observ homework score key evalu metric includ academ perform base find studi propos target learn strategi teach suggest aim help educ better guid student learn improv effect blend learn"
  },
  {
    "doc_id": "10589985",
    "abstract_original": "With the development of the era of artificial intelligence(AI), China has put forward the cultivation of computational thinking(CT) in the compulsory education curriculum standard. CT includes three dimensions: CT concept, CT practice, and CT perspective. As a part of CT, the development of the CT perspective can promote the growth of students ‘ connection ability, questioning ability, and expression ability. CT perspective promotes the formation of computational identity through the internalization of concepts. At present, there are relatively few studies on the CT perspective. Based on this, this study proposes a design-based STEM + AI teaching model, aiming to create a combination of artificial intelligence and interdisciplinary to cultivate pupils ‘ CT perspective and form their computational identity. In this study, a single group of pre-test and post-test experiments were conducted to test the CT perspective and computational identity of students in the third grade of a primary school in Wuhan. The research shows that the design-based STEM + AI teaching has significantly improved the expression ability and questioning ability of primary school students in the CT perspective, as well as the correlation ability, participation ability, realization ability, and goal-setting ability in the computational identity. The implementation of STEM + AI teaching helps students to internalize ideas from the perspective of CT, thus cultivating students' computational identity.",
    "abstract_processed": "develop era artifici intellig ai china put forward cultiv comput think ct compulsori educ curriculum standard ct includ three dimens ct concept ct practic ct perspect part ct develop ct perspect promot growth student ‘ connect abil question abil express abil ct perspect promot format comput ident intern concept present rel studi ct perspect base studi propos design base stem ai teach model aim creat combin artifici intellig interdisciplinari cultiv pupil ‘ ct perspect form comput ident studi singl group pre test post test experi conduct test ct perspect comput ident student third grade primari school wuhan research show design base stem ai teach significantli improv express abil question abil primari school student ct perspect well correl abil particip abil realiz abil goal set abil comput ident implement stem ai teach help student intern idea perspect ct thu cultiv student comput ident"
  },
  {
    "doc_id": "10589990",
    "abstract_original": "Nowadays, the analysis of the relationship between students' ICT literacy and CT skills remains unclear, and less attention is paid to the influence of ICT resources at school on CT skills. To fill these gaps, a survey was performed on 1056 participants between the ages of 11 and 14, attending a secondary school in China. The participants completed one self-reported questionnaire about CT skills, ICT literacy, and ICT resources at school. The study revealed gender differences in CT skills based on the independent samples t-test, with boys having higher CT skills than girls. Additionally, the study found that ICT literacy mediates the relationship between ICT resources at school and CT skills. The research findings provide important insights for improving students' CT skills. Educators should pay attention to the gender differences in CT skills of male and female students and improve the acquired CT skills of female students. In addition, the improvement of students' ICT literacy skills and the improvement of ICT resources at school can also have a positive effect on students' CT skills.",
    "abstract_processed": "nowaday analysi relationship student ict literaci ct skill remain unclear less attent paid influenc ict resourc school ct skill fill gap survey perform particip age attend secondari school china particip complet one self report questionnair ct skill ict literaci ict resourc school studi reveal gender differ ct skill base independ sampl test boy higher ct skill girl addit studi found ict literaci mediat relationship ict resourc school ct skill research find provid import insight improv student ct skill educ pay attent gender differ ct skill male femal student improv acquir ct skill femal student addit improv student ict literaci skill improv ict resourc school also posit effect student ct skill"
  },
  {
    "doc_id": "10589992",
    "abstract_original": "With the explosive growth of data and the rapid development of artificial intelligence(AI) technology, scientific research requires to process a large amount of information. Recently AI tools based on large-scale language models (LLM) have emerged, providing researchers with new problem-solving ways. In this paper, we focus on the application of AI tools in the field of scientific research, and conduct a comprehensive analysis of LLM -based AI tools. Firstly, we introduce different types of LLM softwares and analyze their characteristics and advantages. N ext, we select some typical cases, explore the value and limitations of these tools in practice. Moreover, we summarize the main findings of the existing study and suggest some possible research directions in future. It is expected that this paper can provide reference and guidance for the use of AI tools in scientific and educational research.",
    "abstract_processed": "explos growth data rapid develop artifici intellig ai technolog scientif research requir process larg amount inform recent ai tool base larg scale languag model llm emerg provid research new problem solv way paper focu applic ai tool field scientif research conduct comprehens analysi llm base ai tool firstli introduc differ type llm softwar analyz characterist advantag n ext select typic case explor valu limit tool practic moreov summar main find exist studi suggest possibl research direct futur expect paper provid refer guidanc use ai tool scientif educ research"
  },
  {
    "doc_id": "10589995",
    "abstract_original": "Generative AI presents both opportunities and challenges for primary and secondary teacher capacity development. With the advancement of large language models (LLMs), combining AI with teachers' ubiquitous learning is a topic of concern. This study discusses the necessity of building a ubiquitous learning model for teachers based on big model technology from three perspectives: the research status on ubiquitous learning and LLMs, policy, and teachers' needs, constructing a framework for LLMs to empower teachers' ubiquitous learning for three major scenarios: teaching, teaching and research, and learning. The LLMs can assist teachers to automate the generation of learning situation analysis, teaching objectives and teaching resources to improve efficiency and teaching quality. In the teaching and research scenarios, the LLMs help to develop training content, evaluate teaching and optimize suggestions to improve the teaching and research. In the learning scenario, the LLMs provide personalized resources, stage summaries and evaluation to promote teachers' professional development. In addition, this study proposes the design idea of generative AI prompts to optimize teachers' learning experience and help them better apply the LLMs for ubiquitous learning. However, here are still some potential challenges and risks in the application of LLMs in education. Therefore, we explored the challenges and risks of teacher’ s collaboration with LLMs and propose responses to them. At the same time, we also prospectively analyzed the iteration and development trends of LLMs technology and explored the potential impact of future technological advances on teachers' pervasive learning and professional development.",
    "abstract_processed": "gener ai present opportun challeng primari secondari teacher capac develop advanc larg languag model llm combin ai teacher ubiquit learn topic concern studi discuss necess build ubiquit learn model teacher base big model technolog three perspect research statu ubiquit learn llm polici teacher need construct framework llm empow teacher ubiquit learn three major scenario teach teach research learn llm assist teacher autom gener learn situat analysi teach object teach resourc improv effici teach qualiti teach research scenario llm help develop train content evalu teach optim suggest improv teach research learn scenario llm provid person resourc stage summari evalu promot teacher profession develop addit studi propos design idea gener ai prompt optim teacher learn experi help better appli llm ubiquit learn howev still potenti challeng risk applic llm educ therefor explor challeng risk teacher’ collabor llm propos respons time also prospect analyz iter develop trend llm technolog explor potenti impact futur technolog advanc teacher pervas learn profession develop"
  },
  {
    "doc_id": "10589996",
    "abstract_original": "The jigsaw pedagogy as a student-centered instructional approach has been successfully applied in information technology classrooms, but there is a lack of empirical research on the effectiveness of jigsaw pedagogy in unplugged environments. Therefore, this study combined the jigsaw pedagogy with unplugged activities and verified the teaching effect of such a combination through randomized group experiments. The results of the study showed that the combination of the jigsaw pedagogy and the unplugged activities was more conducive to promoting students' motivation and the development of computational thinking than the unplugged activity alone. Drawing upon the research findings, this study concluded with several implications for teachers to reform information technology classrooms in unplugged environments.",
    "abstract_processed": "jigsaw pedagogi student center instruct approach success appli inform technolog classroom lack empir research effect jigsaw pedagogi unplug environ therefor studi combin jigsaw pedagogi unplug activ verifi teach effect combin random group experi result studi show combin jigsaw pedagogi unplug activ conduc promot student motiv develop comput think unplug activ alon draw upon research find studi conclud sever implic teacher reform inform technolog classroom unplug environ"
  },
  {
    "doc_id": "10590006",
    "abstract_original": "Recently, research on the development of artificial intelligence, in particular generative AI, has been active around the current world. Recent research mainly focuses on generating various types of outputs (text, image, video, etc.) from natural language textual inputs. However, understanding the meaning of these prompts in AI remains a challenge. In this paper, we propose a mechanism for extracting Cartoon images via UML Models based on natural language-based specifications, mapping a cut image's cartoon elements with UML properties extracted through linguistic textual analysis in software engineering. We expect software engineers to automatically help toon writers generate a cartoon's image with linguistic mechanisms.",
    "abstract_processed": "recent research develop artifici intellig particular gener ai activ around current world recent research mainli focus gener variou type output text imag video etc natur languag textual input howev understand mean prompt ai remain challeng paper propos mechan extract cartoon imag via uml model base natur languag base specif map cut imag cartoon element uml properti extract linguist textual analysi softwar engin expect softwar engin automat help toon writer gener cartoon imag linguist mechan"
  },
  {
    "doc_id": "10590167",
    "abstract_original": "In an increasingly technological world, it is becoming more important to be able to fix equipment as it breaks down. In many places, it seems like companies do not focus on such abilities, whether it is through the design of the product, some form of warranty, or Digital Rights Management companies trying to get in the way of repairs. This trend may have been going on for longer than we think, with many companies seemingly changing focus at some point. Nevertheless, what are the benefits of device and product repair? Why not just throw out the broken product and buy a new one? In this paper, we will give a history of the right to repair and discuss how long the anti-repair engineering trend has gone on. We will also go into the potential costs and benefits of engineering with the right to repair in mind and the expenses that come with the current way companies operate. In the end, this paper should inform how, as a whole, the greater world could benefit from right to repair legislation and design. We also intend to cover the potential benefits of the right to repair for businesses that normally impede the right, in addition to the tangible benefits of applying Six Sigma to right to repair.",
    "abstract_processed": "increasingli technolog world becom import abl fix equip break mani place seem like compani focu abil whether design product form warranti digit right manag compani tri get way repair trend may go longer think mani compani seemingli chang focu point nevertheless benefit devic product repair throw broken product buy new one paper give histori right repair discuss long anti repair engin trend gone also go potenti cost benefit engin right repair mind expens come current way compani oper end paper inform whole greater world could benefit right repair legisl design also intend cover potenti benefit right repair busi normal imped right addit tangibl benefit appli six sigma right repair"
  },
  {
    "doc_id": "10590542",
    "abstract_original": "ChatGPT is a relatively recent application, free to the general public, released at the end of November 2022 and rooted in artificial intelligence. The educational community is still debating how such an application could be used in the teaching and learning area, with the facilities it offers and the risks it entails. The purpose of this paper is to present how such an application responds to physics topics at the high school level, and to suggest ways to use it properly. In order to cover the issue comprehensively, it is approached from both the teacher's and the student's point of view.",
    "abstract_processed": "chatgpt rel recent applic free gener public releas end novemb root artifici intellig educ commun still debat applic could use teach learn area facil offer risk entail purpos paper present applic respond physic topic high school level suggest way use properli order cover issu comprehens approach teacher student point view"
  },
  {
    "doc_id": "10590568",
    "abstract_original": "Six Sigma is an up and coming, new way of thinking that strives for as close to perfection as possible. A Six Sigma approach can be applied to numerous aspects of life from computer science to businesses, and in this paper, we will explore how implementing a Six Sigma approach to a business can affect it. One of the first things we will investigate is how Six Sigma in business varies from how it is used in other fields. Once we understand this, we can dive into the various niches that it can apply to businesses. Some of these things are how it will help reduce waste and increase profits for a business. Expanding on this, we will also consider how implementing a new business practice such as a Six Sigma model could affect employee morale. We anticipate that due to a better business environment that something like this could improve, however it will be expanded upon further later in this research paper. Additionally, the last thing we would like to investigate involving Six Sigma in business is how it can change the quality of that business's goods or services. In this paper we will continue to investigate and research the previously stated research topics regarding Six Sigma in business. We will find out whether it is an effective approach and will be using how it affects waste, productivity, morale, and quality, to make an assessment.",
    "abstract_processed": "six sigma come new way think strive close perfect possibl six sigma approach appli numer aspect life comput scienc busi paper explor implement six sigma approach busi affect one first thing investig six sigma busi vari use field understand dive variou nich appli busi thing help reduc wast increas profit busi expand also consid implement new busi practic six sigma model could affect employe moral anticip due better busi environ someth like could improv howev expand upon later research paper addit last thing would like investig involv six sigma busi chang qualiti busi good servic paper continu investig research previous state research topic regard six sigma busi find whether effect approach use affect wast product moral qualiti make assess"
  },
  {
    "doc_id": "10590590",
    "abstract_original": "This study presents a hands-on research experience for an undergraduate junior-level service course, i.e., Circuits and Electromagnetics Devices, for non-Electrical Engineering students and its goal is to demonstrate major research methodologies as well as technical writing principles. The students have learned and investigated scientific research process, literature review sources as well as approaches, technical writing and blind-review principles, and conducted hands-on research on electrical circuit characterization and analysis for an autonomous/electric vehicle operation and a heating, ventilation, and air-conditioning system operations to investigate the contemporary engineering as well as social trends such as smart/green homes or vehicles. In addition, a practical autonomous vehicle set was utilized to explore the team research outcomes. The final student team outcomes as well as feedback and the corresponding surveys, evaluated by the project administrators, indicate the success of the effective research component inclusion in an undergraduate service course.",
    "abstract_processed": "studi present hand research experi undergradu junior level servic cours e circuit electromagnet devic non electr engin student goal demonstr major research methodolog well technic write principl student learn investig scientif research process literatur review sourc well approach technic write blind review principl conduct hand research electr circuit character analysi autonom electr vehicl oper heat ventil air condit system oper investig contemporari engin well social trend smart green home vehicl addit practic autonom vehicl set util explor team research outcom final student team outcom well feedback correspond survey evalu project administr indic success effect research compon inclus undergradu servic cours"
  },
  {
    "doc_id": "10592848",
    "abstract_original": "Digital sculpting, which involves the use of computer tools to create 3 dimensional objects, has grown as a popular method. The integration of Virtual reality (VR) in sculpting process provides immersive experiences, while artificial intelligence (AI) improves realism and creativeness. This bibliometric study tries to explore the intersection of digital sculpting, AI, and Virtual Reality in the world of art and design. The study aims to offer a comprehensive overview of current research in this interdisciplinary field, covering the period from 2003 to 2023. The dataset of 140 documents from Scopus Database, is examined for current trends, influential writers, and developing themes. The study highlights the importance of integrating AI with VR, to achieve greater realism, broader creative possibilities, and innovative paths for art instruction. Recent developments in VR apps, such as Shapelab, and AI tools, such as Spline AI, are discussed, showing the growing use of VR in digital sculpting and transformative AI-driven creative processes. Results from the bibliometric analysis show a dynamic research landscape, with an annual growth rate of 1.61%, diverse global contributions, and significant impacts from countries like the USA, South Korea, and France. Influential authors include Knopf GK, Lee Y-S, and Zhu W, while key terms like “virtual reality,” “algorithms,” and “human-computer interaction” emerges as trending topics. The conclusion highlights the promising future of this interdisciplinary field, with sustained interest, collaborative efforts, and impactful contributions, shaping the future of art and design.",
    "abstract_processed": "digit sculpt involv use comput tool creat dimension object grown popular method integr virtual realiti vr sculpt process provid immers experi artifici intellig ai improv realism creativ bibliometr studi tri explor intersect digit sculpt ai virtual realiti world art design studi aim offer comprehens overview current research interdisciplinari field cover period dataset document scopu databas examin current trend influenti writer develop theme studi highlight import integr ai vr achiev greater realism broader creativ possibl innov path art instruct recent develop vr app shapelab ai tool spline ai discuss show grow use vr digit sculpt transform ai driven creativ process result bibliometr analysi show dynam research landscap annual growth rate divers global contribut signific impact countri like usa south korea franc influenti author includ knopf gk lee zhu w key term like “virtual realiti ” “algorithm ” “human comput interaction” emerg trend topic conclus highlight promis futur interdisciplinari field sustain interest collabor effort impact contribut shape futur art design"
  },
  {
    "doc_id": "10592950",
    "abstract_original": "This investigation explores the viability of four noticeable models, specifically Pix2Pix, Neural Style Transfer (NST), Fast Neural Style Transfer (FastNST), and CycleGAN, within the space of aesthetic style exchange. The think about envelops a fastidious assessment of these models, investigating their capabilities in generating outwardly engaging and elaborately reliable pictures. Through broad tests and quantitative evaluations, Pix2Pix developed as a strong choice, accomplishing a Crest Signal-to-Noise Ratio (PSNR) of 26.78 dB, a Basic Likeness List (SSIM) of 0.832, and a Fréchet Initiation Separate (FID) of 54.21. NST, exceeding expectations in style devotion, achieved a PSNR of 29.45 dB, an SSIM of 0.905, and an FID of 72.03. FastNST, known for its real-time preparation, illustrated an adjusted execution with a PSNR of 28.12 dB, an SSIM of 0.892, and an FID of 68.54. CycleGAN, outlined for unpaired picture interpretation, accomplished a PSNR of 27.65 dB, an SSIM of 0.874, and an FID of 63.72. The results give profitable experiences into the comparative qualities and weaknesses of these models, educating their appropriateness in different artistic assignments.",
    "abstract_processed": "investig explor viabil four notic model specif pix pix neural style transfer nst fast neural style transfer fastnst cyclegan within space aesthet style exchang think envelop fastidi assess model investig capabl gener outwardli engag elabor reliabl pictur broad test quantit evalu pix pix develop strong choic accomplish crest signal nois ratio psnr db basic like list ssim fréchet initi separ fid nst exceed expect style devot achiev psnr db ssim fid fastnst known real time prepar illustr adjust execut psnr db ssim fid cyclegan outlin unpair pictur interpret accomplish psnr db ssim fid result give profit experi compar qualiti weak model educ appropri differ artist assign"
  },
  {
    "doc_id": "10593304",
    "abstract_original": "Handloom sector in India has been there for decades and weaving has been the profession by tradition for many of the communities that have existed since a longtime. If we observe the past few years, we see that there is a decline in the handloom export and an increase in the workforce attrition in this sector. There are multiple reasons for this shift in the workforce from handloom sector to other sectors which are more promising in terms of better pay and relatively less manual labour. This paper tries to propose a new business model that is backed up by artificial intelligence and machine language algorithms that will help and enable to create a centralized platform for the weavers that can give them the direct access to the market insights, customer preferences, latest trends, customer feedback, and much more. The objective of this paper is to reduce the burden from the weaver who other-wise have no insights on the market demand or customer preferences, which creates a demand supply gap and discourages them from continuing the profession of weaving as it costs them huge in terms of investment be it money needed for the looms or the time, and energy spent behind the loom in weaving the handwoven products.",
    "abstract_processed": "handloom sector india decad weav profess tradit mani commun exist sinc longtim observ past year see declin handloom export increas workforc attrit sector multipl reason shift workforc handloom sector sector promis term better pay rel less manual labour paper tri propos new busi model back artifici intellig machin languag algorithm help enabl creat central platform weaver give direct access market insight custom prefer latest trend custom feedback much object paper reduc burden weaver wise insight market demand custom prefer creat demand suppli gap discourag continu profess weav cost huge term invest money need loom time energi spent behind loom weav handwoven product"
  },
  {
    "doc_id": "10594737",
    "abstract_original": "Transportation systems design might be supported by participatory approaches refining service design, user experiences, and safety research. The evaluation of mobility alternatives as design improvement strategies requires more advanced instructional techniques with new structures of complexity that can demonstrate, analyze, or compare system performances in order to achieve environmental sustainability in general and the well-being of the end-users in particular. As an emerging technology, games are capable of representing operations and management of passenger freight transportation and increase situational awareness of capacity bottlenecks. However, few research efforts have been devoted to the synthesis of the research progress. Based on the profiling methodology that has been previously employed in retrospect of healthcare simulations, this article presents a bibliometric review of games for health in transportation systems. The study carries out a literature analysis of the modelling methods to assemble gamified scenarios from a planning and managerial perspective. The Web of Science Core Collections are used to identify research items and investigate all the game-based studies in the cross-disciplinary research area of transportation and public health. The technology, game mechanism, and the health-related issue addressed are grouped into broad categories. The research findings are three-fold. (1) The majority of publications are classified into research efforts revolving around slow and road transportation modes. (2) Although scores, badges, and challenges are considered as the frequently seen gamification features, environmental simulation, avatars, and narratives appear as game mechanisms for the activation of the individual decision-making process. (3) Introducing system dynamics, human-computer interaction design, and a stakeholder accountability framework into the multi-stakeholder simulation setting leverages gaming outcomes with health benefits amid transportation system end-users. The literature study concludes with an integrated framework summarizing the best design practices between 2002 and 2022 on how the lessons learned from serious gameplay in virtual environments could translate into real mobility improvements. A selection of future research questions is curated to envisage new links between transportation and health research communities.",
    "abstract_processed": "transport system design might support participatori approach refin servic design user experi safeti research evalu mobil altern design improv strategi requir advanc instruct techniqu new structur complex demonstr analyz compar system perform order achiev environment sustain gener well end user particular emerg technolog game capabl repres oper manag passeng freight transport increas situat awar capac bottleneck howev research effort devot synthesi research progress base profil methodolog previous employ retrospect healthcar simul articl present bibliometr review game health transport system studi carri literatur analysi model method assembl gamifi scenario plan manageri perspect web scienc core collect use identifi research item investig game base studi cross disciplinari research area transport public health technolog game mechan health relat issu address group broad categori research find three fold major public classifi research effort revolv around slow road transport mode although score badg challeng consid frequent seen gamif featur environment simul avatar narr appear game mechan activ individu decis make process introduc system dynam human comput interact design stakehold account framework multi stakehold simul set leverag game outcom health benefit amid transport system end user literatur studi conclud integr framework summar best design practic lesson learn seriou gameplay virtual environ could translat real mobil improv select futur research question curat envisag new link transport health research commun"
  },
  {
    "doc_id": "10595088",
    "abstract_original": "This paper proposes models for predicting the subjective impressions of interlocutors in discussions according to multimodal nonverbal behaviors. To that end, we focus mainly on the functional aspects of head movement and facial expressions as insightful cues. For example, head movement functions include the speaker’s rhythm and the listener’s back channel and thinking processes, as well as their positive emotions. Facial expression functions include emotional expressions and communicative functions such as the speaker addressing the listener and the listener’s affirmation. In addition, our model employs synergetic functions, which are jointly performed with head movements and facial expressions, assuming that the simultaneous appearance of head and face functions could strengthen the results or lead to multiplexing. On the basis of these nonverbal functions, we define a set of functional features, including the rate of occurrence and composition balance among different functions that emerge during conversation. Then, a feature selection scheme is used to identify the best combinations of intermodal and intramodal features. In the experiments, an SA-Off corpus of 17 groups of discussions involving 4 female participants was used, including interlocutors’ self-reported scores for 16 impression items felt during the discussion, such as helpfulness and interest. The experiments confirmed that our models’ predictions were significantly correlated with the self-reported scores for more than 70% of the impression items. These results indicate the effectiveness of multimodal nonverbal functional features for predicting subjective impressions.",
    "abstract_processed": "paper propos model predict subject impress interlocutor discuss accord multimod nonverb behavior end focu mainli function aspect head movement facial express insight cue exampl head movement function includ speaker’ rhythm listener’ back channel think process well posit emot facial express function includ emot express commun function speaker address listen listener’ affirm addit model employ synerget function jointli perform head movement facial express assum simultan appear head face function could strengthen result lead multiplex basi nonverb function defin set function featur includ rate occurr composit balanc among differ function emerg convers featur select scheme use identifi best combin intermod intramod featur experi sa corpu group discuss involv femal particip use includ interlocutors’ self report score impress item felt discuss help interest experi confirm models’ predict significantli correl self report score impress item result indic effect multimod nonverb function featur predict subject impress"
  },
  {
    "doc_id": "10597373",
    "abstract_original": "Organized misinformation campaigns on Twitter continue to proliferate, even as the platform acknowledges such activities through its transparency center. These deceptive initiatives significantly impact vital societal issues, including climate change, thus spurring research aimed at pinpointing and intercepting these malicious actors. Present-day algorithms for detecting bots harness an array of data drawn from user profiles, tweets, and network configurations, delivering commendable outcomes. Yet, these strategies mainly concentrate on postincident identification of malevolent users, hinging on static training datasets that categorize individuals based on historical activities. Diverging from this approach, we advocate for a forward-thinking methodology, which utilizes user data to foresee and mitigate potential threats before their realization, thereby cultivating more secure, equitable, and unbiased online communities. To this end, our proposed technique forecasts malevolent activities by tracing the projected trajectories of user embeddings before any malevolent action materializes. For validation, we employed a dynamic directed multigraph paradigm to chronicle the evolving engagements between Twitter users. When juxtaposed against the identical dataset, our technique eclipses contemporary methodologies by an impressive 40.66% in F score (F1 score) in the anticipatory identification of harmful users. Furthermore, we undertook a model evaluation exercise to gauge the efficiency of distinct system elements.",
    "abstract_processed": "organ misinform campaign twitter continu prolifer even platform acknowledg activ transpar center decept initi significantli impact vital societ issu includ climat chang thu spur research aim pinpoint intercept malici actor present day algorithm detect bot har array data drawn user profil tweet network configur deliv commend outcom yet strategi mainli concentr postincid identif malevol user hing static train dataset categor individu base histor activ diverg approach advoc forward think methodolog util user data forese mitig potenti threat realiz therebi cultiv secur equit unbias onlin commun end propos techniqu forecast malevol activ trace project trajectori user embed malevol action materi valid employ dynam direct multigraph paradigm chronicl evolv engag twitter user juxtapos ident dataset techniqu eclips contemporari methodolog impress f score f score anticipatori identif harm user furthermor undertook model evalu exercis gaug effici distinct system element"
  },
  {
    "doc_id": "10601375",
    "abstract_original": "Software development has undergone a paradigm change with the introduction of Artificial Intelligence (AI) into DevOps processes. This study examines the complex effects of AI on every stage of the software development lifecycle, from the creation of the code to its deployment and use. Through the viewpoint of “The Intelligent Evolution of Coding,” we explore how productivity benefits, traditional coding habits are being reshaped, and software is being strengthened against security risks thanks to AI-driven code creation and analysis. After that, the story switches to the revolutionary trip “From CI/CD to Autonomous Pipelines,” explaining how AI is streamlining software releases, improving pipelines for continuous integration and deployment, and encouraging development and operations teams to work together more effectively. The paper highlights the symbiotic connection that characterizes the future of software development by emphasizing the dynamic partnership between human knowledge and machine intelligence throughout this research. To fully realize the promise of AI-driven DevOps, businesses must negotiate this disruptive environment with careful attention to ethical implementation, workforce upskilling, and the development of learning ecosystems. In the end, the study imagines a world in which technological advancements enhance human potential, stimulating creativity, resiliency, and flexibility in the dynamic field of software development.",
    "abstract_processed": "softwar develop undergon paradigm chang introduct artifici intellig ai devop process studi examin complex effect ai everi stage softwar develop lifecycl creation code deploy use viewpoint “the intellig evolut code ” explor product benefit tradit code habit reshap softwar strengthen secur risk thank ai driven code creation analysi stori switch revolutionari trip “from ci cd autonom pipelin ” explain ai streamlin softwar releas improv pipelin continu integr deploy encourag develop oper team work togeth effect paper highlight symbiot connect character futur softwar develop emphas dynam partnership human knowledg machin intellig throughout research fulli realiz promis ai driven devop busi must negoti disrupt environ care attent ethic implement workforc upskil develop learn ecosystem end studi imagin world technolog advanc enhanc human potenti stimul creativ resili flexibl dynam field softwar develop"
  },
  {
    "doc_id": "10601657",
    "abstract_original": "The main challenge of pose estimation for six degrees of freedom (6DoF) is the lack of labeled data in real environment. In order to overcome this problem, many studies recently have trained deep learning models with synthetic data. However, a domain gap between real and synthetic environments exists, prompting various approaches to address this issue. In this work, we propose domain adaptation for self-supervised 6DoF pose estimation, which leverages the components and introduces an effective method to reduce domain discrepancy. First, we adopt a multi-level domain adaptation module, on image level and instance level, to learn domain-invariant features. Second, we used entropy-based alignment to minimize the entropy of representation embedding. Finally, we evaluate our approach on LineMOD and Occlusion-LineMOD datasets. Experiments show that our proposed method achieves higher performance compared to the prior methods and demonstrate effectiveness in domain shift scenarios on 6DoF pose estimation.",
    "abstract_processed": "main challeng pose estim six degre freedom dof lack label data real environ order overcom problem mani studi recent train deep learn model synthet data howev domain gap real synthet environ exist prompt variou approach address issu work propos domain adapt self supervis dof pose estim leverag compon introduc effect method reduc domain discrep first adopt multi level domain adapt modul imag level instanc level learn domain invari featur second use entropi base align minim entropi represent embed final evalu approach linemod occlus linemod dataset experi show propos method achiev higher perform compar prior method demonstr effect domain shift scenario dof pose estim"
  },
  {
    "doc_id": "10601953",
    "abstract_original": "The demand for well-trained nursing professionals is ever-increasing, necessitating efficient placement processes post-graduation. This study explores the application of machine learning (ML) algorithms to predict B.Sc. Nursing placement outcomes, aiming to optimize workforce management and graduate placement efficiency. Traditional placement methods often suffer from subjectivity and inefficiency. Leveraging historical placement data and relevant features, ML algorithms discern patterns to forecast individual placement likelihood accurately. Various ML techniques including logistic regression, decision trees, support vector machines, and ensemble methods are employed and evaluated for their predictive efficacy. The CN2 rule inducer model emerges as the top-performing model, demonstrating superior discriminatory ability and accuracy. These findings offer significant implications for nursing education institutions and healthcare organizations, facilitating better alignment of education with workforce demands. However, the study also emphasizes the importance of balancing model performance with interpretability. Further research and implementation efforts are warranted to refine predictive modeling approaches and seamlessly integrate them into nursing education and workforce management practices, ultimately contributing to the advancement of nursing practice and patient care delivery.",
    "abstract_processed": "demand well train nurs profession ever increas necessit effici placement process post graduat studi explor applic machin learn ml algorithm predict b sc nurs placement outcom aim optim workforc manag graduat placement effici tradit placement method often suffer subject ineffici leverag histor placement data relev featur ml algorithm discern pattern forecast individu placement likelihood accur variou ml techniqu includ logist regress decis tree support vector machin ensembl method employ evalu predict efficaci cn rule induc model emerg top perform model demonstr superior discriminatori abil accuraci find offer signific implic nurs educ institut healthcar organ facilit better align educ workforc demand howev studi also emphas import balanc model perform interpret research implement effort warrant refin predict model approach seamlessli integr nurs educ workforc manag practic ultim contribut advanc nurs practic patient care deliveri"
  },
  {
    "doc_id": "10602503",
    "abstract_original": "Emotion recognition involves accurately interpreting human emotions from various sources and modalities, including questionnaires, verbal, and physiological signals. With its broad applications in affective computing, computational creativity, human-robot interactions, and market research, the field has seen a surge in interest in recent years. This paper presents a systematic review of multimodal emotion recognition (MER) techniques developed from 2014 to 2024, encompassing verbal, physiological signals, facial, body gesture, and speech as well as emerging methods like sketches emotion recognition. The review explores various emotion models, distinguishing between emotions, feelings, sentiments, and moods, along with human emotional expression, categorized in both artistic and non-verbal ways. It also discusses the background of automated emotion recognition systems and introduces seven criteria for evaluating modalities alongside a current state analysis of MER, drawn from the human-centric perspective of this field. By selecting the PRISMA guidelines and carefully analyzing 45 selected articles, this review provides comprehensive perspectives into existing studies, datasets, technical approaches, identified gaps, and future directions in MER. It also highlights existing challenges and current applications of the MER.",
    "abstract_processed": "emot recognit involv accur interpret human emot variou sourc modal includ questionnair verbal physiolog signal broad applic affect comput comput creativ human robot interact market research field seen surg interest recent year paper present systemat review multimod emot recognit mer techniqu develop encompass verbal physiolog signal facial bodi gestur speech well emerg method like sketch emot recognit review explor variou emot model distinguish emot feel sentiment mood along human emot express categor artist non verbal way also discuss background autom emot recognit system introduc seven criteria evalu modal alongsid current state analysi mer drawn human centric perspect field select prisma guidelin care analyz select articl review provid comprehens perspect exist studi dataset technic approach identifi gap futur direct mer also highlight exist challeng current applic mer"
  },
  {
    "doc_id": "10602887",
    "abstract_original": "Proposed at the Dartmouth Conference in 1956, the primary objective of artificial intelligence (AI) is to empower machines to think and solve problems akin to humans. Despite the emergence of various large-scale models in recent years, notable progress has been made in the realm of artificial general intelligence (AGI) models. However, machines still encounter challenges in autonomously learning and evolving like humans, and there remains a dearth of a robust mathematical foundation. This paper delves into the autonomous evolutionary process observed in humans and biological entities, asserting that “Needs are the fundamental driving force for organism evolution.” Additionally, the paper introduces corresponding representation algorithms and lays out mathematical theoretical foundations, thereby furnishing a theoretical explanation and a solid mathematical basis for understanding the autonomy of general intelligence models.",
    "abstract_processed": "propos dartmouth confer primari object artifici intellig ai empow machin think solv problem akin human despit emerg variou larg scale model recent year notabl progress made realm artifici gener intellig agi model howev machin still encount challeng autonom learn evolv like human remain dearth robust mathemat foundat paper delv autonom evolutionari process observ human biolog entiti assert “need fundament drive forc organ evolut ” addit paper introduc correspond represent algorithm lay mathemat theoret foundat therebi furnish theoret explan solid mathemat basi understand autonomi gener intellig model"
  },
  {
    "doc_id": "10603677",
    "abstract_original": "Large language models (LLMs) have garnered significant attention due to their impressive performance across various fields. Consequently, numerous researchers are exploring the potential of applying these models to graph problems. However, the effect of the temperature coefficient on graph reasoning within large models remains underexplored. To this end, we investigate the effect of temperature by using NLGraph as a benchmark. We aim to explore the effect of varying the temperature parameter in the discrete range of 0 to 1 on the models’ inference performance. The experimental results show that the LLMs’ sensitivity to temperature varies across tasks at different difficulty levels. In most cases, the accuracy is higher at moderate temperatures and lower at extreme temperature settings, suggesting that proper temperature tuning can improve inference performance. In addition, the effect of temperature change on accuracy is more significant in the shortest path problem. As the temperature increases, the tendency of the model to explore different solutions increases and the creativity and disorder of the response increases, leading to a decrease in accuracy and causing an increase in the rate of change.",
    "abstract_processed": "larg languag model llm garner signific attent due impress perform across variou field consequ numer research explor potenti appli model graph problem howev effect temperatur coeffici graph reason within larg model remain underexplor end investig effect temperatur use nlgraph benchmark aim explor effect vari temperatur paramet discret rang models’ infer perform experiment result show llms’ sensit temperatur vari across task differ difficulti level case accuraci higher moder temperatur lower extrem temperatur set suggest proper temperatur tune improv infer perform addit effect temperatur chang accuraci signific shortest path problem temperatur increas tendenc model explor differ solut increas creativ disord respons increas lead decreas accuraci caus increas rate chang"
  },
  {
    "doc_id": "10603938",
    "abstract_original": "The integration of artificial intelligence (AI) into healthcare is revolutionizing medical information access and professional advice delivery. This study focuses on the development of a medical-specific question-answering model leveraging the Qwen-VL 7B model, an advanced Large Vision-Language Model (LVLM), to enhance the understanding and generation of medical texts. The Qwen-VL 7B model's capabilities in both language and visual comprehension make it an ideal candidate for medical question-answering systems, which require a deep grasp of medical knowledge and language. The research objectives include adapting the Qwen-VL 7B model to medical terminology, utilizing its visual understanding for medical imaging analysis, optimizing question-answering systems for medical scenarios, and evaluating the performance of these models. To achieve these goals, we employed methodologies such as dataset construction, model fine-tuning, and user studies. Results showed that the Qwen-VL-Mediacal model achieved a Rouge-1 score of 0.6147, indicating its potential for medical applications. However, challenges remain, such as understanding complex scenes and abstract concepts. Future research will aim to improve the model's adaptability and reasoning capabilities.",
    "abstract_processed": "integr artifici intellig ai healthcar revolution medic inform access profession advic deliveri studi focus develop medic specif question answer model leverag qwen vl b model advanc larg vision languag model lvlm enhanc understand gener medic text qwen vl b model capabl languag visual comprehens make ideal candid medic question answer system requir deep grasp medic knowledg languag research object includ adapt qwen vl b model medic terminolog util visual understand medic imag analysi optim question answer system medic scenario evalu perform model achiev goal employ methodolog dataset construct model fine tune user studi result show qwen vl mediac model achiev roug score indic potenti medic applic howev challeng remain understand complex scene abstract concept futur research aim improv model adapt reason capabl"
  },
  {
    "doc_id": "10604485",
    "abstract_original": "Computational Thinking (CT) is a transversal ability to solve problems in any area, is crucial for Computer Programming. We believe that CT skills should be developed and encouraged from a young age. However, to promote the development of CT it is necessary to use appropriate materials, which we call Learning Resources (LR). For a more efficient development of CT, it is important that the LR are designed and used in order to obtain the maximum potential of the resource. Scientific evidence from Neuroeducation can be used to fully explore LR. There are many LR available to promote CT, however, they are not correctly classified in order to be easy to understand what specific CT skills they stimulate, neither which ages they are adequate for. Directions for their most convenient usage are also lacking. This paper aims to present an approach to categorize these LR so that when a teacher intends to promote the development of one or more specific CT skills, in a given schooling year, he can find the adequate LR more easily, and also get educational resources concerning their use. This characterization approach is based on OntoCnE ontology. OntoCnE was built by us and is composed of 4 layers that define: how to develop CT (1); which concepts should be taught at each school level (2); which materials are appropriate for each skill (3); and the Neuroeducation guidelines associated with each resource (4). This paper essentially focuses on layers 3 and 4 to perform the LR characterization. To illustrate our approach, we will follow OntoCnE statements to categorize a set of LRs. With this methodological setting we intend to build a catalog of LR more effectively promote CT skills on children.",
    "abstract_processed": "comput think ct transvers abil solv problem area crucial comput program believ ct skill develop encourag young age howev promot develop ct necessari use appropri materi call learn resourc lr effici develop ct import lr design use order obtain maximum potenti resourc scientif evid neuroeduc use fulli explor lr mani lr avail promot ct howev correctli classifi order easi understand specif ct skill stimul neither age adequ direct conveni usag also lack paper aim present approach categor lr teacher intend promot develop one specif ct skill given school year find adequ lr easili also get educ resourc concern use character approach base ontocn ontolog ontocn built us compos layer defin develop ct concept taught school level materi appropri skill neuroeduc guidelin associ resourc paper essenti focus layer perform lr character illustr approach follow ontocn statement categor set lr methodolog set intend build catalog lr effect promot ct skill children"
  },
  {
    "doc_id": "10604513",
    "abstract_original": "Initial programming education is a topic that con-tinues to spark much debate, as it is an academic field with a notably high rate of student dropouts and failures. The challenge of offering this subject through distance education adds to the complexity, given the need for students to adapt to this mode of teaching and learning, which significantly differs from traditional classroom settings. Multiple studies suggest that students must appropriately develop cognitive and non-cognitive skills for effective learning. Yet, there is a pressing need for further investigation into the impact of non-cognitive skills on student performance, with a particular focus on motivation, which plays an important role in student success. In this sense, considering the specificities of learning programming, the context of distance education, this research aims to understand the factors that can stimulate students' motivation for initial learning of programming, developing a virtual learning environment that promotes student motivation to learn to program and evaluate the environment to identify whether its features have the potential to stimulate student motivation.",
    "abstract_processed": "initi program educ topic con tinu spark much debat academ field notabl high rate student dropout failur challeng offer subject distanc educ add complex given need student adapt mode teach learn significantli differ tradit classroom set multipl studi suggest student must appropri develop cognit non cognit skill effect learn yet press need investig impact non cognit skill student perform particular focu motiv play import role student success sens consid specif learn program context distanc educ research aim understand factor stimul student motiv initi learn program develop virtual learn environ promot student motiv learn program evalu environ identifi whether featur potenti stimul student motiv"
  },
  {
    "doc_id": "10604518",
    "abstract_original": "Scientific and technological progress has promoted social change, and digital technologies such as big data, the Internet, cloud computing, and the Internet of Things have begun to develop, changing human thinking structure, living habits, learning behaviors, communication methods, and production technologies. Big data, as a hot topic in current digital technology and digital development, is based on massive data and generates value through computational analysis. It has been applied in various fields and different scenarios. China has issued the “Overall Layout Plan for Digital China Construction” document, which clarifies the need to accelerate the construction of Digital China, promote digital technology innovation, improve the digital governance system, and enhance digital security capabilities. The digital reform and development of education is an important part of the construction of a digital China, and it is an inevitable path to achieve the modernization of China's education. The development of digital education requires innovative digital applications in teaching methods, teaching resources, teaching evaluation, educational governance, and actively promoting the application of digital technologies such as big data and cloud computing in specific educational scenarios. The performance management of university teachers, as one of the important contents of educational governance and university management, relies on big data to establish a data governance system for the performance management of university teachers, which is precisely the demand for the digital development and construction of education. This article explores the application of big data in the digital construction of performance management for university teachers from three aspects: background, definition and characteristics of big data, and digitalization of performance management for university teachers. With big data as the core and data governance as the goal, big data application design is carried out from three perspectives: improving the digital performance system for university teachers, digitizing the performance content of university teachers, and designing a big data platform for university teacher performance management.",
    "abstract_processed": "scientif technolog progress promot social chang digit technolog big data internet cloud comput internet thing begun develop chang human think structur live habit learn behavior commun method product technolog big data hot topic current digit technolog digit develop base massiv data gener valu comput analysi appli variou field differ scenario china issu “overal layout plan digit china construction” document clarifi need acceler construct digit china promot digit technolog innov improv digit govern system enhanc digit secur capabl digit reform develop educ import part construct digit china inevit path achiev modern china educ develop digit educ requir innov digit applic teach method teach resourc teach evalu educ govern activ promot applic digit technolog big data cloud comput specif educ scenario perform manag univers teacher one import content educ govern univers manag reli big data establish data govern system perform manag univers teacher precis demand digit develop construct educ articl explor applic big data digit construct perform manag univers teacher three aspect background definit characterist big data digit perform manag univers teacher big data core data govern goal big data applic design carri three perspect improv digit perform system univers teacher digit perform content univers teacher design big data platform univers teacher perform manag"
  },
  {
    "doc_id": "10604649",
    "abstract_original": "Our contemporary society necessitates professionals equipped with 21st-century skills. Disciplines within Science, Technology, Engineering, Arts, and Mathematics (known as STEAM) have been particularly effective in fostering these skills. However, when considering students with disabilities, especially those with intellectual or developmental disabilities (IDD), this assertion often falls short. In this context, the RoboSTEAMSEN project emerges as an initiative designed to enhance educational processes by providing teachers of IDD students with the necessary resources to promote STEAM engagement. The project proposes the use of active learning methodologies and robotics to achieve this goal. The primary objective of the project is realized through several strategies: understanding the needs of students with disabilities and adapting the use of robotics and active learning methodologies accordingly; training teachers in the use of these resources; and creating a platform to exchange experiences, resources, lessons learned, tools, case scenarios, etc., while reaching other potential stakeholders such as caregivers and policymakers. The main outcomes of the project are teacher training programs and the development of associated competencies, tools to identify and classify resources for the students, and technological platforms to ensure the sustain ability of the project once it concludes.",
    "abstract_processed": "contemporari societi necessit profession equip st centuri skill disciplin within scienc technolog engin art mathemat known steam particularli effect foster skill howev consid student disabl especi intellectu development disabl idd assert often fall short context robosteamsen project emerg initi design enhanc educ process provid teacher idd student necessari resourc promot steam engag project propos use activ learn methodolog robot achiev goal primari object project realiz sever strategi understand need student disabl adapt use robot activ learn methodolog accordingli train teacher use resourc creat platform exchang experi resourc lesson learn tool case scenario etc reach potenti stakehold caregiv policymak main outcom project teacher train program develop associ compet tool identifi classifi resourc student technolog platform ensur sustain abil project conclud"
  },
  {
    "doc_id": "10605616",
    "abstract_original": "The goal of modern educational systems is to prepare not just a performer, but a creatively developed personality capable of solving non-standard problems in the changing conditions of professional activity. A higher educational institution requires the introduction of new approaches to teaching that ensure the development of professional, creative, information, and communicative competencies of graduates. The article presents the discipline “Numerical Methods” and “Theory of Computational Experiments”, which are basic for students in the field of Applied Mathematics and Computer Science. The knowledge, skills and abilities obtained while studying the discipline will make it possible to carry out applied projects in the field of mathematics, natural sciences, operations research, and machine learning. These disciplines can also be recommended to students in the areas of training Applied Informatics and Mathematical Support of Information Systems due to the importance of mastering this material and subsequent use in solving applied problems.",
    "abstract_processed": "goal modern educ system prepar perform creativ develop person capabl solv non standard problem chang condit profession activ higher educ institut requir introduct new approach teach ensur develop profession creativ inform commun compet graduat articl present disciplin “numer methods” “theori comput experiments” basic student field appli mathemat comput scienc knowledg skill abil obtain studi disciplin make possibl carri appli project field mathemat natur scienc oper research machin learn disciplin also recommend student area train appli informat mathemat support inform system due import master materi subsequ use solv appli problem"
  },
  {
    "doc_id": "10605877",
    "abstract_original": "A lack of early exposure to computer science and a shortage of role models are known barriers hindering underrep-resented students' pursuit and success in the field. Consistent research indicates that students lacking early exposure tend to avoid college-level computer science courses and frequently underperform compared to peers with prior experience. In response, we've created a two-week computer science camp tailored for upper elementary and middle school students from rural and low-income backgrounds. The camp adapts computer science concepts to diverse cultures, challenges stereotypes, and showcases the diverse backgrounds of computer scientists. This paper outlines the camp's design, shares experiences from 40 participating students, and highlights engaging lessons that in-corporate technologies such as Sphero Bolt, Sphero Rover, Tello Drones, Lego Spike Prime, and Scratch. We also gather data on students' favorite activities to understand their interests. Our discussion covers effective strategies for participant recruitment, community trust-building, professional development facilitation, camp activity organization, and project promotion. By sharing challenges and lessons learned, we aim to assist fellow researchers and educators in similar initiatives, fostering collaboration and progress in the field of computer science education.",
    "abstract_processed": "lack earli exposur comput scienc shortag role model known barrier hinder underrep resent student pursuit success field consist research indic student lack earli exposur tend avoid colleg level comput scienc cours frequent underperform compar peer prior experi respons creat two week comput scienc camp tailor upper elementari middl school student rural low incom background camp adapt comput scienc concept divers cultur challeng stereotyp showcas divers background comput scientist paper outlin camp design share experi particip student highlight engag lesson corpor technolog sphero bolt sphero rover tello drone lego spike prime scratch also gather data student favorit activ understand interest discuss cover effect strategi particip recruit commun trust build profession develop facilit camp activ organ project promot share challeng lesson learn aim assist fellow research educ similar initi foster collabor progress field comput scienc educ"
  },
  {
    "doc_id": "10605886",
    "abstract_original": "Physiological computing (PC) technology is becoming increasingly popular as wearable hardware improves. However, little is known regarding potential connections between hands-on experience with physiological computing technology and computation thinking perspectives. This is particularly true for black communities. Applications for physiological computing include systems such as wearable technology (e.g., Apple Watch) capable of mapping students' physiological activity to various outputs. The work discussed in this paper presents our initial steps toward filling these gaps. In particular, we share our observations of computational thinking perspectives that emerged while black high school students constructed simple programs driven by near real-time brain wave information. Our findings suggest interactive physiological data may lead to unique computational perspectives during learning activities.",
    "abstract_processed": "physiolog comput pc technolog becom increasingli popular wearabl hardwar improv howev littl known regard potenti connect hand experi physiolog comput technolog comput think perspect particularli true black commun applic physiolog comput includ system wearabl technolog e g appl watch capabl map student physiolog activ variou output work discuss paper present initi step toward fill gap particular share observ comput think perspect emerg black high school student construct simpl program driven near real time brain wave inform find suggest interact physiolog data may lead uniqu comput perspect learn activ"
  },
  {
    "doc_id": "10607286",
    "abstract_original": "In 2021, the first year of Metaverse, Web3.0 ecosystems emerged as a result of the Internet's de-centralized evolution. In the Web3.0 space, there has been a very active advancement of the generative art non-fungible token, which is a special asset stored on a blockchain that allows creators to buy and sell assets and verify ownership. In other words, as it reconstructs the interpersonal relationship, the generative art non-fungible token must carry cultural values to be meaningful, and waiting to observe artificial intelligence generative art in the future requires a new mindset and posture. Design thinking is a design-based approach to solve today's complex problems. This study thus addresses the new Web3.0 ecosystem and introduces environmental sustain ability issues and computational thinking in the form of generative art to discuss the possibilities of future design thinking. By linking with social information, this study also creates an intersection with heterogeneous knowledge and stimulates a new thinking pattern that is different from previous ones. This project of design and research in the Metaverse virtual environment is still a novel topic. Reviewing past literature indicates that relevant papers are very scarce, and more resources are urgently needed for research in this field.",
    "abstract_processed": "first year metavers web ecosystem emerg result internet de central evolut web space activ advanc gener art non fungibl token special asset store blockchain allow creator buy sell asset verifi ownership word reconstruct interperson relationship gener art non fungibl token must carri cultur valu meaning wait observ artifici intellig gener art futur requir new mindset postur design think design base approach solv today complex problem studi thu address new web ecosystem introduc environment sustain abil issu comput think form gener art discuss possibl futur design think link social inform studi also creat intersect heterogen knowledg stimul new think pattern differ previou one project design research metavers virtual environ still novel topic review past literatur indic relev paper scarc resourc urgent need research field"
  },
  {
    "doc_id": "10608031",
    "abstract_original": "This study investigated the effects of image resizing vs cropping on the performance of state-of-the-art models for the brain tumor segmentation task. This is particularly important since many studies simply resize the image without thinking about potential effects of image distortion on the model's segmentation performance. Since the objective of tumor segmentation is to predict the pixels that comprise the actual tumor, image cropping was performed in order to focus more on the brain and the tumor and not on the background. This conjecture was tested using state-of-the-art models namely 2D U-Net, 2D U- Net with VGG19 as backbone, 2D U-Net with InceptionV3 ad backbone, and 2D U-Net with InceptionResNetV2 as backbone. Three different configurations were designed for this purpose. The first configuration used resized images while the second configuration used cropped images. The third configuration used pretrained weights of models of trained on the resized images and then applied them on the cropped images. Overall, the top three models are 2D U-Net with InceptionResNetV2 as backbone trained using the resized images followed by 2D U-Net trained also using the resized images and then finally by 2D U-Net trained using the cropped images. As to why cropping did not perform well in this experiment, several plausible explanations were provided in this study.",
    "abstract_processed": "studi investig effect imag resiz vs crop perform state art model brain tumor segment task particularli import sinc mani studi simpli resiz imag without think potenti effect imag distort model segment perform sinc object tumor segment predict pixel compris actual tumor imag crop perform order focu brain tumor background conjectur test use state art model name u net u net vgg backbon u net inceptionv ad backbon u net inceptionresnetv backbon three differ configur design purpos first configur use resiz imag second configur use crop imag third configur use pretrain weight model train resiz imag appli crop imag overal top three model u net inceptionresnetv backbon train use resiz imag follow u net train also use resiz imag final u net train use crop imag crop perform well experi sever plausibl explan provid studi"
  },
  {
    "doc_id": "10611246",
    "abstract_original": "We propose, examine prototypes of, and collect user input on morphing robotic surfaces, \"robot-room\" elements that, individually or in combination, change the functionality of the rooms we live in, directly controlled by the room’s occupants engaging with it. Robot-rooms represent an advance in human-robot interaction whereby human interaction is within a machine that physically envelops us. We discuss the motivation for such robot-rooms, present initial work aimed at their physical realization, and report on a user study of 80 participants to learn what people might want of and expect from robot rooms, the results of which will inform both the iterative design of the robot room and the thinking of our community as it grapples with how we want to live with (and \"in\") robots.",
    "abstract_processed": "propos examin prototyp collect user input morph robot surfac robot room element individu combin chang function room live directli control room’ occup engag robot room repres advanc human robot interact wherebi human interact within machin physic envelop us discuss motiv robot room present initi work aim physic realiz report user studi particip learn peopl might want expect robot room result inform iter design robot room think commun grappl want live robot"
  },
  {
    "doc_id": "10612168",
    "abstract_original": "Conceptual architecture involves a highly creative exploration of novel ideas, often taken from other disciplines as architects consider radical new forms, materials, textures and colors for buildings. While today's generative AI systems can produce remarkable results, they lack the creativity demonstrated for decades by evolutionary algorithms. SCAPE, our proposed tool, combines evolutionary search with generative AI, enabling users to explore creative and good quality designs inspired by their initial input through a simple point and click interface. SCAPE injects randomness into generative AI, and enables memory, making use of the built-in language skills of GPT -4 to vary prompts via text-based mutation and crossover. We demonstrate that compared to DALL. E 3, SCAPE enables a 67% improvement in image novelty, plus improvements in quality and effectiveness of use; we show that in just three iterations SCAPE has a 24% image novelty increase enabling effective exploration, plus optimization of images by users. We use more than 20 independent architects to assess SCAPE, who provide markedly positive feedback.",
    "abstract_processed": "conceptu architectur involv highli creativ explor novel idea often taken disciplin architect consid radic new form materi textur color build today gener ai system produc remark result lack creativ demonstr decad evolutionari algorithm scape propos tool combin evolutionari search gener ai enabl user explor creativ good qualiti design inspir initi input simpl point click interfac scape inject random gener ai enabl memori make use built languag skill gpt vari prompt via text base mutat crossov demonstr compar dall e scape enabl improv imag novelti plu improv qualiti effect use show three iter scape imag novelti increas enabl effect explor plu optim imag user use independ architect assess scape provid markedli posit feedback"
  },
  {
    "doc_id": "10613367",
    "abstract_original": "This article discusses the latest developments of the Sucre4Stem tool, as part of the Sucre initiative, which aims to promote interest in computational thinking and programming skills in K-12 students. The tool follows the Internet of Things approach and consists of two prominent components: 1) SucreCore and 2) SucreCode. SucreCore incorporates an advanced microcontroller packaged in a more compact design and enables wireless connectivity. SucreCode, the block-based visual programming tool, supports two different sets of blocks depending on the education grade, and facilitates wireless communication with SucreCore. At the educational level, Sucre4Stem fosters new group dynamics and encourages students to experiment real-world projects by promoting the “programming to learn” approach to concepts from other disciplines as opposed to the strategy widely applied in schools of “learning to program” in isolation.",
    "abstract_processed": "articl discuss latest develop sucr stem tool part sucr initi aim promot interest comput think program skill k student tool follow internet thing approach consist two promin compon sucrecor sucrecod sucrecor incorpor advanc microcontrol packag compact design enabl wireless connect sucrecod block base visual program tool support two differ set block depend educ grade facilit wireless commun sucrecor educ level sucr stem foster new group dynam encourag student experi real world project promot “program learn” approach concept disciplin oppos strategi wide appli school “learn program” isol"
  },
  {
    "doc_id": "10615152",
    "abstract_original": "Currently, part of the main tasks of digital control information technologies is to recreate a system that thinks logically and intelligently using a computer, and to create devices that make control decision-making like a human under positions of unpredictability and speculative. In this article, the processes of control decision-making in digital control information systems were systematically analyzed and studied. During the analysis of processes control decision-making in digital control information systems, its functions and shortcomings were determined using systematic approach methods. It was the initial stage of a detailed assessment of task positions and the results of statistical models of benchmark for control decision-making were considered. A control decisionmaking rule (master plan) has been developed that allows identifying and choosing the best solutions according to the benchmark and preferences of the control decision-maker. Based on this master plan, an array the most optimal solutions are formed, ranked among the available solutions for the current position. Also, efficiency measures and benchmark are formed, which are used to evaluate the results according to the selected efficiency benchmark and determine the priority level of option solutions corresponding to these results. A model for choosing the optimal solution according to effectiveness measures and benchmark has been developed. In this article, part of the main tasks of digital control information technologies is the creation and calculation of a computer-based information system that thinks logically and intelligently, as well as devices that make human-like control decision-making under positions of unpredictability and speculative. Computational experiments were conducted to solve fuzzy model tasks of control decisionmaking in digital control information systems. Based on the results of computational experiments on task solving, it can be seen that the quality, efficiency and reliability of control decision-making made in digital control information systems are improved.",
    "abstract_processed": "current part main task digit control inform technolog recreat system think logic intellig use comput creat devic make control decis make like human posit unpredict specul articl process control decis make digit control inform system systemat analyz studi analysi process control decis make digit control inform system function shortcom determin use systemat approach method initi stage detail assess task posit result statist model benchmark control decis make consid control decisionmak rule master plan develop allow identifi choos best solut accord benchmark prefer control decis maker base master plan array optim solut form rank among avail solut current posit also effici measur benchmark form use evalu result accord select effici benchmark determin prioriti level option solut correspond result model choos optim solut accord effect measur benchmark develop articl part main task digit control inform technolog creation calcul comput base inform system think logic intellig well devic make human like control decis make posit unpredict specul comput experi conduct solv fuzzi model task control decisionmak digit control inform system base result comput experi task solv seen qualiti effici reliabl control decis make made digit control inform system improv"
  },
  {
    "doc_id": "10616427",
    "abstract_original": "In In fact, this era has been marked at a crossroad of technology and creativity, amalgamating and bringing up the revolutionary peak in the contemporary landscape of literature due to the induction of artificial intelligence into the production and analysis of Indonesia literature. This paper tries to outline the evolving relationship of human expression with machine intelligence—in other words, it tries to answer how AI algorithms have redefined the landscape of Indonesia literature from creation to critique. This paper will discuss firstly the historical development of AI in literature from a seed idea to its present sophisticated application. It is against this background that the paper explains how this has been done through a comprehensive review of existing literature. It brings out the way AI has become a collaborator and a provocateur in the creative process by making it possible for humanity to create poetry, prose, and narrative structures. This paper will delve into a few of the most telling examples and casuistries into exactly how AI-generated literature differs—from the level of its stylistic tendencies to the quantity of its thematic preoccupations. The research will also analyze the impact of AI on literature analysis and interpretation. Even canonical works were given new keys to be read with the help of advanced algorithms in text and sentiment analysis, and their light was shed on contemporary texts too. Below, the following sections, is a survey of some of the ways AI-driven methodologies have only augmented traditional literary analysis, allowing scholars to draw patterns, themes, and even nuances of language that may escape ordinary human perception.",
    "abstract_processed": "fact era mark crossroad technolog creativ amalgam bring revolutionari peak contemporari landscap literatur due induct artifici intellig product analysi indonesia literatur paper tri outlin evolv relationship human express machin intelligence—in word tri answer ai algorithm redefin landscap indonesia literatur creation critiqu paper discuss firstli histor develop ai literatur seed idea present sophist applic background paper explain done comprehens review exist literatur bring way ai becom collabor provocateur creativ process make possibl human creat poetri prose narr structur paper delv tell exampl casuistri exactli ai gener literatur differs—from level stylist tendenc quantiti themat preoccup research also analyz impact ai literatur analysi interpret even canon work given new key read help advanc algorithm text sentiment analysi light shed contemporari text follow section survey way ai driven methodolog augment tradit literari analysi allow scholar draw pattern theme even nuanc languag may escap ordinari human percept"
  },
  {
    "doc_id": "10616877",
    "abstract_original": "This paper presents a novel automated approach to medical data classification using an interval type-2 fuzzy thinking system (IT2FLS) and wavelet transformation (WT). Wavelet coefficients are highly discriminative features that serve as condensed reconstructions of the underlying data. Uncertainty and high-dimensional data provide issues that are addressed by the combination of WT and IT2FLS. With the use of fuzzy c-means (FCM) clustering for unsupervised structure learning and evolutionary algorithms for supervised parameter adjustment, the IT2FLS employs a hybrid learning approach. The use of WT streamlines this computationally demanding learning process, lowering computational load and improving IT2FLS performance. Well-known medical datasets (Cleveland heart disease and Wisconsin breast cancer) from the UCI Collection for machine learning are used for experimental assessments. Computed performance measures include area under the receiver operator characteristic curve, sensitivity, specificity, and accuracy. The findings demonstrate the better efficacy of the wavelet-IT2FLS methodology in comparison to other machine learning techniques, such as adaptive neuro-fuzzy inference system, fuzzy ARTMAP, support vector machine, and probabilistic neural network. The suggested approach has potential to assist clinicians and medical professionals in making decisions.",
    "abstract_processed": "paper present novel autom approach medic data classif use interv type fuzzi think system fl wavelet transform wt wavelet coeffici highli discrimin featur serv condens reconstruct underli data uncertainti high dimension data provid issu address combin wt fl use fuzzi c mean fcm cluster unsupervis structur learn evolutionari algorithm supervis paramet adjust fl employ hybrid learn approach use wt streamlin comput demand learn process lower comput load improv fl perform well known medic dataset cleveland heart diseas wisconsin breast cancer uci collect machin learn use experiment assess comput perform measur includ area receiv oper characterist curv sensit specif accuraci find demonstr better efficaci wavelet fl methodolog comparison machin learn techniqu adapt neuro fuzzi infer system fuzzi artmap support vector machin probabilist neural network suggest approach potenti assist clinician medic profession make decis"
  },
  {
    "doc_id": "10616950",
    "abstract_original": "In modern robots, the usage of computationally expensive models involving deep neural networks, also referred to as DNNs, for tasks such as the localization of operations awareness, planning, and object recognition is becoming prominent. Nevertheless, resource-constrained machinery, such as low-power aerial vehicles, often lack the requisite internal computing resources to easily run cutting-edge simulations of neural networks. Cloud robotics appears as an answer, allowing robots to offload processing to centralized computers for greater precision models. Nonetheless, the ignored downside of cloud robots lies in the possible delay and data loss experienced during contact over crowded wireless networks. This study discusses the Robot Transferring responsibility Problem, exploring when and where robots should offload sense tasks that improve accuracy while reducing the costs involved with cloud communication. The method involves framing shifting as a sequence decision-making issue concerning robots and suggesting a remedy using sophisticated reinforcement learning. Through models and hardware tests employing advanced thinking DNNs, what was suggested sharing strategy improves vision task efficacy by 1.3 2.6 times as a result of standard strategies, allowing robots to increase their sense accuracy while incurring minimal communication via cloud costs.",
    "abstract_processed": "modern robot usag comput expens model involv deep neural network also refer dnn task local oper awar plan object recognit becom promin nevertheless resourc constrain machineri low power aerial vehicl often lack requisit intern comput resourc easili run cut edg simul neural network cloud robot appear answer allow robot offload process central comput greater precis model nonetheless ignor downsid cloud robot lie possibl delay data loss experienc contact crowd wireless network studi discuss robot transfer respons problem explor robot offload sens task improv accuraci reduc cost involv cloud commun method involv frame shift sequenc decis make issu concern robot suggest remedi use sophist reinforc learn model hardwar test employ advanc think dnn suggest share strategi improv vision task efficaci time result standard strategi allow robot increas sens accuraci incur minim commun via cloud cost"
  },
  {
    "doc_id": "10617194",
    "abstract_original": "Its use in literary criticism might be one of the most novel opportunities to analyze texts and themes since artificial intelligence (AI) touches and improves every facet of human life. This paper has detailed issues on the application of AI-powered literary criticism and an overview of methodologies, applications, and implications accompanying the adoption of AI technologies. The paper starts with the context in which AI has actually emerged as one of the hot topics in literary studies, emanating from the crossroads of computational linguistics, natural language processing, and machine learning. “The true research opportunity that thus emerges from this work is the development of new AI technologies that can help supplement and augment traditional practices of literary analysis in such a way that scholars can get deeper into texts in search of the sorts of patterns and meanings that interest them. This paper presents illustrative examples and case studies in the applications of AI to literary criticism, which include sentiment analysis, topic modelling, and stylometric analysis. What these techniques afford researchers is a set of tools capable of processing large corpora of text with such accuracy and speed that identifying recurring motifs, characters dynamics, and thematic elements over genres, and literary periods is no problem. The following paper considers the ethical issues at the heart of AI-powered literary criticism, calling into question the algorithmic bias of authorship attribution and interpretive tasks it currently automates.",
    "abstract_processed": "use literari critic might one novel opportun analyz text theme sinc artifici intellig ai touch improv everi facet human life paper detail issu applic ai power literari critic overview methodolog applic implic accompani adopt ai technolog paper start context ai actual emerg one hot topic literari studi eman crossroad comput linguist natur languag process machin learn “the true research opportun thu emerg work develop new ai technolog help supplement augment tradit practic literari analysi way scholar get deeper text search sort pattern mean interest paper present illustr exampl case studi applic ai literari critic includ sentiment analysi topic model stylometr analysi techniqu afford research set tool capabl process larg corpora text accuraci speed identifi recur motif charact dynam themat element genr literari period problem follow paper consid ethic issu heart ai power literari critic call question algorithm bia authorship attribut interpret task current autom"
  },
  {
    "doc_id": "10617440",
    "abstract_original": "As artificial intelligence (AI) continues to revolutionize various facets of human existence, its influence in creative domains, particularly literature, has increasingly come to be pronounced. The following paper will handle the ways that character development is changing in modern fiction. It investigates the ways in which AI technologies are outlining the way the creation, representation, and perception of characters in fiction are being developed. That means AI is advancing in character creation in ways that open up a whole new set of doors for writers: the use of powerful tools to generate, field, analyze, and refine their characters in ways previously unthinkable. Using the algorithms of natural language processing (NLP), these days, AI is used to help write dialogue, create characters with their traits, and sometimes even develop the entire character’s arc. This union of human creativity and computational powers doesn’t just make the process of writing faster but, rather, opens doors for new possibilities in innovative storytelling. AI-driven analytics help authors to pick up the insight into reader preferences and trends that tend to help them develop character traits and the storyline, most appealing to the readers. The application of machine-learning algorithms to vast repositories of literature seems to derive character dynamics and tropes that are so archetyped, but their renderings are much more nuanced and impactful. At the same time, this AI character raises very basic questions about authorship, creativity, and the nature of the story. As more and more writers adopt AI for character generation, they do raise some question about authenticity and originality.",
    "abstract_processed": "artifici intellig ai continu revolution variou facet human exist influenc creativ domain particularli literatur increasingli come pronounc follow paper handl way charact develop chang modern fiction investig way ai technolog outlin way creation represent percept charact fiction develop mean ai advanc charact creation way open whole new set door writer use power tool gener field analyz refin charact way previous unthink use algorithm natur languag process nlp day ai use help write dialogu creat charact trait sometim even develop entir character’ arc union human creativ comput power doesn’t make process write faster rather open door new possibl innov storytel ai driven analyt help author pick insight reader prefer trend tend help develop charact trait storylin appeal reader applic machin learn algorithm vast repositori literatur seem deriv charact dynam trope archetyp render much nuanc impact time ai charact rais basic question authorship creativ natur stori writer adopt ai charact gener rais question authent origin"
  },
  {
    "doc_id": "10619721",
    "abstract_original": "ChatGPT is a novel AI tool that poses new questions for experts in education and introduces a need to change traditional instructional and grading systems. The first step towards a successful integration of ChatGPT into educational processes is to understand how students currently use it. In this paper we present our contribution towards this goal, a pilot study analyzing the results of a questionnaire filled out by 300 students of secondary and tertiary education. Our primary conclusions are that students are interested in using ChatGPT in the context of education and that there is no significant difference in the tasks they use it for depending on their academic major. Students use the tool more commonly for topics relevant for their fields and the average satisfaction with the tool grows the more frequently students use it, meaning ChatGPT, like other tools, is learnable.",
    "abstract_processed": "chatgpt novel ai tool pose new question expert educ introduc need chang tradit instruct grade system first step toward success integr chatgpt educ process understand student current use paper present contribut toward goal pilot studi analyz result questionnair fill student secondari tertiari educ primari conclus student interest use chatgpt context educ signific differ task use depend academ major student use tool commonli topic relev field averag satisfact tool grow frequent student use mean chatgpt like tool learnabl"
  },
  {
    "doc_id": "10619845",
    "abstract_original": "Every society has its own characteristics, shaped from time to time by the various innovative, disruptive, but in any case, dynamically changing mechanisms that affect it most. In today's society, technological innovation plays a major role in the development of individuals and their abilities. Education is the most typical and obvious arena for shaping, developing, and preparing for the challenges of the future. As in the leading sectors, in the world of education, rapid responses and immediate reactions to change significantly increase the ability to achieve and maintain success and thus marketability. As a sector responsible for developing the competences of individuals, building knowledge and training professionals, education should seek to keep pace with trends and break with traditional approaches and methods, so that, in addition to incorporating technological developments, a renewed approach to organizational development and methodology is an important means of achieving the desired success and effectiveness. In the course of our work, we provide a summary insight into the project work of student groups who require up-to-date IT skills, use advanced IT tools, plan, and implement their web development workflows supported by database management, front-end planning and design, and back-end programming with a project management approach according to the latest trends, interpreting the advantages and disadvantages of working methods for success.",
    "abstract_processed": "everi societi characterist shape time time variou innov disrupt case dynam chang mechan affect today societi technolog innov play major role develop individu abil educ typic obviou arena shape develop prepar challeng futur lead sector world educ rapid respons immedi reaction chang significantli increas abil achiev maintain success thu market sector respons develop compet individu build knowledg train profession educ seek keep pace trend break tradit approach method addit incorpor technolog develop renew approach organiz develop methodolog import mean achiev desir success effect cours work provid summari insight project work student group requir date skill use advanc tool plan implement web develop workflow support databas manag front end plan design back end program project manag approach accord latest trend interpret advantag disadvantag work method success"
  },
  {
    "doc_id": "10619857",
    "abstract_original": "The importance of change management is still under-emphasised in lean transformation because many people are not familiar with change management models. This may be an area that needs more attention in the future. The survey shows that there are professionals at all levels, but also where there are gaps. However, it gives hope that in the coming years these gaps will be filled and more effective lean transformations can be led. The main lessons from the survey can help to set priorities for the coming years. Those in the support phase are the least aware of the importance of a blame-free environment, which is a key factor for effective lean transformation. In the application phase, there is a clear lack of awareness of the Kanban system. The lack of knowledge of plant management is also consistent with the experience. This is also due to the fact that the development of lean was not always based on existing knowledge, but was promoted as a new method different from traditional practices.",
    "abstract_processed": "import chang manag still emphasis lean transform mani peopl familiar chang manag model may area need attent futur survey show profession level also gap howev give hope come year gap fill effect lean transform led main lesson survey help set prioriti come year support phase least awar import blame free environ key factor effect lean transform applic phase clear lack awar kanban system lack knowledg plant manag also consist experi also due fact develop lean alway base exist knowledg promot new method differ tradit practic"
  },
  {
    "doc_id": "10619907",
    "abstract_original": "The Industry 5.0 requires new skills in a rapidly changing labor market. Generation Z is the first generation of digital natives whose skills to operate digital tools are unquestionable. At the same time, their communication, collaboration, and team-building skills lack the necessary depth to succeed in the world of work. Alongside other technological improvements, Education 4.0 has proposed the introduction of new learning and teaching methods such as project, problem, and design-based approaches. In this comparative study, the project-based approach is presented. The aim of the research was to investigate the teamwork skills of engineering students. 177 students were interviewed about how each project team works together and which skills and competences are missing to succeed together. The results of the quantitative research show that self-assessment scores in all subsamples outperformed the assessment of teams. The results can be incorporated into a future teaching methodology framework for skills development.",
    "abstract_processed": "industri requir new skill rapidli chang labor market gener z first gener digit nativ whose skill oper digit tool unquestion time commun collabor team build skill lack necessari depth succeed world work alongsid technolog improv educ propos introduct new learn teach method project problem design base approach compar studi project base approach present aim research investig teamwork skill engin student student interview project team work togeth skill compet miss succeed togeth result quantit research show self assess score subsampl outperform assess team result incorpor futur teach methodolog framework skill develop"
  },
  {
    "doc_id": "10620119",
    "abstract_original": "In our rapidly evolving world, higher education institutions must keep up with the needs of society and global competition. By incorporating intelligent systems and computer vision technologies into higher education, institutions can create more engaging, personalized, and effective learning experiences that meet the needs of today's students and prepare them for success in an increasingly digital and interconnected world. However, innovative methodologies that bridge the gap between academia and the job market, promoting employability attributes and entrepreneurial skills, are also essential. The main objective of this study is to evaluate the impact of innovative co-creation models involving students, facilitators, and organizations. Through the sharing of good practices already in use, emphasis is placed on holistic approaches, active methodologies, and multicultural learning. The conclusions show students were motivated and committed, and all participants stressed the importance of enjoyment and motivation throughout the process. In addition, these initiatives encourage a transformative mindset that emphasizes the acquisition of essential knowledge and skills for the 21st-century workforce, ultimately reinforcing the institution's role in advancing the economy and society.",
    "abstract_processed": "rapidli evolv world higher educ institut must keep need societi global competit incorpor intellig system comput vision technolog higher educ institut creat engag person effect learn experi meet need today student prepar success increasingli digit interconnect world howev innov methodolog bridg gap academia job market promot employ attribut entrepreneuri skill also essenti main object studi evalu impact innov co creation model involv student facilit organ share good practic alreadi use emphasi place holist approach activ methodolog multicultur learn conclus show student motiv commit particip stress import enjoy motiv throughout process addit initi encourag transform mindset emphas acquisit essenti knowledg skill st centuri workforc ultim reinforc institut role advanc economi societi"
  },
  {
    "doc_id": "10620272",
    "abstract_original": "This study investigates the application of machine learning (ML) algorithms to enhance the precision of wine quality assessment, focusing specifically on Portuguese red wine. Amidst the growing interest in leveraging artificial intelligence (AI) for sensory analysis, our research distinguishes itself by employing a rigorous methodological framework. Our approach, named the ‘Incremental Analysis of Baseline Accuracy,’ identifies the chemical variables most predictive of wine quality. This framework aims to streamline the predictive process by pinpointing key variables that significantly influence quality assessments. In this paper, we demonstrate the feasibility of a methodology that precisely determines the criticality of chemical inputs, both their exact values and their correct order, to identify which inputs significantly contribute to the quality assessment of a sensory perception, such as taste. The centerpiece of our paper is a vibrant 3D pie chart that illustrates the percentage criticality of different input variables for perceiving the quality of red wine. This chart symbolizes the essence of our paper: a ‘pie’ representing the empirical conclusion, not mere conjecture. Through this paper, we have shown that it is possible to quantify a qualitative, perceptual aspect like taste perception, which is often believed to be assessable only through subjective conjecture. Moreover, our findings, facilitated by the Incremental Analysis of the Baseline Accuracy method, demonstrate that this perception can be systematically quantified, challenging traditional assumptions about sensory analysis.",
    "abstract_processed": "studi investig applic machin learn ml algorithm enhanc precis wine qualiti assess focus specif portugues red wine amidst grow interest leverag artifici intellig ai sensori analysi research distinguish employ rigor methodolog framework approach name ‘increment analysi baselin accuraci ’ identifi chemic variabl predict wine qualiti framework aim streamlin predict process pinpoint key variabl significantli influenc qualiti assess paper demonstr feasibl methodolog precis determin critic chemic input exact valu correct order identifi input significantli contribut qualiti assess sensori percept tast centerpiec paper vibrant pie chart illustr percentag critic differ input variabl perceiv qualiti red wine chart symbol essenc paper ‘pie’ repres empir conclus mere conjectur paper shown possibl quantifi qualit perceptu aspect like tast percept often believ assess subject conjectur moreov find facilit increment analysi baselin accuraci method demonstr percept systemat quantifi challeng tradit assumpt sensori analysi"
  },
  {
    "doc_id": "10622486",
    "abstract_original": "We consider the problem of computing gate-circuit approximations of quantum algorithms, i.e., unitary operators, from the perspective of computable (effective) analysis. The scientific community thinks the Solovay-Kitaev theorem a mile-stone in quantum compiling - the task of computing gate-circuit approximations - because it proves the existence of efficient quantum compilers in an analytic sense. However, since we cannot represent unitary operators in a mere analytical way on digital computers, contemporary digital implementations of quantum compiling resort to heuristic numerics and remain below the computational performance engineers hope to realize using the result of Solovay and Kitaev. This paper discusses quantum compiling within a framework of computable analysis, establishing a concept of computable unitary operators for digital computing based on the theory of Turing machines. Particularly, we prove that digital quantum compiling is uncomputable due to the underlying algebraic structure. Finally, we discuss several implications of our findings for heuristic digital implementations of quantum compiling, hinting toward possible research directions to thoroughly understand the relevant bottlenecks.",
    "abstract_processed": "consid problem comput gate circuit approxim quantum algorithm e unitari oper perspect comput effect analysi scientif commun think solovay kitaev theorem mile stone quantum compil task comput gate circuit approxim prove exist effici quantum compil analyt sens howev sinc cannot repres unitari oper mere analyt way digit comput contemporari digit implement quantum compil resort heurist numer remain comput perform engin hope realiz use result solovay kitaev paper discuss quantum compil within framework comput analysi establish concept comput unitari oper digit comput base theori ture machin particularli prove digit quantum compil uncomput due underli algebra structur final discuss sever implic find heurist digit implement quantum compil hint toward possibl research direct thoroughli understand relev bottleneck"
  },
  {
    "doc_id": "10627914",
    "abstract_original": "In today's technology world, Artificial Intelligence (AI) has grown omnipresent, transforming industries and affecting many facets of our everyday lives. Given the abundance of AI models in many categories, it is critical to comprehend their advantages, disadvantages, and uses in order to make well-informed decisions and progress the field. NLP, Computer Vision, Speech Recognition, Robotics, Machine Learning (ML) algorithms, Deep Learning models, Reinforcement Learning, Generative Adversarial Networks (GANs), Expert Systems, Au- tonomous Vehicles, Recommendation Systems, and Predictive Analytics are just a few of the categories that this paper compares and reviews in depth. We assess each model's performance, scalability, and appropriateness for various applications through a methodical examination. By combining extant research with practical examples, we illustrate the state of AI technologies now and offer predictions for their future development. The goal of this assessment is to help experts in the industry, researchers, and practitioners navigate the intricate AI ecosystem and realize AI's full potential for the good of society.",
    "abstract_processed": "today technolog world artifici intellig ai grown omnipres transform industri affect mani facet everyday live given abund ai model mani categori critic comprehend advantag disadvantag use order make well inform decis progress field nlp comput vision speech recognit robot machin learn ml algorithm deep learn model reinforc learn gener adversari network gan expert system au tonom vehicl recommend system predict analyt categori paper compar review depth assess model perform scalabl appropri variou applic method examin combin extant research practic exampl illustr state ai technolog offer predict futur develop goal assess help expert industri research practition navig intric ai ecosystem realiz ai full potenti good societi"
  },
  {
    "doc_id": "10629107",
    "abstract_original": "Today, the 3D evaluation of digitized medical image data is a routine examination in certain medical fields, we can think of the use of CT (Computer Tomography) or MRI (Magnetic Resonance Imaging) equipment. In contrast, the evaluation of 3D images and 3D data in digital pathology has not yet reached this level. One of the reasons for this is the resolution of digitized pathological sections, as well as the computing capacity required for the 3D reconstruction model created from them. In the course of our research, we designed and developed a solution that helps overcome difficulties arising from hardware resources with a technique called real-time network video streaming. Our solution enables users to collaboratively visualize 3D medical data even on low computing capacity devices. In the paper, we describe a part of this solution, which refers to the definition of the quality of service indicator. In our research, we implemented several solutions to define quality service in order to provide the best possible result to the user. In the paper, we describe and compare these solutions.",
    "abstract_processed": "today evalu digit medic imag data routin examin certain medic field think use ct comput tomographi mri magnet reson imag equip contrast evalu imag data digit patholog yet reach level one reason resolut digit patholog section well comput capac requir reconstruct model creat cours research design develop solut help overcom difficulti aris hardwar resourc techniqu call real time network video stream solut enabl user collabor visual medic data even low comput capac devic paper describ part solut refer definit qualiti servic indic research implement sever solut defin qualiti servic order provid best possibl result user paper describ compar solut"
  },
  {
    "doc_id": "10629693",
    "abstract_original": "The emergence of cloud computing technology has motivated a very high number of users in different organizations to access its services in running and delivering their various operations and services. However, this surge of cloud users has led to the problem of uneven load sharing among the cloud computing infrastructures. As a result, federated cloud infrastructure was initiated to provide more cloud computing resources to accommodate more cloud users’ requests and also to provide equal requests mapping with the available cloud resources. Nevertheless, the issue of unequal allocation of requests within the datacenter(s) that makes up the federated cloud environment still persists. This research work presents an intra-datacenter load balancing algorithm in a federated cloud environment named; the intra-balancer adapted throttled algorithm to evenly distribute requests in each datacenter that formulate the federated cloud infrastructures. The simulation of the intra-balancer was carried out in CloudAnalyst, the results of the implementation showed that the intra-balancer outperformed the Round-Robin and ESCE with 98.93ms and 2.26ms for the response and processing time respectively. The results assert that the intra-balancer algorithm provides a better load balancing solution in a federated cloud environment.",
    "abstract_processed": "emerg cloud comput technolog motiv high number user differ organ access servic run deliv variou oper servic howev surg cloud user led problem uneven load share among cloud comput infrastructur result feder cloud infrastructur initi provid cloud comput resourc accommod cloud users’ request also provid equal request map avail cloud resourc nevertheless issu unequ alloc request within datacent make feder cloud environ still persist research work present intra datacent load balanc algorithm feder cloud environ name intra balanc adapt throttl algorithm evenli distribut request datacent formul feder cloud infrastructur simul intra balanc carri cloudanalyst result implement show intra balanc outperform round robin esc ms ms respons process time respect result assert intra balanc algorithm provid better load balanc solut feder cloud environ"
  },
  {
    "doc_id": "10630378",
    "abstract_original": "This study demonstrates the utilization of Machine Learning (ML) for network slice prediction, enabling the optimization of resources for diverse network slices. Traditional methods for network slice prediction often lack efficiency and result in inaccuracies. By leveraging ML algorithms such as Naive Bayes and Random Forest, an intelligent framework that automates network slice prediction is developed. This framework enhances network virtualization and management, facilitating resource allocation. The ML algorithms take real-time network conditions and usages, such as packet delay and smart city, as input and output for selecting the most suitable network slice. Data analysis is further conducted to reveal the connections between the input parameters and how these parameters influence the selection of the accurate network slice. Network slicing plays a crucial role as it enables the customization of services and facilitates efficient scaling to meet the specific needs of different applications and industries. The accuracy scores of the employed ML algorithms were generally perfect, except for the KNN and SVM classifiers, which achieved an accuracy of 94.30% and 92.16%, respectively, for the prediction of network slices based on incoming network connections and usages.",
    "abstract_processed": "studi demonstr util machin learn ml network slice predict enabl optim resourc divers network slice tradit method network slice predict often lack effici result inaccuraci leverag ml algorithm naiv bay random forest intellig framework autom network slice predict develop framework enhanc network virtual manag facilit resourc alloc ml algorithm take real time network condit usag packet delay smart citi input output select suitabl network slice data analysi conduct reveal connect input paramet paramet influenc select accur network slice network slice play crucial role enabl custom servic facilit effici scale meet specif need differ applic industri accuraci score employ ml algorithm gener perfect except knn svm classifi achiev accuraci respect predict network slice base incom network connect usag"
  },
  {
    "doc_id": "10630499",
    "abstract_original": "This study aims to explore the application of deep learning models in multi-track music generation to enhance the efficiency and quality of music production. Considering the limited capability of traditional methods in extracting and representing audio features, a multi-track music generation model based on the Bidirectional Encoder Representations from Transformers (BERT) Transformer network is proposed. This model first utilizes the BERT model to encode and represent music data, capturing semantic and emotional information within the music data. Subsequently, the encoded music features are inputted into the Transformer network to learn the temporal relationships and structural patterns among music sequences, thereby generating new multi-track music compositions. The performance of this model is evaluated, revealing that compared to other algorithms, the proposed model achieves an accuracy of 95.98% in music generation prediction, with an improvement in precision by 4.77%. Particularly, the model demonstrates significant advantages in predicting pitch of music tracks. Hence, the multi-track music generation model proposed in this study exhibits excellent performance in accuracy and pitch prediction, offering valuable experimental reference for research and practice in the field of multi-track music generation.",
    "abstract_processed": "studi aim explor applic deep learn model multi track music gener enhanc effici qualiti music product consid limit capabl tradit method extract repres audio featur multi track music gener model base bidirect encod represent transform bert transform network propos model first util bert model encod repres music data captur semant emot inform within music data subsequ encod music featur input transform network learn tempor relationship structur pattern among music sequenc therebi gener new multi track music composit perform model evalu reveal compar algorithm propos model achiev accuraci music gener predict improv precis particularli model demonstr signific advantag predict pitch music track henc multi track music gener model propos studi exhibit excel perform accuraci pitch predict offer valuabl experiment refer research practic field multi track music gener"
  },
  {
    "doc_id": "10630739",
    "abstract_original": "Self-efficacy is critical for improving computational thinking in gaming. However, conventional assessment methods like questionnaires can produce disengaged responses or require additional work to understand the questions and have limitations in the assessment of dynamic self-efficacy. To address this challenge, this study proposes a method using in-game features to assess self-efficacy, which can change over the playtime. The employed in-game feature is the Planning Stage, in which learners strategize and prepare their approach before engaging with challenges. We collect data on the time spent in this stage, which is newly proposed in this study. The experiment was conducted with twenty-five students in the Multimedia Technology and Animation Major playing Tenacity-P to accomplish tasks from a computer programming course. To validate the method, we compared self-efficacy results from the game-based approach with those from conventional questionnaires. The findings highlight the need for strategic planning in managing difficult tasks. As challenges increased, performance measures varied more, underscoring the importance of strong problem-solving skills. Efficient strategic planning directly improved self-efficacy, as participants with better planning skills maintained higher self-efficacy despite increasing task difficulty.",
    "abstract_processed": "self efficaci critic improv comput think game howev convent assess method like questionnair produc disengag respons requir addit work understand question limit assess dynam self efficaci address challeng studi propos method use game featur assess self efficaci chang playtim employ game featur plan stage learner strateg prepar approach engag challeng collect data time spent stage newli propos studi experi conduct twenti five student multimedia technolog anim major play tenac p accomplish task comput program cours valid method compar self efficaci result game base approach convent questionnair find highlight need strateg plan manag difficult task challeng increas perform measur vari underscor import strong problem solv skill effici strateg plan directli improv self efficaci particip better plan skill maintain higher self efficaci despit increas task difficulti"
  },
  {
    "doc_id": "10631247",
    "abstract_original": "The immense technological progress in artificial intelligence research and applications is increasingly drawing attention to the environmental sustainability of such systems, a field that has been termed ‘Green AI’. With this contribution we aim to broaden the discourse on Green AI by investigating the current status of approaches to both environmental assessment and ecodesign of AI systems. We propose a life-cycle-based system thinking approach that accounts for the four key elements of these software-hardware-systems: model, data, server, and cloud. We conduct an exemplary estimation of the carbon footprint of relevant compute hardware and highlight the need to further investigate methods for Green AI and ways to facilitate wide-spread adoption of its principles. We envision that AI could be leveraged to mitigate its own environmental challenges, which we denote as ‘AI4greenAI’.",
    "abstract_processed": "immens technolog progress artifici intellig research applic increasingli draw attent environment sustain system field term ‘green ai’ contribut aim broaden discours green ai investig current statu approach environment assess ecodesign ai system propos life cycl base system think approach account four key element softwar hardwar system model data server cloud conduct exemplari estim carbon footprint relev comput hardwar highlight need investig method green ai way facilit wide spread adopt principl envis ai could leverag mitig environment challeng denot ‘ai greenai’"
  },
  {
    "doc_id": "10632117",
    "abstract_original": "Securing user electronics devices has become a significant concern in the digital period, and a forward-thinking solution covers the fusion of blockchain (BC) technology and deep learning (DL) methods. Blockchain improves device safety by transforming access management, storing credentials on a tamper-resistant ledger, mitigating the risk of unauthorized access and giving a robust defence against malevolent actors. Integrating DL into this framework also raises safety measures, as it permits devices to inspect and regulate to develop attacks distinctly. DL models accurately recognize intricate designs and anomalies, allowing the technique to distinguish and threaten possible attacks in real time. The fusion of BC and DL not only improves the reliability of user electronics but also establishes a dynamic and adaptive safety system, enhancing consumer confidence in the safety of their devices. Therefore, this study presents a BC-Based Access Management with DL Threat Modeling (BCAM-DLTM) technique for securing consumer electronics devices in the IoT ecosystems. The BCAM-DLTM technique mainly follows a two-phase procedure: access management and threat detection. Moreover, BC technology can be applied to the access management of consumer electronics devices. Besides, the BCAM-DLTM technique applies a deep belief networks (DBNs) model for proficiently identifying threats. To enhance the recognition results of the DBN model, the hyperparameter tuning procedure uses the reptile search algorithm (RSA). The experimental outcome study of the BCAM-DLTM approach employs the NSLKDD dataset. The comprehensive results of the BCAM-DLTM approach portrayed a superior accuracy outcome of 99.63% over existing models in terms of distinct metrics.",
    "abstract_processed": "secur user electron devic becom signific concern digit period forward think solut cover fusion blockchain bc technolog deep learn dl method blockchain improv devic safeti transform access manag store credenti tamper resist ledger mitig risk unauthor access give robust defenc malevol actor integr dl framework also rais safeti measur permit devic inspect regul develop attack distinctli dl model accur recogn intric design anomali allow techniqu distinguish threaten possibl attack real time fusion bc dl improv reliabl user electron also establish dynam adapt safeti system enhanc consum confid safeti devic therefor studi present bc base access manag dl threat model bcam dltm techniqu secur consum electron devic iot ecosystem bcam dltm techniqu mainli follow two phase procedur access manag threat detect moreov bc technolog appli access manag consum electron devic besid bcam dltm techniqu appli deep belief network dbn model profici identifi threat enhanc recognit result dbn model hyperparamet tune procedur use reptil search algorithm rsa experiment outcom studi bcam dltm approach employ nslkdd dataset comprehens result bcam dltm approach portray superior accuraci outcom exist model term distinct metric"
  },
  {
    "doc_id": "10632148",
    "abstract_original": "There is a growing search for methodologies and tools that foster student motivation and learning. This experimental study aims to examine students’ acceptance and attitude towards the use of game-based applications, as well as analyze how game-based learning impacts the acquisition and development of basic competences. To this end, online questionnaire responses from 135 undergraduate computer science students were analyzed using Structural Equation Modeling (SEM). The results indicate that students perceive these tools as useful and easy to use, thus exerting a positive influence on learning motivation and behavior change towards the implementation of game-based learning. Furthermore, the crucial role of game-based learning strategies in the development of formative collaborative learning is emphasized, as well as their positive influence on the acquisition of essential soft skills for the comprehensive training of computer science students. The conclusions underscore the importance of considering the GBL approach as a valuable educational strategy to motivate and enhance learning and develop fundamental skills in students.",
    "abstract_processed": "grow search methodolog tool foster student motiv learn experiment studi aim examin students’ accept attitud toward use game base applic well analyz game base learn impact acquisit develop basic compet end onlin questionnair respons undergradu comput scienc student analyz use structur equat model sem result indic student perceiv tool use easi use thu exert posit influenc learn motiv behavior chang toward implement game base learn furthermor crucial role game base learn strategi develop form collabor learn emphas well posit influenc acquisit essenti soft skill comprehens train comput scienc student conclus underscor import consid gbl approach valuabl educ strategi motiv enhanc learn develop fundament skill student"
  },
  {
    "doc_id": "10633328",
    "abstract_original": "This paper presents a pilot study that examines the capacity of novice testers to generate Metamorphic Relations (MRs) for autonomous driving systems (ADSs), specifically fo-cusing on parking functions. By comparing MRs generated by human participants with those generated by artificial intelligence (AI), we seek to understand the variances in quality, particularly in terms of correctness, applicability, novelty, and utility. Our findings indicate that despite receiving only minimal training, human participants were capable of producing MRs with a wide range of effectiveness. Notably, humans exhibited a potential for creative thinking, contrasting with AI's ability to generate MRs that adhere closely to technical and applicability standards. The study underscores the need for improved educational strategies aimed at enhancing the quality and confidence of MRs produced by humans. Future research directions will explore the optimization of training approaches, particularly within a constrained timeframe to create a positive learning experience and maintain participant engagement, to fully harness the creative capabilities of human learners in the context of ADS testing.",
    "abstract_processed": "paper present pilot studi examin capac novic tester gener metamorph relat mr autonom drive system adss specif fo cuse park function compar mr gener human particip gener artifici intellig ai seek understand varianc qualiti particularli term correct applic novelti util find indic despit receiv minim train human particip capabl produc mr wide rang effect notabl human exhibit potenti creativ think contrast ai abil gener mr adher close technic applic standard studi underscor need improv educ strategi aim enhanc qualiti confid mr produc human futur research direct explor optim train approach particularli within constrain timefram creat posit learn experi maintain particip engag fulli har creativ capabl human learner context ad test"
  },
  {
    "doc_id": "10633413",
    "abstract_original": "This study reports on the development and implementation of the Interactive Design Research Toolkit (IDRT), a mobile application that supports the teaching and learning (T&L) of Human-Centered Design (HCD) practices. Guided by the Attention, Relevance, Confidence, and Satisfaction (ARCS) Model of Motivational Design and leveraging mobile microlearning (MML) principles, the IDRT integrates multimodal instructions and gamification features to encourage students to employ HCD. Implemented in a design-project-based class, 37 students' perceptions and engagement were evaluated using the Instructional Materials Motivation Survey. Results indicate positive feedback, high engagement levels, and increased comprehension of HCD. Analysis of design reports reveals a more diverse application of HCD, particularly among higher-performing students, indicating the IDRT's influence on intrinsic motivation. However, challenges were identified among lower-performing students, indicating the need for further research to enhance engagement. Overall, the study underscores the potential of MML as a viable instruction method to influence students' motivation and proficiency positively and to scaffold the T&L of HCD.",
    "abstract_processed": "studi report develop implement interact design research toolkit idrt mobil applic support teach learn l human center design hcd practic guid attent relev confid satisfact arc model motiv design leverag mobil microlearn mml principl idrt integr multimod instruct gamif featur encourag student employ hcd implement design project base class student percept engag evalu use instruct materi motiv survey result indic posit feedback high engag level increas comprehens hcd analysi design report reveal divers applic hcd particularli among higher perform student indic idrt influenc intrins motiv howev challeng identifi among lower perform student indic need research enhanc engag overal studi underscor potenti mml viabl instruct method influenc student motiv profici posit scaffold l hcd"
  },
  {
    "doc_id": "10633465",
    "abstract_original": "Purpose: This paper reports on an ongoing study examining the implementation of image-based generative AI in higher education to study the impacts and changes to learning behaviors and academic performance of architecture undergraduate students. The findings will be part of a methodological framework to evaluate whether or not AI is a high-value digital tool in this context. Approach: The study is designed through a series of workshops with architecture students, which aim to identify the role of image-based AI in the architecture design process for under-graduate students in Sino-foreign higher education institutions in order to assess the potential of using AI in the future architecture industry, especially for junior architects. Findings: The preliminary findings of this ongoing study indicate that AI increases the creativity of architecture design concepts, especially via better visual presentation for junior students. However, AI does not seem to be able to comprehend basic architecture design principles when it is implemented. Originality/value: The outcomes of this study will aid the larger teaching community when adopting AI in their teaching while mitigating the potential negative impacts on the students' learning experiences.",
    "abstract_processed": "purpos paper report ongo studi examin implement imag base gener ai higher educ studi impact chang learn behavior academ perform architectur undergradu student find part methodolog framework evalu whether ai high valu digit tool context approach studi design seri workshop architectur student aim identifi role imag base ai architectur design process graduat student sino foreign higher educ institut order assess potenti use ai futur architectur industri especi junior architect find preliminari find ongo studi indic ai increas creativ architectur design concept especi via better visual present junior student howev ai seem abl comprehend basic architectur design principl implement origin valu outcom studi aid larger teach commun adopt ai teach mitig potenti neg impact student learn experi"
  },
  {
    "doc_id": "10636140",
    "abstract_original": "In recent years, large language models (LLMs) have been employed significantly in different domains of computing education. Nevertheless, these models have been focused on essential adherence to their integration as coding assistants in computing education. However, attention has been switched to thoroughly examining and analyzing LLM behavior, particularly in computing education for programming tasks such as code generation, code explanation, and programming error message explanation. Therefore, it becomes imperative to understand their behavior to examine potential pitfalls. This article addresses this gap systematically and details how different LLM-based coding chatbots, such as ChatGPT, Codex, Copilot, and others, react to various coding inputs within computing education. To achieve this objective, we collected and analyzed articles from 2021 to 2024, and 72 studies were thoroughly examined. These objectives include investigating the existing limitations and challenges associated with utilizing these systems for coding tasks, assessing their responses to prompts containing coding syntax, examining the impact of their output on student learning, and evaluating their performance as debugging tools. The findings of this review highlight that it is premature to incorporate these systems into computing education due to their limitations that may limit their effectiveness as comprehensive coding assistants for computer science students. These limitations include issues with handling prompts containing code snippets, potential negative impacts on student learning, limited debugging capabilities, and other ineffectiveness. The finding also reports multiple research directions that can be considered in future research related to LLMs in computing education.",
    "abstract_processed": "recent year larg languag model llm employ significantli differ domain comput educ nevertheless model focus essenti adher integr code assist comput educ howev attent switch thoroughli examin analyz llm behavior particularli comput educ program task code gener code explan program error messag explan therefor becom imper understand behavior examin potenti pitfal articl address gap systemat detail differ llm base code chatbot chatgpt codex copilot other react variou code input within comput educ achiev object collect analyz articl studi thoroughli examin object includ investig exist limit challeng associ util system code task assess respons prompt contain code syntax examin impact output student learn evalu perform debug tool find review highlight prematur incorpor system comput educ due limit may limit effect comprehens code assist comput scienc student limit includ issu handl prompt contain code snippet potenti neg impact student learn limit debug capabl ineffect find also report multipl research direct consid futur research relat llm comput educ"
  },
  {
    "doc_id": "10638338",
    "abstract_original": "In our day-to-day lives, social media marketing has a significant impact on how people think. To find out how social media marketing impacts female business owners, researchers conducted this study. The study's sample size was 152 people drawn from the Chennai District of Tamil Nadu. Structured interviews were used to obtain primary data, and Cronbach's Alpha was used to test variables for reliability. Multiple regression was utilised to analyse independent and dependent variables using percentage analysis. There was a significant impact on product positioning, sales growth, and profit growth that can be attributed to the use of social media marketing by female entrepreneurs. It is recommended that you learn more about the technological advancements of social media marketing.",
    "abstract_processed": "day day live social media market signific impact peopl think find social media market impact femal busi owner research conduct studi studi sampl size peopl drawn chennai district tamil nadu structur interview use obtain primari data cronbach alpha use test variabl reliabl multipl regress utilis analys independ depend variabl use percentag analysi signific impact product posit sale growth profit growth attribut use social media market femal entrepreneur recommend learn technolog advanc social media market"
  },
  {
    "doc_id": "10638342",
    "abstract_original": "Introducing an innovative electronic chessboard system set to transform the gaming landscape. This groundbreaking system employs magnet reed sensors to meticulously track chess piece movements, seamlessly translating them into digital signals processed by an Arduino microcontroller. The result is real-time visualization on a computer screen, providing players with immediate feedback and enabling detailed game analysis. Beyond traditional chess, the system offers versatility, with potential applications in large-scale events, remote viewing, and interactive learning platforms. By creating a dynamic learning environment, it not only engages chess enthusiasts but also fosters strategic thinking across diverse learning styles. With its blend of technology and strategy, this electronic chessboard system promises to revolutionize gaming and education alike, inspiring players of all ages and skill levels.",
    "abstract_processed": "introduc innov electron chessboard system set transform game landscap groundbreak system employ magnet reed sensor meticul track chess piec movement seamlessli translat digit signal process arduino microcontrol result real time visual comput screen provid player immedi feedback enabl detail game analysi beyond tradit chess system offer versatil potenti applic larg scale event remot view interact learn platform creat dynam learn environ engag chess enthusiast also foster strateg think across divers learn style blend technolog strategi electron chessboard system promis revolution game educ alik inspir player age skill level"
  },
  {
    "doc_id": "10638366",
    "abstract_original": "In the contemporary healthcare sector, the convergence of artificial intelligence (AI) and emotional intelligence (EI) carries substantial ramifications for practitioners of medicine. Emotional intelligence is becoming an increasingly significant asset for medical professionals, especially in light of the integration of AI technologies into clinical processes, encompassing the ability to perceive, comprehend, and regulate emotions. This research examines the various dynamics of EI within the framework of AI integration, illustrating its importance in numerous domains. An increasing number of medical practitioners are collaborating with AI-driven systems, which creates a nuanced relationship between the analytical prowess of AI and the emotive intelligence of humans; thus, a balance must be maintained. Additionally, this study examines the effects of EI on critical facets of medical education, interactions between practitioners and patients, and overall job satisfaction. This abstract advocates for a stance that underscores the criticality of bolstering EI talents in the face of technological advancements. A harmonious integration that acknowledges the potential conflicts and synergies between EI and AI to support both the cognitive and affective aspects of healthcare practice.",
    "abstract_processed": "contemporari healthcar sector converg artifici intellig ai emot intellig ei carri substanti ramif practition medicin emot intellig becom increasingli signific asset medic profession especi light integr ai technolog clinic process encompass abil perceiv comprehend regul emot research examin variou dynam ei within framework ai integr illustr import numer domain increas number medic practition collabor ai driven system creat nuanc relationship analyt prowess ai emot intellig human thu balanc must maintain addit studi examin effect ei critic facet medic educ interact practition patient overal job satisfact abstract advoc stanc underscor critic bolster ei talent face technolog advanc harmoni integr acknowledg potenti conflict synergi ei ai support cognit affect aspect healthcar practic"
  },
  {
    "doc_id": "10638941",
    "abstract_original": "Many researchers have come up with different ways to build a business model architecture for efficient services to run m-commerce applications. The framework for developing mobile commerce applications needs to change at the same time as the IT expansion and business transformation. We are pursuing a theoretical business framework to find an optimal solution for the seamless service-oriented m-commerce application performance. In this approach, we identify the components of m -commerce applications that could reduce mobility barriers and improve application execution time and device energy efficiency. This led us to propose a framework for m-commerce application performance that uses the Mobile Cloud Computing (MCC) solutions. This plan focuses on making the application run faster and use less energy, and making it easier for users to move around. We help mobile commerce application developers make smart RDMCA (Resource-Demanding M-commerce Applications) that provide good services for mobile commerce businesses and consumers. A theoretical proposed business framework is being set up to find an optimal solution for service-oriented m -commerce application performance. In this way, we find the important parts of the m -commerce system (signal range determiner) that help make the application run faster, use less energy, and make it easier to move around. We think that improving this framework will help mobile commerce app developers to make RDMCA’s that provide good services for both mobile commerce enterprises and end users.",
    "abstract_processed": "mani research come differ way build busi model architectur effici servic run commerc applic framework develop mobil commerc applic need chang time expans busi transform pursu theoret busi framework find optim solut seamless servic orient commerc applic perform approach identifi compon commerc applic could reduc mobil barrier improv applic execut time devic energi effici led us propos framework commerc applic perform use mobil cloud comput mcc solut plan focus make applic run faster use less energi make easier user move around help mobil commerc applic develop make smart rdmca resourc demand commerc applic provid good servic mobil commerc busi consum theoret propos busi framework set find optim solut servic orient commerc applic perform way find import part commerc system signal rang determin help make applic run faster use less energi make easier move around think improv framework help mobil commerc app develop make rdmca’ provid good servic mobil commerc enterpris end user"
  },
  {
    "doc_id": "10639567",
    "abstract_original": "This study aims to explore how users’ immersion in games affects their computational thinking and problem-solving abilities and to obtain basic knowledge for applying games to health promotion and treatment. “The Japanese version of the Game Engagement Questionnaire (GEQ-J)” was prepared to grasp the immersion of games, and “the Japanese version of the Computational Thinking (CT) Scale” was prepared to measure CT. Correlation analysis was conducted to examine their relationships. We analyzed their relationships using correlation analysis and generalized structural equation modeling (GSEM). The results of the correlation analysis showed both weak positive correlations and weak negative correlations between the immersion factor and CT skills, indicating the importance of striking an appropriate balance between increasing player immersion and improving CT skills during game design. The results of generalized structural equation modeling revealed that while increased presence promoted creativity, high immersion hurt algorithmic thinking, flow state hurt problem-solving skills, and the factor of game immersion had no significant effect on cooperative skills. These findings suggest the importance of considering game design elements that target specific cognitive abilities in designing game-based health promotion and treatment programs. For example, immersive game design may effectively enhance creativity and problem-solving skills. This study is expected to contribute to the development of new approaches in the field of game-based health promotion and treatment.",
    "abstract_processed": "studi aim explor users’ immers game affect comput think problem solv abil obtain basic knowledg appli game health promot treatment “the japanes version game engag questionnair geq j ” prepar grasp immers game “the japanes version comput think ct scale” prepar measur ct correl analysi conduct examin relationship analyz relationship use correl analysi gener structur equat model gsem result correl analysi show weak posit correl weak neg correl immers factor ct skill indic import strike appropri balanc increas player immers improv ct skill game design result gener structur equat model reveal increas presenc promot creativ high immers hurt algorithm think flow state hurt problem solv skill factor game immers signific effect cooper skill find suggest import consid game design element target specif cognit abil design game base health promot treatment program exampl immers game design may effect enhanc creativ problem solv skill studi expect contribut develop new approach field game base health promot treatment"
  },
  {
    "doc_id": "10640006",
    "abstract_original": "This article explores strategies for cultivating a paradigm shift in the engineering design of intelligent machines, moving from conventional anthropocentric priorities toward a more ecocentric orientation aligned with ecological ethics. Through a comprehensive literature review, historical patterns of anthropomorphism in intelligent systems are traced, revealing how human-centered considerations have persistently dominated machine design across eras. To disrupt this enduring lineage and integrally reorient technology innovation toward ecological balance, four targeted strategies are proposed: (1) adopting question-seeking and systems thinking; (2) designing integrated ecosystems rather than discrete networks; (3) balancing exploitation with exploration; and (4) infusing diverse perspectives through transdisciplinarity. By reforming engineering education and culture from the ground up, the creation of intelligent machines can be realigned to enrich our shared environment rather than simply maximize human primacy. This paper offers a constructive roadmap to transform the promise of increasingly autonomous technologies in the $21^{\\text {st }}$ century and beyond.",
    "abstract_processed": "articl explor strategi cultiv paradigm shift engin design intellig machin move convent anthropocentr prioriti toward ecocentr orient align ecolog ethic comprehens literatur review histor pattern anthropomorph intellig system trace reveal human center consider persist domin machin design across era disrupt endur lineag integr reorient technolog innov toward ecolog balanc four target strategi propos adopt question seek system think design integr ecosystem rather discret network balanc exploit explor infus divers perspect transdisciplinar reform engin educ cultur ground creation intellig machin realign enrich share environ rather simpli maxim human primaci paper offer construct roadmap transform promis increasingli autonom technolog \\text st centuri beyond"
  },
  {
    "doc_id": "10640025",
    "abstract_original": "This paper proposed an intelligent path-following control strategy that combines the line-of-sight (LOS) guidance law and Q-learning (QL) for an underactuated unmanned surface vehicle (USV) with unknown model parameters. The improved LOS achieves satisfactory path-following results for USVs with uncertain models, where the embedded QL method learns the vehicle model by the self-regulation of uncertain parameters to accomplish the robustness and adaptation for the path-following. Simulation results in tracking a straight line and a circular path are demonstrated respectively. The environmental effect of wave disturbances is also analyzed, which verifies the effectiveness of the improved LOS method based on QL.",
    "abstract_processed": "paper propos intellig path follow control strategi combin line sight lo guidanc law q learn ql underactu unman surfac vehicl usv unknown model paramet improv lo achiev satisfactori path follow result usv uncertain model embed ql method learn vehicl model self regul uncertain paramet accomplish robust adapt path follow simul result track straight line circular path demonstr respect environment effect wave disturb also analyz verifi effect improv lo method base ql"
  },
  {
    "doc_id": "10643928",
    "abstract_original": "This paper presents a novel algorithm for the Vertex Cover problem, inspired by the Think-Like-A-Vertex (TLAV) paradigm. The Vertex Cover problem, a fundamental challenge in graph theory, finds significant relevance in the context of the compute continuum, where the optimal placement of application images across a diverse range of computational resources is a critical concern. Our proposed TLAV-based algorithm addresses this challenge by leveraging local information at each vertex to make intelligent decisions, thereby reducing the global complexity of the problem. While this approach could potentially lead to resource overprovisioning, we argue that in the context of the compute continuum, this trade-off can provide more flexibility and redundancy, enhancing the reliability of the system. Through extensive analysis and experimental results, we demonstrate the efficiency and scalability of our algorithm on large-scale graphs, making a significant contribution to the field of resource management in the compute continuum.",
    "abstract_processed": "paper present novel algorithm vertex cover problem inspir think like vertex tlav paradigm vertex cover problem fundament challeng graph theori find signific relev context comput continuum optim placement applic imag across divers rang comput resourc critic concern propos tlav base algorithm address challeng leverag local inform vertex make intellig decis therebi reduc global complex problem approach could potenti lead resourc overprovis argu context comput continuum trade provid flexibl redund enhanc reliabl system extens analysi experiment result demonstr effici scalabl algorithm larg scale graph make signific contribut field resourc manag comput continuum"
  },
  {
    "doc_id": "10643971",
    "abstract_original": "The information society is a reality nowadays, and computational thinking has become a relevant competence for everybody, regardless of age, social status, and primary activity. Information society is everywhere in contemporary life, and algorithmic thinking represents a significant competency for individuals, irrespective of their educational background and social condition. Developing and applying programming competencies represents a high-value know-how ability. Block-based coding and design tools like Scratch and TinkerCAD Arduino allow people to successfully build programming competencies in online environments regardless of age and social status. This article presents empirical evidence of the positive impact of the block-based programming language Scratch and the design tool TikerCAD Arduino in practical workshops to develop computational thinking with school children, school teachers, and university students. The results permit finding patterns, and almost transversal teaching approaches to build an elementary computational thinking competency applying Scratch and TinkerCAD Arduino, with a block-based approach in both tools and textual programming in the second one. The motivation and wishes of learning in all participants were hegemonic. Those results demonstrate the positive impact of Scratch and TinkerCAD Arduino on developing computational thinking competencies without restrictions. This work shows the application of Scratch and TinkerCAD Arduino in non-WEIRD contexts and, during the pandemic time, demonstrates the relevance of online education. The results show that developing programming competencies with Scratch and TinkerCAD Arduino motivated students’ autonomy and motivation for learning regardless of their education level and status. Those results encourage us to continue using Scratch and TinkerCAD Arduino to develop programming competencies without considering age and education level.",
    "abstract_processed": "inform societi realiti nowaday comput think becom relev compet everybodi regardless age social statu primari activ inform societi everywher contemporari life algorithm think repres signific compet individu irrespect educ background social condit develop appli program compet repres high valu know abil block base code design tool like scratch tinkercad arduino allow peopl success build program compet onlin environ regardless age social statu articl present empir evid posit impact block base program languag scratch design tool tikercad arduino practic workshop develop comput think school children school teacher univers student result permit find pattern almost transvers teach approach build elementari comput think compet appli scratch tinkercad arduino block base approach tool textual program second one motiv wish learn particip hegemon result demonstr posit impact scratch tinkercad arduino develop comput think compet without restrict work show applic scratch tinkercad arduino non weird context pandem time demonstr relev onlin educ result show develop program compet scratch tinkercad arduino motiv students’ autonomi motiv learn regardless educ level statu result encourag us continu use scratch tinkercad arduino develop program compet without consid age educ level"
  },
  {
    "doc_id": "10645537",
    "abstract_original": "In recent decades, computer science (CS) has undergone remarkable growth and diversification. Creating attractive, social, or hands-on games has already been identified as a possible approach to get teenagers and young adults interested in CS. However, overcoming the global gap between the interest and participation of men and women in CS is still a worldwide problem. To address this challenge, we present a multiplayer game that is used in a workshop setting to motivate girls to program through a 3D game environment. The paper aims to expand the educational landscape within computer science education by offering a motivating and engaging platform for young women to explore programming quests in a collaborative environment. The study involved 235 girls and 50 coaches for the workshop evaluation and a subset of 20 participants for an in-game analysis. In this paper, we explore the engagement in programming and assess the cognitive workload while playing and solving programming quests within the game, as well as the learning experience and the outcome. The results show that the positive outcomes of the workshop underscore the effectiveness of a game-based collaborative learning approach to get girls interested in computer science activities. The variety of solutions found for the different tasks demonstrates the creativity and problem-solving skills of the participants and underlines the effectiveness of the workshop in promoting critical thinking and computational skills.",
    "abstract_processed": "recent decad comput scienc cs undergon remark growth diversif creat attract social hand game alreadi identifi possibl approach get teenag young adult interest cs howev overcom global gap interest particip men women cs still worldwid problem address challeng present multiplay game use workshop set motiv girl program game environ paper aim expand educ landscap within comput scienc educ offer motiv engag platform young women explor program quest collabor environ studi involv girl coach workshop evalu subset particip game analysi paper explor engag program assess cognit workload play solv program quest within game well learn experi outcom result show posit outcom workshop underscor effect game base collabor learn approach get girl interest comput scienc activ varieti solut found differ task demonstr creativ problem solv skill particip underlin effect workshop promot critic think comput skill"
  },
  {
    "doc_id": "10645865",
    "abstract_original": "Computational thinking (CT) gained significant importance in education, leading to a surge in the development of dedicated instructional platforms. The cultivation of students’ CT skills posed a challenge, often involving the introduction of abstract and challenging-to-visualize programming concepts. This study aimed to bridge this gap by introducing an augmented reality-based coding game—an interactive learning platform designed to facilitate students in acquiring programming skills and enhancing their grasp of computational thinking concepts. The augmented reality (AR) digital game is specifically directed towards fundamental CT skills, such as pattern recognition, decomposition, abstraction, and developing algorithms. To evaluate the effectiveness of the AR game in enhancing CT skills, a study was conducted with 124 middle school students, entailing in grades 6th and 8th. The experimental group (N = 63) utilized the AR game, while the control group (N = 61) relied on conventional text materials. The findings of the experiment strongly supported the integration of AR technology along with game-based learning as a means to enhance CT knowledge and skills while simultaneously reducing cognitive load.",
    "abstract_processed": "comput think ct gain signific import educ lead surg develop dedic instruct platform cultiv students’ ct skill pose challeng often involv introduct abstract challeng visual program concept studi aim bridg gap introduc augment realiti base code game—an interact learn platform design facilit student acquir program skill enhanc grasp comput think concept augment realiti ar digit game specif direct toward fundament ct skill pattern recognit decomposit abstract develop algorithm evalu effect ar game enhanc ct skill studi conduct middl school student entail grade th th experiment group n util ar game control group n reli convent text materi find experi strongli support integr ar technolog along game base learn mean enhanc ct knowledg skill simultan reduc cognit load"
  },
  {
    "doc_id": "10645883",
    "abstract_original": "In this paper, we explore the innovative application of physical laws, specifically Newton’s Law of Universal Gravitation, as metaphors within the realm of creative computing. By adapting gravitational concepts to measure the semantic “distances” and “attractions” between entities in textual data, we propose a computational model that interprets these relationships through the lens of physical force dynamics. This approach allows us to creatively visualise complex data interactions in a 3D space, where the metaphorical ‘mass’ and ‘distance’ between entities dictate their spatial arrangement based on calculated ‘gravitational’ forces. The core of our methodology involves the adaptation of the gravitational formula. We apply this model to a case study that demonstrates how entities with stronger semantic links are visually closer, creating imaginative and interpretative 3D scenes. This paper not only highlights the utility of physical metaphors in enhancing computational creativity but also opens new avenues for the application of such models in digital media, interactive art, and educational technologies. Further, this methodology can be extended to visualise and interpret health data, providing a novel representation of chronic conditions. By bridging physical theories and computational aesthetics, we provide a fresh perspective on data visualisation and creative computing.",
    "abstract_processed": "paper explor innov applic physic law specif newton’ law univers gravit metaphor within realm creativ comput adapt gravit concept measur semant “distances” “attractions” entiti textual data propos comput model interpret relationship len physic forc dynam approach allow us creativ visualis complex data interact space metaphor ‘mass’ ‘distance’ entiti dictat spatial arrang base calcul ‘gravitational’ forc core methodolog involv adapt gravit formula appli model case studi demonstr entiti stronger semant link visual closer creat imagin interpret scene paper highlight util physic metaphor enhanc comput creativ also open new avenu applic model digit media interact art educ technolog methodolog extend visualis interpret health data provid novel represent chronic condit bridg physic theori comput aesthet provid fresh perspect data visualis creativ comput"
  },
  {
    "doc_id": "10645894",
    "abstract_original": "The rapid growing application of language models (LLMs) in education offers exciting prospects for personalized learning and interactive experiences. However, a critical challenge emerges - the risk of \"hallucinations,\" where LLMs generate factually incorrect or misleading information. This paper proposes Comparative and Cross-Verification Prompting (CCVP), a novel technique specifically designed to mitigate hallucinations in educational LLMs. CCVP leverages the strengths of multiple LLMs, a Principal Language Model (PLM) and Auxiliary Language Models (ALMs), to verify the accuracy and educational relevance of the PLM's response to a prompt. Through a series of prompts and assessments, CCVP harnesses the diverse perspectives of various LLMs and incorporates human expertise for intricate cases. This method addresses the limitations of relying on a single model and fosters critical thinking skills in learners within the educational context. We detail the CCVP approach with examples specifically applicable to educational settings, such as geography. We also discuss its strengths and limitations, including computational cost, data reliance, and ethical considerations. We highlight its potential applications in educational disciplines, including fact-checking content, detecting bias, and promoting responsible LLM use. CCVP presents a promising avenue for ensuring the accuracy and trustworthiness of LLM-generated educational content. Further research and development will refine its scalability, address potential biases, and solidify its position as a vital tool for harnessing the power of LLMs while fostering responsible knowledge dissemination in education.",
    "abstract_processed": "rapid grow applic languag model llm educ offer excit prospect person learn interact experi howev critic challeng emerg risk hallucin llm gener factual incorrect mislead inform paper propos compar cross verif prompt ccvp novel techniqu specif design mitig hallucin educ llm ccvp leverag strength multipl llm princip languag model plm auxiliari languag model alm verifi accuraci educ relev plm respons prompt seri prompt assess ccvp har divers perspect variou llm incorpor human expertis intric case method address limit reli singl model foster critic think skill learner within educ context detail ccvp approach exampl specif applic educ set geographi also discuss strength limit includ comput cost data relianc ethic consider highlight potenti applic educ disciplin includ fact check content detect bia promot respons llm use ccvp present promis avenu ensur accuraci trustworthi llm gener educ content research develop refin scalabl address potenti bias solidifi posit vital tool har power llm foster respons knowledg dissemin educ"
  },
  {
    "doc_id": "10647763",
    "abstract_original": "Quantum Key Distribution technology is maturing quickly. The systems that were once closer to laboratory devices and focused on the single link are nowadays commercial products, and the companies that build them are ramping up production. Now there is a need to go beyond the single link and start thinking in getting closer to the network. In this talk we will explore, from a standardization point of view, the network architectures available and the gaps that need to be closed to support the creation of large-scale quantum secure networks, like the planned European Quantum Communications Infrastructure.",
    "abstract_processed": "quantum key distribut technolog matur quickli system closer laboratori devic focus singl link nowaday commerci product compani build ramp product need go beyond singl link start think get closer network talk explor standard point view network architectur avail gap need close support creation larg scale quantum secur network like plan european quantum commun infrastructur"
  },
  {
    "doc_id": "10650372",
    "abstract_original": "Constrained by the finite depth of field (DOF) in optical cameras, imaging devices face difficulties in achieving complete sharpness across all objects or areas within the same scene. Multi-focus image fusion (MFIF) technology has emerged in response to this challenge. This technique combines complementary information from multiple partially focused images to generate an all-in-focus fused image. The fully clear image is the foundation of subsequent visual tasks. However, existing methods rarely focus on the fusion of image sequence, even though image sequence are more common in practical scenarios. In this paper, we have proposed a novel MFIF generative model based on transformer encoder, termed as SPAFusion. We think that MFIF should focus on patches from the same regions within the source images. Therefore, the attention mechanism of our model is based on patches. We further introduce a shift patch mechanism to integrate long-range dependencies. Benefit from the patch attention and shift patch mechanisms, our model boasts a significantly reduced parameter count and computational complexity compared to existing transformer-based MFIF models. Additionally, the introduction of the shift patch mechanism enables the model to integrate long-range dependencies, allowing it to incorporate both intra-domain and cross-domain contextual information. Finally, we employ pooling to obtain the fused image, enabling our model to support the fusion of image sequence. Experiments show the superiority of our SPAFusion compared to the state-of-the-art MFIF models.",
    "abstract_processed": "constrain finit depth field dof optic camera imag devic face difficulti achiev complet sharp across object area within scene multi focu imag fusion mfif technolog emerg respons challeng techniqu combin complementari inform multipl partial focus imag gener focu fuse imag fulli clear imag foundat subsequ visual task howev exist method rare focu fusion imag sequenc even though imag sequenc common practic scenario paper propos novel mfif gener model base transform encod term spafus think mfif focu patch region within sourc imag therefor attent mechan model base patch introduc shift patch mechan integr long rang depend benefit patch attent shift patch mechan model boast significantli reduc paramet count comput complex compar exist transform base mfif model addit introduct shift patch mechan enabl model integr long rang depend allow incorpor intra domain cross domain contextu inform final employ pool obtain fuse imag enabl model support fusion imag sequenc experi show superior spafus compar state art mfif model"
  },
  {
    "doc_id": "10650485",
    "abstract_original": "Object detection is an essential task in the field of computer vision. The one-stage object detection model directly completes object detection through a single forward propagation and has fast real-time object detection capabilities, making it widely used—especially the model of the You Only Look Once (YOLO) series. Improving the detection accuracy of the YOLO model has always been a research topic. The gradient architecture cascades feature information extraction and aggregates all features at the end, which can improve the feature fusion ability of the network. Combining the idea of gradient architecture, this paper proposes a YOLO based on gradient architecture: Gradient-YOLO. Specifically, this paper integrates gradient architecture into the backbone, neck, and bottleneck structures in the YOLO network, obtaining gradient backbone, gradient neck, and gradient bottleneck, respectively. By combining gradient architecture, various network parts in Gradient-YOLO can fully aggregate multi-layer features, reduce feature loss, and thus improve detection accuracy. This paper takes the mature YOLOv5 model and the latest YOLOv8 model as the baseline and combines gradient thinking to obtain Gradient-YOLOv5 and GradientYOLOv8. Moreover, conduct experimental testing on the MS COCO dataset. Regarding the mAP@.5 detection indicator, compared to YOLOv5s, Gradient-YOLOv5s increased by 5.07%. Compared to YOLOv8n, Gradient-YOLOv8n has increased by 4.63%. Therefore, the combination of gradient architecture can improve the detection accuracy of YOLO networks.",
    "abstract_processed": "object detect essenti task field comput vision one stage object detect model directli complet object detect singl forward propag fast real time object detect capabl make wide used—especi model look yolo seri improv detect accuraci yolo model alway research topic gradient architectur cascad featur inform extract aggreg featur end improv featur fusion abil network combin idea gradient architectur paper propos yolo base gradient architectur gradient yolo specif paper integr gradient architectur backbon neck bottleneck structur yolo network obtain gradient backbon gradient neck gradient bottleneck respect combin gradient architectur variou network part gradient yolo fulli aggreg multi layer featur reduc featur loss thu improv detect accuraci paper take matur yolov model latest yolov model baselin combin gradient think obtain gradient yolov gradientyolov moreov conduct experiment test ms coco dataset regard map detect indic compar yolov gradient yolov increas compar yolov n gradient yolov n increas therefor combin gradient architectur improv detect accuraci yolo network"
  },
  {
    "doc_id": "10650943",
    "abstract_original": "Computational creativity is defined as the ability of artificial systems to generate artifacts with substantial novelty and originality, comparable to those crafted by human experts. This study introduces an innovative approach to implementing computational creativity in the scientific domain, exemplified through the automatic generation of trigonometric identities using a novel LeakGAN model, a Generative Adversarial Network with leaked information. The novelty of the proposed LeakGAN lies in its discriminator model, constructed on the foundation of a Convolutional Neural Network (CNN), aimed at capturing the most relevant features from input data. These features are subsequently leaked to the generator model, enabling the production of identities with substantial originality and quality. The introduced novelty in the discriminator’s architecture encompasses the use of a new activation function called Mish, strategically employed to enhance the network's convergence rate and address over-fitting issues during training. Additionally, an attention layer is introduced to highlight the most relevant information within the feature space, thereby improving the network's learning capacity. Furthermore, a unique mixed pooling layer is utilized, combining the advantageous effects of max-pooling and average pooling operations to enhance the network's adaptability to varying feature distributions. Performance analysis, incorporating BiLingual Evaluation Understudy (BLEU) metrics and various comparative studies, substantiates the efficacy of the proposed LeakGAN model in generating novel identities compared to its traditional counterparts. Moreover, human evaluation involving 20 mathematical experts confirms the significant novelty of the generated identities compared to existing standard textbook problems. Consequently, the proposed technique proves valuable for generating diverse trigonometric identities suitable for inclusion as chapter-end exercises in middle school mathematics textbooks.",
    "abstract_processed": "comput creativ defin abil artifici system gener artifact substanti novelti origin compar craft human expert studi introduc innov approach implement comput creativ scientif domain exemplifi automat gener trigonometr ident use novel leakgan model gener adversari network leak inform novelti propos leakgan lie discrimin model construct foundat convolut neural network cnn aim captur relev featur input data featur subsequ leak gener model enabl product ident substanti origin qualiti introduc novelti discriminator’ architectur encompass use new activ function call mish strateg employ enhanc network converg rate address fit issu train addit attent layer introduc highlight relev inform within featur space therebi improv network learn capac furthermor uniqu mix pool layer util combin advantag effect max pool averag pool oper enhanc network adapt vari featur distribut perform analysi incorpor bilingu evalu understudi bleu metric variou compar studi substanti efficaci propos leakgan model gener novel ident compar tradit counterpart moreov human evalu involv mathemat expert confirm signific novelti gener ident compar exist standard textbook problem consequ propos techniqu prove valuabl gener divers trigonometr ident suitabl inclus chapter end exercis middl school mathemat textbook"
  },
  {
    "doc_id": "10654434",
    "abstract_original": "In this study the pair computational problem-solving between the student and ChatGPT was analyzed. The three university students who were experienced in using Python program in computational problem-solving participated in the study. In data collection, a problem involving “limit and sequence” from calculus was used to examine students' collaboration with ChatGPT. Students were asked to construct a program that produces a solution to this problem in Python, and meanwhile, it was stated that they could work in pairs with ChatGPT. The responses provided by ChatGPT to the students in the computational problem-solving were evaluated in both computational and mathematical contexts and a list of cases in which ChatGPT could and could not support students in the computational thinking practices was created. Aside from the incorrect or implicit answers provided by ChatGPT, in general, it was determined that ChatGPT supported the student's performance in computational thinking. It was deduced that it was important for the student to make a rational problem-solving plan and to guide the ChatGPT with the appropriate prompts in order to use rational questioning that leads to productive argumentation with ChatGPT.",
    "abstract_processed": "studi pair comput problem solv student chatgpt analyz three univers student experienc use python program comput problem solv particip studi data collect problem involv “limit sequence” calculu use examin student collabor chatgpt student ask construct program produc solut problem python meanwhil state could work pair chatgpt respons provid chatgpt student comput problem solv evalu comput mathemat context list case chatgpt could could support student comput think practic creat asid incorrect implicit answer provid chatgpt gener determin chatgpt support student perform comput think deduc import student make ration problem solv plan guid chatgpt appropri prompt order use ration question lead product argument chatgpt"
  },
  {
    "doc_id": "10654535",
    "abstract_original": "The graph model for conflict resolution (GMCR) is a branch of decision-making; therefore, how to scientifically abstract the evaluative thinking of decision-makers (DMs) has always been a core research point in decision science. In this context, further consideration of the heterogeneous behavior of competitors and their impact on the evolution of conflicts deserves special attention. Usually, DMs' evaluation thinking has certain ambiguity and uncertainty, and they are accustomed to giving qualitative evaluation information. Given the unique advantages of trapezoidal interval type-2 fuzzy sets (TrIT2FS) in the fusion of decision domains and transformational linguistic expressions, this paper constructs a theoretical framework for a graph model on TrIT2FS and proposes a method for calculating DMs preference ranking and a heterogeneous combinatorial foresight stability function. Firstly, the DMs will consider multiple factors in the decision evaluation process, and there are specific regret avoidance psychological behavior characteristics; thus, this paper integrates VIKOR and regret theory to solve the DM's preference ranking and expands on a new preference ranking method. Secondly, mixed stability definitions based on TrIT2FS are proposed to facilitate the description of different sanctioning behaviors of heterogeneous opponents. Subsequently, a heterogeneous combinatorial foresight stability function is proposed to quickly obtain conflict evolution solutions in complex dynamic conflict problems based on the extended mixed stability definitions. Finally, to thoroughly test the correctness and practicality of the proposed theory, the conflict between inputs and outputs of the technological transformation of enterprises under the low-carbon strategy is used as a specific application scenario and example for validation.",
    "abstract_processed": "graph model conflict resolut gmcr branch decis make therefor scientif abstract evalu think decis maker dm alway core research point decis scienc context consider heterogen behavior competitor impact evolut conflict deserv special attent usual dm evalu think certain ambigu uncertainti accustom give qualit evalu inform given uniqu advantag trapezoid interv type fuzzi set trit fs fusion decis domain transform linguist express paper construct theoret framework graph model trit fs propos method calcul dm prefer rank heterogen combinatori foresight stabil function firstli dm consid multipl factor decis evalu process specif regret avoid psycholog behavior characterist thu paper integr vikor regret theori solv dm prefer rank expand new prefer rank method secondli mix stabil definit base trit fs propos facilit descript differ sanction behavior heterogen oppon subsequ heterogen combinatori foresight stabil function propos quickli obtain conflict evolut solut complex dynam conflict problem base extend mix stabil definit final thoroughli test correct practic propos theori conflict input output technolog transform enterpris low carbon strategi use specif applic scenario exampl valid"
  },
  {
    "doc_id": "10654818",
    "abstract_original": "Vision-language models (VLMs) have recently shown promising results in traditional downstream tasks. Evaluation studies have emerged to assess their abilities, with the majority focusing on the third-person perspective, and only a few addressing specific tasks from the first-person per-spective. However, the capability of VLMs to “think” from a first-person perspective, a crucial attribute for advancing autonomous agents and robotics, remains largely unexplored. To bridge this research gap, we introduce EgoThink, a novel visual question-answering benchmark that encompasses six core capabilities with twelve detailed dimensions. The benchmark is constructed using selected clips from ego-centric videos, with manually annotated question-answer pairs containing first-person information. To comprehensively assess VLMs, we evaluate twenty-one popular VLMs on EgoThink. Moreover, given the open-ended format of the answers, we use GPT-4 as the automatic judge to compute single-answer grading. Experimental results indicate that although GPT-4V leads in numerous dimensions, all evaluated VLMs still possess considerable potential for improvement in first-person perspective tasks. Meanwhile, enlarging the number of trainable parameters has the most significant impact on model performance on EgoThink. In conclusion, EgoThink serves as a valuable addition to existing evaluation benchmarks for VLMs, providing an indispensable resource for future research in the realm of embodied artificial intelligence and robotics.",
    "abstract_processed": "vision languag model vlm recent shown promis result tradit downstream task evalu studi emerg assess abil major focus third person perspect address specif task first person per spectiv howev capabl vlm “think” first person perspect crucial attribut advanc autonom agent robot remain larg unexplor bridg research gap introduc egothink novel visual question answer benchmark encompass six core capabl twelv detail dimens benchmark construct use select clip ego centric video manual annot question answer pair contain first person inform comprehens assess vlm evalu twenti one popular vlm egothink moreov given open end format answer use gpt automat judg comput singl answer grade experiment result indic although gpt v lead numer dimens evalu vlm still possess consider potenti improv first person perspect task meanwhil enlarg number trainabl paramet signific impact model perform egothink conclus egothink serv valuabl addit exist evalu benchmark vlm provid indispens resourc futur research realm embodi artifici intellig robot"
  },
  {
    "doc_id": "10655313",
    "abstract_original": "Significant progress in video question answering (VideoQA) have been made thanks to thriving large image-language pretraining frameworks. Although image-language models can efficiently represent both video and language branches, they typically employ goal-free vision perception and do not interact vision with language well during the answer generation, thus omitting crucial visual cues. In this paper, we are inspired by the human recognition and learning pattern and propose VideoDistill, a framework with language-aware (i.e., goal-driven) behavior in both vision perception and answer generation. VideoDistill generates answers only from question-related visual embeddings and follows a thinking-observing-answering approach that closely resembles human behavior, distinguishing it from previous research. Specifically, we develop a language-aware gating mechanism to replace the standard cross-attention, avoiding language's direct fusion into visual representations. We incorporate this mechanism into two key components of the entire framework. The first component is a differentiable sparse sampling module, which selects frames containing the necessary dynamics and semantics relevant to the questions. The second component is a vision refinement module that merges existing spatial-temporal attention layers to ensure extracting multi-grained visual semantics associated with the questions. We conduct evaluations on various challenging video question-answering benchmarks, and VideoDistill achieves state-of-the-art performance in both general and long-form VideoQA datasets. In Addition, we verify that VideoDistill can effectively alleviate the utilization of language shortcut solutions in the EgoTaskQA dataset.",
    "abstract_processed": "signific progress video question answer videoqa made thank thrive larg imag languag pretrain framework although imag languag model effici repres video languag branch typic employ goal free vision percept interact vision languag well answer gener thu omit crucial visual cue paper inspir human recognit learn pattern propos videodistil framework languag awar e goal driven behavior vision percept answer gener videodistil gener answer question relat visual embed follow think observ answer approach close resembl human behavior distinguish previou research specif develop languag awar gate mechan replac standard cross attent avoid languag direct fusion visual represent incorpor mechan two key compon entir framework first compon differenti spars sampl modul select frame contain necessari dynam semant relev question second compon vision refin modul merg exist spatial tempor attent layer ensur extract multi grain visual semant associ question conduct evalu variou challeng video question answer benchmark videodistil achiev state art perform gener long form videoqa dataset addit verifi videodistil effect allevi util languag shortcut solut egotaskqa dataset"
  },
  {
    "doc_id": "10656240",
    "abstract_original": "Our brain can effortlessly recognize objects even when partially hidden from view. Seeing the visible of the hidden is called amodal completion; however, this task remains a challenge for generative AI despite rapid progress. We propose to sidestep many of the difficulties of existing approaches, which typically involve a two-step process of predicting amodal masks and then generating pixels. Our method involves thinking outside the box, literally! We go outside the object bounding box to use its context to guide a pretrained diffusion inpainting model, and then progressively grow the occluded object and trim the extra background. We overcome two technical challenges: 1) how to be free of unwanted co-occurrence bias, which tends to regenerate similar occluders, and 2) how to judge if an amodal completion has succeeded. Our amodal completion method exhibits improved photorealistic completion results compared to existing approaches in numerous successful completion cases. And the best part? It doesn't require any special training or fine-tuning of models.",
    "abstract_processed": "brain effortlessli recogn object even partial hidden view see visibl hidden call amod complet howev task remain challeng gener ai despit rapid progress propos sidestep mani difficulti exist approach typic involv two step process predict amod mask gener pixel method involv think outsid box liter go outsid object bound box use context guid pretrain diffus inpaint model progress grow occlud object trim extra background overcom two technic challeng free unwant co occurr bia tend regener similar occlud judg amod complet succeed amod complet method exhibit improv photorealist complet result compar exist approach numer success complet case best part requir special train fine tune model"
  },
  {
    "doc_id": "10656242",
    "abstract_original": "Despite recent advances in text-to-3D generative methods, there is a notable absence of reliable evaluation metrics. Existing metrics usually focus on a single criterion each, such as how well the asset aligned with the input text. These metrics lack the flexibility to generalize to different evaluation criteria and might not align well with human preferences. Conducting user preference studies is an alternative that offers both adaptability and human-aligned results. User studies, however, can be very ex-pensive to scale. This paper presents an automatic, ver-satile, and human-aligned evaluation metric for text-to-3D generative models. To this end, we first develop a prompt generator using GPT-4V to generate evaluating prompts, which serve as input to compare text-to-3D models. We further design a method instructing GPT-4V to compare two 3D assets according to user-defined crite-ria. Finally, we use these pairwise comparison results to assign these models Elo ratings. Experimental results suggest our metric strongly aligns with human preference across different evaluation criteria. Our code is available at https://github.com/3DTopia/GPTEval3D.",
    "abstract_processed": "despit recent advanc text gener method notabl absenc reliabl evalu metric exist metric usual focu singl criterion well asset align input text metric lack flexibl gener differ evalu criteria might align well human prefer conduct user prefer studi altern offer adapt human align result user studi howev ex pensiv scale paper present automat ver satil human align evalu metric text gener model end first develop prompt gener use gpt v gener evalu prompt serv input compar text model design method instruct gpt v compar two asset accord user defin crite ria final use pairwis comparison result assign model elo rate experiment result suggest metric strongli align human prefer across differ evalu criteria code avail http github com dtopia gpteval"
  },
  {
    "doc_id": "10656844",
    "abstract_original": "We introduce Mind Artist (MindArt), a novel and efficient neural decoding architecture to snap artistic photographs from our mind in a controllable manner. Recently, progress has been made in image reconstruction with non-invasive brain recordings, but it's still difficult to generate realistic images with high semantic fidelity due to the scarcity of data annotations. Unlike previous methods, this work casts the neural decoding into optimal transport (OT) and representation decoupling problems. Specifically, under discrete OT theory, we design a graph matching-guided neural representation learning framework to seek the underlying correspondences between conceptual semantics and neural signals, which yields a natural and meaningful self-supervisory task. Moreover, the proposed MindArt, structured with multiple stand-alone modal branches, enables the seamless incorporation of semantic representation into any visual style information, thus leaving it to have multi-modal reconstruction and training-free semantic editing capabilities. By doing so, the reconstructed images of MindArt have phenomenal realism both in terms of semantics and appearance. We compare our MindArt with leading alternatives, and achieve SOTA performance in different decoding tasks. Importantly, our approach can directly generate a series of stylized “mind snapshots” w/o extra optimizations, which may open up more potential applications. Code is available at https://github.com/JxuanC/MindArt.",
    "abstract_processed": "introduc mind artist mindart novel effici neural decod architectur snap artist photograph mind control manner recent progress made imag reconstruct non invas brain record still difficult gener realist imag high semant fidel due scarciti data annot unlik previou method work cast neural decod optim transport ot represent decoupl problem specif discret ot theori design graph match guid neural represent learn framework seek underli correspond conceptu semant neural signal yield natur meaning self supervisori task moreov propos mindart structur multipl stand alon modal branch enabl seamless incorpor semant represent visual style inform thu leav multi modal reconstruct train free semant edit capabl reconstruct imag mindart phenomen realism term semant appear compar mindart lead altern achiev sota perform differ decod task importantli approach directli gener seri styliz “mind snapshots” w extra optim may open potenti applic code avail http github com jxuanc mindart"
  },
  {
    "doc_id": "10656885",
    "abstract_original": "Object inpainting is a task that involves adding objects to real images and seamlessly compositing them. With the recent commercialization of products like Stable Diffusion and Generative Fill, inserting objects into images by using prompts has achieved impressive visual results. In this paper, we propose a prompt suggestion model to simplify the process of prompt input. When the user provides an image and a mask, our model predicts suitable prompts based on the partial contextual information in the masked image, and the shape and location of the mask. Specifically, we introduce a concept-diffusion in the CLIP space that predicts CLIP-text embeddings from a masked image. These diffused embeddings can be directly injected into open-source in-painting models like Stable Diffusion and its variants. Alternatively, they can be decoded into natural language for use in other publicly available applications such as Generative Fill. Our prompt suggestion model demonstrates a balanced accuracy and diversity, showing its capability to be both contextually aware and creatively adaptive.",
    "abstract_processed": "object inpaint task involv ad object real imag seamlessli composit recent commerci product like stabl diffus gener fill insert object imag use prompt achiev impress visual result paper propos prompt suggest model simplifi process prompt input user provid imag mask model predict suitabl prompt base partial contextu inform mask imag shape locat mask specif introduc concept diffus clip space predict clip text embed mask imag diffus embed directli inject open sourc paint model like stabl diffus variant altern decod natur languag use publicli avail applic gener fill prompt suggest model demonstr balanc accuraci divers show capabl contextu awar creativ adapt"
  },
  {
    "doc_id": "10657848",
    "abstract_original": "Mitigating hallucinations in large vision-language models (LVLMs) remains an open problem. Recent benchmarks do not address hallucinations in open-ended free-form responses, which we term “Type I hallucinations”. Instead, they focus on hallucinations responding to very specific question formats-typically a multiple-choice response regarding a particular object or attribute-which we term “Type II hallucinations”. Additionally, such benchmarks often require external API calls to models which are subject to change. In practice, we observe that a reduction in Type II hallucinations does not lead to a reduction in Type I hallucinations but rather that the two forms of halluci-nations are often anti-correlated. To address this, we propose THRONE, a novel object-based automatic framework for quantitatively evaluating Type I hallucinations in LVLM free-form outputs. We use public language models (LMs) to identify hallucinations in LVLM responses and compute informative metrics. By evaluating a large selection of recent LVLMs using public datasets, we show that an improvement in existing metrics do not lead to a reduction in Type I hallucinations, and that established benchmarks for measuring Type I hallucinations are incomplete. Finally, we provide a simple and effective data augmentation method to reduce Type I and Type II hallucinations as a strong baseline.",
    "abstract_processed": "mitig hallucin larg vision languag model lvlm remain open problem recent benchmark address hallucin open end free form respons term “type hallucinations” instead focu hallucin respond specif question format typic multipl choic respons regard particular object attribut term “type ii hallucinations” addit benchmark often requir extern api call model subject chang practic observ reduct type ii hallucin lead reduct type hallucin rather two form halluci nation often anti correl address propos throne novel object base automat framework quantit evalu type hallucin lvlm free form output use public languag model lm identifi hallucin lvlm respons comput inform metric evalu larg select recent lvlm use public dataset show improv exist metric lead reduct type hallucin establish benchmark measur type hallucin incomplet final provid simpl effect data augment method reduc type type ii hallucin strong baselin"
  },
  {
    "doc_id": "10659792",
    "abstract_original": "Mobile robots are widely used in industrial, medical, agricultural and other scenarios. The core technology is path planning. The existing methods have limited ability to deal with complex environment, low search efficiency, unsmooth path, easy to trap local optimum, and lack of real-time performance. Intelligent algorithm is a better method to solve this problem. Because the A * algorithm has strong search ability, clear algorithm thinking, and can be constrained to the global optimal path, it has the advantages of high efficiency, stability and optimality. Therefore, a motion trajectory planning method based on A * algorithm is proposed for mobile robots. Firstly, this paper analyzes several commonly used mobile robot path planning algorithms, and selects the A * algorithm as the object of this study. Secondly, the working principle, advantages and disadvantages of the A * algorithm are introduced in detail, as well as the design modules of the A * algorithm. Then, the problem of motion trajectory planning for mobile robots is analyzed and a solution is proposed. Aiming at the problems of low planning efficiency, turning path, sharp and unsmooth path, the efficiency and stability of A * algorithm are optimized by adding heuristic algorithm, corner optimization and path smoothing. Finally, the working environment of the mobile robot is established by using the grid method, and the path planning simulation experiment is carried out on the MATLAB platform. The experimental results show that the method of path planning using A * algorithm is effective and has a wide application prospect.",
    "abstract_processed": "mobil robot wide use industri medic agricultur scenario core technolog path plan exist method limit abil deal complex environ low search effici unsmooth path easi trap local optimum lack real time perform intellig algorithm better method solv problem algorithm strong search abil clear algorithm think constrain global optim path advantag high effici stabil optim therefor motion trajectori plan method base algorithm propos mobil robot firstli paper analyz sever commonli use mobil robot path plan algorithm select algorithm object studi secondli work principl advantag disadvantag algorithm introduc detail well design modul algorithm problem motion trajectori plan mobil robot analyz solut propos aim problem low plan effici turn path sharp unsmooth path effici stabil algorithm optim ad heurist algorithm corner optim path smooth final work environ mobil robot establish use grid method path plan simul experi carri matlab platform experiment result show method path plan use algorithm effect wide applic prospect"
  },
  {
    "doc_id": "10660872",
    "abstract_original": "The use of wireless control systems for human-computer interaction has grown in popularity recently. Earlier, people used to stick to input tools like a keyboard or mouse, which restrict one’s movement and interaction options, but now, newer technologies like computer vision, machine learning and AI have opened new and interactive ways of interacting with computers. This paper presents a hand gestures approach that not only can control presentations but is also useful for facilitating drawing and managing system volume which enrich the user experience and engagement by offering an interface that eliminates the need for keyboard and mouse. With the help of this algorithm, the computer system accurately responds to hand movements in real time. With this model, one can easily navigate through slides, play, or pause videos, and perform multiple presentation related tasks using hand gestures. It boosts mobility and enhances audience engagement by removing the limitations posed by traditional input methods. It also allows users to digitally draw on the system. Users can sketch diagrams, annotate slides, and unleash their creativity without requiring drawing tablets. It uses Google’s mediapipe module to detect hand landmarks. We incorporated specific gestures that enable the model to initiate a particular action. It showed an accuracy of $\\mathbf{9 8 \\%}$ under normal lighting conditions, which slightly drops to $95 \\%$ and $\\mathbf{9 6 \\%}$ in low and bright light, respectively, while the overall accuracy remains at $96.33 \\%$.",
    "abstract_processed": "use wireless control system human comput interact grown popular recent earlier peopl use stick input tool like keyboard mous restrict one’ movement interact option newer technolog like comput vision machin learn ai open new interact way interact comput paper present hand gestur approach control present also use facilit draw manag system volum enrich user experi engag offer interfac elimin need keyboard mous help algorithm comput system accur respond hand movement real time model one easili navig slide play paus video perform multipl present relat task use hand gestur boost mobil enhanc audienc engag remov limit pose tradit input method also allow user digit draw system user sketch diagram annot slide unleash creativ without requir draw tablet use google’ mediapip modul detect hand landmark incorpor specif gestur enabl model initi particular action show accuraci \\mathbf \\ normal light condit slightli drop \\ \\mathbf \\ low bright light respect overal accuraci remain \\"
  },
  {
    "doc_id": "10663020",
    "abstract_original": "In today's data-driven world, the importance of data literacy is paramount. However, software engineering education has not adequately addressed integrating comprehensive data science curricula, leaving students ill-equipped for the future of artificial intelligence (AI), which is built on the foundations of data science. This gap is exacerbated by the lack of tailored courses and the intimidating nature of existing tools for begin-ners. Consequently, students often miss out on essential skills like data cleanup, real-world application of machine learning (ML) algorithms, and the integration of big data in software products. This paper addresses these challenges by proposing a novel approach to applied data science for software engineering students. We argue for a shift from traditional algorithm-focused teaching to a curriculum emphasizing real-world problem-solving, lever-aging data science techniques. By empowering students to define and tackle their own data-driven projects, we aim to increase motivation, enhance data literacy, and instill a data-thinking mindset in future software engineers to prepare them for the AI world. Overall, this paper contributes to the advancement of software engineering education for young learners by offering a comprehensive framework, the data action educational framework (DAEF), and a data science toolkit that enables DAEF by empowering learners to create original data-driven mobile apps.",
    "abstract_processed": "today data driven world import data literaci paramount howev softwar engin educ adequ address integr comprehens data scienc curricula leav student ill equip futur artifici intellig ai built foundat data scienc gap exacerb lack tailor cours intimid natur exist tool begin ner consequ student often miss essenti skill like data cleanup real world applic machin learn ml algorithm integr big data softwar product paper address challeng propos novel approach appli data scienc softwar engin student argu shift tradit algorithm focus teach curriculum emphas real world problem solv lever age data scienc techniqu empow student defin tackl data driven project aim increas motiv enhanc data literaci instil data think mindset futur softwar engin prepar ai world overal paper contribut advanc softwar engin educ young learner offer comprehens framework data action educ framework daef data scienc toolkit enabl daef empow learner creat origin data driven mobil app"
  },
  {
    "doc_id": "10663149",
    "abstract_original": "The purposes of this research were to: 1) to develop a blended learning management model through project-based virtual classrooms in educational computer program courses., and 2) to study the results of using a blended learning management model through project-based virtual classrooms in educational computer programming courses. The research uses a purposive sampling selection, the sample groups of the research were 15 Second-year students with a bachelor's degree in Teacher Training in the Electrical Engineering Department, at King Mongkut's University of Technology North Bangkok. the data analysis by descriptive statistics such as mean, standard deviation and inference statistics via using t-test. The research tools used in this research are: 1) Virtual classrooms used for online learning, 2) Achievement tests 3) Project assessment forms for Basic Computer Subjects, and 4) Satisfaction Assessment. The research results show that 1) the efficiency of the blended learning management model through project-based virtual classrooms had the efficient of 80.26/81.67 higher than the 80/80 criteria., 2) the learning achievement of students after studying is significantly higher than before studying at a statistically significant level of .01. 3) the students’ satisfaction with the blended learning management model was at a high level (M=4.43, SD.=0.63) and 4) the evaluation results of students’ basic computer work development were higher than the established threshold of 80 percent.",
    "abstract_processed": "purpos research develop blend learn manag model project base virtual classroom educ comput program cours studi result use blend learn manag model project base virtual classroom educ comput program cours research use purpos sampl select sampl group research second year student bachelor degre teacher train electr engin depart king mongkut univers technolog north bangkok data analysi descript statist mean standard deviat infer statist via use test research tool use research virtual classroom use onlin learn achiev test project assess form basic comput subject satisfact assess research result show effici blend learn manag model project base virtual classroom effici higher criteria learn achiev student studi significantli higher studi statist signific level students’ satisfact blend learn manag model high level sd evalu result students’ basic comput work develop higher establish threshold percent"
  },
  {
    "doc_id": "10663178",
    "abstract_original": "This study's objectives were to: 1) compare computational thinking skills before and after game-based learning activities; and 2) study students' satisfaction after game-based learning. The research methodology uses the ADDIE model by driving game-based learning activities and promoting students with computational thinking skills, including decomposition, pattern recognition, abstraction, and algorithm design. The statistical methods used to analyze the data were mean, standard deviation, and t-test. The study's findings revealed that 1) the students' computational thinking skills improved significantly after engaging in game-based learning activities, demonstrating statistical significance at the.05 level, and 2) the overall students' satisfaction after activities with game-based learning was averaged at the highest level (= 4.75, S.D. = 0.52).",
    "abstract_processed": "studi object compar comput think skill game base learn activ studi student satisfact game base learn research methodolog use addi model drive game base learn activ promot student comput think skill includ decomposit pattern recognit abstract algorithm design statist method use analyz data mean standard deviat test studi find reveal student comput think skill improv significantli engag game base learn activ demonstr statist signific level overal student satisfact activ game base learn averag highest level"
  },
  {
    "doc_id": "10663721",
    "abstract_original": "There is evidence that a user’s subjective confidence in an Artificial Intelligence (AI)-based system is crucial in its use, even more decisive than the objective effectiveness and efficiency of the system. Therefore, different methods have been proposed for analyzing confidence in AI. In our research, we set out to evaluate how the degree of perceived trust in an AI system could affect a user’s final decision to follow AI recommendations. To this end, we established trustworthy criteria that such an evaluation should meet by following a co-creation approach with a multidisciplinary group of 10 experts. After a systematic review of 3,204 articles, we found that none of the tools met the inclusion criteria. Thus, we introduce the so-called “Perceived Operational Trust Degree in AI” (POTDAI) tool that is based on the findings from the expert group and the literature analysis, with a methodology that adds rigor to that employed previously to create similar evaluation tools. We propose a short questionnaire for quick and easy application, inspired by the original version of the Technology Acceptance Model (TAM) with six Likert-type items. In this way, we also respond to the need pointed out by authors such as Vorm and Combs to extend the TAM to address questions related to user perception in systems with an AI component. Thus, POTDAI can be used alone or in combination with TAM to obtain additional information on its usefulness and ease of use.",
    "abstract_processed": "evid user’ subject confid artifici intellig ai base system crucial use even decis object effect effici system therefor differ method propos analyz confid ai research set evalu degre perceiv trust ai system could affect user’ final decis follow ai recommend end establish trustworthi criteria evalu meet follow co creation approach multidisciplinari group expert systemat review articl found none tool met inclus criteria thu introduc call “perceiv oper trust degre ai” potdai tool base find expert group literatur analysi methodolog add rigor employ previous creat similar evalu tool propos short questionnair quick easi applic inspir origin version technolog accept model tam six likert type item way also respond need point author vorm comb extend tam address question relat user percept system ai compon thu potdai use alon combin tam obtain addit inform use eas use"
  },
  {
    "doc_id": "10664621",
    "abstract_original": "The world is grappling with a serious problem: many young individuals are taking their own lives. There is also a challenge in understanding the rising trend of this tendency. It is essential to explore the reasons driving people of all ages to consider suicide and find ways to encourage them to choose life instead. In the modern era, social media acts as a crucial platform where people share their thoughts, activities, and emotional states. This has led to the consideration of whether analyzing social media posts could help discern whether individuals are experiencing joy or sadness, particularly to detect levels of sadness that could indicate suicidal thoughts. This paper employs artificial intelligence and machine learning tools to analyze the social media posts of individuals to gauge their mental state, specifically targeting signs that might indicate a risk of suicide. The study has found a high frequency of suicidal thoughts among those who appear depressed on social media. This research investigated the possibility to identify the likelihood of someone contemplating suicidal through their online behavior. This research demonstrates the potential of utilizing social media analysis to identify and support individuals at risk of suicide, providing new insights into recognizing and assessing suicidal thoughts and representing a significant advancement in suicide prevention efforts.",
    "abstract_processed": "world grappl seriou problem mani young individu take live also challeng understand rise trend tendenc essenti explor reason drive peopl age consid suicid find way encourag choos life instead modern era social media act crucial platform peopl share thought activ emot state led consider whether analyz social media post could help discern whether individu experienc joy sad particularli detect level sad could indic suicid thought paper employ artifici intellig machin learn tool analyz social media post individu gaug mental state specif target sign might indic risk suicid studi found high frequenc suicid thought among appear depress social media research investig possibl identifi likelihood someon contempl suicid onlin behavior research demonstr potenti util social media analysi identifi support individu risk suicid provid new insight recogn assess suicid thought repres signific advanc suicid prevent effort"
  },
  {
    "doc_id": "10664730",
    "abstract_original": "Introducing middle school students to STEAM projects can foster an interest in computer science and engineering solutions. These projects provide hands-on experiences that may encourage students to explore careers in science, technology, engineering, art, and mathematics. Engaging students in real-world problems can help them develop critical thinking skills and generate innovative ideas. STEAM projects can also spark students' curiosity and creativity. This paper will explore developing and implementing a STEAM lesson to introduce students to the engineering and design process and computational thinking. Moreover, this project also addresses a major environmental concern currently in New Jersey, specifically the destruction of the environment by the spotted lanternfly. Therefore, students are also applying skills in civil duty and environmental awareness as a part of their design and plan to eradicate this invasive species.",
    "abstract_processed": "introduc middl school student steam project foster interest comput scienc engin solut project provid hand experi may encourag student explor career scienc technolog engin art mathemat engag student real world problem help develop critic think skill gener innov idea steam project also spark student curios creativ paper explor develop implement steam lesson introduc student engin design process comput think moreov project also address major environment concern current new jersey specif destruct environ spot lanternfli therefor student also appli skill civil duti environment awar part design plan erad invas speci"
  },
  {
    "doc_id": "10664854",
    "abstract_original": "Computational thinking (CT) has become an indispensable skill in the 21st century and has permeated into K-12 education at all levels. The evaluation of CT has become a crucial concern for educators and researchers. Currently., while extensive research has investigated the assessment of students' CT conceptual understanding., the measurement of their thinking processes is less involved. The game-based assessment appears to address this issue by analyzing students' behaviors and reactions during the gameplay process., which has become an emerging assessment tool in CT education. This drives the need for a comprehensive overview of this field. To fill this gap., this study aims to conduct a systematic literature review on the assessment of CT through games. It explores CT skills assessed through games., focusing on target groups, game forms., and benefits. A total of fifteen studies were examined. Findings indicate that algorithmic thinking, problem decomposition, pattern recognition., and abstraction were commonly assessed in games. Different ways for assessing CT skills in games were identified, involving progression level, log data, and manual coding. The benefits of CT game-based assessments were broadly reported, such as enjoyable experiences for students, instant feedback, easy administration for teachers and researchers, and richer information on students' cognitive processes. However, limited has been done in exploring the use of digital games for younger age groups, and the psychometric qualities of the tools were hardly reported in the reviewed studies. The study sheds light on the research and teaching practices in using games and interactive assessment platforms in CT education.",
    "abstract_processed": "comput think ct becom indispens skill st centuri permeat k educ level evalu ct becom crucial concern educ research current extens research investig assess student ct conceptu understand measur think process less involv game base assess appear address issu analyz student behavior reaction gameplay process becom emerg assess tool ct educ drive need comprehens overview field fill gap studi aim conduct systemat literatur review assess ct game explor ct skill assess game focus target group game form benefit total fifteen studi examin find indic algorithm think problem decomposit pattern recognit abstract commonli assess game differ way assess ct skill game identifi involv progress level log data manual code benefit ct game base assess broadli report enjoy experi student instant feedback easi administr teacher research richer inform student cognit process howev limit done explor use digit game younger age group psychometr qualiti tool hardli report review studi studi shed light research teach practic use game interact assess platform ct educ"
  },
  {
    "doc_id": "10664967",
    "abstract_original": "Research shows that improving students' understanding of Computational Thinking (CT) in unplugged, science-based courses benefits their understanding of algorithmic thinking. This paper describes use of the APP approach, a UDL-based guideline of self-regulation for problem formulation and problem solving, and then presents a program of lessons designed to improve a student's CT skills through improvement of executive functioning and higher-level cognitive skills, using the APP framework to explore the field of solar weather, an underrepresented but relevant topic for 6-12 grade students. The approach has strong resonances with the POWER approach to expository writing, the scientific method, and software engineering.",
    "abstract_processed": "research show improv student understand comput think ct unplug scienc base cours benefit understand algorithm think paper describ use app approach udl base guidelin self regul problem formul problem solv present program lesson design improv student ct skill improv execut function higher level cognit skill use app framework explor field solar weather underrepres relev topic grade student approach strong reson power approach expositori write scientif method softwar engin"
  },
  {
    "doc_id": "10664997",
    "abstract_original": "Computational thinking (CT) is a key competency with a significant impact on students' academic performance in STEM fields. It empowers students to enhance problem-solving skills by decomposing problems, utilizing abstraction and pattern recognition, and employing algorithmic thinking to design solutions and build models. This is particularly important in STEM disciplines where logical reasoning is essential for addressing complex real-world challenges in academic and industrial settings. Given the increasing demand for professionals equipped with strong algorithmic thinking and problem-solving abilities in Industry 5, educational institutions are focusing on enhancing students' CT and problem-solving skills. This study presents an initiative conducted over the past two years at our institute to teach CT in a gateway course to students with different backgrounds in STEM fields. The approach involved designing specific learning modules on Abstraction, Decomposition, Pattern Recognition, and Algorithmic Thinking and integrating them into the LMS. After studying these learning modules, the students were exposed to specific assignments that required the application of related CT skills. Pre and post surveys were employed by using standard CT tests to measure the impact of the intervention on students' CT levels. The results indicated an improvement in students' perceptions of their mastery of CT. Academic course grades also showed an improvement, with increased A scores and reduced F grades post-intervention. This two-year study on improving CT skills has yielded promising results. Moving forward, the research aims to enhance the existing modules further and distribute them to a broader range of introductory-level STEM courses in other universities. This future direction aligns with the goal of expanding the impact of CT education and integrating it more widely into STEM curricula.",
    "abstract_processed": "comput think ct key compet signific impact student academ perform stem field empow student enhanc problem solv skill decompos problem util abstract pattern recognit employ algorithm think design solut build model particularli import stem disciplin logic reason essenti address complex real world challeng academ industri set given increas demand profession equip strong algorithm think problem solv abil industri educ institut focus enhanc student ct problem solv skill studi present initi conduct past two year institut teach ct gateway cours student differ background stem field approach involv design specif learn modul abstract decomposit pattern recognit algorithm think integr lm studi learn modul student expos specif assign requir applic relat ct skill pre post survey employ use standard ct test measur impact intervent student ct level result indic improv student percept masteri ct academ cours grade also show improv increas score reduc f grade post intervent two year studi improv ct skill yield promis result move forward research aim enhanc exist modul distribut broader rang introductori level stem cours univers futur direct align goal expand impact ct educ integr wide stem curricula"
  },
  {
    "doc_id": "10666582",
    "abstract_original": "This research article examines the use of artificial intelligence (AI) literacy in the field of research. Employing a multi-method methodological approach, it integrates narrative review, a quasi-experiment of an AI literacy course, and methodological triangulation. As a result, it describes a comprehensive content construct to develop AI literacy processes aimed at researchers. This construct encompasses generic competencies, generative AI, search engines, document interaction, document analysis by characteristics, generation of co-citation maps, literature reviews, database integration, data analysis, research tools, ethics in AI literacy, development of critical thinking through AI, and evaluation of AI literacy. The proposal provides a solid guide to strengthen the understanding and application of AI in research.",
    "abstract_processed": "research articl examin use artifici intellig ai literaci field research employ multi method methodolog approach integr narr review quasi experi ai literaci cours methodolog triangul result describ comprehens content construct develop ai literaci process aim research construct encompass gener compet gener ai search engin document interact document analysi characterist gener co citat map literatur review databas integr data analysi research tool ethic ai literaci develop critic think ai evalu ai literaci propos provid solid guid strengthen understand applic ai research"
  },
  {
    "doc_id": "10666721",
    "abstract_original": "Dementia is a condition that often comes with aging and affects how people think, remember, and behave. Diagnosing dementia early is important because it can greatly improve patients’ lives. This systematic review looks at how deep learning (DL) techniques have been used to diagnose dementia automatically from 2012 to 2023. We explore how different DL methods like Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), and Deep Neural Networks (DNN) are used to diagnose types of dementia such as Alzheimer’s, vascular dementia, and Lewy body dementia. We also discuss the difficulties of using DL for diagnosing dementia, like the lack of large and varied datasets and the challenge of applying models to different groups of people. These issues indicate the need for more dependable and understandable models that consider a wide range of patient characteristics and biomarkers. Longitudinal studies are also needed to understand how the disease progresses and how treatments work. Collaboration among researchers, doctors, and data scientists is crucial to ensure DL models are scientifically sound and effective in clinical settings. In summary, DL techniques show promise for automated dementia diagnosis and could improve how accurately and efficiently it is diagnosed in practice. However, further research is needed to address the challenges highlighted in this review.",
    "abstract_processed": "dementia condit often come age affect peopl think rememb behav diagnos dementia earli import greatli improv patients’ live systemat review look deep learn dl techniqu use diagnos dementia automat explor differ dl method like convolut neural network cnn recurr neural network rnn deep neural network dnn use diagnos type dementia alzheimer’ vascular dementia lewi bodi dementia also discuss difficulti use dl diagnos dementia like lack larg vari dataset challeng appli model differ group peopl issu indic need depend understand model consid wide rang patient characterist biomark longitudin studi also need understand diseas progress treatment work collabor among research doctor data scientist crucial ensur dl model scientif sound effect clinic set summari dl techniqu show promis autom dementia diagnosi could improv accur effici diagnos practic howev research need address challeng highlight review"
  },
  {
    "doc_id": "10669020",
    "abstract_original": "With the extensive application of wood-based panels in the home decor industry, determining formaldehyde release form wood-based panels (FRWBP) is crucial for ensuring environmental air quality and human health. This article addresses the issues of insufficient monitoring of the testing stages for FRWBP and the difficulty in tracing the operation records of operator during determining FRWBP by the chamber method. It proposes a system for monitoring and analyzing the testing stages of FRWBP based on electrical monitoring. The system employs non-invasive sensing technology that does not interfere with normal testing process to collect real-time electrical usage data from the devices. The data is uploaded to an industrial computer for storage and processing. Statistical features of the electrical time series data are extracted using a sliding window approach and optimized with Principal Component Analysis (PCA). Subsequently, the binary tree support vector machine algorithm (BTSVM) optimized by k-means clustering algorithm is used to identify the detection states of the wood-based panels. Experimental results show that the system can achieve traceability of the formaldehyde detection stage records of artificial boards, and the designed algorithm model can also effectively identify the detection status of wood-based panels. The system and methods proposed in this paper have significant prospects for implementation in monitoring and traceability management within the testing industry.",
    "abstract_processed": "extens applic wood base panel home decor industri determin formaldehyd releas form wood base panel frwbp crucial ensur environment air qualiti human health articl address issu insuffici monitor test stage frwbp difficulti trace oper record oper determin frwbp chamber method propos system monitor analyz test stage frwbp base electr monitor system employ non invas sens technolog interfer normal test process collect real time electr usag data devic data upload industri comput storag process statist featur electr time seri data extract use slide window approach optim princip compon analysi pca subsequ binari tree support vector machin algorithm btsvm optim k mean cluster algorithm use identifi detect state wood base panel experiment result show system achiev traceabl formaldehyd detect stage record artifici board design algorithm model also effect identifi detect statu wood base panel system method propos paper signific prospect implement monitor traceabl manag within test industri"
  },
  {
    "doc_id": "10669100",
    "abstract_original": "Contribution: We present a framework for teachers to investigate the relationships between attributes of students’ solutions in the process of problem solving or computational thinking. We provide visualization and evaluation techniques to find hidden patterns in the students’ solutions which allow teachers to predict the specific behavior of students or to prevent some student mistakes or misconceptions in advance or further pedagogical intervention. Background: Formal concept analysis is a method of unsupervised Machine Learning that applies mathematical lattice theory to organize data based on objects and their shared attributes. Several fuzzy extensions of formal concept analysis have a great potential to visualize and evaluate students’ solutions, to categorize the solutions into overlapping biclusters (formal concepts) or to generate the attribute implications between extracted attributes. Research Question: Does formal concept analysis describe the various solutions and the relationships between the extracted attributes of students’ solutions in the educational and computational thinking game Light-Bot? Methodology: Targeting the evaluation of 64 students’ solutions in the Light-Bot game, we construct the formal contexts of the extracted attributes. We apply formal concept analysis to construct the concept lattices from two binary formal contexts and to generate attribute implications and their fuzzy counterparts to find the dependencies between the extracted attributes. Findings: The results of our paper provide a description of various students’ solutions which are visualized in the concept lattices. 1) Regarding the concept lattice of binary formal contexts, we obtained the characterization of the largest biclusters which includes a description of the largest group of similar solutions. 2) The attribute implications mainly reveal the characterization of similar solutions, e.g., with a higher count of executed commands in solutions. 3) Using fuzzy attribute implications, we obtained the characterization of solutions with unnecessary commands, going out of the game area, or using indirect recursion.",
    "abstract_processed": "contribut present framework teacher investig relationship attribut students’ solut process problem solv comput think provid visual evalu techniqu find hidden pattern students’ solut allow teacher predict specif behavior student prevent student mistak misconcept advanc pedagog intervent background formal concept analysi method unsupervis machin learn appli mathemat lattic theori organ data base object share attribut sever fuzzi extens formal concept analysi great potenti visual evalu students’ solut categor solut overlap biclust formal concept gener attribut implic extract attribut research question formal concept analysi describ variou solut relationship extract attribut students’ solut educ comput think game light bot methodolog target evalu students’ solut light bot game construct formal context extract attribut appli formal concept analysi construct concept lattic two binari formal context gener attribut implic fuzzi counterpart find depend extract attribut find result paper provid descript variou students’ solut visual concept lattic regard concept lattic binari formal context obtain character largest biclust includ descript largest group similar solut attribut implic mainli reveal character similar solut e g higher count execut command solut use fuzzi attribut implic obtain character solut unnecessari command go game area use indirect recurs"
  },
  {
    "doc_id": "10669809",
    "abstract_original": "Entrepreneurship education is critical in encouraging students' innovation, creativity, and entrepreneurial spirit. It provides essential skills and knowledge, enabling them to open their creative potential and apply innovative thinking across diverse professional fields. With the widespread application of large language models in education, intelligent-assisted teaching in entrepreneurship education is stepping into a new learning phase anytime and anywhere. Entrepreneurship education extends across interdisciplinary knowledge fields, incorporating subjects like finance and risk management, which require advanced mathematical computational skills. This complexity presents new challenges for artificial-intelligence-assisted question-and-answer models. The study explores how students can maximize the knowledge repository of current large language models to improve learning efficiency and experimentally validates the performance differences between large language models and graph convolutional reasoning models regarding the complex semantic reasoning and mathematical computational demands in entrepreneurship education questions. Based on case studies, it is found that despite the broad prospects of large language models in entrepreneurship education, they still need to improve in practical applications. Especially in tasks within entrepreneurship education that demand precision, such as mathematical computations and risk assessment, the accuracy and efficiency of existing models still need improvement. Therefore, further exploration into algorithm optimization, model fusion, and other technical enhancements can improve the processing capabilities of intelligent question-and-answer systems for specific domain issues, aiming to meet the practical needs of entrepreneurship education.",
    "abstract_processed": "entrepreneurship educ critic encourag student innov creativ entrepreneuri spirit provid essenti skill knowledg enabl open creativ potenti appli innov think across divers profession field widespread applic larg languag model educ intellig assist teach entrepreneurship educ step new learn phase anytim anywher entrepreneurship educ extend across interdisciplinari knowledg field incorpor subject like financ risk manag requir advanc mathemat comput skill complex present new challeng artifici intellig assist question answer model studi explor student maxim knowledg repositori current larg languag model improv learn effici experiment valid perform differ larg languag model graph convolut reason model regard complex semant reason mathemat comput demand entrepreneurship educ question base case studi found despit broad prospect larg languag model entrepreneurship educ still need improv practic applic especi task within entrepreneurship educ demand precis mathemat comput risk assess accuraci effici exist model still need improv therefor explor algorithm optim model fusion technic enhanc improv process capabl intellig question answer system specif domain issu aim meet practic need entrepreneurship educ"
  },
  {
    "doc_id": "10673182",
    "abstract_original": "Due to the widespread use of machine learning models in various third-party libraries in languages, such as the sklearn library, people can quickly learn how to simply use machine learning models to empower the projects. However, in many times, most people simply take the model and apply it, never thinking about its generalization ability in the projects where it belongs to, that is, whether the performance of the model will continue to be excellent in different application scenarios and completely different dataset structures. This work mainly tested the generalization ability of two models. By using a dataset for model training, a brand-new dataset is introduced into the trained model to test its generalization ability. If it is found that the generalization ability is not high, our model is optimized to improve its generalization ability as much as possible. After optimization, their generalization ability (represented by precision improvement here, as explained below) has significantly improved, from 38.56% to 100.00% and from 40.24% to 54.79% respectively.",
    "abstract_processed": "due widespread use machin learn model variou third parti librari languag sklearn librari peopl quickli learn simpli use machin learn model empow project howev mani time peopl simpli take model appli never think gener abil project belong whether perform model continu excel differ applic scenario complet differ dataset structur work mainli test gener abil two model use dataset model train brand new dataset introduc train model test gener abil found gener abil high model optim improv gener abil much possibl optim gener abil repres precis improv explain significantli improv respect"
  },
  {
    "doc_id": "10673186",
    "abstract_original": "In the era of \"Internet plus Education\", precise ideological and political education is a key subject for higher education and an important indicator of contemporary college students’ education evaluation. The precise evaluation of ideological and political education focuses on the multi-source collection of teaching evidence throughout the entire process, emphasizing the multidimensional evaluation and measurement of the teaching process and its effectiveness, and providing new ideas for learning evaluation. This article draws on the ideas of teaching evaluation and combines the characteristics of the integration of online and offline precise ideological and political education. From the process of \"individual student modeling learning value precise ideological and political evaluation\", a multi-source data representation model is established; A multi-source data fusion method for precise evaluation of ideological and political education has been established from three levels: behavior, cognition, and communication; Furthermore, a multi-source data fusion evaluation system based on Kalman filtering algorithm was proposed, which includes four stages: data acquisition, data association, data fusion, interpretation, and decision-making. Through empirical research, it has been found that in a precise ideological and political evaluation system, multi-source data from online teaching platform logs, classroom teaching videos, learning performance and effectiveness can accurately evaluate the types and performance of students’ ideological and political learning engagement, and have a good prediction of the status of ideological and political learning engagement.",
    "abstract_processed": "era internet plu educ precis ideolog polit educ key subject higher educ import indic contemporari colleg students’ educ evalu precis evalu ideolog polit educ focus multi sourc collect teach evid throughout entir process emphas multidimension evalu measur teach process effect provid new idea learn evalu articl draw idea teach evalu combin characterist integr onlin offlin precis ideolog polit educ process individu student model learn valu precis ideolog polit evalu multi sourc data represent model establish multi sourc data fusion method precis evalu ideolog polit educ establish three level behavior cognit commun furthermor multi sourc data fusion evalu system base kalman filter algorithm propos includ four stage data acquisit data associ data fusion interpret decis make empir research found precis ideolog polit evalu system multi sourc data onlin teach platform log classroom teach video learn perform effect accur evalu type perform students’ ideolog polit learn engag good predict statu ideolog polit learn engag"
  },
  {
    "doc_id": "10674863",
    "abstract_original": "Pet robots, a sub-class of robotic companions, have garnered the interest of the scientific community and the public recently, due to their potential to help humans with everyday activities and enhance the psychological well-being of individuals across various aspects, for example, they can either serve as mere products of entertainment or as an alternative solution to mental healthcare. However, challenges must be solved when developing and crafting a pet robot that can adapt to the mentioned uses. A significant problem is that pet robots must bring their owners the experience that is close to having a real pet, both physically and psychologically. Therefore, there are specific requirements for the robot design and the variety of robot behaviors to make the robot as friendly and interactive as possible. This research aims to develop a versatile companion pet robot suitable for individuals of all ages, featuring a user-friendly design and high-end functionalities. The robot can move around and is equipped with basic functionalities such as voice recognition, emotional expressions, etc. Additionally, the robot integrated an advanced feature of autonomous thought processing, enabling it to generate responses and interact more dynamically and intuitively with its users.",
    "abstract_processed": "pet robot sub class robot companion garner interest scientif commun public recent due potenti help human everyday activ enhanc psycholog well individu across variou aspect exampl either serv mere product entertain altern solut mental healthcar howev challeng must solv develop craft pet robot adapt mention use signific problem pet robot must bring owner experi close real pet physic psycholog therefor specif requir robot design varieti robot behavior make robot friendli interact possibl research aim develop versatil companion pet robot suitabl individu age featur user friendli design high end function robot move around equip basic function voic recognit emot express etc addit robot integr advanc featur autonom thought process enabl gener respons interact dynam intuit user"
  },
  {
    "doc_id": "10675823",
    "abstract_original": "Computational literacies are becoming increasingly necessary for full societal participation. This paper investigates how Latine and multilingual students leverage their linguistic and cultural resources to develop coding and literacy skills. Data included interviews with Latine and multilingual students, teacher interviews, and teacher co-design meeting notes. Results showed that students learned coding and language through their families and communities, leveraged their cultural knowledge of storytelling to engage in computing, and built self-efficacy through peer support. Findings from this pilot study shed light on how to mobilize Latine and multilingual students’ rich languages and cultures for equitable computer science learning.",
    "abstract_processed": "comput literaci becom increasingli necessari full societ particip paper investig latin multilingu student leverag linguist cultur resourc develop code literaci skill data includ interview latin multilingu student teacher interview teacher co design meet note result show student learn code languag famili commun leverag cultur knowledg storytel engag comput built self efficaci peer support find pilot studi shed light mobil latin multilingu students’ rich languag cultur equit comput scienc learn"
  },
  {
    "doc_id": "10675866",
    "abstract_original": "Despite the commitment of educators, policymakers and industry leaders, the goal of broadening participation in CS to students who have been historically underrepresented and excluded remains elusive. Drawing on in-depth interviews with 41 administrators and teachers across 20 elementary, middle and high schools in a New York City, which has a robust CS for All initiative, we build on prior work to examine how normative, structural, and political barriers vary across schools offering CS through different implementation models. We also examine promising equity-focused leadership strategies aimed at overcoming these barriers.",
    "abstract_processed": "despit commit educ policymak industri leader goal broaden particip cs student histor underrepres exclud remain elus draw depth interview administr teacher across elementari middl high school new york citi robust cs initi build prior work examin norm structur polit barrier vari across school offer cs differ implement model also examin promis equiti focus leadership strategi aim overcom barrier"
  },
  {
    "doc_id": "10675889",
    "abstract_original": "In the context of virtual digital, the metaverse is regarded as an important field for the integration of computer technology and culture and art. Metaverse art must create metaphors based on media attributes like other media art. This article explains the necessity of the development of the metaverse, as well as the value of crypto art, and how to carry out new creative models and how to better embrace it. Never before have art forms in human history been as rich and complex as they are today, and the understanding of art is not only very demanding, but also requires high thinking and strong cultural judgment.",
    "abstract_processed": "context virtual digit metavers regard import field integr comput technolog cultur art metavers art must creat metaphor base media attribut like media art articl explain necess develop metavers well valu crypto art carri new creativ model better embrac never art form human histori rich complex today understand art demand also requir high think strong cultur judgment"
  },
  {
    "doc_id": "10676315",
    "abstract_original": "Research Purpose and Contribution: The study aimed to construct an evaluation framework for assessing pupils’ computational thinking (CT) during classroom learning problem solving. As a self-report evaluation scale for pupils, this evaluation framework further enriched the CT assessment instruments for pupils and provided a specialized instrument for experts to evaluate pupils’ CT in problem-solving situations during classroom learning.  Background: CT cultivation and assessment methods are hot topics in the field of education. CT assessment can effectively test the effect of CT cultivation. There are many CT assessment methods, of which evaluation frameworks are an effective self-reporting assessment method. Existing studies on self-reported CT evaluation frameworks are commonly applicable to students at different stages. However, few studies have focused on the specific context from the perspective of practice for pupils. Thus, the evaluation framework of pupils’ CT is worth exploring.  Intended Outcomes: A CT evaluation framework for evaluating pupils’ CT in problem-solving situations in classroom learning was constructed to facilitate researchers’ understanding of pupils’ CT levels and problem-solving skills.  Application Design: In this study, data from 897 pupils in the fifth and sixth grades were collected using an online questionnaire that included 27 items about CT. Exploratory factor analysis (EFA), confirmatory factor analysis (CFA), and item analysis were conducted to analyze the data in this study, with 17 items remaining in the final evaluation framework.  Findings: The fitting validity, convergence validity, and discriminant validity all met the recommended criteria, which showed that the evaluation framework was effective. The total reliability of CT was 0.911, indicating that the consistency and reliability of the evaluation framework constructed in this study were satisfied.",
    "abstract_processed": "research purpos contribut studi aim construct evalu framework assess pupils’ comput think ct classroom learn problem solv self report evalu scale pupil evalu framework enrich ct assess instrument pupil provid special instrument expert evalu pupils’ ct problem solv situat classroom learn background ct cultiv assess method hot topic field educ ct assess effect test effect ct cultiv mani ct assess method evalu framework effect self report assess method exist studi self report ct evalu framework commonli applic student differ stage howev studi focus specif context perspect practic pupil thu evalu framework pupils’ ct worth explor intend outcom ct evalu framework evalu pupils’ ct problem solv situat classroom learn construct facilit researchers’ understand pupils’ ct level problem solv skill applic design studi data pupil fifth sixth grade collect use onlin questionnair includ item ct exploratori factor analysi efa confirmatori factor analysi cfa item analysi conduct analyz data studi item remain final evalu framework find fit valid converg valid discrimin valid met recommend criteria show evalu framework effect total reliabl ct indic consist reliabl evalu framework construct studi satisfi"
  },
  {
    "doc_id": "10676986",
    "abstract_original": "A novel approach was proposed to develop a composition generation system for creating note sequences representing question-and-answer phrases (QAPs) in melodic phrases. Using a small dataset containing fewer than 10 compositions, the system is expected to generate new melodies that extend beyond the limitations of the original dataset. The modeling of note sequence data and selecting appropriate notes in specific sequences within the melody were chosen for gamelan skeletal melody generation using the Genetic Algorithm (GA) method. Gamelan, a traditional musical ensemble from Java, was selected as the focus of this research, with experiments centered on the gamelan skeletal melody, which plays a role similar to chord progressions in Western music. The evaluation was conducted by statistically analyzing the sequence of notations generated from the dataset and through expert testing. The experimental results demonstrate that the proposed method can generate compositions with well-formed melodic phrases through a small dataset containing varying lengths, data mapping, feature selection based on QAP patterns, and GA. GA can enhance creativity in creating note sequences and new QAP patterns, including novel patterns.",
    "abstract_processed": "novel approach propos develop composit gener system creat note sequenc repres question answer phrase qap melod phrase use small dataset contain fewer composit system expect gener new melodi extend beyond limit origin dataset model note sequenc data select appropri note specif sequenc within melodi chosen gamelan skelet melodi gener use genet algorithm ga method gamelan tradit music ensembl java select focu research experi center gamelan skelet melodi play role similar chord progress western music evalu conduct statist analyz sequenc notat gener dataset expert test experiment result demonstr propos method gener composit well form melod phrase small dataset contain vari length data map featur select base qap pattern ga ga enhanc creativ creat note sequenc new qap pattern includ novel pattern"
  },
  {
    "doc_id": "10677186",
    "abstract_original": "Polycystic Ovary Syndrome (PCOD) has emerged as a significant health concern in India, with prevalence rates reported between 9% to 36%. However, societal stigmas and misconceptions hinder the timely recognition and diagnosis of PCOD. A multi-modal AI-based framework for PCOD Detection and Risk Assessment is presented considering algorithms that include SVM, CNN, KNN, Otsu, and Näıve Bayes. This work integrates both image and numerical data utilizing ultrasound images, blood test results, and various patient parameters. 12 key parameters: height, weight, BMI, FSH, TSH, LH, AMH, PRL, Vitamin D3, progesterone, and RBS are considered. We conducted a survey involving 81 participants. Our survey revealed that 45% of participants were unaware of their PCOD status despite exhibiting symptoms, and 73% of participants exhibited symptoms of PCOD. 19.8% of respondents confirmed PCOD diagnoses. Our framework enhances diagnostic precision but also mitigates the emotional toll wrought by PCOD through early intervention and support.",
    "abstract_processed": "polycyst ovari syndrom pcod emerg signific health concern india preval rate report howev societ stigma misconcept hinder time recognit diagnosi pcod multi modal ai base framework pcod detect risk assess present consid algorithm includ svm cnn knn otsu näıve bay work integr imag numer data util ultrasound imag blood test result variou patient paramet key paramet height weight bmi fsh tsh lh amh prl vitamin progesteron rb consid conduct survey involv particip survey reveal particip unawar pcod statu despit exhibit symptom particip exhibit symptom pcod respond confirm pcod diagnos framework enhanc diagnost precis also mitig emot toll wrought pcod earli intervent support"
  },
  {
    "doc_id": "10678083",
    "abstract_original": "Large language models (LLMs) have achieved a great success in natural language processing, and have a significant potential for multi-modal applications. Despite the surprising zero-shot or few-shot ability, it is also required to effectively fine-tune pre-trained language models for specific downstream tasks. In this paper, we introduce CaptionT5, a video captioning model that fine-tunes T5 towards understanding videos and generating descriptive captions. To generate a more corespondent caption, CaptionT5 introduces thought-augmented fine-tuning for video captioning, in which a pre-trained language model is fine-tuned on thought-augmented video inputs. This resembles the process that human see a video, think of visual concepts such as objects and actions, and then tell a correct and natural sentence based on the thoughts. To automatically generate thoughts, we propose (1) CLIP-guided thought sampling that samples thoughts based on the similarity in an image-text multimodal embedding space by leveraging CLIP. We also propose (2) CLIP-guided caption ranking during decoding for further performance gains. Through experimentation on VATEX, MSRVTT, and YC2 datasets, we empirically demonstrate that CaptionT5 performs competitively against prior-art video captioning approaches without using encoders specialized for video data. Further experiments show that CaptionT5 is especially effective under small number of sampled video frames.",
    "abstract_processed": "larg languag model llm achiev great success natur languag process signific potenti multi modal applic despit surpris zero shot shot abil also requir effect fine tune pre train languag model specif downstream task paper introduc captiont video caption model fine tune toward understand video gener descript caption gener corespond caption captiont introduc thought augment fine tune video caption pre train languag model fine tune thought augment video input resembl process human see video think visual concept object action tell correct natur sentenc base thought automat gener thought propos clip guid thought sampl sampl thought base similar imag text multimod embed space leverag clip also propos clip guid caption rank decod perform gain experiment vatex msrvtt yc dataset empir demonstr captiont perform competit prior art video caption approach without use encod special video data experi show captiont especi effect small number sampl video frame"
  },
  {
    "doc_id": "10685684",
    "abstract_original": "This study is a systematic review of the effects of computational thinking on students’ academic performance from 2006 to 2023. The main purpose of this study is to explore whether computational thinking can promote students’ academic performance and the characteristics of such research. After literature collection and screening from three databases, a total of $\\mathbf{2 3}$ articles were included. According to the coding table, the literature was coded in five aspects, including basic information, sample, research, computational thinking and academic performance. Then, the publication trend, research types, effect results, computational thinking measurement and the characteristics of academic achievement evaluation of the impact of computational thinking and academic achievement are reviewed. It is found that computational thinking has a better effect on students’ academic achievement, and finally some suggestions are put forward.",
    "abstract_processed": "studi systemat review effect comput think students’ academ perform main purpos studi explor whether comput think promot students’ academ perform characterist research literatur collect screen three databas total \\mathbf articl includ accord code tabl literatur code five aspect includ basic inform sampl research comput think academ perform public trend research type effect result comput think measur characterist academ achiev evalu impact comput think academ achiev review found comput think better effect students’ academ achiev final suggest put forward"
  },
  {
    "doc_id": "10685695",
    "abstract_original": "As the process of artificial intelligence progresses, it is recognized that computational thinking is one of the basic skills for understanding and solving problems and one of the core literacies of the IT discipline. There are various ways to develop students’ computational thinking, and at the primary and secondary school levels, graphical programming classes are an important way to do so. This study establishes a framework for an instructional program aimed at developing students’ computational thinking skills based on elementary school graphic programming classes. Combining curriculum standards, graphic programming standards for youth programming skills, and International Computational Thinking Challenge standards, relevant teaching cases are designed to foster students’ computational thinking and promote the development of computational concepts, computational practices, and computational concepts.",
    "abstract_processed": "process artifici intellig progress recogn comput think one basic skill understand solv problem one core literaci disciplin variou way develop students’ comput think primari secondari school level graphic program class import way studi establish framework instruct program aim develop students’ comput think skill base elementari school graphic program class combin curriculum standard graphic program standard youth program skill intern comput think challeng standard relev teach case design foster students’ comput think promot develop comput concept comput practic comput concept"
  },
  {
    "doc_id": "10685722",
    "abstract_original": "With the development of virtual reality technology, 3D virtual robots are increasingly used in primary school robot programming teaching. Therefore, in this study, 64 fifth-grade students were divided into two groups, and the experimental research method was used to investigate which method is more conducive to improving students’ learning engagement and computational thinking by combining or separately using 3D virtual robots and physical robots in robot programming courses. The results show that the combined use of 3D virtual and physical robots in a robot programming course improves students’ Programming self-efficacy scale and learning engagement, thus improving students’ computational thinking.",
    "abstract_processed": "develop virtual realiti technolog virtual robot increasingli use primari school robot program teach therefor studi fifth grade student divid two group experiment research method use investig method conduc improv students’ learn engag comput think combin separ use virtual robot physic robot robot program cours result show combin use virtual physic robot robot program cours improv students’ program self efficaci scale learn engag thu improv students’ comput think"
  },
  {
    "doc_id": "10685815",
    "abstract_original": "In this study, the teaching design of the artificial intelligence curriculum was carried out with reference to the 5E teaching model, using the virtual simulation platform as a teaching aid. In the teaching practice, students’ computational thinking, autonomous learning, and goal attainment were tested respectively, and the effects of the virtual simulation platform and the 5E teaching model on the learning outcomes of the AI curriculum were explored.",
    "abstract_processed": "studi teach design artifici intellig curriculum carri refer e teach model use virtual simul platform teach aid teach practic students’ comput think autonom learn goal attain test respect effect virtual simul platform e teach model learn outcom ai curriculum explor"
  },
  {
    "doc_id": "10687081",
    "abstract_original": "The two-system theory of human thinking process is applied to the radio propagation modeling and prediction. System 1 corresponds to a quick and intuitive estimation of propagation parameters such as path losses and angles of arrival/departure. System 2 is a more deliberate process that takes more time to ‘think’ and provides more accurate results. In this paper we describe the necessary components of a two-system propagation modeling framework, present initial results, and discuss the challenges.",
    "abstract_processed": "two system theori human think process appli radio propag model predict system correspond quick intuit estim propag paramet path loss angl arriv departur system deliber process take time ‘think’ provid accur result paper describ necessari compon two system propag model framework present initi result discuss challeng"
  },
  {
    "doc_id": "10688269",
    "abstract_original": "Making neuro-inspired structures more resistant to common difficulties is the focus of this study. AI and deep learning are crucial in many fields; therefore, neural networks must be reliable and durable. This post proposes a robust framework using 10 advanced tactics for a new and complete robustness approach. Our technique uses dropout, gradient masking, transfer learning, adversarial training, randomized smoothing, input preparation, strong activation functions, ensemble learning, Bayesian neural networks, and gradient masking. These strategies are aimed at addressing hostile assaults, noise, and environmental changes. Combining these approaches makes the system more versatile, making it ideal for self-driving vehicles, medical diagnostics, and hacking. We conducted comprehensive research to evaluate the proposed method’s accuracy, durability, resistance, generalization, computational cost, and real-world usage. Line charts illustrate the method’s strengths and weaknesses. These numbers demonstrate how the proposed approach differs from previous ones. They demonstrate its versatility and efficacy. Finally, our results demonstrate a reliable, versatile, and proven method for neural network resilience. Our method handles common modifications using sophisticated methods. This yields a forward-thinking, effective solution to AI environmental changes. The reliability of neuro-inspired systems has improved, which will affect artificial intelligence.",
    "abstract_processed": "make neuro inspir structur resist common difficulti focu studi ai deep learn crucial mani field therefor neural network must reliabl durabl post propos robust framework use advanc tactic new complet robust approach techniqu use dropout gradient mask transfer learn adversari train random smooth input prepar strong activ function ensembl learn bayesian neural network gradient mask strategi aim address hostil assault nois environment chang combin approach make system versatil make ideal self drive vehicl medic diagnost hack conduct comprehens research evalu propos method’ accuraci durabl resist gener comput cost real world usag line chart illustr method’ strength weak number demonstr propos approach differ previou one demonstr versatil efficaci final result demonstr reliabl versatil proven method neural network resili method handl common modif use sophist method yield forward think effect solut ai environment chang reliabl neuro inspir system improv affect artifici intellig"
  },
  {
    "doc_id": "10689567",
    "abstract_original": "Mobile crowdsensing (MCS) has recently shown good performance in solving large-scale sensing tasks. As an essential topic in MCS, recommending tasks to participants has received extensive attention from researchers. Most studies assume that participants are absolutely rational, which is unrealistic because it is difficult for participants to know all the information about the transaction. Furthermore, most of them do not consider how to learn the preferences of new participants. In addition, their works are difficult to extend to different MCS scenarios. Considering the above problems, we propose an extensible bounded rationality-based task recommendation scheme (EBRTR), which contains a task recommendation framework and a bounded rationality decision-making model. First, a task recommendation framework that can be easily extended to various MCS scenarios is designed. Second, in our bounded rationality decision-making model, for participants with historical task information, according to the implicit information in their historical tasks, the human thinking mode with bounded rationality is simulated, and the improved classification and regression tree (ICART) algorithm is designed to construct the decision tree. For participants who newly join the platform, social information is introduced to construct an initial decision tree. Finally, extensive experimental evaluations demonstrate the effectiveness of the proposed scheme.",
    "abstract_processed": "mobil crowdsens mc recent shown good perform solv larg scale sens task essenti topic mc recommend task particip receiv extens attent research studi assum particip absolut ration unrealist difficult particip know inform transact furthermor consid learn prefer new particip addit work difficult extend differ mc scenario consid problem propos extens bound ration base task recommend scheme ebrtr contain task recommend framework bound ration decis make model first task recommend framework easili extend variou mc scenario design second bound ration decis make model particip histor task inform accord implicit inform histor task human think mode bound ration simul improv classif regress tree icart algorithm design construct decis tree particip newli join platform social inform introduc construct initi decis tree final extens experiment evalu demonstr effect propos scheme"
  },
  {
    "doc_id": "10689568",
    "abstract_original": "The soroban is a traditional arithmetic tool whose life in modern Japan reflected an inherently material dimension of computational numeracy. Using a system of commands to carry out operations, the soroban was both doubted and enthusiastically embraced by educators as a way of teaching basic mathematics, sparking conversations of what it really meant to understand arithmetic. Despite the introduction of Western-style pen and paper arithmetic, it persisted as the standard tool of computing in households, businesses, and bureaucracy, driving the Taylorist training of human calculators who could apply its commands with corporal discipline and the design of mechanical calculators that simplified its procedures. Even when educators held an “intuitive” ideal of mental calculation that moved students away from calculating with physical tools, the soroban persevered as a virtual interface that calculators accessed in their minds.",
    "abstract_processed": "soroban tradit arithmet tool whose life modern japan reflect inher materi dimens comput numeraci use system command carri oper soroban doubt enthusiast embrac educ way teach basic mathemat spark convers realli meant understand arithmet despit introduct western style pen paper arithmet persist standard tool comput household busi bureaucraci drive taylorist train human calcul could appli command corpor disciplin design mechan calcul simplifi procedur even educ held “intuitive” ideal mental calcul move student away calcul physic tool soroban persev virtual interfac calcul access mind"
  },
  {
    "doc_id": "10690228",
    "abstract_original": "In access control security models, the users of an organization's information system may be granted with conflicting privileges. This is usually the case when the underlying security policy implements both permission and prohibition rules. In this paper, we propose to capture uncertainty in security models, within the framework of possibility theory. We define efficient strategies for handling conflicting privileges derived by a security policy, based on priorities assigned to the permissions and prohibitions. We show that these strategies are in line with the possibilistic management of inconsistency in security policies.",
    "abstract_processed": "access control secur model user organ inform system may grant conflict privileg usual case underli secur polici implement permiss prohibit rule paper propos captur uncertainti secur model within framework possibl theori defin effici strategi handl conflict privileg deriv secur polici base prioriti assign permiss prohibit show strategi line possibilist manag inconsist secur polici"
  },
  {
    "doc_id": "10697011",
    "abstract_original": "This paper meticulously examines the escalating impact of AI Generative Tools on academic assessments and suggests renovating strategies to uphold the integrity of educational evaluations. With the increasing prevalence of AI-assisted cheating, traditional assessment methods encounter unprecedented challenges, prompting a fundamental shift in educational practices. The paper navigates the proliferation of AI Generative Tools, inspecting their diverse forms and motivations while addressing the ethical dilemmas arising from their integration into academic settings. Recognizing the constraints of current plagiarism detection tools, the paper explores innovative approaches to mitigate AI influence, emphasizing educational awareness programs, unambiguous academic integrity policies, and advancements in detection technologies. Advocating a departure from conventional assessment paradigms, the paper proposes the adoption of randomized questions, live assessments, and competency-based evaluations. Additionally, it recommends collaborative and authentic assessments to foster teamwork, communication, and the real-world application of knowledge. The paper delves into the necessity for updated policies, underscoring the enforcement of academic integrity and highlighting the significance of faculty development programs to empower educators in addressing AI-assisted cheating. The conclusion underscores the imperative for educational institutions to adapt proactively, providing practical insights and issuing a call to action in response to the dynamic challenges posed by AI.",
    "abstract_processed": "paper meticul examin escal impact ai gener tool academ assess suggest renov strategi uphold integr educ evalu increas preval ai assist cheat tradit assess method encount unpreced challeng prompt fundament shift educ practic paper navig prolifer ai gener tool inspect divers form motiv address ethic dilemma aris integr academ set recogn constraint current plagiar detect tool paper explor innov approach mitig ai influenc emphas educ awar program unambigu academ integr polici advanc detect technolog advoc departur convent assess paradigm paper propos adopt random question live assess compet base evalu addit recommend collabor authent assess foster teamwork commun real world applic knowledg paper delv necess updat polici underscor enforc academ integr highlight signific faculti develop program empow educ address ai assist cheat conclus underscor imper educ institut adapt proactiv provid practic insight issu call action respons dynam challeng pose ai"
  },
  {
    "doc_id": "10697362",
    "abstract_original": "Integrating drone technology and artificial intelligence (AI) education into the curriculum requirements of the Taiwanese 12-year basic education for senior high schools provides a disruptive approach to education in light of rapid technological advancements. Utilizing Python programming and the YOLO (You Only Look Once) package, this study proposes a curriculum structure that encompasses drone control and AI-based image recognition. The program primarily aims to develop students’ computational thinking and AI literacy, foster integrated project-based learning, and enhance problem-solving abilities.",
    "abstract_processed": "integr drone technolog artifici intellig ai educ curriculum requir taiwanes year basic educ senior high school provid disrupt approach educ light rapid technolog advanc util python program yolo look packag studi propos curriculum structur encompass drone control ai base imag recognit program primarili aim develop students’ comput think ai literaci foster integr project base learn enhanc problem solv abil"
  },
  {
    "doc_id": "10698637",
    "abstract_original": "The relationship between Cognitive Theory and Cloud Technology is a learning stage for humans, especially technology users, in various innovations used by users in modeling reasoning to develop human direction toward a better future. It includes learning on a large scale, such as objectively coordinated thinking, which provides for decision-making, social interaction, and access to various technological devices used. The above also focuses on human familiarity with various distributed computing services in cloud technology, including PaaS, SaaS, and IaaS. This research used a systems literature review model for over 20 years (2000 – 2023). Meanwhile, the applications used are Vos Viewer and Publish or Perish. Due to the author's limited access to IEEE, ACM, and WoS, the database used and the focus of the literature is the Scopus Database. In five years (2019–2023), the writing purpose accounted for only 55 articles, with 39 explicitly addressing cognitive theory and human behavior in the context of cloud technology. In this research, five factors influence human behavior with cloud technology: social interaction, access and connectivity, problem-solving, decision-making, and data confidentiality security. However, of the five impacts entered and obtained from the papers and journals studied, the most critical findings from this research are social interaction, data privacy and security, and decision-making. People will use cloud technology for social interaction, to protect and maintain the confidentiality of their data, and to make various decisions related to their activities. This research also shows that most references come from journals, not conference proceedings articles.",
    "abstract_processed": "relationship cognit theori cloud technolog learn stage human especi technolog user variou innov use user model reason develop human direct toward better futur includ learn larg scale object coordin think provid decis make social interact access variou technolog devic use also focus human familiar variou distribut comput servic cloud technolog includ paa saa iaa research use system literatur review model year – meanwhil applic use vo viewer publish perish due author limit access ieee acm wo databas use focu literatur scopu databas five year – write purpos account articl explicitli address cognit theori human behavior context cloud technolog research five factor influenc human behavior cloud technolog social interact access connect problem solv decis make data confidenti secur howev five impact enter obtain paper journal studi critic find research social interact data privaci secur decis make peopl use cloud technolog social interact protect maintain confidenti data make variou decis relat activ research also show refer come journal confer proceed articl"
  },
  {
    "doc_id": "10700103",
    "abstract_original": "Logic Programming allows for the exploration and development of Computational Thinking skills. Those being abstraction, decomposition, pattern recognition, and generalisation, among others, which are fundamental for problem-solving. What is more, Logic Programming helps building up Logical Thinking skills, also distinguishing valid arguments from fallacies and contradictions, as well as establishing connections between arguments through reasoning, to name some. These practices are not only essential for the development of knowledge in STEM, but also in Computer Science disciplines. Recently, arguments have been standing in favour of the early integration of programming within compulsory education. The international scientific community is looking forward to researching and initiatives being deployed towards this direction. This article introduces Metagame -Metajuego-, a methodological proposal which integrates key aspects to facilitate the effective integration of Logic Programming in primary education through collaborative and gamifying strategies. Furthermore, concrete cases of games are presented which have been formulated thanks to applying the proposed methodological approach to different educational contexts. The narratives upon which these games are based, incorporate learning cores presented in the curricular school designs where they were implemented.",
    "abstract_processed": "logic program allow explor develop comput think skill abstract decomposit pattern recognit generalis among other fundament problem solv logic program help build logic think skill also distinguish valid argument fallaci contradict well establish connect argument reason name practic essenti develop knowledg stem also comput scienc disciplin recent argument stand favour earli integr program within compulsori educ intern scientif commun look forward research initi deploy toward direct articl introduc metagam metajuego methodolog propos integr key aspect facilit effect integr logic program primari educ collabor gamifi strategi furthermor concret case game present formul thank appli propos methodolog approach differ educ context narr upon game base incorpor learn core present curricular school design implement"
  },
  {
    "doc_id": "10700402",
    "abstract_original": "The teaching of programming in primary and secondary education has once again revealed the heterogeneity of the ways in which students learn and instructors teach such a capability. Language barriers and technological skills of the involved people are some of the factors that affect the usability and usefulness of educational programming environments. This article presents a gamified programming environment, called Damo's Quest, that supports middle school instructors while they teach programming to students who have little access to computer technology and proficiency in English language. The platform offers a gamified-educational experience, in which students must deal with challenges in fantasy stories (in virtual worlds) by programming various solutions. The usability and perceived usefulness of the first version of this tool have been evaluated by two researchers, who are experts in computational thinking. Although preliminary, the results are highly encouraging.",
    "abstract_processed": "teach program primari secondari educ reveal heterogen way student learn instructor teach capabl languag barrier technolog skill involv peopl factor affect usabl use educ program environ articl present gamifi program environ call damo quest support middl school instructor teach program student littl access comput technolog profici english languag platform offer gamifi educ experi student must deal challeng fantasi stori virtual world program variou solut usabl perceiv use first version tool evalu two research expert comput think although preliminari result highli encourag"
  },
  {
    "doc_id": "10702203",
    "abstract_original": "Currently, the power sector is characterized by the dispersion of data across different times, spaces, or complexities, as well as difficulties in the unified collection of sample data, leading to significant challenges in obtaining multi-scale fine-tuning samples. In light of this, this paper focuses on the collection and preprocessing of textual data in the power sector and proposes a method for constructing multi-scale fine-tuning samples in the power sector based on the chain of thought. By introducing multi-scale analysis methods, power system data is divided according to different temporal and spatial scales, thereby creating a sample set with hierarchical structure and diversity. This method can adaptively adjust the selection and enhancement strategies of samples based on the characteristics of data at different scales, thus effectively representing and modeling the complex data of the power system and improving the efficiency and accuracy of text data processing in the power sector.",
    "abstract_processed": "current power sector character dispers data across differ time space complex well difficulti unifi collect sampl data lead signific challeng obtain multi scale fine tune sampl light paper focus collect preprocess textual data power sector propos method construct multi scale fine tune sampl power sector base chain thought introduc multi scale analysi method power system data divid accord differ tempor spatial scale therebi creat sampl set hierarch structur divers method adapt adjust select enhanc strategi sampl base characterist data differ scale thu effect repres model complex data power system improv effici accuraci text data process power sector"
  },
  {
    "doc_id": "10710556",
    "abstract_original": "Writing a book about artificial general intelligence in 2023 means chasing a moving target. I started working on this book before ChatGPT was released, quickly gained tens of millions of users, and reinvigorated the AGI debate. As I am finalizing this book in October 2023, there is intense discussion among both technologists and politicians about AI regulation. By the time you read this, much will have happened in terms of both technology and policy. But my descriptions of how the underlying computational methods work will still be true, and I think the various points I make throughout the book about both natural and artificial intelligence will still apply.",
    "abstract_processed": "write book artifici gener intellig mean chase move target start work book chatgpt releas quickli gain ten million user reinvigor agi debat final book octob intens discuss among technologist politician ai regul time read much happen term technolog polici descript underli comput method work still true think variou point make throughout book natur artifici intellig still appli"
  },
  {
    "doc_id": "1087496",
    "abstract_original": "We review some of the open issues in computational stereo. In particular, we will discuss the problem of extracting better matching primitives and of dealing with occlusions. Markov Random Field models - an extension of standard regularization - suggest sophisticated stereo matching algorithms. They are, however, ill-suited to efficient, real-time applications. We will conclude reviewing a new simple but fast algorithm implemented by one of us (Drumheller, 1986) on the TMC Connection Machine (TM) computer. Some of its features are: (a) the potential for combining different primitives, including color information; (b) the use of a stronger and new formulation of the uniqueness constraint; and (c) its disparity representation that maps efficiently into the architecture of the Connection Machine computer.",
    "abstract_processed": "review open issu comput stereo particular discuss problem extract better match primit deal occlus markov random field model extens standard regular suggest sophist stereo match algorithm howev ill suit effici real time applic conclud review new simpl fast algorithm implement one us drumhel tmc connect machin tm comput featur potenti combin differ primit includ color inform b use stronger new formul uniqu constraint c dispar represent map effici architectur connect machin comput"
  },
  {
    "doc_id": "1093885",
    "abstract_original": "In this paper we compute the mean delay for an unslotted ALOHA random access channel for both fixed and variable length packets. The analysis is based on the concept of a user cycle and obtains steady state results. When the channel is \"stable\", the results seem quite accurate. The input parameters to the model are the number of users, the mean think time, and mean retransmission time. The model yields total traffic, throughput and delay but only the latter is emphasized here. Because of the steady state nature of the analysis, no information is obtained on stability. The results are verified by simulation.",
    "abstract_processed": "paper comput mean delay unslot aloha random access channel fix variabl length packet analysi base concept user cycl obtain steadi state result channel stabl result seem quit accur input paramet model number user mean think time mean retransmiss time model yield total traffic throughput delay latter emphas steadi state natur analysi inform obtain stabil result verifi simul"
  },
  {
    "doc_id": "1157916",
    "abstract_original": "We describe an instructional approach to enhance mathematical orientation in programming skills among beginning computer science students. We were motivated by the belief that adequate mathematical education is a crucial component in a programmer's training, since mathematical skills are an indispensable component of a proficient programmers' knowledge. We use elementary mathematics to anchor the new CS knowledge and skills, by engaging the students in solving authentic mathematically oriented problems, whose solutions require mathematical inquiry, as well as mathematically oriented programming skills. Solving problems of this type continuously throughout CS studies enables the students to grasp the CS professional work, and in particular the role of mathematics in the work of proficient programmers. We describe three examples of problems, for which we analyze the advantage of using mathematics and recommend pedagogical activity accordingly. We also exemplify and analyze the implementation of our approach in class.",
    "abstract_processed": "describ instruct approach enhanc mathemat orient program skill among begin comput scienc student motiv belief adequ mathemat educ crucial compon programm train sinc mathemat skill indispens compon profici programm knowledg use elementari mathemat anchor new cs knowledg skill engag student solv authent mathemat orient problem whose solut requir mathemat inquiri well mathemat orient program skill solv problem type continu throughout cs studi enabl student grasp cs profession work particular role mathemat work profici programm describ three exampl problem analyz advantag use mathemat recommend pedagog activ accordingli also exemplifi analyz implement approach class"
  },
  {
    "doc_id": "1157933",
    "abstract_original": "In this paper we describe a student-centered laboratory developed by the Department of Computing and Mathematical Sciences at Texas A&M University-Corpus Christi and partially supported by a National Science Foundation CCLI Program grant (DUE-9950839). This laboratory is utilized by students, freshmen to graduate level, as an active learning laboratory. These are students from several disciplines including computer sciences, mathematics, geographical information systems, engineering technology, and educational technology. The laboratory is centered around a computer-controlled model railroad system and a range of simple to sophisticated robotic platforms. The laboratory equipment and layout encourage \"near-peer\" teaching activities such as presentations and group projects. The student projects move beyond basic theory verification by requiring students to practice higher-level thinking, and students are able to physically observe the results of their own computational solutions to problems. The student projects encourage students to reorganize knowledge, understand computation in the context of larger systems, and discover the connections among several disciplines.",
    "abstract_processed": "paper describ student center laboratori develop depart comput mathemat scienc texa univers corpu christi partial support nation scienc foundat ccli program grant due laboratori util student freshmen graduat level activ learn laboratori student sever disciplin includ comput scienc mathemat geograph inform system engin technolog educ technolog laboratori center around comput control model railroad system rang simpl sophist robot platform laboratori equip layout encourag near peer teach activ present group project student project move beyond basic theori verif requir student practic higher level think student abl physic observ result comput solut problem student project encourag student reorgan knowledg understand comput context larger system discov connect among sever disciplin"
  },
  {
    "doc_id": "1158740",
    "abstract_original": "The commonly used programming approach in teaching computer graphics requires students to learn a lot before they can generate basic and not-so-realistic images. As a result, students may easily be lost in the jungle of programming primitives, and their high expectation fades away quickly. Moreover, the API based programming approach does not support global illumination models. To address these problems, a new approach that combines ray tracing and programming has been used in a junior level elective course, Introduction to Computing with Geometry, with great success. With ray tracing, we are able to cover the camera metaphor, basic shapes, geometric modeling, coefficients of an illumination model, light sources, textures, surface tessellation, smooth and nonsmooth triangles, and algebraic surfaces. A student can learn all the basics and generate beautiful and realistic looking images easily and quickly. This paper details our approach and presents our course materials, exercises, student work and evaluation.",
    "abstract_processed": "commonli use program approach teach comput graphic requir student learn lot gener basic realist imag result student may easili lost jungl program primit high expect fade away quickli moreov api base program approach support global illumin model address problem new approach combin ray trace program use junior level elect cours introduct comput geometri great success ray trace abl cover camera metaphor basic shape geometr model coeffici illumin model light sourc textur surfac tessel smooth nonsmooth triangl algebra surfac student learn basic gener beauti realist look imag easili quickli paper detail approach present cours materi exercis student work evalu"
  },
  {
    "doc_id": "1174227",
    "abstract_original": "In the complexity and simulation communities there is growing support for the use of bottom-up computer-based simulation in the analysis of complex systems. The presumption is that because these models are more complex than their linear predecessors they must be more suited to the modeling of systems that appear, superficially at least, to be (compositionally and dynamically) complex. Indeed the apparent ability of such models to allow the emergence of collective phenomena from quite simple underlying rules is very compelling. But does this 'evidence' alone 'prove' that nonlinear bottom-up models are superior to simpler linear models when considering complex systems behavior? Philosophical explorations concerning the efficacy of models, whether they be formal scientific models or our personal worldviews, has been a popular pastime for many philosophers, particularly philosophers of science. This paper offers yet another critique of modeling that uses the results and observations of nonlinear mathematics and bottom-up simulation themselves to develop a modeling paradigm that is significantly broader than the traditional model-focused paradigm. In this broader view of modeling we are encouraged to concern ourselves more with the modeling process rather than the (computer) model itself and embrace a nonlinear modeling culture. This emerging view of modeling also counteracts the growing preoccupation with nonlinear models over linear models.",
    "abstract_processed": "complex simul commun grow support use bottom comput base simul analysi complex system presumpt model complex linear predecessor must suit model system appear superfici least composit dynam complex inde appar abil model allow emerg collect phenomena quit simpl underli rule compel evid alon prove nonlinear bottom model superior simpler linear model consid complex system behavior philosoph explor concern efficaci model whether formal scientif model person worldview popular pastim mani philosoph particularli philosoph scienc paper offer yet anoth critiqu model use result observ nonlinear mathemat bottom simul develop model paradigm significantli broader tradit model focus paradigm broader view model encourag concern model process rather comput model embrac nonlinear model cultur emerg view model also counteract grow preoccup nonlinear model linear model"
  },
  {
    "doc_id": "1174599",
    "abstract_original": "Technological systems involving hazards are typically managed by experienced personnel guided by well-formulated, pre-determined procedures. These procedures are designed to ensure that operations proceed in a safe and cost-effective manner. Yet normal operations in these systems are exposed to unexpected contingencies that can require personnel to develop and deploy new procedures in real-time. Creative thinking in such situations is therefore necessary in order to prevent degradation of operations, particularly when there is potential for personal injury, economic loss or environmental damage. One approach to addressing these situations is improvisation. The research described here discusses a series of studies conducted to evaluate the efficacy of a computer-based system for supporting improvisation in simulated crisis situations. The design and implementation of the system are first discussed, drawing upon prior work in blackboard-based systems. The experimental design is then reviewed, followed by a discussion of how the studies were run using groups of emergency response personnel from the Port of Rotterdam in The Netherlands. The group task was to address unexpected contingencies in a timely fashion. A number of measures of group decision effectiveness and uniqueness are presented. Results of the studies suggest that availability of decision support may have had an uneven influence on solution effectiveness and no influence on solution uniqueness. Possible implications for the design of group decision support systems for improvisation are then discussed, along with a number of observations on conducting experimentally-based research on group improvisation.",
    "abstract_processed": "technolog system involv hazard typic manag experienc personnel guid well formul pre determin procedur procedur design ensur oper proceed safe cost effect manner yet normal oper system expos unexpect conting requir personnel develop deploy new procedur real time creativ think situat therefor necessari order prevent degrad oper particularli potenti person injuri econom loss environment damag one approach address situat improvis research describ discuss seri studi conduct evalu efficaci comput base system support improvis simul crisi situat design implement system first discuss draw upon prior work blackboard base system experiment design review follow discuss studi run use group emerg respons personnel port rotterdam netherland group task address unexpect conting time fashion number measur group decis effect uniqu present result studi suggest avail decis support may uneven influenc solut effect influenc solut uniqu possibl implic design group decis support system improvis discuss along number observ conduct experiment base research group improvis"
  },
  {
    "doc_id": "1174830",
    "abstract_original": "Today, we assist to the explosive development of mobile computing devices like PDAs and cellphones, the integration of embedded intelligence (like Web server) in more and more common devices, and the proliferation of wireless communication technologies (IRdA, Bluetooth, IEEE 802.11, GPRS). All these trends contribute to move us closer to the ubiquitous computing world described by Mark Weiser. But while the technology is here, applications, and more important, models and tools for designing future ambient computing systems are still rare. One of the first innovative concepts of ubiquitous computing, context-awareness is still hard to use and understand from a programming perspective. We think that the problem resides in the lack of system support: in traditional computing, operating system offers simple to use and easy to understand abstractions of computational resources. Ubiquitous computing involves an integration of \"computing\" into the real-world, which is a radically different environment for applications. We think that this environment requires new operating system services and abstractions. Because the real world is made of physical entities, \"living\" in the physical space, ambient computing software should be able to use abstraction representing such objects, in a simple way. In this paper, we present a light framework to design ubiquitous computing software, called SPREAD. Unlike many approaches which hides too much of the real-world behind traditional computing abstraction, SPREAD defines programming abstraction based on the properties of the physical space. Hence, physical properties, like relative proximity, are used as implicitly in SPREAD as variable addressing in a computer memory. In SPREAD, application (or process) behavior can be \"mechanically\" driven, in the sense that actions flow can be directly dependent of physical mobility. To support this concept, we introduce a programming and execution model allowing designing computing and information systems driven directly by arranging and moving physical objects in the space. We demonstrate the use of the model to implement a few practical applications, highlighting its simplicity and expression power.",
    "abstract_processed": "today assist explos develop mobil comput devic like pda cellphon integr embed intellig like web server common devic prolifer wireless commun technolog irda bluetooth ieee gpr trend contribut move us closer ubiquit comput world describ mark weiser technolog applic import model tool design futur ambient comput system still rare one first innov concept ubiquit comput context awar still hard use understand program perspect think problem resid lack system support tradit comput oper system offer simpl use easi understand abstract comput resourc ubiquit comput involv integr comput real world radic differ environ applic think environ requir new oper system servic abstract real world made physic entiti live physic space ambient comput softwar abl use abstract repres object simpl way paper present light framework design ubiquit comput softwar call spread unlik mani approach hide much real world behind tradit comput abstract spread defin program abstract base properti physic space henc physic properti like rel proxim use implicitli spread variabl address comput memori spread applic process behavior mechan driven sens action flow directli depend physic mobil support concept introduc program execut model allow design comput inform system driven directli arrang move physic object space demonstr use model implement practic applic highlight simplic express power"
  },
  {
    "doc_id": "1180314",
    "abstract_original": "In this study, we propose a specification which is able to estimate the uncertainty more easily and quickly and also able to maintain a confidence level when measuring the magnitude and phase of 1-port and 2-port transmission /spl middot/ reflection coefficient using a VNA and attached coaxial cable probes. This proposed specification is available when it needs extra special condition of uncertainty estimation and when there is no additional standard equipment such as a beadless airline or mismatch standard at the measurement institute. We compare and examine this proposed uncertainty estimation method with recommends the EA specification and Agilent specification. As a result, we think that this proposed specification can be used as a reference for uncertainty estimation and calculation of a VNA system, that is, a reference based on the ISO/IEC 17025 requirements.",
    "abstract_processed": "studi propos specif abl estim uncertainti easili quickli also abl maintain confid level measur magnitud phase port port transmiss spl middot reflect coeffici use vna attach coaxial cabl probe propos specif avail need extra special condit uncertainti estim addit standard equip beadless airlin mismatch standard measur institut compar examin propos uncertainti estim method recommend ea specif agil specif result think propos specif use refer uncertainti estim calcul vna system refer base iso iec requir"
  },
  {
    "doc_id": "1186019",
    "abstract_original": "Understanding preservice teachers' thinking styles and dispositions and how these are related to positive changes in their teacher behaviors provide valuable information for teacher preparation. This study aimed to investigate the relationship between preservice teachers' critical-thinking dispositions and three thinking styles (judicial, legislative, and executive) and their behavior change in a computer simulation. 178 preservice teachers participated in this study. Their interactive teaching experiences were measured via the CS-TGCTS simulation. The findings in this study suggest that preservice teachers with a high level of critical-thinking dispositions and those with judicial or legislative thinking styles are analytical and reflective vis A-vis their teaching practice and, as a consequence, they experienced great behavior change, whereas those with executive styles did not exhibit significant behavior change at the end of the simulated teaching.",
    "abstract_processed": "understand preservic teacher think style disposit relat posit chang teacher behavior provid valuabl inform teacher prepar studi aim investig relationship preservic teacher critic think disposit three think style judici legisl execut behavior chang comput simul preservic teacher particip studi interact teach experi measur via cs tgct simul find studi suggest preservic teacher high level critic think disposit judici legisl think style analyt reflect vi vi teach practic consequ experienc great behavior chang wherea execut style exhibit signific behavior chang end simul teach"
  },
  {
    "doc_id": "1186172",
    "abstract_original": "This paper presents a web-based distance education system that contains synchronous (live) video lectures, asynchronous learning materials with video-on-demand (VOD) archive data, and question and answer functions through digital reporting between a lecturer and students. It is intended to provide a collaborative workplace to encourage interactions among a lecturer/learners. As such, this environments enables learners to exchange their knowledge and their way of thinking, furthermore, to refine/build the knowledge acquired via lectures. One of the main purposes in our research is to build a flexible e-Learning environment by embedding self/collaborative support functions for the digitized live lectures in order to reinforce much more meaningful knowledge and skills. Moreover, we propose an innovative educational method of a cooperative link between a university and an industry for the higher education. The knowledge repository means a kind of data-warehouse with the computational mechanism to handle/manage various data occurred in e-Learning process. The knowledge repository may be utilized for any information referencing, diagnosing/evaluating of learners' activities, consulting and so on. We also tackle problems of knowledge sharing, knowledge-retrieval and various types of collaboration in the learning environment. The heart of our project is the exploration of how we can effectively make use of this knowledge repository to support learners who have a range of different needs, though we don't mention its technical details here.",
    "abstract_processed": "paper present web base distanc educ system contain synchron live video lectur asynchron learn materi video demand vod archiv data question answer function digit report lectur student intend provid collabor workplac encourag interact among lectur learner environ enabl learner exchang knowledg way think furthermor refin build knowledg acquir via lectur one main purpos research build flexibl e learn environ embed self collabor support function digit live lectur order reinforc much meaning knowledg skill moreov propos innov educ method cooper link univers industri higher educ knowledg repositori mean kind data warehous comput mechan handl manag variou data occur e learn process knowledg repositori may util inform referenc diagnos evalu learner activ consult also tackl problem knowledg share knowledg retriev variou type collabor learn environ heart project explor effect make use knowledg repositori support learner rang differ need though mention technic detail"
  },
  {
    "doc_id": "1197913",
    "abstract_original": "As the utility marketplace continues to evolve, long-term survival and prosperity require clear, strategic thinking on the enterprise transforming initiatives needed to effectively increase efficiency and improve revenue opportunities. After a vision is formulated or refined, one of the crucial steps to be undertaken involves a business-process modeling exercise aimed at determining the operational processes that will support the strategy. In many cases, business-process automation (integrating information across systems) serves as the foundation for an enterprise business-process model. Adapting a modern business-process model includes embracing change. Toward that end, enterprise-application integration (EAI), the nimble strategy that involves technology and process that enables disparate systems to exchange business-level information in languages that each understands, provides the backbone infrastructure for implementing a business-process model. Ultimately, EAI serves as the enabler of high-level strategies detailed out as part of a business-process modeling effort and provides the flexible framework to address changing business climates.",
    "abstract_processed": "util marketplac continu evolv long term surviv prosper requir clear strateg think enterpris transform initi need effect increas effici improv revenu opportun vision formul refin one crucial step undertaken involv busi process model exercis aim determin oper process support strategi mani case busi process autom integr inform across system serv foundat enterpris busi process model adapt modern busi process model includ embrac chang toward end enterpris applic integr eai nimbl strategi involv technolog process enabl dispar system exchang busi level inform languag understand provid backbon infrastructur implement busi process model ultim eai serv enabl high level strategi detail part busi process model effort provid flexibl framework address chang busi climat"
  },
  {
    "doc_id": "1198181",
    "abstract_original": "We describe and discuss the coding method and self-organizing process of the information in the brain, advance a kind of encoding system: the \"natural encoding system\" which is particular to nature itself. In the problem of machine imitation, we further discuss the topological property equivalence problem of artificial and natural intelligence system on the basis of hierarchy structures of the virtual machine. More specifically we present the three large hierarchy structures of the intelligence system: the physical hierarchy, the physiological hierarchy and the psychological hierarchy. We also describe the relations between the three large hierarchies and some sub-stratums, the encoding method of information, the holographic frame structure of the information, the functions of the virtual machine system on different levels, etc. in more detail.",
    "abstract_processed": "describ discuss code method self organ process inform brain advanc kind encod system natur encod system particular natur problem machin imit discuss topolog properti equival problem artifici natur intellig system basi hierarchi structur virtual machin specif present three larg hierarchi structur intellig system physic hierarchi physiolog hierarchi psycholog hierarchi also describ relat three larg hierarchi sub stratum encod method inform holograph frame structur inform function virtual machin system differ level etc detail"
  },
  {
    "doc_id": "1205164",
    "abstract_original": "The arrival of VHDL-AMS opened a lot of doors for the mixed signal analysis community. For the first time, standardised and widespread interoperability has been made possible, and people from different organisations could sensibly exchange information and designs. However, this interoperability comes at a price. The structure of the language - of any language, human or computer, come to that - colours the thinking of those using it. This paper comments on a number of issues that are often ignored - if indeed they are acknowledged at all - when designing or describing mixed signal systems. It is qualitative, and aimed at users of automated design systems, as opposed to those who design the design systems.",
    "abstract_processed": "arriv vhdl am open lot door mix signal analysi commun first time standardis widespread interoper made possibl peopl differ organis could sensibl exchang inform design howev interoper come price structur languag languag human comput come colour think use paper comment number issu often ignor inde acknowledg design describ mix signal system qualit aim user autom design system oppos design design system"
  },
  {
    "doc_id": "1213498",
    "abstract_original": "Interconnection network performance is a key factor when constructing parallel computers. The choice of an interconnection network used in a parallel computer depends on a large number of performance factors which are very often application dependent. We give the outline of a performance evaluation and comparison methodology using what we think of as the most important parameters to be considered when solving such a problem. This methodology is applied on a new interconnection network called MCRB network and on Omega network.",
    "abstract_processed": "interconnect network perform key factor construct parallel comput choic interconnect network use parallel comput depend larg number perform factor often applic depend give outlin perform evalu comparison methodolog use think import paramet consid solv problem methodolog appli new interconnect network call mcrb network omega network"
  },
  {
    "doc_id": "1215092",
    "abstract_original": "In order to study various aspects of students' understanding of atomic orbitals, we have built a 3D virtual environment - \"Virtual Water\" - to support the learning of some concepts of physics and chemistry at the final high school or first-year university levels. It focuses on the microscopic structure of water and explores, among others, concepts related to atomic and molecular orbitals. To evaluate that software, we have made a qualitative study with 20 first-year students of science and engineering courses at the university of Coimbra, Portugal. Having been asked to describe their views about how they conceive electrons in an atom before seeing \"Virtual Water\", students revealed some misconceptions. We have tried, with partial success, to overcome them by making students explore our virtual environment.",
    "abstract_processed": "order studi variou aspect student understand atom orbit built virtual environ virtual water support learn concept physic chemistri final high school first year univers level focus microscop structur water explor among other concept relat atom molecular orbit evalu softwar made qualit studi first year student scienc engin cours univers coimbra portug ask describ view conceiv electron atom see virtual water student reveal misconcept tri partial success overcom make student explor virtual environ"
  },
  {
    "doc_id": "1218700",
    "abstract_original": "Approximately 25 years have passed since the \"sense-act-think\" paradigm was advanced as the operational definition of a robot, and as a broad roadmap for robotics research. With the appearance of mobile robots that do real work in the real world, \"communicate\" has de facto been added to the list of functionalities that are essential features of robots. In keeping with the theme of the ROSE-2003 Workshop, this paper attempts to articulate and justify a set of intellectual and engineering challenges for 21 st century sensing and perception for robotics. It especially argues for examining the current and re-examining future roles for teleoperation, both as a practical route around the improbability that machine intelligence will equal human intelligence in the foreseeable future, and because it is apparent that sensor improvement is driven in large part by incremental advances in sensor-display design-and-test loops that are in turn driven by human factors governing perception.",
    "abstract_processed": "approxim year pass sinc sens act think paradigm advanc oper definit robot broad roadmap robot research appear mobil robot real work real world commun de facto ad list function essenti featur robot keep theme rose workshop paper attempt articul justifi set intellectu engin challeng st centuri sens percept robot especi argu examin current examin futur role teleoper practic rout around improb machin intellig equal human intellig forese futur appar sensor improv driven larg part increment advanc sensor display design test loop turn driven human factor govern percept"
  },
  {
    "doc_id": "1222055",
    "abstract_original": "This research tries to construct a new architecture of intelligent information processing imitating that of human thought and having ability of autonomous learning. Its processing is divided into logical and intuitive processing, which are selected flexibly and properly for the changing situation. To investigate its effectiveness, it is applied to a robot playing a Tetris game, which is regarded as a symbol of human intellectual behavior. The robot consists of three elements: recognition part, thinking part, and action part. The thinking part consists of logical and intuitive processing. Logical processing has the ability of accurate and slow processing, and intuitive processing has the ability of rough and quick processing. The learning method of logical processing consists of fuzzy Q-learning with neural network and intuitive processing consists of neural network, which is trained by empirical knowledge of logical processing. The combination of logical and intuitive processing leads to the improvement of game playing results for the reason that intuitive and logical processing built along with playing time becomes more applicable. As a result, it is shown that the proposed method is a useful approach.",
    "abstract_processed": "research tri construct new architectur intellig inform process imit human thought abil autonom learn process divid logic intuit process select flexibl properli chang situat investig effect appli robot play tetri game regard symbol human intellectu behavior robot consist three element recognit part think part action part think part consist logic intuit process logic process abil accur slow process intuit process abil rough quick process learn method logic process consist fuzzi q learn neural network intuit process consist neural network train empir knowledg logic process combin logic intuit process lead improv game play result reason intuit logic process built along play time becom applic result shown propos method use approach"
  },
  {
    "doc_id": "1222080",
    "abstract_original": "In this paper, we propose an emergent system in which an autonomous mobile robot can acquire environment oriented behavior. In the general robotic engineering, a system designer gave the model of environment and sensory-motor commands beforehand. However, we think that the autonomous robot has to be developed through the interaction between robot's behavior and the environmental information by itself. So, we construct the controller for the autonomous robot to acquire the adaptive behavior with the chaotic neural networks (CNNs). Furthermore, we make use of the dynamic learning method (DLM) as an on-line learning method. The results of the computational experiments show the chaotic search of this network plays an important role for the acquisition of the adaptive behavior.",
    "abstract_processed": "paper propos emerg system autonom mobil robot acquir environ orient behavior gener robot engin system design gave model environ sensori motor command beforehand howev think autonom robot develop interact robot behavior environment inform construct control autonom robot acquir adapt behavior chaotic neural network cnn furthermor make use dynam learn method dlm line learn method result comput experi show chaotic search network play import role acquisit adapt behavior"
  },
  {
    "doc_id": "1222167",
    "abstract_original": "It is often known that an EEG has a personal characteristic. However, there are no researches to achieve the consideration of the personal characteristic. Then, the analyzed frequency components of the EEG have that the frequency components in which characteristics are contained significantly, and that not. Moreover, these combinations have the human equation. We think that these combinations are the personal characteristics frequency components of the EEG. In this paper, the EEG analysis method by using the GA, the FA and the NN is proposed. The GA is used for selecting the personal characteristics frequency components. The FA is used for extracting the characteristic data of the EEG. The NN is used for estimating extracted the characteristics data of the EEG. Finally, in order to show the effectiveness of the proposed method, EEG pattern was classified using computer simulations. The EEG pattern has 4 conditions, which are listening to rock music, Schmaltzy Japanese ballad music, healing music and classical music. The result, in the case of not using the personal characteristics frequency components, gave over 95% accuracy. This result of our experiment shows the effectiveness of the proposed method.",
    "abstract_processed": "often known eeg person characterist howev research achiev consider person characterist analyz frequenc compon eeg frequenc compon characterist contain significantli moreov combin human equat think combin person characterist frequenc compon eeg paper eeg analysi method use ga fa nn propos ga use select person characterist frequenc compon fa use extract characterist data eeg nn use estim extract characterist data eeg final order show effect propos method eeg pattern classifi use comput simul eeg pattern condit listen rock music schmaltzi japanes ballad music heal music classic music result case use person characterist frequenc compon gave accuraci result experi show effect propos method"
  },
  {
    "doc_id": "1222264",
    "abstract_original": "This paper describes electroencephalogram-based control of a mobile robot. The control purpose is to achieve direction control of a mobile robot only by electroencephalogram. We develop an algorithm for detecting direction thinking ('going left' or 'going right') and apply it to direction control of a mobile robot. The detecting algorithm is based on time-frequency domain analysis using continuous wavelet transformation. Our experimental results demonstrate the possibility of achieving direction control of a mobile robot only by electroencephalogram.",
    "abstract_processed": "paper describ electroencephalogram base control mobil robot control purpos achiev direct control mobil robot electroencephalogram develop algorithm detect direct think go left go right appli direct control mobil robot detect algorithm base time frequenc domain analysi use continu wavelet transform experiment result demonstr possibl achiev direct control mobil robot electroencephalogram"
  },
  {
    "doc_id": "1225947",
    "abstract_original": "The cognitive models of information representation and the capacity of human memory are fundamental research areas in cognitive informatics, which help to reveal the mechanism and potential of the brain. This paper develops the object-attribute-relation (OAR) model for describing information representation and storage in the brain. According to the OAR model, the human memory and knowledge are represented by relations, i.e. connections of synapses between neurons, rather than by the neurons themselves as the traditional container metaphor described. Based on the OAR model, the memory capacity of the human brain is calculated as in the order of 10/sup 8432/ bits. The determination of the magnitude of human memory capacity is not only theoretically significant in cognitive informatics, but also practically useful to estimate the human potential, as well as the gap between the natural and machine intelligence.",
    "abstract_processed": "cognit model inform represent capac human memori fundament research area cognit informat help reveal mechan potenti brain paper develop object attribut relat oar model describ inform represent storag brain accord oar model human memori knowledg repres relat e connect synaps neuron rather neuron tradit contain metaphor describ base oar model memori capac human brain calcul order sup bit determin magnitud human memori capac theoret signific cognit informat also practic use estim human potenti well gap natur machin intellig"
  },
  {
    "doc_id": "1225970",
    "abstract_original": "From a scientific perspective explaining how the brain thinks is a big goal. Cognitive informatics studies intelligent behavior from a computational point of view in terms of updated research efforts and processes of brain science and neuroscience. Cognitive informatics is the interdisciplinary study of cognition. Cognition includes mental states and processes, such as thinking, reasoning, remembering, language understanding and generation, visual and auditory perception, learning, consciousness, emotions, etc. In this paper we will point out basic research topics of learning, memory, thought, language, and neural computing which are active fields related to cognitive informatics.",
    "abstract_processed": "scientif perspect explain brain think big goal cognit informat studi intellig behavior comput point view term updat research effort process brain scienc neurosci cognit informat interdisciplinari studi cognit cognit includ mental state process think reason rememb languag understand gener visual auditori percept learn conscious emot etc paper point basic research topic learn memori thought languag neural comput activ field relat cognit informat"
  },
  {
    "doc_id": "1234824",
    "abstract_original": "Multi-agent system is one of the most popular research interests in robotics nowadays. How would collections of simple robots aid us in human endeavours? Let us think about an ant colony. Ants have little capability, but when many of them are working together, they can do incredible tasks. By examining the major control architectures available in robotics area, decentralized-based reactive control architecture gives the tools required. Priority-based scheme is used in arbitration level to select which behaviour to run. It does not need to gather all information from various sensors to plan its action like deliberative control, which is also known as sensors fusion that clearly required a lot of computational time. Besides that, the mapping that the deliberate control architecture produces might not be valid at the time when changes occur between the time it gathers the information and the time it plans its actions. Instead, intelligence will arise when these simple agents work together to perform some complex task cooperatively. Our multi-agent system consists of three mobile robots that are required to transfer a large object through a restricted area. We are using a leader follower strategy to accomplish this task. Intelligence in multi-agent system in our context is that any agents have a possibility to be a leader or a follower depending on current situation of the environment. This means that all agents are homogeneously equal in hardware and software. By having this capability, it will ensure the burden of the programming task will be decreased because there will be only one program needed for the whole system. In this paper, decentralized reactive control architecture is used to develop an intelligent multi-agent cooperative strategy to perform complex task like carrying a load and navigation.",
    "abstract_processed": "multi agent system one popular research interest robot nowaday would collect simpl robot aid us human endeavour let us think ant coloni ant littl capabl mani work togeth incred task examin major control architectur avail robot area decentr base reactiv control architectur give tool requir prioriti base scheme use arbitr level select behaviour run need gather inform variou sensor plan action like delib control also known sensor fusion clearli requir lot comput time besid map deliber control architectur produc might valid time chang occur time gather inform time plan action instead intellig aris simpl agent work togeth perform complex task cooper multi agent system consist three mobil robot requir transfer larg object restrict area use leader follow strategi accomplish task intellig multi agent system context agent possibl leader follow depend current situat environ mean agent homogen equal hardwar softwar capabl ensur burden program task decreas one program need whole system paper decentr reactiv control architectur use develop intellig multi agent cooper strategi perform complex task like carri load navig"
  },
  {
    "doc_id": "1237164",
    "abstract_original": "This paper presents a general problem-solving method combining the principles of artificial intelligence and evolutionary computation. The problem-solving method is based on the computer language GENETICA, which stands for \"Genetic Evolution of Novel Entities Through the Interpretation of Composite Abstractions.\" GENETICAs programming environment includes a computational system that evolves data abstractions, viewed as genotypes of data generation scenarios for a GENETICA program, with respect to either confirmation or optimization goals. A problem can be formulated as a GENETICA program, while the solution is represented as a data structure resulting from an evolved data generation scenario. This approach to problem solving offers: 1) generality, since it concerns virtually any problem stated in formal logic; 2) effectiveness, since formally expressed problem-solving knowledge can be incorporated in the problem statement; and 3) creativity, since unpredictable solutions can be obtained by evolved data structures. It is shown that domain specific languages, including genetic programming ones, that inherit GENETICAs features can be developed in GENETICA. The language G-CAD, specialized to problem solving in the domain of architectural design, is presented as a case study followed by experimental results.",
    "abstract_processed": "paper present gener problem solv method combin principl artifici intellig evolutionari comput problem solv method base comput languag genetica stand genet evolut novel entiti interpret composit abstract genetica program environ includ comput system evolv data abstract view genotyp data gener scenario genetica program respect either confirm optim goal problem formul genetica program solut repres data structur result evolv data gener scenario approach problem solv offer gener sinc concern virtual problem state formal logic effect sinc formal express problem solv knowledg incorpor problem statement creativ sinc unpredict solut obtain evolv data structur shown domain specif languag includ genet program one inherit genetica featur develop genetica languag g cad special problem solv domain architectur design present case studi follow experiment result"
  },
  {
    "doc_id": "1238685",
    "abstract_original": "Why would you need a security clearance to work? The answer is that, depending on where you want to work and the kind of work you want to do, you may, in fact, need one. Even a low-level, non-academic position at it university may require a security clearance if the work being done is defense related. Out in the \"real world\", the need to have a clearance is much more commonplace. This is because much government-funded research is dictated by military requirements. Therefore, it is a good idea to think about the potential impact on your job prospects of needing to qualify for a clearance as well as the effect of doing work that is classified on your career development. The paper discusses these two issues.",
    "abstract_processed": "would need secur clearanc work answer depend want work kind work want may fact need one even low level non academ posit univers may requir secur clearanc work done defens relat real world need clearanc much commonplac much govern fund research dictat militari requir therefor good idea think potenti impact job prospect need qualifi clearanc well effect work classifi career develop paper discuss two issu"
  },
  {
    "doc_id": "1241066",
    "abstract_original": "In standard situations, agents in a multi-agent community need to communicate each other to accomplish cooperation and coordination of joint activities. Normally it is expected that each agent can contact any other using a reliable communication infrastructure. Often one has to think about situations when a communication subsystem becomes disintegrated and some agents become isolated from the rest of the community. The paper provides basic analysis of such inaccessibility situations, and reviews possible technologies to remedy the resulting difficulties. The concepts of a so-called doubler agent and stand-in agent for maintaining agents accessibility is introduced. A brief discussion on suitability of the acquaintance models for maintaining accessibility on a symbolic level is also touched.",
    "abstract_processed": "standard situat agent multi agent commun need commun accomplish cooper coordin joint activ normal expect agent contact use reliabl commun infrastructur often one think situat commun subsystem becom disintegr agent becom isol rest commun paper provid basic analysi inaccess situat review possibl technolog remedi result difficulti concept call doubler agent stand agent maintain agent access introduc brief discuss suitabl acquaint model maintain access symbol level also touch"
  },
  {
    "doc_id": "1244258",
    "abstract_original": "The concept of concept is central to several mathematical fields dealing with the processing and interpretation of knowledge, such as Computational Learning Theory in Machine Learning or Formal Concept Analysis in Artificial Intelligence. It has however had much less of an impact on other related mathematical fields, amongst which Data Mining and Knowledge Discovery in Databases, for which the pattern rather than the concept seems to play the role of the basic unit of knowledge. In this paper we examine the potential role of cybernetical thinking in the formal analysis of concepts with relevance to learning and performance.",
    "abstract_processed": "concept concept central sever mathemat field deal process interpret knowledg comput learn theori machin learn formal concept analysi artifici intellig howev much less impact relat mathemat field amongst data mine knowledg discoveri databas pattern rather concept seem play role basic unit knowledg paper examin potenti role cybernet think formal analysi concept relev learn perform"
  },
  {
    "doc_id": "1244618",
    "abstract_original": "We introduce a genetic algorithm (GA)-based method for structural optimization of multiplicative general parameter (MGP) finite impulse response (FIR) filters. These computationally efficient reduced-rank adaptive filters are robust, suitable for predictive configurations, and they have numerous applications in 50/60 Hz power systems instrumentation. The design process of such filters has three independent stages: Lagrange multipliers-based optimization of the sinusoid-predictive basis filter, genetic algorithm-based search of optimal FIR tap cross-connections and, finally, the online MGP-adaptation phase guided by variations in signal statistics. Thus, our multi-stage design procedure is a complementary fusion of hard computing (HC) and soft computing (SC) methodologies. Such advantageous fusion (or symbiosis) thinking is emerging among researchers and practicing engineers, and it can potentially lead to competitive combinations of individual HC and SC methods.",
    "abstract_processed": "introduc genet algorithm ga base method structur optim multipl gener paramet mgp finit impuls respons fir filter comput effici reduc rank adapt filter robust suitabl predict configur numer applic hz power system instrument design process filter three independ stage lagrang multipli base optim sinusoid predict basi filter genet algorithm base search optim fir tap cross connect final onlin mgp adapt phase guid variat signal statist thu multi stage design procedur complementari fusion hard comput hc soft comput sc methodolog advantag fusion symbiosi think emerg among research practic engin potenti lead competit combin individu hc sc method"
  },
  {
    "doc_id": "1244654",
    "abstract_original": "Human cognition stems from his identifying the relationship or relative distance between himself and any other objects or persons, for which prerequisite is establishing his 'self'. In other words, it is presumable that the potential of intelligent machine's establishing its 'self' would require us to engineer its sense of 'ego' and 'intention', which involves such factors as 'emotions', 'instincts', and 'sensibilities'. This dissertation introduces the psycho-quantum theory which illustrates the human psychodynamics by the quantum mechanics approach, and its application for constructing the distribution model of emotional modalities and the autonomous system, the essential elements for creating an ego in a computer. We have attempted to create the artificial 'ego' and 'desire' based on our probability model and state transition analysis, then accordingly developed our methodology of the artificial thought process as well as the judging mechanism of such computer. Furthermore, this dissertation introduces the sensibility inference function of our psycho-quantum computer, by which we discuss our methods to itemize 126 emotional modalities of human, construct the three-dimensional dynamic model of emotions, and analyze the emotion distribution and its longitudinal modal transition so as to derive the artificial instinct and to determine/infer its relationship with external factors. Currently, our technology to construct the comprehensive psycho-quantum computer is yet in developmental stage; however, its potential is enormous so that it will constitute a key technology in new robotics industry.",
    "abstract_processed": "human cognit stem identifi relationship rel distanc object person prerequisit establish self word presum potenti intellig machin establish self would requir us engin sens ego intent involv factor emot instinct sensibl dissert introduc psycho quantum theori illustr human psychodynam quantum mechan approach applic construct distribut model emot modal autonom system essenti element creat ego comput attempt creat artifici ego desir base probabl model state transit analysi accordingli develop methodolog artifici thought process well judg mechan comput furthermor dissert introduc sensibl infer function psycho quantum comput discuss method item emot modal human construct three dimension dynam model emot analyz emot distribut longitudin modal transit deriv artifici instinct determin infer relationship extern factor current technolog construct comprehens psycho quantum comput yet development stage howev potenti enorm constitut key technolog new robot industri"
  },
  {
    "doc_id": "1245062",
    "abstract_original": "We are developing algorithms for computational contextual vocabulary acquisition (CVA; computing a meaning for an unknown word from context) and applying the computational CVA system to build an educational curriculum for enhancing students' abilities to use CVA strategies in their reading. The knowledge gained from case studies of students using our CVA techniques feeds back into further development of our computational theory.",
    "abstract_processed": "develop algorithm comput contextu vocabulari acquisit cva comput mean unknown word context appli comput cva system build educ curriculum enhanc student abil use cva strategi read knowledg gain case studi student use cva techniqu feed back develop comput theori"
  },
  {
    "doc_id": "1245122",
    "abstract_original": "Global networking is changing the way that we think about and perform computation. Network-based computing may link tens or hundreds of distributed devices, sensors and computing resources to support an application. Therefore, a critical challenge is how dynamically to discover and integrate these distributed services seamlessly for various applications. In this paper, many cutting-edge technologies including semantic Web, Web services, peer-to-peer network and content-based routing, are used to address this challenge. With these technologies, we propose a new framework for dynamic integration of distributed services. Moreover, a prototype system with basic capabilities is implemented as a proof-of-concept to demonstrate the potential of this framework and its constituent technologies in network-based computing.",
    "abstract_processed": "global network chang way think perform comput network base comput may link ten hundr distribut devic sensor comput resourc support applic therefor critic challeng dynam discov integr distribut servic seamlessli variou applic paper mani cut edg technolog includ semant web web servic peer peer network content base rout use address challeng technolog propos new framework dynam integr distribut servic moreov prototyp system basic capabl implement proof concept demonstr potenti framework constitu technolog network base comput"
  },
  {
    "doc_id": "1245525",
    "abstract_original": "The purpose of this paper is to contemplate the birth of two related disciplines - digital media and dynamic media - by reflecting on fifteen years of experience at the University of Central Florida. During this interval, several research and creative initiatives converged, leading to today's School of Film and Digital Media with 25 faculties and nearly 1000 students.",
    "abstract_processed": "purpos paper contempl birth two relat disciplin digit media dynam media reflect fifteen year experi univers central florida interv sever research creativ initi converg lead today school film digit media faculti nearli student"
  },
  {
    "doc_id": "1251408",
    "abstract_original": "Progress in AI (artificial intelligence) is bottlenecked by contemporary thinking. Soft computing methodologies recognize the fundamental role of imprecision in any computational intelligence. This paper goes one step further in that it recognizes the fundamental need for heuristics - both as a generalization of numeric imprecision according to S.H. Rubin (1999) and, as a consequence, of Godel's Incompleteness Theorem by V.A. Uspenskii (1987). Heuristic ontologies were compared with logical ontologies and shown to be advantageous for the realization of intelligent computation. It was also noted how the mechanics of evolutionary biology and that presupposed for thought can be computationally equivalent. In particular, randomness and symmetry by G.J. Chaitin (1975) are shown to underpin computational evolution by providing for heuristic discovery, knowledge transference and creative computation. The capability for the transference of heuristic knowledge was evidenced to be fundamental to the evolution of what M. Minsky (1987) has termed, \"a society of mind\". The need for transformational representations of this knowledge was demonstrated by S. Amarel (1968). A modeling language, designed to exploit domain symmetries, was characterized for the game of Tic-Tac-Toe. Applications to UAVs and intelligent agents - among a plethora of others - will follow. In conclusion, Marvin Minsky argues that many AI researchers seem to have lost their way in recent years and should be investigating core problems such as how a person reasons according to C.T. Clark. It is hoped that this paper will sow the seeds for a proper response to Minsky's admonition by inciting a restoration in the type of creative thinking that attracted many AI researchers into the field in the first place.",
    "abstract_processed": "progress ai artifici intellig bottleneck contemporari think soft comput methodolog recogn fundament role imprecis comput intellig paper goe one step recogn fundament need heurist gener numer imprecis accord h rubin consequ godel incomplet theorem v uspenskii heurist ontolog compar logic ontolog shown advantag realiz intellig comput also note mechan evolutionari biolog presuppos thought comput equival particular random symmetri g j chaitin shown underpin comput evolut provid heurist discoveri knowledg transfer creativ comput capabl transfer heurist knowledg evidenc fundament evolut minski term societi mind need transform represent knowledg demonstr amarel model languag design exploit domain symmetri character game tic tac toe applic uav intellig agent among plethora other follow conclus marvin minski argu mani ai research seem lost way recent year investig core problem person reason accord c clark hope paper sow seed proper respons minski admonit incit restor type creativ think attract mani ai research field first place"
  },
  {
    "doc_id": "1254768",
    "abstract_original": "The human control thought process, including iconic imagery inference control thinking and abstract logical inference control thinking , could be mostly simulated by computer. The model of human-like intelligent inference and control was presented in a previous paper (Peijin Wang, 2001). In this paper based on the single input single output system, a real structure of the model which finds an application in the practical control system is pointed out and analyzed .The features of the controller structure are intelligence, implementation and stability. A better result is achieved by the controller, it provide the basis for human-like intelligent control to be used in complex system.",
    "abstract_processed": "human control thought process includ icon imageri infer control think abstract logic infer control think could mostli simul comput model human like intellig infer control present previou paper peijin wang paper base singl input singl output system real structur model find applic practic control system point analyz featur control structur intellig implement stabil better result achiev control provid basi human like intellig control use complex system"
  },
  {
    "doc_id": "1255422",
    "abstract_original": "In our opinion, there are two main concerns in Roubos and Babugka's note, that are summarized as follows. 1) The kinds of problems used in our paper to test the algorithm proposed in \"A proposal to improve the accuracy of linguistic modeling\" and other studies. The authors claim that they are very simple to be considered as benchmarks for nonlinear modeling techniques. 2) The interpretability of the different kinds of models considered. Roubos and Babuska think that there is no difference between the interpretability of fuzzy linguistic models, Takagi-Sugeno-Kang (TSK) fuzzy models, and mathematical formulations (linear models, in this case). We agree with some of the opinions of the authors of the note but not with some others.",
    "abstract_processed": "opinion two main concern roubo babugka note summar follow kind problem use paper test algorithm propos propos improv accuraci linguist model studi author claim simpl consid benchmark nonlinear model techniqu interpret differ kind model consid roubo babuska think differ interpret fuzzi linguist model takagi sugeno kang tsk fuzzi model mathemat formul linear model case agre opinion author note other"
  },
  {
    "doc_id": "1257862",
    "abstract_original": "Heuristics are widely used for solving computational intractable synthesis problems. However, until now, there has been limited effort to systematically develop heuristics that can be applied to a variety of synthesis tasks. We focus on development of general optimization principles so that they can be applied to a wide range of synthesis problems. In particular, we propose a new way to realize the most constraining principle where at each step we gradually relax the constraints on the most constrained elements of the solution. This basic optimization mechanism is augmented with several new heuristic principles: minimal freedom reduction, negative thinking, calibration, simultaneous step consideration, and probabilistic modeling. We have successfully applied these optimization principles to a number of common behavioral synthesis tasks. Specifically, we demonstrate a systematic way to develop optimization algorithms for maximum independent set, time-constrained scheduling, and soft real-time system scheduling. The effectiveness of the approach and algorithms is validated on extensive real-life benchmarks.",
    "abstract_processed": "heurist wide use solv comput intract synthesi problem howev limit effort systemat develop heurist appli varieti synthesi task focu develop gener optim principl appli wide rang synthesi problem particular propos new way realiz constrain principl step gradual relax constraint constrain element solut basic optim mechan augment sever new heurist principl minim freedom reduct neg think calibr simultan step consider probabilist model success appli optim principl number common behavior synthesi task specif demonstr systemat way develop optim algorithm maximum independ set time constrain schedul soft real time system schedul effect approach algorithm valid extens real life benchmark"
  },
  {
    "doc_id": "1261500",
    "abstract_original": "Simulations are used extensively for studying artificial intelligence. However, the simulation technology in use by and designed for the artificial intelligence community often fails to take advantage of much of the work by the larger simulation community to produce distributed, repeatable, and efficient simulations. We present the system for parallel agent discrete event simulation, (SPADES), which is a simulation environment for the artificial intelligence community. SPADES focuses on the agent as a fundamental simulation component. The thinking time of an agent is tracked and reflected in the results of the agents' actions by using a software-in-the-loop mechanism. SPADES supports distributed execution of the agents across multiple systems, while at the same time producing repeatable results regardless of network or system load. We discuss the design of SPADES and give experimental results. SPADES is flexible enough for a variety of application domains in the artificial intelligence research community.",
    "abstract_processed": "simul use extens studi artifici intellig howev simul technolog use design artifici intellig commun often fail take advantag much work larger simul commun produc distribut repeat effici simul present system parallel agent discret event simul spade simul environ artifici intellig commun spade focus agent fundament simul compon think time agent track reflect result agent action use softwar loop mechan spade support distribut execut agent across multipl system time produc repeat result regardless network system load discuss design spade give experiment result spade flexibl enough varieti applic domain artifici intellig research commun"
  },
  {
    "doc_id": "1261661",
    "abstract_original": "Simulation projects provide a useful way to tie together the expected learning outcomes in a simulation class. Designing a good project is a challenging task and simulation instructors are always on the lookout for interesting ideas. We provide simulation instructors with two interesting simulation applications, a supply chain project and a Web site design project. The supply chain problem is based on a real company problem and the Web site design problem is based on a textbook problem. Each application is described in detail and links are provided so that other simulation instructors can access handouts and possible solutions. The authors also provide some insights about simulation project design.",
    "abstract_processed": "simul project provid use way tie togeth expect learn outcom simul class design good project challeng task simul instructor alway lookout interest idea provid simul instructor two interest simul applic suppli chain project web site design project suppli chain problem base real compani problem web site design problem base textbook problem applic describ detail link provid simul instructor access handout possibl solut author also provid insight simul project design"
  },
  {
    "doc_id": "1261662",
    "abstract_original": "We present a critique of the current teaching practices of simulation. We challenge the current view of simulation, to the extent that most textbooks' contents will be found to be secondary to the missing necessary primary material. We advocate that (simulation) education has four general objectives, which are to teach students how to learn, how to think creatively, how to problem solve, and how to be professionals. These four objectives of education may not be possible to teach. In the words of Oscar Wilde, \"Education is an admirable thing, but it is well to remember from time to time that nothing that is worth knowing can be taught\". So an education in simulation requires that students be put into learning situations that enable them to learn the requisite knowledge concerning the four objectives.",
    "abstract_processed": "present critiqu current teach practic simul challeng current view simul extent textbook content found secondari miss necessari primari materi advoc simul educ four gener object teach student learn think creativ problem solv profession four object educ may possibl teach word oscar wild educ admir thing well rememb time time noth worth know taught educ simul requir student put learn situat enabl learn requisit knowledg concern four object"
  },
  {
    "doc_id": "1262477",
    "abstract_original": "This paper introduces a new /spl epsiv/-insensitive fuzzy c-regression models (/spl epsiv/FCRM), that can be used in fuzzy modeling. To fit these regression models to real data, a weighted /spl epsiv/-insensitive loss function is used. The proposed method make it possible to exclude an intrinsic inconsistency of fuzzy modeling, where crisp loss function (usually quadratic) is used to match real data and the fuzzy model. The /spl epsiv/-insensitive fuzzy modeling is based on human thinking and learning. This method allows easy control of generalization ability and outliers robustness. This approach leads to c simultaneous quadratic programming problems with bound constraints and one linear equality constraint. To solve this problem, computationally efficient numerical method, called incremental learning, is proposed. Finally, examples are given to demonstrate the validity of introduced approach to fuzzy modeling.",
    "abstract_processed": "paper introduc new spl epsiv insensit fuzzi c regress model spl epsiv fcrm use fuzzi model fit regress model real data weight spl epsiv insensit loss function use propos method make possibl exclud intrins inconsist fuzzi model crisp loss function usual quadrat use match real data fuzzi model spl epsiv insensit fuzzi model base human think learn method allow easi control gener abil outlier robust approach lead c simultan quadrat program problem bound constraint one linear equal constraint solv problem comput effici numer method call increment learn propos final exampl given demonstr valid introduc approach fuzzi model"
  },
  {
    "doc_id": "1263408",
    "abstract_original": "This article constitutes an effort to gain insights into the nature of creativity and its mechanisms leading to creative solutions to problems. This article claims that reflection constitutes the underlying mechanism, serving as a catalyst for creativity. A total of five experiments is presented, incurred in industrial and academic research environments and pedagogical settings, that demonstrate the occurrence of creativity, deliberately triggered by reflection. The key contribution of this article is that, although the exact definition of creativity continues to elude us, two mechanisms have been uncovered that are potentially useful in triggering creativity, at will, in ordinary scientific and engineering personnel to achieve quantum leaps in our knowledge and achievement. Reflection plays a key, catalytic role in both of these mechanisms and also appears to underlie the inner workings of Nature.",
    "abstract_processed": "articl constitut effort gain insight natur creativ mechan lead creativ solut problem articl claim reflect constitut underli mechan serv catalyst creativ total five experi present incur industri academ research environ pedagog set demonstr occurr creativ deliber trigger reflect key contribut articl although exact definit creativ continu elud us two mechan uncov potenti use trigger creativ ordinari scientif engin personnel achiev quantum leap knowledg achiev reflect play key catalyt role mechan also appear underli inner work natur"
  },
  {
    "doc_id": "1263434",
    "abstract_original": "To help evaluate the supercomputers, the authors selected a computational neuroscience simulation program that has a bandwidth requirement in excess of 1.5 Gb/s. The simulation runs on the Thinking Machines CM-2 and the target visualization engine is the Convex C3880. The authors benchmarked the various operations required to transmit data from the CM-2 to the Convex C3880. The results show that the parallel to serial data transformation operation on the CM-2 and the network interfaces are the major bottlenecks.",
    "abstract_processed": "help evalu supercomput author select comput neurosci simul program bandwidth requir excess gb simul run think machin cm target visual engin convex c author benchmark variou oper requir transmit data cm convex c result show parallel serial data transform oper cm network interfac major bottleneck"
  },
  {
    "doc_id": "1264545",
    "abstract_original": "The human control thought process, including iconic imagery inference control thinking and abstract logical inference control thinking, could be mostly simulated by computer. The model of human-like intelligent inference and control is presented in the previous paper. In this paper based on the single input and single output system, a real structure of the model which finds an application in the practical control system is pointed out and analyzed .The features of the controller structure are intelligence, implementation and stability. A better result is achieved by the controller, and it provides the basis for human-like intelligent control to be used in complex system.",
    "abstract_processed": "human control thought process includ icon imageri infer control think abstract logic infer control think could mostli simul comput model human like intellig infer control present previou paper paper base singl input singl output system real structur model find applic practic control system point analyz featur control structur intellig implement stabil better result achiev control provid basi human like intellig control use complex system"
  },
  {
    "doc_id": "1265259",
    "abstract_original": "As the skills that constitute literacy evolve to accommodate digital media, computer science education finds itself in a sorry state. While students are more in need of computational skills than ever, computer science suffers dramatically low retention rates and a declining percentage of women and minorities. Studies of the problem point to the overemphasis in computer science classes on abstraction over application, technical details instead of usability, and the stereotypical view of programmers as loners lacking creativity. In spring 2003, Georgia Institute of Technology trialed a new course, Introduction to Media Computation, which teaches programming and computation in the context of media creation and manipulation. Students implement PhotoShop-style filters and digital video special effects, splice sounds, and search Web pages. The course is open only to noncomputer science and nonengineering majors at Georgia Tech, such as liberal arts, management and architecture students. The course is supported through the use of a Web-based collaboration environment where students actively share and discuss their digital creations. The results have been dramatic. 120 students enrolled, 2/3 female, and only three students withdrew. By the end of the semester, the combined withdrawal, failure and D-grade rate had reached 11.5% - compared to 42.9% in the traditional introductory computer science course. 60% of the students who took media computation reported that they would be interested in taking an advanced version of the course; only 6% reported that they would otherwise be interested in taking more computer science. Results of the trial indicate that media computation motivates and engages an audience that is poorly served by traditional computer science courses.",
    "abstract_processed": "skill constitut literaci evolv accommod digit media comput scienc educ find sorri state student need comput skill ever comput scienc suffer dramat low retent rate declin percentag women minor studi problem point overemphasi comput scienc class abstract applic technic detail instead usabl stereotyp view programm loner lack creativ spring georgia institut technolog trial new cours introduct media comput teach program comput context media creation manipul student implement photoshop style filter digit video special effect splice sound search web page cours open noncomput scienc nonengin major georgia tech liber art manag architectur student cours support use web base collabor environ student activ share discuss digit creation result dramat student enrol femal three student withdrew end semest combin withdraw failur grade rate reach compar tradit introductori comput scienc cours student took media comput report would interest take advanc version cours report would otherwis interest take comput scienc result trial indic media comput motiv engag audienc poorli serv tradit comput scienc cours"
  },
  {
    "doc_id": "1272420",
    "abstract_original": "Think of a digital simulation as a computational device for which one must allocate three computational resources for computing: (a) the given inputs, (b) the outputs and (c) each state variable in the dynamics. This paper assigns these computational resources to guarantee a specified bound on response errors. We define the economical simulation problem (ESP) as designing the simulation of a stable linear system and distributing computational resources (wordlength) among the digital devices such that the computational cost (memory) is minimized without violating the required simulation accuracy. This problem is generally not convex because of the scaling constraint. By exploring the special structure of this joint optimization of the choice of the realizations and the computational resources to be applied, and under a scaling assumption, the ESP is converted to a convex problem. Numerical results are given which compare this method with existing approaches.",
    "abstract_processed": "think digit simul comput devic one must alloc three comput resourc comput given input b output c state variabl dynam paper assign comput resourc guarante specifi bound respons error defin econom simul problem esp design simul stabl linear system distribut comput resourc wordlength among digit devic comput cost memori minim without violat requir simul accuraci problem gener convex scale constraint explor special structur joint optim choic realiz comput resourc appli scale assumpt esp convert convex problem numer result given compar method exist approach"
  },
  {
    "doc_id": "1285606",
    "abstract_original": "The basic disciplinary frame of the intelligence science has been proposed, the general features of the research objects of the intelligence science have been summarized, the relationships among the industrialization, informatization, intellectualization and automation have been investigated in this paper. The intelligence science consists of three portions: scientific foundation, technical methodology and application fields. The general features of intelligence science include complexity, intersection, nonlinearity, anthropomorphic property, uncertainty, incompleteness and distribution etc. The industrialization has been advanced in the direction: primary industrialization /spl rarr/ automatic industrialization /spl rarr/ information industrialization /spl rarr/ intelligent industrialization. The proposed new scientific discipline would reflect the new height, new thought and new way for developing the control and automation science from one angle of view, and present a strong wish for establishing the new discipline of intelligence science.",
    "abstract_processed": "basic disciplinari frame intellig scienc propos gener featur research object intellig scienc summar relationship among industri informat intellectu autom investig paper intellig scienc consist three portion scientif foundat technic methodolog applic field gener featur intellig scienc includ complex intersect nonlinear anthropomorph properti uncertainti incomplet distribut etc industri advanc direct primari industri spl rarr automat industri spl rarr inform industri spl rarr intellig industri propos new scientif disciplin would reflect new height new thought new way develop control autom scienc one angl view present strong wish establish new disciplin intellig scienc"
  },
  {
    "doc_id": "1285750",
    "abstract_original": "Joint behaviors widely existing in intelligent systems are important to investigate the cooperation among intelligent agents. In this paper, we put forward a comprehensive and novel model of joint behaviors in support of analysis and design of intelligent systems. The model includes two kinds of joint behaviors, their formal semantics are defined, and important properties are discussed, specified and proved.",
    "abstract_processed": "joint behavior wide exist intellig system import investig cooper among intellig agent paper put forward comprehens novel model joint behavior support analysi design intellig system model includ two kind joint behavior formal semant defin import properti discuss specifi prove"
  },
  {
    "doc_id": "1287907",
    "abstract_original": "Many computer architecture and organization instructors are turning to simulators with visualization as teaching aids. Many simulators have already been developed and made freely available on the Internet. It is beneficial to document and organize these simulators to all instructors of computer architecture and organization courses to take full advantage of this time-saving resource conveniently. This paper describes and analyzes three cache memory simulators. These cache memory simulators can be used with the popular computer architecture and organization textbooks. Our document of these cache memory simulators and comparative evaluation of their usability may provide computer architecture instructors with insight in selecting appropriate cache memory simulators to satisfy their pedagogical needs.",
    "abstract_processed": "mani comput architectur organ instructor turn simul visual teach aid mani simul alreadi develop made freeli avail internet benefici document organ simul instructor comput architectur organ cours take full advantag time save resourc conveni paper describ analyz three cach memori simul cach memori simul use popular comput architectur organ textbook document cach memori simul compar evalu usabl may provid comput architectur instructor insight select appropri cach memori simul satisfi pedagog need"
  },
  {
    "doc_id": "1289316",
    "abstract_original": "Several physics processes modify the state of a scientific simulation over time. In fact, researchers often divide a simulation's development into areas - called packages - according to physics specialization. In this article, we use the word \"package\" primarily to mean a portion of scientific software whose components communicate internally much more than they do with outside routines, but packages can take the form of third-party libraries for common mathematical or computer science functions. Most parts of a simulation refer to the \"infrastructure\" portion of the state, so we can think of this portion as a package with lots of customers. How we share data within and between these packages is crucial to developer productivity. In this installment of Scientific Programming, we explore some of the pros and cons of the different ways to share data in C++ code.",
    "abstract_processed": "sever physic process modifi state scientif simul time fact research often divid simul develop area call packag accord physic special articl use word packag primarili mean portion scientif softwar whose compon commun intern much outsid routin packag take form third parti librari common mathemat comput scienc function part simul refer infrastructur portion state think portion packag lot custom share data within packag crucial develop product instal scientif program explor pro con differ way share data c code"
  },
  {
    "doc_id": "1289321",
    "abstract_original": "Summary form only given. We are at a novel crossroads in technology where we are witnessing the confluence of computing, communicating and networking. A number of exciting applications are both driving and being driven by this confluence, including low-power sensor networks, large-scale ad hoc wireless networks, and wireless multimedia transmission. Many of these applications demand a move away from classical centralized architectures and algorithms towards more decentralized and distributed ones. Signal processing plays a key role in this revolution- not in isolation but rather as a pivotal interdisciplinary systems component, intimately integrated with communications, information theory, coding theory, and networking protocols. Sensor networks represent a particularly rich applications base. We would provide a snapshot of the sensor network related activities in a number of research groups at Berkeley. Motivated by the communications and computational constraints imposed by large-scale low-power sensor networks, we would describe some of our signal processing centric research including: (i) distributed sampling; (ii) distributed source coding; (iii) distributed estimation; and (iv) robust transmission. We would highlight the key foundational role played by multi-user information theory, particularly the so-called area of side-information coding for both source coding (compression) and channel coding (transmission). A deeper look reveals a beautiful functional duality between source and channel coding with side-information. This unexpectedly unifies a host of seemingly unrelated problem areas like distributed compression, digital watermarking, multimedia transmission over packet-error networks, and seamless digital upgrade of analog TV. Finally, as a microcosm of the expressive power of interdisciplinary thinking, we would describe a novel video compression paradigm dubbed PRISM (power-efficient, robust, hlh-compression, syndrome-based multimedia coding). PRISM's architecture, in stark contrast to that driving current video codecs like MPEG, allows for a novel shifting of the computational complexity from the encoder to the decoder, making it ideally suited for \"uplink\" transmission scenarios in wireless multimedia and surveillance applications.",
    "abstract_processed": "summari form given novel crossroad technolog wit confluenc comput commun network number excit applic drive driven confluenc includ low power sensor network larg scale ad hoc wireless network wireless multimedia transmiss mani applic demand move away classic central architectur algorithm toward decentr distribut one signal process play key role revolut isol rather pivot interdisciplinari system compon intim integr commun inform theori code theori network protocol sensor network repres particularli rich applic base would provid snapshot sensor network relat activ number research group berkeley motiv commun comput constraint impos larg scale low power sensor network would describ signal process centric research includ distribut sampl ii distribut sourc code iii distribut estim iv robust transmiss would highlight key foundat role play multi user inform theori particularli call area side inform code sourc code compress channel code transmiss deeper look reveal beauti function dualiti sourc channel code side inform unexpectedli unifi host seemingli unrel problem area like distribut compress digit watermark multimedia transmiss packet error network seamless digit upgrad analog tv final microcosm express power interdisciplinari think would describ novel video compress paradigm dub prism power effici robust hlh compress syndrom base multimedia code prism architectur stark contrast drive current video codec like mpeg allow novel shift comput complex encod decod make ideal suit uplink transmiss scenario wireless multimedia surveil applic"
  },
  {
    "doc_id": "129520",
    "abstract_original": "The role of real-time man-in-the-loop simulation across the entire life cycle of a weapon system is examined. Novel aspects of the concept include the potential for the selective use of the developer's engineering simulator during operational test and evaluation as well as the merits of a tightly coupled approach to the design of the engineering simulator and that of related training devices/simulators. Attention is given to the model which is emerging at the helicopter component of McDonnell Douglas and its relationship to some advanced thinking about a US Army preliminary master plan for simulation. The author draws some parallels between the approach as implemented by the 'prime' and the approach as it might be implemented between different Government laboratories in the context of the draft master plan. The author examines a particular aspect of this application, the simulation of the operational mission environment and where that responsibility might best lie. The issue of 'fidelity' is discussed with respect to current simulation technology limitations and their known effects upon performance.<>",
    "abstract_processed": "role real time man loop simul across entir life cycl weapon system examin novel aspect concept includ potenti select use develop engin simul oper test evalu well merit tightli coupl approach design engin simul relat train devic simul attent given model emerg helicopt compon mcdonnel dougla relationship advanc think us armi preliminari master plan simul author draw parallel approach implement prime approach might implement differ govern laboratori context draft master plan author examin particular aspect applic simul oper mission environ respons might best lie issu fidel discuss respect current simul technolog limit known effect upon perform"
  },
  {
    "doc_id": "1297253",
    "abstract_original": "We need mobile supercomputers that provide massive computational performance from the power in a battery. These supercomputers will make our personal devices much easier to use. They will perform real-time speech recognition, video transmission and analysis, and high bandwidth communication. And they will do so without us having to worry about where the next electrical outlet will be. But to achieve this functionality, we must rethink the way we design computers. Rather than worrying solely about performance, with the occasional nod to power consumption and cost, we need to judge computers by their performance-power-cost product. This new way of looking at processors will lead us to new computer architectures and new ways of thinking about computer system design.",
    "abstract_processed": "need mobil supercomput provid massiv comput perform power batteri supercomput make person devic much easier use perform real time speech recognit video transmiss analysi high bandwidth commun without us worri next electr outlet achiev function must rethink way design comput rather worri sole perform occasion nod power consumpt cost need judg comput perform power cost product new way look processor lead us new comput architectur new way think comput system design"
  },
  {
    "doc_id": "1314515",
    "abstract_original": "This work presents the design and implementation of an interactive free-form 3D sketching paradigm to support creative designs. This work builds on advances in a large number of related technologies such as multi-screen displays, constraint-based assembly modelling, deformable modelling and state-of-the-art multi-sensory interfaces. This work presents the current design and implementation features of the proposed design paradigm.",
    "abstract_processed": "work present design implement interact free form sketch paradigm support creativ design work build advanc larg number relat technolog multi screen display constraint base assembl model deform model state art multi sensori interfac work present current design implement featur propos design paradigm"
  },
  {
    "doc_id": "1318942",
    "abstract_original": "In our software-defined radio project, we aim at combining two standards luetooth and HIPERLAN/2. The HIPERLAN/2 receiver requires more computational power than Bluetooth. We choose to use this computational power also for Bluetooth and look for more advanced demodulation algorithms such as a maximum a posteriori probability (MAP) receiver. The paper discusses a simplified MAP receiver for Bluetooth GFSK signals. Laurent decomposition provides an orthogonal vector space for the MAP receiver. As the first Laurent waveform contains the most energy, we have used only this waveform for our (simplified) MAP receiver. This receiver requires a E/sub b//N/sub 0/ of about 11 dB for a BER of 10/sup -3/, required by the Bluetooth standard. This value is about 6 dB better than single bit demodulators. This performance is only met if the receiver has exact knowledge of the modulation index.",
    "abstract_processed": "softwar defin radio project aim combin two standard luetooth hiperlan hiperlan receiv requir comput power bluetooth choos use comput power also bluetooth look advanc demodul algorithm maximum posteriori probabl map receiv paper discuss simplifi map receiv bluetooth gfsk signal laurent decomposit provid orthogon vector space map receiv first laurent waveform contain energi use waveform simplifi map receiv receiv requir e sub b n sub db ber sup requir bluetooth standard valu db better singl bit demodul perform met receiv exact knowledg modul index"
  },
  {
    "doc_id": "1323421",
    "abstract_original": "The anticipatory timing control in sensory-motor coupling is indispensable to generate coordinative movement among humans, however its cognitive mechanism still remains obscure. In this study we used synchronization tapping task as a model system, and negative asynchrony phenomenon where the tap onset precedes the stimulus onset was analyzed as an example of the anticipation. Especially, applying dual task method, the relationship between the anticipation mechanism and the higher brain function such as attention and working memory was investigated. The results revealed two types of anticipatory timing control. In the inter stimulus-onset interval (ISI) range of 450 to 1800 ms, automatic anticipation that is not affected by attentional resources was observed and was based on feed forward dynamics. In the 2400 to 3600 ms range, the anticipation showed trade-off relationship in the allocation of attentional resources. Magnitude of synchronization error (SE) between tap onset and stimulus onset in this region was scaled by the ISI and the feed back dynamics concerning ISI was suggested. Accordingly, anticipation in timing control was shown to be a dual processing between the attentional process and the embodied automatic process.",
    "abstract_processed": "anticipatori time control sensori motor coupl indispens gener coordin movement among human howev cognit mechan still remain obscur studi use synchron tap task model system neg asynchroni phenomenon tap onset preced stimulu onset analyz exampl anticip especi appli dual task method relationship anticip mechan higher brain function attent work memori investig result reveal two type anticipatori time control inter stimulu onset interv isi rang ms automat anticip affect attent resourc observ base feed forward dynam ms rang anticip show trade relationship alloc attent resourc magnitud synchron error se tap onset stimulu onset region scale isi feed back dynam concern isi suggest accordingli anticip time control shown dual process attent process embodi automat process"
  },
  {
    "doc_id": "1342108",
    "abstract_original": "How to use various kinds of intelligent technology to find an optimal product design scheme is very important in today's highly competitive marketplace. Based on the analyzing and summarizing of current intelligent design methods, an optimization design system with hybrid intelligence, which integrates human intelligence with machine intelligence was explored. Intelligent tools such as genetic algorithm (GA) and case-based reasoning (CBR), were used to find a feasible and optimal solution quickly in a large design space. The way to combine the designer's intelligence during the whole automatic optimization searching process was described. The optimization design system not only integrates the intelligence of design examples, experts, designers and computer, but also supports the designers to utilize all the knowledge resources to design. Finally, a case study is used to specify the implementation procedure of this method.",
    "abstract_processed": "use variou kind intellig technolog find optim product design scheme import today highli competit marketplac base analyz summar current intellig design method optim design system hybrid intellig integr human intellig machin intellig explor intellig tool genet algorithm ga case base reason cbr use find feasibl optim solut quickli larg design space way combin design intellig whole automat optim search process describ optim design system integr intellig design exampl expert design comput also support design util knowledg resourc design final case studi use specifi implement procedur method"
  },
  {
    "doc_id": "1342537",
    "abstract_original": "Many advances in automatic parallelization and optimization have been achieved through the polyhedral model. It has been extensively shown that this computational model provides convenient abstractions to reason about and apply program transformations. Nevertheless, the complexity of code generation has long been a deterrent for using polyhedral representation in optimizing compilers. First, code generators have a hard time coping with generated code size and control overhead that may spoil theoretical benefits achieved by the transformations. Second, this step is usually time consuming, hampering the integration of the polyhedral framework in production compilers or feedback-directed, iterative optimization schemes. Moreover, current code generation algorithms only cover a restrictive set of possible transformation functions. This paper discusses a general transformation framework able to deal with nonunimodular, noninvertible, nonintegral or even nonuniform functions. It presents several improvements to a state-of-the-art code generation algorithm. Two directions are explored: generated code size and code generator efficiency. Experimental evidence proves the ability of the improved method to handle real-life problems.",
    "abstract_processed": "mani advanc automat parallel optim achiev polyhedr model extens shown comput model provid conveni abstract reason appli program transform nevertheless complex code gener long deterr use polyhedr represent optim compil first code gener hard time cope gener code size control overhead may spoil theoret benefit achiev transform second step usual time consum hamper integr polyhedr framework product compil feedback direct iter optim scheme moreov current code gener algorithm cover restrict set possibl transform function paper discuss gener transform framework abl deal nonunimodular noninvert nonintegr even nonuniform function present sever improv state art code gener algorithm two direct explor gener code size code gener effici experiment evid prove abil improv method handl real life problem"
  },
  {
    "doc_id": "1343114",
    "abstract_original": "In order to simulate creative design thinking of human being and then improve those product design methods commonly used, a model of creative thinking consisting of alternant emanative and converging thinking was put forth. These shortages in case-based reasoning (CBR) and genetic algorithms (GA) were analyzed by the model. It was proved that the fundamental reason of these shortages is that they only can simulate a single process in the model of creative thinking. Then a simulation algorithm of directed similarity association is brought forward so as to realize the computation of similarity degree of product demand between components, and simulate the whole model of creative thinking by combining CBR and GA. A corresponding product design system was put forward, and then an experiment was conducted, and the results show that the combined intelligent algorithm has good performance in search.",
    "abstract_processed": "order simul creativ design think human improv product design method commonli use model creativ think consist altern eman converg think put forth shortag case base reason cbr genet algorithm ga analyz model prove fundament reason shortag simul singl process model creativ think simul algorithm direct similar associ brought forward realiz comput similar degre product demand compon simul whole model creativ think combin cbr ga correspond product design system put forward experi conduct result show combin intellig algorithm good perform search"
  },
  {
    "doc_id": "1349996",
    "abstract_original": "Radiated emission algorithms for a printed circuit board EMC expert system are described. The expert system mimics the thinking processes that human EMC engineers would use to analyze circuit boards and make design recommendations. Working with limited information about the enclosure, cables or the exact nature of the signals, the expert system evaluates different structures on the printed circuit board, looking for potentially strong radiated emission sources. Results obtained from the analysis of a sample printed circuit board are provided to demonstrate how the expert system quickly identifies problems that would otherwise be difficult to locate.",
    "abstract_processed": "radiat emiss algorithm print circuit board emc expert system describ expert system mimic think process human emc engin would use analyz circuit board make design recommend work limit inform enclosur cabl exact natur signal expert system evalu differ structur print circuit board look potenti strong radiat emiss sourc result obtain analysi sampl print circuit board provid demonstr expert system quickli identifi problem would otherwis difficult locat"
  },
  {
    "doc_id": "1357744",
    "abstract_original": "We describe a project, The City that We Want, which enabled the constructionist use of technology within a generative theme to enable students to design and construct their ideas about how to improve life in their communities. We used a variety of computational technologies combined with crafts and scrap materials. The goal was for children to learn in a more contextualized manner important ideas in the disciplines through their projects. We designed the overall project itself as an object to think with in order to facilitate a broader reform in the schools. The willing participation, inspired projects, and commitment and development of the teachers demonstrated significant value.",
    "abstract_processed": "describ project citi want enabl constructionist use technolog within gener theme enabl student design construct idea improv life commun use varieti comput technolog combin craft scrap materi goal children learn contextu manner import idea disciplin project design overal project object think order facilit broader reform school will particip inspir project commit develop teacher demonstr signific valu"
  },
  {
    "doc_id": "1357766",
    "abstract_original": "In this workshop, I will describe some of our ongoing research activities related to the use of modelling tools, construction kits and system dynamics simulations to support learning in different educational settings. These activities are related to innovative technological development and educational practice in a number of domains where deep scientific thinking is required.",
    "abstract_processed": "workshop describ ongo research activ relat use model tool construct kit system dynam simul support learn differ educ set activ relat innov technolog develop educ practic number domain deep scientif think requir"
  },
  {
    "doc_id": "1360194",
    "abstract_original": "Perhaps the easiest way to present the central theme of this article is to ask the following thought question: \"how many people would it take to destroy the world?\" By \"world\" in this context, I am referring to humankind. Destroying the world has been a recurring theme in novels and movies for many years. The end of the world is also an element of many religions. However, until this century there was no real belief that mankind could destroy itself. So, for most of human pre-history and history, destruction of the human race would only have been remotely possible through mass murder/suicide. This was hardly a likely prospect. In the 1800's mechanized warfare and massive production and transport of weapons and supplies became possible. This increased the destructive potential of war, but still did not make it a likely mechanism for global self-destruction. It was only in the 1940s and 1950s that we have achieved the means to destroy the world, with the development and massive production of nuclear weapons. However, developing this capability required a very large technological effort, which only resided in the hands of the large governments. Tens of thousands of people, supported by economies of tens of millions, were required to produce this capability.",
    "abstract_processed": "perhap easiest way present central theme articl ask follow thought question mani peopl would take destroy world world context refer humankind destroy world recur theme novel movi mani year end world also element mani religion howev centuri real belief mankind could destroy human pre histori histori destruct human race would remot possibl mass murder suicid hardli like prospect mechan warfar massiv product transport weapon suppli becam possibl increas destruct potenti war still make like mechan global self destruct achiev mean destroy world develop massiv product nuclear weapon howev develop capabl requir larg technolog effort resid hand larg govern ten thousand peopl support economi ten million requir produc capabl"
  },
  {
    "doc_id": "1360210",
    "abstract_original": "The recent urgency for counterterrorism and the fight to protect ones' homeland are of grave concern to nations throughout the world. Finding an efficient process that could have screened passengers prior to boarding a flight or even a train may have derailed many devastating events. Scientific research has continuously proved that there is an explicit marker of neuronal activity that correlates with awareness, past experience, and short-term interactions from the well-known P300 peak of an evoked potential. This study examines the effects of memory recognition to certain key stimuli mixed with irrelevant variables in an effort to identify if a trained terrorist, per se, could not only be identified from a group of subjects, but also validate that the willingness to withhold information is out of the control of the individual; it's simple, one has no control in concealing their brain's activity.",
    "abstract_processed": "recent urgenc counterterror fight protect one homeland grave concern nation throughout world find effici process could screen passeng prior board flight even train may derail mani devast event scientif research continu prove explicit marker neuron activ correl awar past experi short term interact well known p peak evok potenti studi examin effect memori recognit certain key stimuli mix irrelev variabl effort identifi train terrorist per se could identifi group subject also valid willing withhold inform control individu simpl one control conceal brain activ"
  },
  {
    "doc_id": "1369136",
    "abstract_original": "Edmund Berkeley established himself as an influential force in the early development of computer science. The article examines Berkeley's work with symbolic logic and explores how this knowledge shaped his ideas about early electronic computers. It further explores how Berkeley applied symbolic logic and human reasoning to the design of relay computers, especially machines designed for the insurance industry.",
    "abstract_processed": "edmund berkeley establish influenti forc earli develop comput scienc articl examin berkeley work symbol logic explor knowledg shape idea earli electron comput explor berkeley appli symbol logic human reason design relay comput especi machin design insur industri"
  },
  {
    "doc_id": "1370309",
    "abstract_original": "Stalling from the thinking about the representation of geo-spatial data in computer network, the challenge of grid computing environment to geo-spatial information science and technology is pointed in This work. After review and summation of the achieved progress and existing problems of geo-spatial information systems in the past 20 years, the authors propose a new representation method for spatial data and spatial information - the spatial information multi-grid (SIMG), which can not only easily run under grid computing environment, but also properly consider the difference of natural and social characteristics in Earth space as well as the different level of economical development in different area. The system structure, data representation, data storage and data access in SIMG are described with emphasis on key techniques. The data conversion and transferring between SIMG and conventional spatial databases are also discussed. The applicability of SIMG in global, national, provincial and local decision-making is briefly indicated.",
    "abstract_processed": "stall think represent geo spatial data comput network challeng grid comput environ geo spatial inform scienc technolog point work review summat achiev progress exist problem geo spatial inform system past year author propos new represent method spatial data spatial inform spatial inform multi grid simg easili run grid comput environ also properli consid differ natur social characterist earth space well differ level econom develop differ area system structur data represent data storag data access simg describ emphasi key techniqu data convers transfer simg convent spatial databas also discuss applic simg global nation provinci local decis make briefli indic"
  },
  {
    "doc_id": "1372322",
    "abstract_original": "Teachers may engage in end-user programming to support student learning or administrative activities associated with teaching. The objective of this research is to understand strategies used by teachers in program comprehension and to identify specific problems they face. A think-aloud study was conducted of teachers comprehending an event-driven application, consisting of a graphical user interface and the scripts controlling it. We found that end users followed a strongly top-down strategy and breadth-wise exploration of the application. Depth-wise exploration was observed in half the teachers. Teachers varied greatly in their motivations and persistence to dig deeply into the code. Problems of the teachers included difficulties comprehending the event-driven application, given the distributed nature of the code, choosing appropriate inputs for running the program, and reasoning about the results of their test runs.",
    "abstract_processed": "teacher may engag end user program support student learn administr activ associ teach object research understand strategi use teacher program comprehens identifi specif problem face think aloud studi conduct teacher comprehend event driven applic consist graphic user interfac script control found end user follow strongli top strategi breadth wise explor applic depth wise explor observ half teacher teacher vari greatli motiv persist dig deepli code problem teacher includ difficulti comprehend event driven applic given distribut natur code choos appropri input run program reason result test run"
  },
  {
    "doc_id": "1383168",
    "abstract_original": "We present and analyze a portable, high-performance algorithm for finding connected components on modern distributed memory multiprocessors. The algorithm is a hybrid of the classic DFS on the subgraph local to each processor and a variant of the Shiloach-Vishkin PRAM algorithm on the global collection of subgraphs. We implement the algorithm in Split-C and measure performance on the the Cray T3D, the Meiko CS-2, and the Thinking Machines CM-5 using a class of graphs derived from cluster dynamics methods in computational physics. On a 256 processor Cray T3D, the implementation outperforms all previous solutions by an order of magnitude. A characterization of graph parameters allows us to select graphs that highlight key performance features. We study the effects of these parameters and machine characteristics on the balance of time between the local and global phases of the algorithm and find that edge density, surface-to-volume ratio, and relative communication cost dominate performance. By understanding the effect of machine characteristics on performance, the study sheds light on the impact of improvements in computational and/or communication performance on this challenging problem.",
    "abstract_processed": "present analyz portabl high perform algorithm find connect compon modern distribut memori multiprocessor algorithm hybrid classic df subgraph local processor variant shiloach vishkin pram algorithm global collect subgraph implement algorithm split c measur perform cray meiko cs think machin cm use class graph deriv cluster dynam method comput physic processor cray implement outperform previou solut order magnitud character graph paramet allow us select graph highlight key perform featur studi effect paramet machin characterist balanc time local global phase algorithm find edg densiti surfac volum ratio rel commun cost domin perform understand effect machin characterist perform studi shed light impact improv comput commun perform challeng problem"
  },
  {
    "doc_id": "1384137",
    "abstract_original": "In the last few decades, a silent revolution is taking place. The exponential growth in microelectronic processing power has been achieved by ever decreasing the size of integrated circuits. These circuits which integrate electrical, mechanical and sometimes optical devices, have evolved from silicon revolution. It replaced big complex, costly systems with small, affordable, high performance microsystems. Microsystems are expected to further enable silicon chips to sense, \"think\", act, and communicate. In essence, to become intlelligent machines. Structures of current microsystems are approaching fundamental limits and the next generation of devices might. show unexpected properties due to quantum effects and fluctuations. A new research field is developing in which we pursue understanding of basic physics associated with such quantum structures, explore their control1 ability, and propose new devices. In this talk, we will begin with a summary of engineering problem solving and proceed to discuss the impact of technology on the development of newly emerging discipline of soft computing and compulational intelligence. The relationship between technology and intelligent mechatronics will be pointed out.",
    "abstract_processed": "last decad silent revolut take place exponenti growth microelectron process power achiev ever decreas size integr circuit circuit integr electr mechan sometim optic devic evolv silicon revolut replac big complex costli system small afford high perform microsystem microsystem expect enabl silicon chip sens think act commun essenc becom intlellig machin structur current microsystem approach fundament limit next gener devic might show unexpect properti due quantum effect fluctuat new research field develop pursu understand basic physic associ quantum structur explor control abil propos new devic talk begin summari engin problem solv proceed discuss impact technolog develop newli emerg disciplin soft comput compul intellig relationship technolog intellig mechatron point"
  },
  {
    "doc_id": "1384872",
    "abstract_original": "The so called associative thinking, which humans are known to perform on every day basis, is attributed to the fact that human brain memorizes information using the dynamical system made of interconnected neurons. Retrieval of information in such a system is accomplished in associative sense; starting from an arbitrary state, which might be an encoded representation of a visual image, the brain activity converges to another state, which is stable and which is what the brain remembers. In this paper we explore the possibility of using an associative memory for the purpose of enhancing the interactive capability of perceptual vision systems. By following the biological memory principles, we show how vision systems can be designed to recognize faces, facial gestures and orientations, using low-end video-cameras and little computational power. In doing that we use the public domain associative memory code.",
    "abstract_processed": "call associ think human known perform everi day basi attribut fact human brain memor inform use dynam system made interconnect neuron retriev inform system accomplish associ sens start arbitrari state might encod represent visual imag brain activ converg anoth state stabl brain rememb paper explor possibl use associ memori purpos enhanc interact capabl perceptu vision system follow biolog memori principl show vision system design recogn face facial gestur orient use low end video camera littl comput power use public domain associ memori code"
  },
  {
    "doc_id": "1386655",
    "abstract_original": "MATLAB is one of the most widely used mathematical computing environments in technical computing. It is an interactive environment that provides high-performance computational routines and an easy-to-use, C-like scripting language. It started out as an interactive interface to EISPACK and LINPACK and has remained a serial program. In 1995, C. Moler of Mathworks argued that there was no market at the time for a parallel MATLAB. But times have changed and we are seeing increasing interest in developing a parallel MATLAB, from both academic and commercial sectors. In a recent survey, 27 parallel MATLAB projects have been identified. We expand upon that survey and discuss the approaches the projects have taken to parallelize MATLAB. Also, we describe innovative features in some of the parallel MATLAB projects. Then we will conclude with an idea of a \"right\" parallel MATLAB. Finally we will give an example of what we think is a \"right\" parallel MATLAB: MATLAB*P.",
    "abstract_processed": "matlab one wide use mathemat comput environ technic comput interact environ provid high perform comput routin easi use c like script languag start interact interfac eispack linpack remain serial program c moler mathwork argu market time parallel matlab time chang see increas interest develop parallel matlab academ commerci sector recent survey parallel matlab project identifi expand upon survey discuss approach project taken parallel matlab also describ innov featur parallel matlab project conclud idea right parallel matlab final give exampl think right parallel matlab matlab p"
  },
  {
    "doc_id": "1390730",
    "abstract_original": "This work focuses on the construction of an expert system shell for airborne equipment design. Traditional expert systems are constructed using a single monolithic software program for a specific application. Since the airborne equipment design is critical & complex, it demands the use of expert system technology. Since present aircrafts take in different equipments for different purposes, it is not feasible to think in terms of independently developed monolithic expert system program for each equipment. To overcome these problems, we have designed and developed a complex competent system i.e., a generic component based expert system for airborne equipment design. The main advantage of the component-based approach is that, the knowledge base is not hard coded and these components can be coupled with any domain-specific knowledge bases. The expert system with its expertise knowledge is made to guide the designer by providing design guidelines & testing procedures for the desired equipment. The expert system also audits the design and provides guidelines to modify & to improve the design.",
    "abstract_processed": "work focus construct expert system shell airborn equip design tradit expert system construct use singl monolith softwar program specif applic sinc airborn equip design critic complex demand use expert system technolog sinc present aircraft take differ equip differ purpos feasibl think term independ develop monolith expert system program equip overcom problem design develop complex compet system e gener compon base expert system airborn equip design main advantag compon base approach knowledg base hard code compon coupl domain specif knowledg base expert system expertis knowledg made guid design provid design guidelin test procedur desir equip expert system also audit design provid guidelin modifi improv design"
  },
  {
    "doc_id": "1397903",
    "abstract_original": "This article provides an introduction to the special issue on Expanding the Boundaries of E-Collaboration. It presents an operational definition of the term e-collaboration, and a historical review of the development of e-collaboration tools and related academic research. That is followed by an introductory development of the notion of e-collaboration boundaries. The article concludes with a summarized discussion of the articles published in the special issue.",
    "abstract_processed": "articl provid introduct special issu expand boundari e collabor present oper definit term e collabor histor review develop e collabor tool relat academ research follow introductori develop notion e collabor boundari articl conclud summar discuss articl publish special issu"
  },
  {
    "doc_id": "1401110",
    "abstract_original": "One of the most prominent research goals in the field of mobile autonomous robots is to create robots that are able to adapt to new environments, i.e., the robots should be able to learn during their \"lifetime\" possibly without (or a minimum) of human intervention. When employing artificial neural networks (ANNs) to control the robot, reinforcement learning (RL) techniques are a good candidate for achieving continuous on-line learning. A problem with RL applied to robot learning is that the state (and action) space of a robot is typically not discrete. Thus, the robot had to evaluate an infinite number of possible actions at every time step in order to select the best. To overcome this problem we add a second network module to the neurocontroller acting as a memory of previous decisions (state-action pairs) of the robot. The robot's actual decisions, then, are based on previous decisions retrieved from memory. Additionally, intrinsic noise in the memory network gives the robot the possibility to evaluate new \"ideas\", hence it becomes creative. We analyze the potential of the above approach by measuring the ability of (simulated) robots to learn simple tasks using temporal difference (TD) learning.",
    "abstract_processed": "one promin research goal field mobil autonom robot creat robot abl adapt new environ e robot abl learn lifetim possibl without minimum human intervent employ artifici neural network ann control robot reinforc learn rl techniqu good candid achiev continu line learn problem rl appli robot learn state action space robot typic discret thu robot evalu infinit number possibl action everi time step order select best overcom problem add second network modul neurocontrol act memori previou decis state action pair robot robot actual decis base previou decis retriev memori addit intrins nois memori network give robot possibl evalu new idea henc becom creativ analyz potenti approach measur abil simul robot learn simpl task use tempor differ td learn"
  },
  {
    "doc_id": "1401215",
    "abstract_original": "The research of human's information processing of design thinking show a key role in many fields such as intelligent design, intelligent manufacturing system and next generation CAD system. In order to form a formalization description and disclose the process of conceptual generation under the interaction of designer and computer environment, This work aims to achieve design analysis for early concept generation and present one improved model integrated cognition and computation to construct one robust process model. In order to meet common sense in designing, introspection and prototype driven should be applied to achieve design analysis in the process of concept generation. And generational variable index of product concept is extracted based on the demands of information processing.",
    "abstract_processed": "research human inform process design think show key role mani field intellig design intellig manufactur system next gener cad system order form formal descript disclos process conceptu gener interact design comput environ work aim achiev design analysi earli concept gener present one improv model integr cognit comput construct one robust process model order meet common sens design introspect prototyp driven appli achiev design analysi process concept gener gener variabl index product concept extract base demand inform process"
  },
  {
    "doc_id": "1406994",
    "abstract_original": "A haptic model of bowing the violin and viola is presented that focuses on just the geometry of the contact point between the bow hair and the string, giving a simplified description that focuses on aspects which the performer thinks about consciously. The model allows artificial constraints on the bow motion to be provided, giving the player physical feedback if one dimension of the contact point becomes incorrect, while allowing full movement in other dimensions.",
    "abstract_processed": "haptic model bow violin viola present focus geometri contact point bow hair string give simplifi descript focus aspect perform think conscious model allow artifici constraint bow motion provid give player physic feedback one dimens contact point becom incorrect allow full movement dimens"
  },
  {
    "doc_id": "1408447",
    "abstract_original": "One of the defining characteristics of engineering is the use of models in problem solving. Graphic models or cartoon-like depictions of an identified body of interest are used to design, to simulate, to test hypotheses and to make predictions. While students are repeatedly exposed to free body diagrams, circuit schematics and other forms of pictorial modeling in their textbooks and lectures, faculty repeatedly complain that students overlook the models and just seek an equation that they think fits the problem situation - a situation characterized as \"plugging and chugging\". This indicates that students do not fully understand the function these models serve as visual representations of mathematical models and provisional hypotheses of the problem space. The goal of this interactive workshop is to give engineering educators better tools to scaffold this process.",
    "abstract_processed": "one defin characterist engin use model problem solv graphic model cartoon like depict identifi bodi interest use design simul test hypothes make predict student repeatedli expos free bodi diagram circuit schemat form pictori model textbook lectur faculti repeatedli complain student overlook model seek equat think fit problem situat situat character plug chug indic student fulli understand function model serv visual represent mathemat model provision hypothes problem space goal interact workshop give engin educ better tool scaffold process"
  },
  {
    "doc_id": "1408453",
    "abstract_original": "At the University of Virginia, the School of Engineering and Applied Science established a formal distance-learning program in 1983. Both of us have been teaching in this program for nearly 20 years. Between us we have taught five distinct types of courses, most through multiple iterations. In this paper, we describe our uses of information technology to enhance the learning environment for our students including solids modeling, finite element analysis, computational fluid dynamics, and statistics and data visualization. We then reflect on the distance learning experience from both the professor's and student perspectives.",
    "abstract_processed": "univers virginia school engin appli scienc establish formal distanc learn program us teach program nearli year us taught five distinct type cours multipl iter paper describ use inform technolog enhanc learn environ student includ solid model finit element analysi comput fluid dynam statist data visual reflect distanc learn experi professor student perspect"
  },
  {
    "doc_id": "1408516",
    "abstract_original": "It is well known that many students struggle and eventually are unsuccessful in their attempt to complete their first computer science course. At Arizona State University, the first course taken by computer science majors and a few other majors is CSE 110. CSE110 teaches first year college students basic programming principles using the Java programming language. In order to do well in this course, students need to not only have a background in basic logical thinking, but also need to know basics about using computers along with Internet and file transfer protocol. To address this problem, a CSE110 workshop has been designed for incoming freshmen that have little or no background in computers. This paper defines the content and instruction of this workshop as well as an assessment of its effectiveness. To help ensure that future freshmen are better prepared, software development curriculum materials are being developed for use at the high school level. Two summer teacher workshops have already been held and a third is planned.",
    "abstract_processed": "well known mani student struggl eventu unsuccess attempt complet first comput scienc cours arizona state univers first cours taken comput scienc major major cse cse teach first year colleg student basic program principl use java program languag order well cours student need background basic logic think also need know basic use comput along internet file transfer protocol address problem cse workshop design incom freshmen littl background comput paper defin content instruct workshop well assess effect help ensur futur freshmen better prepar softwar develop curriculum materi develop use high school level two summer teacher workshop alreadi held third plan"
  },
  {
    "doc_id": "1408688",
    "abstract_original": "Graphics has always been a requisite form of communication for engineering practice. The history of major engineering accomplishments is replete with examples of graphical communications: from styli etchings on clay tablets to near-recent blueprint drawings. In the last two decades, engineering graphics instruction has been significantly influenced by the advancement of computers and other new technologies. During this short span, the discipline has gone from teaching manual drafting and pencil drawings to the use of 3-D computer modeling and simulation software. This paper briefly reviews the evolution of graphical communication in engineering practice, and focuses on the current status of graphical communication in the engineering curriculum. This report is bolstered by results of a recent survey conducted at the 2003 annual meeting of the Engineering Design Graphics Division of ASEE. The survey proposed an extensive list of student outcomes for engineering graphical communication, as mandated by the new ABET EC2000 outcomes requirement criterion 3 (g): \"an ability to communicate effectively.\" Graphics faculty ranked these graphics student outcomes, and accompanying performance criteria, on level of importance in the modern curriculum. The results represent a consensus of current thinking on engineering graphical communication education.",
    "abstract_processed": "graphic alway requisit form commun engin practic histori major engin accomplish replet exampl graphic commun styli etch clay tablet near recent blueprint draw last two decad engin graphic instruct significantli influenc advanc comput new technolog short span disciplin gone teach manual draft pencil draw use comput model simul softwar paper briefli review evolut graphic commun engin practic focus current statu graphic commun engin curriculum report bolster result recent survey conduct annual meet engin design graphic divis ase survey propos extens list student outcom engin graphic commun mandat new abet ec outcom requir criterion g abil commun effect graphic faculti rank graphic student outcom accompani perform criteria level import modern curriculum result repres consensu current think engin graphic commun educ"
  },
  {
    "doc_id": "1408709",
    "abstract_original": "In this paper, we report our first experiment in teaching the theory of computability in the problem-based way. As far as we know, this is the first experiment of applying the problem-based method to a purely theoretical course of computer science. Performing the course consisted of three parts: First, the new subjects were learnt according to the classical seven step method, which contains both individual and group work, and problem reports were written. Second, the students participated in a traditional exercise session, in which the new techniques were practised in details. And third, the students kept a learning diary, in which they processed the subjects further, tried to construct an overall schema of things learnt, and supervised their own learning. The results were really successful: the students committed themselves well and the drop out percentage was very small; they achieved very deep understanding of the subjects measured by their grades and quality of learning diaries; the experience was enjoyable for both the students and the teachers; and finally, the method supported different kinds of learners very well.",
    "abstract_processed": "paper report first experi teach theori comput problem base way far know first experi appli problem base method pure theoret cours comput scienc perform cours consist three part first new subject learnt accord classic seven step method contain individu group work problem report written second student particip tradit exercis session new techniqu practis detail third student kept learn diari process subject tri construct overal schema thing learnt supervis learn result realli success student commit well drop percentag small achiev deep understand subject measur grade qualiti learn diari experi enjoy student teacher final method support differ kind learner well"
  },
  {
    "doc_id": "1411821",
    "abstract_original": "In this paper, new learning methods tolerant to imprecision are introduced and applied to fuzzy modeling based on the Takagi-Sugeno-Kang fuzzy system. The fuzzy modeling has an intrinsic inconsistency. It may perform thinking tolerant to imprecision, but learning methods are zero-tolerant to imprecision. The proposed methods make it possible to exclude this intrinsic inconsistency of a fuzzy modeling, where zero-tolerance learning is used to obtain fuzzy model tolerant to imprecision. These new methods can be called /spl epsiv/-insensitive learning or /spl epsiv/ learning, where, in order to fit the fuzzy model to real data, the /spl epsiv/-insensitive loss function is used. This leads to a weighted or \"fuzzified\" version of Vapnik's support vector regression machine. This paper introduces two approaches to solving the /spl epsiv/-insensitive learning problem. The first approach leads to the quadratic programming problem with bound constraints and one linear equality constraint. The second approach leads to a problem of solving a system of linear inequalities. Two computationally efficient numerical methods for the /spl epsiv/-insensitive learning are proposed. The /spl epsiv/-insensitive learning leads to a model with the minimal Vapnik-Chervonenkis dimension, which results in an improved generalization ability of this model and its outliers robustness. Finally, numerical examples are given to demonstrate the validity of the introduced methods.",
    "abstract_processed": "paper new learn method toler imprecis introduc appli fuzzi model base takagi sugeno kang fuzzi system fuzzi model intrins inconsist may perform think toler imprecis learn method zero toler imprecis propos method make possibl exclud intrins inconsist fuzzi model zero toler learn use obtain fuzzi model toler imprecis new method call spl epsiv insensit learn spl epsiv learn order fit fuzzi model real data spl epsiv insensit loss function use lead weight fuzzifi version vapnik support vector regress machin paper introduc two approach solv spl epsiv insensit learn problem first approach lead quadrat program problem bound constraint one linear equal constraint second approach lead problem solv system linear inequ two comput effici numer method spl epsiv insensit learn propos spl epsiv insensit learn lead model minim vapnik chervonenki dimens result improv gener abil model outlier robust final numer exampl given demonstr valid introduc method"
  },
  {
    "doc_id": "1416363",
    "abstract_original": "In this paper, we present the format of a graduate course in digital communications fostering course projects, active student participation, and communication among students. We illustrate how electrical engineering students show increased interest in theoretical mathematical concepts, if motivated by a design problem, and are actually able to improve the performance of a state-of-the-art software package.",
    "abstract_processed": "paper present format graduat cours digit commun foster cours project activ student particip commun among student illustr electr engin student show increas interest theoret mathemat concept motiv design problem actual abl improv perform state art softwar packag"
  },
  {
    "doc_id": "1419802",
    "abstract_original": "The purpose of this research is to realize a \"co-creation system\". Co-creation means co-emergence of real-time coordination by sharing subjective space and time between different persons. Human communication with emergent reality like this is essential to improve communicability in social systems, and we assume such communication needs two kinds of information process at the same time. One is explicit communication such as the transmission of messages and the other is implicit embodied interaction such as the sympathy and direct experience. The conventional IT system mainly covers the former process but we have been pointing out the importance of the latter process. Especially, this implicit process is related with rhythmic interaction between humans, such as entrainment of body motion. From this background, using these implicit and explicit processing complementarily, we are developing co-creative man-machine interfaces and communication media. We think this dual-processing based new technology will be effective for recovering human linkage and mutual-reliability that has been weakened in modern IT society.",
    "abstract_processed": "purpos research realiz co creation system co creation mean co emerg real time coordin share subject space time differ person human commun emerg realiti like essenti improv communic social system assum commun need two kind inform process time one explicit commun transmiss messag implicit embodi interact sympathi direct experi convent system mainli cover former process point import latter process especi implicit process relat rhythmic interact human entrain bodi motion background use implicit explicit process complementarili develop co creativ man machin interfac commun media think dual process base new technolog effect recov human linkag mutual reliabl weaken modern societi"
  },
  {
    "doc_id": "1423965",
    "abstract_original": "When thinking about systems, it's tempting to only envision computational elements such as machines, operating systems, and programming languages, or human elements such as user interfaces, business practices, and public policy. However, to mangle an analogy from physics, the observer is also part of the system. When reasoning about or designing (or breaking into) secure systems, it's important to remember the tools, mindset, and background we bring to the table. Computer security's primary background fields are computer science and computer engineering (although some might make a case for mathematical logic). These fields sometimes bring very different approaches to the same basic security problems. We take a light-hearted look at these differences.",
    "abstract_processed": "think system tempt envis comput element machin oper system program languag human element user interfac busi practic public polici howev mangl analog physic observ also part system reason design break secur system import rememb tool mindset background bring tabl comput secur primari background field comput scienc comput engin although might make case mathemat logic field sometim bring differ approach basic secur problem take light heart look differ"
  },
  {
    "doc_id": "1425525",
    "abstract_original": "This paper presents a model metrics and a methodology for evaluating the critical path on the data flow execution graph (DFEG) of multimedia algorithms specified as C programs. The paper describes an efficient dynamic critical path evaluation approach that generates no explicit execution graph. Such approach includes two key stages: 1) the instrumentation of the C code and the mapping into a C++ code version and 2) the execution of the C++ code under real input data and finally the actual dynamic evaluation of the critical path. The model metrics and the software analysis methodologies aim at the estimation and at the increase of the upper bound of execution speed and parallelization potential. Both metrics and methodology are particularly tailored for application with complex multimedia algorithms. Critical path analysis and the subsequent algorithmic development stage is a fundamental methodological preliminary step for the efficient definition of architectures when the objective is the implementation of the multimedia algorithm on systems-on-chips or heterogeneous platforms.",
    "abstract_processed": "paper present model metric methodolog evalu critic path data flow execut graph dfeg multimedia algorithm specifi c program paper describ effici dynam critic path evalu approach gener explicit execut graph approach includ two key stage instrument c code map c code version execut c code real input data final actual dynam evalu critic path model metric softwar analysi methodolog aim estim increas upper bound execut speed parallel potenti metric methodolog particularli tailor applic complex multimedia algorithm critic path analysi subsequ algorithm develop stage fundament methodolog preliminari step effici definit architectur object implement multimedia algorithm system chip heterogen platform"
  },
  {
    "doc_id": "1430102",
    "abstract_original": "In the area of testing ICs, once an IC has failed a traditional go/no-go test, it needs to be tested further to determine if it can support error-tolerant operation for one or more high volume customers. This test must be very efficient since many chips will probably fail, and those that pass will be sold at a discount. We have already developed several efficient test procedures to support error-tolerance. One is a built-in self-test methodology that can sort chips into various bins based on their error-rate, just like resistors are sorted into 1%, 5% and 10% bins (Breuer, 2004). Digital systems designers have almost always focused on the concept of exact computational capability. Error-tolerant VLSI chips are a step in this direction using today's technologies, addressing current computational needs, and accepting present realities of scale and yield.",
    "abstract_processed": "area test ic ic fail tradit go go test need test determin support error toler oper one high volum custom test must effici sinc mani chip probabl fail pass sold discount alreadi develop sever effici test procedur support error toler one built self test methodolog sort chip variou bin base error rate like resistor sort bin breuer digit system design almost alway focus concept exact comput capabl error toler vlsi chip step direct use today technolog address current comput need accept present realiti scale yield"
  },
  {
    "doc_id": "1432316",
    "abstract_original": "Intelligence is thought to be related to interaction rather than a deep but passive thinking. Interactive tangible media \"iTMedia\" is proposed to explore these issues. Personal robotics is a major area to investigate these ideas. A new design methodology for personal and emotional robotics is proposed. Sciences of the artificial and intelligence have been investigated. A short history of artificial intelligence is presented in terms of logic, heuristics, and mobility; a science of intelligence is presented in terms of imitation and understanding; intelligence issues for robotics and intelligence measures are described. A design methodology for personal robots based on science of emotion is investigated. We investigate three different aspects of design: visceral, behavioral, and reflective. We also discuss affect and emotion in robots, robots that sense emotion, robots that induce emotion in people, and implications and ethical issues of emotional robots. Personal robotics for the elderly is investigated to explore these ideas.",
    "abstract_processed": "intellig thought relat interact rather deep passiv think interact tangibl media itmedia propos explor issu person robot major area investig idea new design methodolog person emot robot propos scienc artifici intellig investig short histori artifici intellig present term logic heurist mobil scienc intellig present term imit understand intellig issu robot intellig measur describ design methodolog person robot base scienc emot investig investig three differ aspect design viscer behavior reflect also discuss affect emot robot robot sens emot robot induc emot peopl implic ethic issu emot robot person robot elderli investig explor idea"
  },
  {
    "doc_id": "1437155",
    "abstract_original": "Theorists and practitioners have fairly different perspectives on how wireless broadcast works. Theorists think about synchrony; practitioners think about backoff. Theorists assume reliable communication; practitioners worry about collisions. The examples are endless. Our goal is to begin to reconcile the theory and practice of wireless broadcast, in the presence of failures. We propose new models for wireless broadcast and use them to examine what makes a broadcast model good. In the process, we pose some interesting questions that help to bridge the gap.",
    "abstract_processed": "theorist practition fairli differ perspect wireless broadcast work theorist think synchroni practition think backoff theorist assum reliabl commun practition worri collis exampl endless goal begin reconcil theori practic wireless broadcast presenc failur propos new model wireless broadcast use examin make broadcast model good process pose interest question help bridg gap"
  },
  {
    "doc_id": "1437699",
    "abstract_original": "The investigation (i.e. modelling, simulation, understanding and control) of complex adaptive systems is a problematic issue mainly due to the immaturity of systems scientific modelling paradigms. The apparent analogies between complex adaptive systems and production networks provide us the opportunity to formulate the latter one in terms of the first, and integrate the knowledge and way of thinking of the two fields. Through the application of agent based modelling and the development of a methodology, a unique way of thinking is presented that involves the formulation of natural concepts in terms of simulation models",
    "abstract_processed": "investig e model simul understand control complex adapt system problemat issu mainli due immatur system scientif model paradigm appar analog complex adapt system product network provid us opportun formul latter one term first integr knowledg way think two field applic agent base model develop methodolog uniqu way think present involv formul natur concept term simul model"
  },
  {
    "doc_id": "1437762",
    "abstract_original": "Our examination focuses on the skills involved in the process of problem solving. In particular, a distinction is made between general problem solving processes and those relating to various types of specific problems. The role of knowledge, motivation, disposition and metacognitive style played in problem solving is also to be discussed. We interpret problem solving as a complex method in which creative and critical thinking play determinative roles. We would like to underline the significance of heuristic and algorithmic approaches in thinking-development from the point of view of the concrete engineering problem",
    "abstract_processed": "examin focus skill involv process problem solv particular distinct made gener problem solv process relat variou type specif problem role knowledg motiv disposit metacognit style play problem solv also discuss interpret problem solv complex method creativ critic think play determin role would like underlin signific heurist algorithm approach think develop point view concret engin problem"
  },
  {
    "doc_id": "1490962",
    "abstract_original": "Summary form only given. As technology advances, many human-like robots are being developed. These humanoid robots should be classified as inanimate objects; however, they share many properties with human beings. This raises the question of how infants classify them. Developmental psychology has addressed the issue of how infants come to characterize humans as agents having mental states that is indispensable foundation for sociality. Some studies suggest that infants attribute mental states only to humans. For instance, Legerstee et al. (2000) found that 6-month-old infants do expect people to communicate with people, not with objects. These results indicate that human cognition specializes in human in early infancy. Other studies have suggested, however, that infants attribute mental states to non-human objects that appear to be interactive with a person. For instance, Johnson et al. (1999) indicated that 12-month-old infants did gaze following to a non-human but interactive stuff. These results imply that interactivity between humans and objects is the key factor in mental attribution, however, interesting questions remain to be answered: do infants also have expectation for robots to communicate with person? In this study, we investigated whether 6-month-old infants expected an experimenter to talk to a humanoid robot \"Robovie\" [Ishiguro, et al., (2001) using infants' looking time as a measurement of violation-of-expectation. Violation-of-expectation method uses infants' property that they look longer at the event that they do not expect than at the event that they expect. During test trials, we show infants the stimulus in which an actor talks to the robot and another person. If infants regard robots as communicative existence like human, they will not be surprised and look at the robot as long as at the person. But if infants do not attribute communicational property to robots, they will look longer at the robot than at the person. To show infants how the robot behaved and interacted with people, we added a familiarization period prior to the test trials, which phase provided infants with prior knowledge about the robots. The stimuli in the familiarization of these conditions are as follows: 1) interactive robot condition: the robot behaved like a human, and the person and the robot interacted with each other; 2) non-active robot condition: the robot was stationary and the person was both active and talked to the robot; 3) active robot condition: the robot behaved like a human, and the person was stationary and silent. If the robots' appearance is dominant for expectation, the results of all condition are same. If robot' action is dominant, the results of the interactive robot condition and the active robot condition are same. And if human-robot interaction is dominant, the result of the interactive robot condition is only different. In the results, infants who had watched the interactive robot looked at the robot as long as at the person. However, infants who had previously observed other robots (non-active robot and active robot) looked longer at the robot than at the person. A previous study suggested that infants come to think of the same robot as intentional agents earlier than they can attribute simple geometric object as intentional agents (Kamewari, et al.). Therefore, it is thought that early infants have the cognitive base that specialized in appearance. Our findings, however, imply that early infants are also sensitive about external forms of human communications, such as \"turn-taking\" (Trevarthen, 1980), so they come to regard a non-human target as communicative by learning",
    "abstract_processed": "summari form given technolog advanc mani human like robot develop humanoid robot classifi inanim object howev share mani properti human be rais question infant classifi development psycholog address issu infant come character human agent mental state indispens foundat social studi suggest infant attribut mental state human instanc legerste et al found month old infant expect peopl commun peopl object result indic human cognit special human earli infanc studi suggest howev infant attribut mental state non human object appear interact person instanc johnson et al indic month old infant gaze follow non human interact stuff result impli interact human object key factor mental attribut howev interest question remain answer infant also expect robot commun person studi investig whether month old infant expect experiment talk humanoid robot robovi ishiguro et al use infant look time measur violat expect violat expect method use infant properti look longer event expect event expect test trial show infant stimulu actor talk robot anoth person infant regard robot commun exist like human surpris look robot long person infant attribut commun properti robot look longer robot person show infant robot behav interact peopl ad familiar period prior test trial phase provid infant prior knowledg robot stimuli familiar condit follow interact robot condit robot behav like human person robot interact non activ robot condit robot stationari person activ talk robot activ robot condit robot behav like human person stationari silent robot appear domin expect result condit robot action domin result interact robot condit activ robot condit human robot interact domin result interact robot condit differ result infant watch interact robot look robot long person howev infant previous observ robot non activ robot activ robot look longer robot person previou studi suggest infant come think robot intent agent earlier attribut simpl geometr object intent agent kamewari et al therefor thought earli infant cognit base special appear find howev impli earli infant also sensit extern form human commun turn take trevarthen come regard non human target commun learn"
  },
  {
    "doc_id": "1504153",
    "abstract_original": "The key technique of virtual prototyping is real-time a performance simulation for a product, such as virtual assembly simulation and mechanism movement simulation. However, the key to realize this simulation is yet the representation of a product model, and but, the traditional digital model of a product (such as relation model and hierarchical model) doesn't meet the demand. Therefore, this paper provides a scene graph model of a digital product based on DAG. The definition of the scene graph model is given and the features to represent a virtual product with DAG are analyzed o Finally, the principles of dynamically assembling and disassembling product with DAG and its simulating method are explained with an example.",
    "abstract_processed": "key techniqu virtual prototyp real time perform simul product virtual assembl simul mechan movement simul howev key realiz simul yet represent product model tradit digit model product relat model hierarch model meet demand therefor paper provid scene graph model digit product base dag definit scene graph model given featur repres virtual product dag analyz final principl dynam assembl disassembl product dag simul method explain exampl"
  },
  {
    "doc_id": "1504214",
    "abstract_original": "In this paper, we present a novel computational approach for stimulating creativity of designers. The tree structured genetic algorithm is used for generating 2D sketch shapes and 3D images. This approach is illustrated by an artwork design example, which uses general mathematical expressions to form 2D sketch shapes for artistic flower vases and the combination of general and complex function expressions to form 3D images of artistic flowers. It shows that approach is able to generate some solutions for supporting creative thinking of designers.",
    "abstract_processed": "paper present novel comput approach stimul creativ design tree structur genet algorithm use gener sketch shape imag approach illustr artwork design exampl use gener mathemat express form sketch shape artist flower vase combin gener complex function express form imag artist flower show approach abl gener solut support creativ think design"
  },
  {
    "doc_id": "1508848",
    "abstract_original": "Reinforcement learning theory encourages the use of agents for stimulating and assisting learners in their efforts to develop thinking styles. In this study the authors looked at a similar scenario of human-environmental interaction using Internet-mediated simulations as learning environments. One hundred and forty-nine vocational high schools students participated in this study to see if they can develop adequate thinking style when they learned in a simulation environment with help from agents. The results show that the judicial thinking style was best suited to the system we designed for this project - that is, we observed the greatest amount of development for this particular thinking style. Our results indicate that it is possible to establish and support thinking styles via Internet-mediated simulations.",
    "abstract_processed": "reinforc learn theori encourag use agent stimul assist learner effort develop think style studi author look similar scenario human environment interact use internet mediat simul learn environ one hundr forti nine vocat high school student particip studi see develop adequ think style learn simul environ help agent result show judici think style best suit system design project observ greatest amount develop particular think style result indic possibl establish support think style via internet mediat simul"
  },
  {
    "doc_id": "1510539",
    "abstract_original": "JHAVE fosters the use of algorithm visualization as an effective pedagogical tool for computer science educators, helping students to better understand algorithms. The Java-hosted algorithm visualization environment (JHAVE) is not an AV system itself but rather a support environment for a variety of AV systems (called AV engines by JHAVE). In broad terms, JHAVE gives such an engine a drawing context on which it can render its pictures in any way. In return, JHAVE provides the engine with effortless ways to synchronize its graphical displays with i) a standard set of VCR-like controls, ii) information and pseudocode windows, iii) input generators, iv) stop-and-think questions, and v) meaningful content generation tools.",
    "abstract_processed": "jhave foster use algorithm visual effect pedagog tool comput scienc educ help student better understand algorithm java host algorithm visual environ jhave av system rather support environ varieti av system call av engin jhave broad term jhave give engin draw context render pictur way return jhave provid engin effortless way synchron graphic display standard set vcr like control ii inform pseudocod window iii input gener iv stop think question v meaning content gener tool"
  },
  {
    "doc_id": "1511444",
    "abstract_original": "This concept of evolvable, process-oriented modular systems may be viewed as a new business model to sustain European competitiveness in micro and mini assembly. It is clear that this business model implies a high dynamic lifecycle for shop floors. The system will move from a static life cycle since the modules that create the different systems will live beyond the product lifecycle. This dynamicity imposes strong requirements on the way systems are designed, installed, operated, and reengineered. Re-configurability is not enough. These requirements will not only have an impact on the individual control architecture of the modules but also on, and this is very important, how the system is created, and several types of co-existing architectures",
    "abstract_processed": "concept evolv process orient modular system may view new busi model sustain european competit micro mini assembl clear busi model impli high dynam lifecycl shop floor system move static life cycl sinc modul creat differ system live beyond product lifecycl dynam impos strong requir way system design instal oper reengin configur enough requir impact individu control architectur modul also import system creat sever type co exist architectur"
  },
  {
    "doc_id": "1511608",
    "abstract_original": "Summary form only given. In the last few decades, a silent revolution is taking place. The exponential growth in microelectronic processing power has been achieved by ever decreasing the size of integrated circuits. These circuits which integrate electrical, mechanical and sometimes optical devices, have evolved from silicon revolution. It replaced big complex, costly systems with small, affordable, high performance microsystems. Microsystems are expected to further enable silicon chips to sense, \"think\", act, and communicate, in essence, to become intelligent machines. Structures of current microsystems are approaching fundamental limits and the next generation of devices might show unexpected properties due to quantum effects and fluctuations. A new research field is developing in which we pursue understanding of basic physics associated with such quantum structures, explore their controllability, and propose new devices. In this talk, we begin with a summary of engineering problem solving and proceed to discuss the impact of technology on the development of newly emerging discipline of soft computing and computational intelligence. The relationship between technology and intelligent mechatronics are pointed out.",
    "abstract_processed": "summari form given last decad silent revolut take place exponenti growth microelectron process power achiev ever decreas size integr circuit circuit integr electr mechan sometim optic devic evolv silicon revolut replac big complex costli system small afford high perform microsystem microsystem expect enabl silicon chip sens think act commun essenc becom intellig machin structur current microsystem approach fundament limit next gener devic might show unexpect properti due quantum effect fluctuat new research field develop pursu understand basic physic associ quantum structur explor control propos new devic talk begin summari engin problem solv proceed discuss impact technolog develop newli emerg disciplin soft comput comput intellig relationship technolog intellig mechatron point"
  },
  {
    "doc_id": "1514661",
    "abstract_original": "We introduce a genetic algorithm-based method for structural optimization of multiplicative general parameter (MGP) finite impulse response (FIR) filters. These computationally efficient reduced-rank adaptive filters are robust, suitable for predictive configurations, and they have numerous applications in 50/60 Hz power systems instrumentation. The design process of such filters has three independent stages: Lagrange multipliers-based optimization of the sinusoid-predictive basis filter, genetic algorithm-based search of optimal FIR tap cross-connections and, finally, the online MGP-adaptation phase guided by variations in signal statistics. Thus, our multistage design procedure is a complementary fusion of hard computing (HC) and soft computing (SC) methodologies. Such advantageous fusion (or symbiosis) thinking is emerging among researchers and practicing engineers, and it can potentially lead to competitive combinations of individual HC and SC methods.",
    "abstract_processed": "introduc genet algorithm base method structur optim multipl gener paramet mgp finit impuls respons fir filter comput effici reduc rank adapt filter robust suitabl predict configur numer applic hz power system instrument design process filter three independ stage lagrang multipli base optim sinusoid predict basi filter genet algorithm base search optim fir tap cross connect final onlin mgp adapt phase guid variat signal statist thu multistag design procedur complementari fusion hard comput hc soft comput sc methodolog advantag fusion symbiosi think emerg among research practic engin potenti lead competit combin individu hc sc method"
  },
  {
    "doc_id": "1521133",
    "abstract_original": "User and system behaviour is difficult to predict for novel systems, and this affects the capacity of the system (the number of active users that can be supported with acceptable response delay). This leads to a range of values, in the form of a feasible or acceptable region for the potential capacity, conditional on the uncertain parameters. This work considers uncertainties in the delay between requests (user think time), network latency, and cache behaviour due to users' locality of reference. The acceptable region is shown to be bounded approximately by linear constraints which are easy to derive. This simple result is useful for sensitivity and scalability analysis, and appears to have been overlooked. It is applied to a Web-based system for telephony, using voiceXML for service ranging from interactive voice response, to voice-based E-mail.",
    "abstract_processed": "user system behaviour difficult predict novel system affect capac system number activ user support accept respons delay lead rang valu form feasibl accept region potenti capac condit uncertain paramet work consid uncertainti delay request user think time network latenc cach behaviour due user local refer accept region shown bound approxim linear constraint easi deriv simpl result use sensit scalabl analysi appear overlook appli web base system telephoni use voicexml servic rang interact voic respons voic base e mail"
  },
  {
    "doc_id": "1530848",
    "abstract_original": "Though 20 years have passed since the birth of CSCW, the original goal of it is not reached as well as people expected. This situation is mostly due to the supporting technology especially the infrastructure. Today, great changes have taken place in technology, including grid computing and Web services. These technologies, we think, significantly affect the application of CSCW. In this paper, a framework called CoFrame is proposed to answer the challenges faced by CSCW. Based on the emerging grid and Web service technologies, CoFrame provides some general yet flexible cooperation related services and organizes them into different layers. The elaborately designed services and architecture make CoFrame adaptive to diverse requirements of different domains. The paper details the framework and demonstrates its application with a case study in e-learning.",
    "abstract_processed": "though year pass sinc birth cscw origin goal reach well peopl expect situat mostli due support technolog especi infrastructur today great chang taken place technolog includ grid comput web servic technolog think significantli affect applic cscw paper framework call cofram propos answer challeng face cscw base emerg grid web servic technolog cofram provid gener yet flexibl cooper relat servic organ differ layer elabor design servic architectur make cofram adapt divers requir differ domain paper detail framework demonstr applic case studi e learn"
  },
  {
    "doc_id": "1532840",
    "abstract_original": "Topological concepts and techniques have been broadly applied in computer graphics and geometric modeling. However, the homotopy type of a mapping between two surfaces has not been addressed before. In this paper, we present a novel solution to the problem of computing continuous maps with different homotopy types between two arbitrary triangle meshes with the same topology. Inspired by the rich theory of topology as well as the existing body of work on surface mapping, our newly-developed mapping techniques are both fundamental and unique, offering many attractive advantages. First, our method allows the user to change the homotopy type or global structure of the mapping with minimal intervention. Moreover, to locally affect shape correspondence, we articulate a new technique that robustly satisfies hard feature constraints, without the use of heuristics to ensure validity. In addition to acting as a useful tool for computer graphics applications, our method can be used as a rigorous and practical mechanism for the visualization of abstract topological concepts such as homotopy type of surface mappings, homology basis, fundamental domain, and universal covering space. At the core of our algorithm is a procedure for computing the canonical homology basis and using it as a common cut graph for any surface with the same topology. We demonstrate our results by applying our algorithm to shape morphing in this paper.",
    "abstract_processed": "topolog concept techniqu broadli appli comput graphic geometr model howev homotopi type map two surfac address paper present novel solut problem comput continu map differ homotopi type two arbitrari triangl mesh topolog inspir rich theori topolog well exist bodi work surfac map newli develop map techniqu fundament uniqu offer mani attract advantag first method allow user chang homotopi type global structur map minim intervent moreov local affect shape correspond articul new techniqu robustli satisfi hard featur constraint without use heurist ensur valid addit act use tool comput graphic applic method use rigor practic mechan visual abstract topolog concept homotopi type surfac map homolog basi fundament domain univers cover space core algorithm procedur comput canon homolog basi use common cut graph surfac topolog demonstr result appli algorithm shape morph paper"
  },
  {
    "doc_id": "1544759",
    "abstract_original": "In this paper, we offer an approach to software evolvability based on our wrapping infrastructure for integration in constructed complex systems. We believe that the self-modeling systems that we have built using wrappings may be able to manage their own evolution to some extent. In a wrapping-based system, the design decisions are visible in the resource definitions, with the associated context assumptions, so it is much easier to change them. We expect such a system to build and examine models of its environment, and its behavior in the environment, to check them against the specifications that define the assumptions about the use of the system, so it can call for help when they are violated. We also think we can build the system to make the changes itself in some cases. In particular, there is a class of system change causes that are known to the original system designers (usually based on uncertainties about the environment or the current state of hardware components), and the system can be built with enough information to react to those changes accordingly.",
    "abstract_processed": "paper offer approach softwar evolv base wrap infrastructur integr construct complex system believ self model system built use wrap may abl manag evolut extent wrap base system design decis visibl resourc definit associ context assumpt much easier chang expect system build examin model environ behavior environ check specif defin assumpt use system call help violat also think build system make chang case particular class system chang caus known origin system design usual base uncertainti environ current state hardwar compon system built enough inform react chang accordingli"
  },
  {
    "doc_id": "1547239",
    "abstract_original": "Granular computing emerges as a new multi-disciplinary study and has received much attention in recent years. A conceptual framework is presented by extracting shared commonalities from many fields. The framework stresses multiple views and multiple levels of understanding in each view. It is argued that granular computing is more about a philosophical way of thinking and a practical methodology of problem solving. By effectively using levels of granularity, granular computing provides a systematic, natural way to analyze, understand, represent, and solve real world problems. With granular computing, one aims at structured thinking at the philosophical level, and structured problem solving at the practical level.",
    "abstract_processed": "granular comput emerg new multi disciplinari studi receiv much attent recent year conceptu framework present extract share common mani field framework stress multipl view multipl level understand view argu granular comput philosoph way think practic methodolog problem solv effect use level granular granular comput provid systemat natur way analyz understand repres solv real world problem granular comput one aim structur think philosoph level structur problem solv practic level"
  },
  {
    "doc_id": "1554326",
    "abstract_original": "In this research, we show two experiments using non-verbal interaction. We think nonverbal communication is basic, and important for communication between human. Moreover, We focus on the networked robotics which is fusion of network technology and robot technology. We constructed nonverbal interface by using human natural motion. In the first experiment, we created commands using hand motion which is based on natural motion, such as beckoning, hissing away and so on. We constructed robot manipulation system using these commands. Furthermore, we compared the user-friendly of our system with present keyboard manipulation system. In the second experiment, in order to manipulate a robot using more natural motion, we proposed 'pointing movement'. Moreover, we constructed networked robots that recognizes human motion spatially. Accordingly, the user was able to manipulate the robot with more natural motion in larger space.",
    "abstract_processed": "research show two experi use non verbal interact think nonverb commun basic import commun human moreov focu network robot fusion network technolog robot technolog construct nonverb interfac use human natur motion first experi creat command use hand motion base natur motion beckon hiss away construct robot manipul system use command furthermor compar user friendli system present keyboard manipul system second experi order manipul robot use natur motion propos point movement moreov construct network robot recogn human motion spatial accordingli user abl manipul robot natur motion larger space"
  },
  {
    "doc_id": "1554342",
    "abstract_original": "In this paper, we introduce a reinforcement learning method for autonomous robots to obtain generalized behavioral concepts. Reinforcement learning is a well formulated method for autonomous robots to obtain a new behavioral concept by themselves. However, these behavioral concepts cannot be applied to other environments that are different from the place where the robots have learned the concepts. On the contrary, we, human beings, can apply our behavioral concepts to some different environments, objects, and/or situations. We think this ability owes to some memory structure like schema system that was originally proposed by J. Piaget. We previously proposed a modular-learning method called Dual-Schemata model. In this paper, we add a reinforcement learning mechanism to this model. By being provided with this structure, autonomous robots become able to obtain new generalized behavioral concepts by themselves. We also show this kind of structure enables autonomous robots to behave appropriately even in a novel socially interactive environment.",
    "abstract_processed": "paper introduc reinforc learn method autonom robot obtain gener behavior concept reinforc learn well formul method autonom robot obtain new behavior concept howev behavior concept cannot appli environ differ place robot learn concept contrari human be appli behavior concept differ environ object situat think abil owe memori structur like schema system origin propos j piaget previous propos modular learn method call dual schemata model paper add reinforc learn mechan model provid structur autonom robot becom abl obtain new gener behavior concept also show kind structur enabl autonom robot behav appropri even novel social interact environ"
  },
  {
    "doc_id": "1565550",
    "abstract_original": "Spatial agents are widely involved in robotics, simulated situations in GIS and virtual environment. Most of these agents are controlled by high-level natural language instructions or driven by limited natural language stories coming from real people. This kind of spatial information is usually qualitative rather than quantitative and is often incomplete according to the human spatial cognitive nature. This paper presents an approach to qualitative spatial orientation reasoning in 3-dimensional spatial environment. Signs in three components represent qualitative orientations in 3D space with respect to each spatial agent. By using sign algebra and efficient methods for dealing with uncertainties, the paper proposes a method for qualitative orientation reasoning between different reference agents, from which an analytical mechanism is built. The presented method can be integrated into the perception-deliberation-action control loop in spatial agent environment.",
    "abstract_processed": "spatial agent wide involv robot simul situat gi virtual environ agent control high level natur languag instruct driven limit natur languag stori come real peopl kind spatial inform usual qualit rather quantit often incomplet accord human spatial cognit natur paper present approach qualit spatial orient reason dimension spatial environ sign three compon repres qualit orient space respect spatial agent use sign algebra effici method deal uncertainti paper propos method qualit orient reason differ refer agent analyt mechan built present method integr percept deliber action control loop spatial agent environ"
  },
  {
    "doc_id": "1567117",
    "abstract_original": "For the coding bit-rate control problem on the H.264 wireless video communication, on the basis of in-depth rate-distortion theory analysis, this paper researches current common rate distortion computation model, establish the relationship between the total distortion statistics measurement, the coding bit-rate measurement, the quantization parameter and the macro block intra frame refresh rate, and put forward new associated error control and code-rate control thinking. This method not only can acquire the optimal control point in the rate-distortion curve from the global perspective under the code error environment, but also can self-adaptive adjust the bit allocation and the quantization parameter under given network bandwidth. Furthermore, it can also implement intra frame macro block refresh at the same time and play important role in counteracting the channel code error to minimize the total distortion under certain bit-rated according to current network package loss probability, by which to establish the rate-distortion model of associated signal source channel and apply the rate-distortion optimized solution method to optimal allocate the bit-rate between the signal source coding and the channel coding. This method can provide valuable reference for the video robust coding transmission and resource allocation under the wireless environment.",
    "abstract_processed": "code bit rate control problem h wireless video commun basi depth rate distort theori analysi paper research current common rate distort comput model establish relationship total distort statist measur code bit rate measur quantiz paramet macro block intra frame refresh rate put forward new associ error control code rate control think method acquir optim control point rate distort curv global perspect code error environ also self adapt adjust bit alloc quantiz paramet given network bandwidth furthermor also implement intra frame macro block refresh time play import role counteract channel code error minim total distort certain bit rate accord current network packag loss probabl establish rate distort model associ signal sourc channel appli rate distort optim solut method optim alloc bit rate signal sourc code channel code method provid valuabl refer video robust code transmiss resourc alloc wireless environ"
  },
  {
    "doc_id": "1572260",
    "abstract_original": "As the power of computational grids increases, there is a corresponding need for better usability in PSE community. In this paper, we describe our experiences on design of project GridPSi, a grid-enabled PSE for physical simulation. GridPSi provides a rich suite of functions that facilitate the composition of computational scripts to automate physical simulations by design domain-specific templates for a verity of research fields. The generic functionality provided by it includes problem modeling, mesh file conversion, computational script generation, solution scheme specification and access to grid resources. GridPSi offers a simple interface that is intuitive to users in the human-PSE interactions and ways of thinking. Furthermore, we developed higher-level graphical components named PDE wizards that build upon the core functions to guide users through problem modeling process with minimum effort. By using Unicore as grid middleware, we are lowering the barriers to entry for users wishing to exploit grid technologies",
    "abstract_processed": "power comput grid increas correspond need better usabl pse commun paper describ experi design project gridpsi grid enabl pse physic simul gridpsi provid rich suit function facilit composit comput script autom physic simul design domain specif templat veriti research field gener function provid includ problem model mesh file convers comput script gener solut scheme specif access grid resourc gridpsi offer simpl interfac intuit user human pse interact way think furthermor develop higher level graphic compon name pde wizard build upon core function guid user problem model process minimum effort use unicor grid middlewar lower barrier entri user wish exploit grid technolog"
  },
  {
    "doc_id": "1574323",
    "abstract_original": "Since 1967, the Winter Simulation Conference has been a forum for the introduction of innovative approaches to effectively analyze discrete-event simulation experiments. The goal of this panel is to bring together key contributors to analysis methodology research in order to clarify areas that they think are essentially complete, and identify areas that need more work. In doing so, we hope to help provide direction to younger researchers looking for the \"right\" problems to work on.",
    "abstract_processed": "sinc winter simul confer forum introduct innov approach effect analyz discret event simul experi goal panel bring togeth key contributor analysi methodolog research order clarifi area think essenti complet identifi area need work hope help provid direct younger research look right problem work"
  },
  {
    "doc_id": "1574548",
    "abstract_original": "This paper presents the road towards multi-hypothesis intention simulation agents architecture and is focused on the fractal information fusion model (FIF) that are formed to support a systems-thinking in an agent architecture that aligns with the global information grid, NATO net enabled capabilities and Swedish armed force enterprise architecture initiatives. The Joint Directors of Laboratories information fusion model and the Observe, Orient, Decide, Act loop by John Boyd is combined and used as the foundation together with the knowledge model, level of conceptual interoperability shaping the FIF-model. The FIF-model's effect in shaping of the multi-hypothesis intention simulation agents architecture is presented",
    "abstract_processed": "paper present road toward multi hypothesi intent simul agent architectur focus fractal inform fusion model fif form support system think agent architectur align global inform grid nato net enabl capabl swedish arm forc enterpris architectur initi joint director laboratori inform fusion model observ orient decid act loop john boyd combin use foundat togeth knowledg model level conceptu interoper shape fif model fif model effect shape multi hypothesi intent simul agent architectur present"
  },
  {
    "doc_id": "1582903",
    "abstract_original": "Interchange formats are notoriously difficult to finish. That is, once one is developed, it is highly nontrivial to prove (or disprove) generality, and difficult at best to gain acceptance from all major players in the application domain. This paper addresses such a problem for hybrid systems, but not from the perspective of a tool interchange format, but rather that of tool availability in a toolbox. Through the paper we explain why we think this is a good approach for hybrid systems, and we also analyze the domain of hybrid systems to discern the semantic partitions that can be formed to yield a classification of tools based on their semantics. These discoveries give us the foundation upon which to build semantic capabilities, and to guarantee operational interaction between tools based on matched operational semantics.",
    "abstract_processed": "interchang format notori difficult finish one develop highli nontrivi prove disprov gener difficult best gain accept major player applic domain paper address problem hybrid system perspect tool interchang format rather tool avail toolbox paper explain think good approach hybrid system also analyz domain hybrid system discern semant partit form yield classif tool base semant discoveri give us foundat upon build semant capabl guarante oper interact tool base match oper semant"
  },
  {
    "doc_id": "1589650",
    "abstract_original": "Recent technological advances have made it possible to support long lifetime and large volume streaming data transmissions in sensor networks. A major challenge is to maximize the lifetime of battery-powered sensors to support such transmissions. Battery, as the power provider of the sensors, therefore emerges as the key factor for achieving high performance in such applications. Recent study in battery technology reveals that the behavior of battery discharging is more complex than we used to think. Battery powered sensors might waste a huge amount of energy if we do not carefully schedule and budget their discharging. In this paper we study the effect of battery behavior on routing for streaming data transmissions in wireless sensor networks. We first give an on-line computable energy model to mathematically model battery discharge behavior. We show that the model can capture and describe battery behavior accurately at low computational complexity and thus is suitable for on-line battery capacity computation. Based on this battery model we then present a battery-aware routing (BAR) protocol to schedule the routing in wireless sensor networks. The routing protocol is sensitive to the battery status of routing nodes and avoids energy loss. We use the battery data from actual sensors to evaluate the performance of our protocol. The results show that the battery-aware protocol proposed in this paper performs well and can save a significant amount of energy compared to existing routing protocols for streaming data transmissions. The network lifetime is also prolonged with maximum data throughput. As far as we know; this is the first work considering battery-awareness with an accurate analytical on-line computable battery model in sensor network routing. We believe our battery model can be used to explore other energy efficient schemes for wireless networks as well.",
    "abstract_processed": "recent technolog advanc made possibl support long lifetim larg volum stream data transmiss sensor network major challeng maxim lifetim batteri power sensor support transmiss batteri power provid sensor therefor emerg key factor achiev high perform applic recent studi batteri technolog reveal behavior batteri discharg complex use think batteri power sensor might wast huge amount energi care schedul budget discharg paper studi effect batteri behavior rout stream data transmiss wireless sensor network first give line comput energi model mathemat model batteri discharg behavior show model captur describ batteri behavior accur low comput complex thu suitabl line batteri capac comput base batteri model present batteri awar rout bar protocol schedul rout wireless sensor network rout protocol sensit batteri statu rout node avoid energi loss use batteri data actual sensor evalu perform protocol result show batteri awar protocol propos paper perform well save signific amount energi compar exist rout protocol stream data transmiss network lifetim also prolong maximum data throughput far know first work consid batteri awar accur analyt line comput batteri model sensor network rout believ batteri model use explor energi effici scheme wireless network well"
  },
  {
    "doc_id": "1592036",
    "abstract_original": "In this paper, we present our findings of investigating non-linear multi-target tracking techniques when jointly used with object classification. The transferable belief model (TBM) is utilized in the multi-target evaluation, data association, and target classification stages. A particle filter is used to track each of the targets and uses a motion model that is relevant to the classification given to that target. The targets are classified based upon their motion throughout the scene and their land based position. We show how this system can deal with prior knowledge and lack of knowledge. Situations, with data of this type, regularly occur in real world scenarios and we think it is very important that any system must be able to cope well to such situations. Bayesian and regular DST methods have shortcomings when dealing with such scenarios. We show that the TBM approach can be generally more computational tractable and more robust.",
    "abstract_processed": "paper present find investig non linear multi target track techniqu jointli use object classif transfer belief model tbm util multi target evalu data associ target classif stage particl filter use track target use motion model relev classif given target target classifi base upon motion throughout scene land base posit show system deal prior knowledg lack knowledg situat data type regularli occur real world scenario think import system must abl cope well situat bayesian regular dst method shortcom deal scenario show tbm approach gener comput tractabl robust"
  },
  {
    "doc_id": "1592083",
    "abstract_original": "The online content market for music is changing rapidly with the spread of technology and innovative business models. It is difficult for suppliers of online content to anticipate these developments and the effects of their businesses. The paper describes a multi-agent simulation to model possible scenarios in this market and argues that agent-based modeling can be a useful tool in thinking about future developments in these markets. It demonstrates this by applying the model to two simple scenarios of interest in the domain, the disintermediation of the value chain in the Internet and the lock-in of consumers to Apple's iTunes download platform.",
    "abstract_processed": "onlin content market music chang rapidli spread technolog innov busi model difficult supplier onlin content anticip develop effect busi paper describ multi agent simul model possibl scenario market argu agent base model use tool think futur develop market demonstr appli model two simpl scenario interest domain disintermedi valu chain internet lock consum appl itun download platform"
  },
  {
    "doc_id": "1592597",
    "abstract_original": "The High Performance Fortran language is a 'standard by consensus', developed by individuals and vendors in the high performance computing industry, to provide a low barrier entry to parallel computing. It promises to be an easier to use development environment for distributed memory computing platforms compared to the programming complexity required by message passing libraries such as PVM and MPI. HPF promises much and is still in its infancy. Since HPF was developed in part based on experiences gained with early parallel Fortran compilers such as Thinking Machines CM Fortran, we decided to test the effectiveness of HPF with today's generation of HPF compilers by porting a complex existing model code originally developed using CM Fortran. The model code that we selected is a hybrid computational aeroacoustics code that solves the 3D, time-dependent Euler equations in the near flow field and uses a moving surface Kirchhoff's formula to predict the far field sound radiating from turbofan engine inlets. The original CM Fortran model code was developed on a Thinking Machines CM5. The extensive production research use of this model, using varying grid sizes, provides excellent benchmarks with which to compare the HPF port. Two HPF compilers were selected in the porting effort -- The Portland Group's (PGI) pghpf and the xlhpf compiler from IBM. IBM's xlhpf does not implement some elements of the HPF subset while PGI's offering provides several full-HPF extensions. porting efforts using each compiler exposed the strengths and weaknesses of each. Porting this complex code exposed many of the growing pains associated with the current generation of compilers. Critical sections of the code will be explained and these critical areas of the conversion effort will be discussed. Where necessary we will demonstrate how different porting strategies affected the performance of the code. Finally we will present how the ported code ran, using a varying number of processors, on an IBM SP2 and an SGI Origin 2000. While the current simple port does not match the speed of a CM-5, we hope further porting efforts and improved compiler technology will enable us to eventually match and then surpass CM-5 performance levels. With the shutdown of the NCSA CM-5 and the eventual removal and failure of the remaining Thinking Machines hardware currently installed, this effort will demonstrate that investments in CM Fortran code need not be abandoned and that new life can be breathed into those dusty decks.",
    "abstract_processed": "high perform fortran languag standard consensu develop individu vendor high perform comput industri provid low barrier entri parallel comput promis easier use develop environ distribut memori comput platform compar program complex requir messag pass librari pvm mpi hpf promis much still infanc sinc hpf develop part base experi gain earli parallel fortran compil think machin cm fortran decid test effect hpf today gener hpf compil port complex exist model code origin develop use cm fortran model code select hybrid comput aeroacoust code solv time depend euler equat near flow field use move surfac kirchhoff formula predict far field sound radiat turbofan engin inlet origin cm fortran model code develop think machin cm extens product research use model use vari grid size provid excel benchmark compar hpf port two hpf compil select port effort portland group pgi pghpf xlhpf compil ibm ibm xlhpf implement element hpf subset pgi offer provid sever full hpf extens port effort use compil expos strength weak port complex code expos mani grow pain associ current gener compil critic section code explain critic area convers effort discuss necessari demonstr differ port strategi affect perform code final present port code ran use vari number processor ibm sp sgi origin current simpl port match speed cm hope port effort improv compil technolog enabl us eventu match surpass cm perform level shutdown ncsa cm eventu remov failur remain think machin hardwar current instal effort demonstr invest cm fortran code need abandon new life breath dusti deck"
  },
  {
    "doc_id": "1595854",
    "abstract_original": "Emotions have been shown to have an important role on several human processes such as decision-making, planning, cognition, and, in particular, learning. However, many e-learning systems disregard the emotional aspects of the learning process and the impact of these aspects on the student's performance. The paper presents an intelligent agent with synthesized emotions that influence its beliefs, desires, and intentions in order to drive the agent behavior. Based on this model, we propose an artificial tutor, integrated in an e-learning system, which develops lectures plans and tailors its behavior towards the student according to the student reactions and his/her presumed affective states.",
    "abstract_processed": "emot shown import role sever human process decis make plan cognit particular learn howev mani e learn system disregard emot aspect learn process impact aspect student perform paper present intellig agent synthes emot influenc belief desir intent order drive agent behavior base model propos artifici tutor integr e learn system develop lectur plan tailor behavior toward student accord student reaction presum affect state"
  },
  {
    "doc_id": "1602314",
    "abstract_original": "The release of WSRF showed that an OGSA infrastructure of stateful WS-Resources could be built on top of plain WSDL, while retaining Web services as stateless entities. This Grid and SOA convergence allows developers to focus on enrich descriptions with current Semantic Web services technologies (SWS), whereas WSRF and WSNotification provide the mechanisms to build stateful and distributed architectures. However, we think a direct exportation of SWS interfaces to describe WS-Resources would be of limited value, due to property changes are not properly captured with static profiles, and current WSRF lacks of semantic features. We propose a topic-based modeling of WS-Resource capabilities, along with simple WSRF and WSNotification extensions to achieve 'semantic-by-design' WS-Resource descriptions. We also illustrate how these enhancements can be applied to our Semantic Web Data Sources Integrated Architecture (DAWIS), allowing dynamic matching and discovering of Semantic WSResources.",
    "abstract_processed": "releas wsrf show ogsa infrastructur state ws resourc could built top plain wsdl retain web servic stateless entiti grid soa converg allow develop focu enrich descript current semant web servic technolog sw wherea wsrf wsnotif provid mechan build state distribut architectur howev think direct export sw interfac describ ws resourc would limit valu due properti chang properli captur static profil current wsrf lack semant featur propos topic base model ws resourc capabl along simpl wsrf wsnotif extens achiev semant design ws resourc descript also illustr enhanc appli semant web data sourc integr architectur dawi allow dynam match discov semant wsresourc"
  },
  {
    "doc_id": "1611585",
    "abstract_original": "The accepted view of programming, rooted in Turing's fundamental characterization of algorithms, has had a profound impact on the theory and practice of computing with yet broader implications for thinking about mind and culture. Where programming is traditionally conceived in terms of requirements, specification and implementation, this paper argues for a complementary conceptualization to support the development of the next generation of computing applications. It briefly reviews an extended programme of research into empirical modeling, an approach to creating interactive environments to enable programming based on identification and prescription",
    "abstract_processed": "accept view program root ture fundament character algorithm profound impact theori practic comput yet broader implic think mind cultur program tradit conceiv term requir specif implement paper argu complementari conceptu support develop next gener comput applic briefli review extend programm research empir model approach creat interact environ enabl program base identif prescript"
  },
  {
    "doc_id": "1614899",
    "abstract_original": "\"SoftMan\" coordination is developed from the traditional computing method, it not only exhibits those agent's features, such as autonomous, intelligent, mobile, but also applies the method of AL, and extends the distributed computing. The main advantages of the \"SoftMan\" paradigm lie in its ability to fully utilize network resources and to provide the best service for mobile customer. A novel digital gas fields real-time produce scheduling system (DGRPS) is presented, which is based on the theory of \"SoftMan\" coordination. The system architecture and software structure of DGRPS was put forward. The result of system simulation demonstrates that it is an effective method. At last, we give a novel thinking about the development of \"SoftMan\" system and forecast its research trend in near the future",
    "abstract_processed": "softman coordin develop tradit comput method exhibit agent featur autonom intellig mobil also appli method al extend distribut comput main advantag softman paradigm lie abil fulli util network resourc provid best servic mobil custom novel digit ga field real time produc schedul system dgrp present base theori softman coordin system architectur softwar structur dgrp put forward result system simul demonstr effect method last give novel think develop softman system forecast research trend near futur"
  },
  {
    "doc_id": "1620788",
    "abstract_original": "Fast, accurate, and effective performance analysis is essential for the design of modern processor architectures and improving application performance. Recent trends toward highly concurrent processors make this goal increasingly difficult. Conventional techniques, based on simulators and performance monitors, are ill-equipped to analyze how a plethora of concurrent events interact and how they affect performance. Prior research has shown the utility of critical path analysis in solving this problem. This analysis abstracts the execution of a program with a dependence graph. With simple manipulations on the graph, designers can gain insights into the bottlenecks of a design. This paper extends critical path analysis to understand the performance of a next-generation, high-ILP architecture. The TRIPS architecture introduces new features not present in conventional superscalar architectures. We show how dependence constraints introduced by these features, specifically the execution model and operand communication links, can be modeled with a dependence graph. We describe a new algorithm that tracks critical path information at a fine-grained level and yet can deliver an order of magnitude (30x) improvement in performance over previously proposed techniques. Finally, we provide a breakdown of the critical path for a select set of benchmarks and show an example where we use this information to improve the performance of a heavily-hand-optimized program by as much as 11%.",
    "abstract_processed": "fast accur effect perform analysi essenti design modern processor architectur improv applic perform recent trend toward highli concurr processor make goal increasingli difficult convent techniqu base simul perform monitor ill equip analyz plethora concurr event interact affect perform prior research shown util critic path analysi solv problem analysi abstract execut program depend graph simpl manipul graph design gain insight bottleneck design paper extend critic path analysi understand perform next gener high ilp architectur trip architectur introduc new featur present convent superscalar architectur show depend constraint introduc featur specif execut model operand commun link model depend graph describ new algorithm track critic path inform fine grain level yet deliv order magnitud x improv perform previous propos techniqu final provid breakdown critic path select set benchmark show exampl use inform improv perform heavili hand optim program much"
  },
  {
    "doc_id": "1623647",
    "abstract_original": "We were requested to predict the future specifications of the electronic materials, electronic packages and micro processors for high performance computer systems going as far out as the year 2000 and beyond. These were to be based on the emerging requirements of the end users. Literature and conferences yielded very little quantitative data. As a result, we understood to design and develop a deterministic and macroscopic model based on physics, math, VLSI design, architecture and integration level considerations. The resulting model transcended the electronic world from system performance to microprocessor description to packaging specifications and required material's specifications. Based on this model, it is likely, that the world will see an integration of 100 million transistors on a single chip providing clock frequencies approaching 213 MHz and CPU power near about 238 MIPS. Transportation is a major business for Alcoa. We have used our model to examine what architectural directions the Mobile 2000 would take for satisfying its command and control, navigational, entertainment, communication, engine, transmission and body/cockpit control and management systems. A scenario is developed based on the current and emerging requirements for the above functions leading to the automobile of the year 2000. This is then translated to yield control and system requirements which then are converted to the total computational requirements. The requirements are used to define the future system specifications based on our model's predictions. Alternative architectures are then presented. Cautions and caveats are discussed based on our experience on several large scale Computer Integrated Manufacturing (CIM) networks', design development and implementation. It is imperative to bring the large scale systems thinking to Mobile 2000's automation and support systems so that the classical pitfalls of cost, performance, lack of planning, ad hoc and proliferation of incompatible systems does not take place in this exciting arena.",
    "abstract_processed": "request predict futur specif electron materi electron packag micro processor high perform comput system go far year beyond base emerg requir end user literatur confer yield littl quantit data result understood design develop determinist macroscop model base physic math vlsi design architectur integr level consider result model transcend electron world system perform microprocessor descript packag specif requir materi specif base model like world see integr million transistor singl chip provid clock frequenc approach mhz cpu power near mip transport major busi alcoa use model examin architectur direct mobil would take satisfi command control navig entertain commun engin transmiss bodi cockpit control manag system scenario develop base current emerg requir function lead automobil year translat yield control system requir convert total comput requir requir use defin futur system specif base model predict altern architectur present caution caveat discuss base experi sever larg scale comput integr manufactur cim network design develop implement imper bring larg scale system think mobil autom support system classic pitfal cost perform lack plan ad hoc prolifer incompat system take place excit arena"
  },
  {
    "doc_id": "1630243",
    "abstract_original": "The ongoing liberalisation of the power sector adds a new dimension to the main issues in modelling of power systems. The very complex interactions and interdependencies among power market participants are much like those studied in game theory. However, the strategies used by market participants are often too complex to be conveniently modelled by standard game theoretic techniques. In addition, there has been much less research in the field of dynamic strategic behaviour and their impact on the electricity price in European markets. In this paper, we show new, prosperous combination of computational science and new ideas in evolutionary economics and cognitive science offering appealing extensions to traditional game theoretical modelling. We demonstrate the feasibility of implementing our approach in Matlab using learning algorithm and illustrate its advantages in more detailed and realistic representation of the strategic behaviour of biggest power producers in European power market.",
    "abstract_processed": "ongo liberalis power sector add new dimens main issu model power system complex interact interdepend among power market particip much like studi game theori howev strategi use market particip often complex conveni model standard game theoret techniqu addit much less research field dynam strateg behaviour impact electr price european market paper show new prosper combin comput scienc new idea evolutionari econom cognit scienc offer appeal extens tradit game theoret model demonstr feasibl implement approach matlab use learn algorithm illustr advantag detail realist represent strateg behaviour biggest power produc european power market"
  },
  {
    "doc_id": "1630728",
    "abstract_original": "The simulation of computer networks requires accurate models of user behavior. To this end, we present empirical models of end-user network traffic derived from the analysis of NETI@home data. There are two forms of models presented. The first models traffic for a specific TCP or UDP port. The second models all TCP or UDP traffic for an end-user. These models are meant to be network- independent and contain aspects such as bytes sent, bytes received, and user think time. The empirical models derived in this study can then be used to enable more realistic simulations of computer networks.",
    "abstract_processed": "simul comput network requir accur model user behavior end present empir model end user network traffic deriv analysi neti home data two form model present first model traffic specif tcp udp port second model tcp udp traffic end user model meant network independ contain aspect byte sent byte receiv user think time empir model deriv studi use enabl realist simul comput network"
  },
  {
    "doc_id": "1630958",
    "abstract_original": "Service Oriented EXtensible Modeling and Simulation Supporting Environment Architecture (SO-XMSSEA) is presented based on XMSF thinking and the new technology development of web service and grid. Simulation Service Bus (SSB) is the underlying infrastructure to take charge of services communicating in SO-XMSSEA including message dispatch, integration, services interaction, management with services quality and security, and adaptation with other domain applications. We introduce the main mechanism of SSB structure and survey the communication and data transferring between clients and server. As the most important approach for composing HLA systems, the core module of SO-RTI Server and System Integration Server are discussed in detail. WSRF based grid technology is selected to construct prototype SSB implementation. A test HLA system based on SSB shows the interoperability on heterogeneous systems so that different types of systems can communicate smoothly through WAN and makes more facility to maintain and evolve.",
    "abstract_processed": "servic orient extens model simul support environ architectur xmssea present base xmsf think new technolog develop web servic grid simul servic bu ssb underli infrastructur take charg servic commun xmssea includ messag dispatch integr servic interact manag servic qualiti secur adapt domain applic introduc main mechan ssb structur survey commun data transfer client server import approach compos hla system core modul rti server system integr server discuss detail wsrf base grid technolog select construct prototyp ssb implement test hla system base ssb show interoper heterogen system differ type system commun smoothli wan make facil maintain evolv"
  },
  {
    "doc_id": "1631269",
    "abstract_original": "The emergence of e-commerce has changed the way business is done world-wide. Opportunities have arisen for initiating new international and domestic business ventures. As individuals and businesses increase information sharing, vulnerability to attack or intrusion rises. Therefore, security is a necessity in an ecommerce transaction. The purpose of this paper is to investigate and present the new approach to ecommerce security. Our philosophy is to look for significantly new Paradigms and shifts from previous thinking, and facilitates the debate within a constructive environment of new approaches to existing and on going global problems of tackling security issues in ecommerce.",
    "abstract_processed": "emerg e commerc chang way busi done world wide opportun arisen initi new intern domest busi ventur individu busi increas inform share vulner attack intrus rise therefor secur necess ecommerc transact purpos paper investig present new approach ecommerc secur philosophi look significantli new paradigm shift previou think facilit debat within construct environ new approach exist go global problem tackl secur issu ecommerc"
  },
  {
    "doc_id": "1631376",
    "abstract_original": "Experience is showing several problems with use cases such as lack of a precise definition that led some companies to develop their own version, lack of notion of atomicity, and considering only the user interface. If the analyst misinterpreted or neglected some structural or behavioral aspects, the resulting software system may not display the correct behavior or may ungracefully terminate. The use of events in the behavioral pattern analysis approach (BPA) provides cohesive integration between the static abstraction (classes) and the dynamic behavior. This integration may partially or totally eliminate the pre-mentioned problems. This paper presents the use of BPA to model a robot system in a manufacturing setting",
    "abstract_processed": "experi show sever problem use case lack precis definit led compani develop version lack notion atom consid user interfac analyst misinterpret neglect structur behavior aspect result softwar system may display correct behavior may ungrac termin use event behavior pattern analysi approach bpa provid cohes integr static abstract class dynam behavior integr may partial total elimin pre mention problem paper present use bpa model robot system manufactur set"
  },
  {
    "doc_id": "1631394",
    "abstract_original": "Agent-Based Geographical Information System (ABGIS) could be characterized as a kind of system integrating features commonly found in Geographical Information System and in Agent-Based Simulation Tools. ABGIS provides a powerful simulation tool and an envyronment that is an excelent metaphor to represent our spatio-temporal world. With ABGIS we could explore the dynamics of spatio-temporal systems, particularly, but not exclusively, complex systems. It is possible to simulate complex systems having as a starting point only simple elements (agents), embedded in some type of environment. These agents can inter-act which each other in only specific and very simple ways. As the result of the interaction among the agents and the environment, the behavior of the complex system at macrocosmic level then emerges. According this line of thinking, there are a lot of social, biological, and ecological processes that can be simulated by agent-based models [1],[2]. In this article we give a general description of the desirable capabilities of ABSGIS, describing some features it should incorporate, and presenting some examples that could explore this kind of tool.",
    "abstract_processed": "agent base geograph inform system abgi could character kind system integr featur commonli found geograph inform system agent base simul tool abgi provid power simul tool envyron excel metaphor repres spatio tempor world abgi could explor dynam spatio tempor system particularli exclus complex system possibl simul complex system start point simpl element agent embed type environ agent inter act specif simpl way result interact among agent environ behavior complex system macrocosm level emerg accord line think lot social biolog ecolog process simul agent base model articl give gener descript desir capabl absgi describ featur incorpor present exampl could explor kind tool"
  },
  {
    "doc_id": "1631435",
    "abstract_original": "Presents abstracts of papers presented at the conference proceedings.",
    "abstract_processed": "present abstract paper present confer proceed"
  },
  {
    "doc_id": "1637974",
    "abstract_original": "The design, realization, and application of intelligent, autonomous, sensor-driven, behavior-based robotic agents are discussed. The authors have identified four philosophical goals for machine intelligence grounded in reality to flourish: integration, real-world issues, interdisciplinary teamwork, and critical thinking. Building a robot requires that the designer integrates control in electronic and mechanical systems and produces a working device, confronts the user with interactions, between different subsystems, and gives the designer the opportunity to trade off between the different subsystems in constructing an autonomous agent. The environment also encourages biomedical engineers to confront the issues involved in getting a physical agent to operate reliably in a realistic environment by giving them the opportunity to build their own animal, providing a unique perspective on the many problems that nervous systems actually solve.",
    "abstract_processed": "design realiz applic intellig autonom sensor driven behavior base robot agent discuss author identifi four philosoph goal machin intellig ground realiti flourish integr real world issu interdisciplinari teamwork critic think build robot requir design integr control electron mechan system produc work devic confront user interact differ subsystem give design opportun trade differ subsystem construct autonom agent environ also encourag biomed engin confront issu involv get physic agent oper reliabl realist environ give opportun build anim provid uniqu perspect mani problem nervou system actual solv"
  },
  {
    "doc_id": "1648335",
    "abstract_original": "The contemporary idea for interaction has embraced new understandings of the content of experience and the structure of space. New electronic technologies and advanced digital media have separated realities from the realm of the body and transformed experiences into ubiquitous events. The architectural discourse, once largely a discourse of form and style, has overcome these limitations and encountered, in territories of information, the product of a new way of thinking. Marcos Novak emerges in this context of multimedia as an innovative creator whose \"liquid architectures\" represent a break with the traditional discourse of physicality. His creations",
    "abstract_processed": "contemporari idea interact embrac new understand content experi structur space new electron technolog advanc digit media separ realiti realm bodi transform experi ubiquit event architectur discours larg discours form style overcom limit encount territori inform product new way think marco novak emerg context multimedia innov creator whose liquid architectur repres break tradit discours physic creation"
  },
  {
    "doc_id": "1663811",
    "abstract_original": "Smooth Skinning is still the most popular method for the animation of deformable human and creature characters. It has became almost an industry standard because of its intuitiveness to use and efficiency to compute. However it suffers from a number of problems, such as the collapsing elbow and candywrapper effect. In this paper, we present a new method, which is able to solve these defects with very little extra stretching computations. The advantage of this method is its compatibility with the current animation workflow. The animator can change the skin weight any way they like and therefore it favours creativity. The aim of our method is trying to retain the realism and computational efficiency at the same time. It is suitable for situations, where real time response is necessary, like computer games. A practical implementation in the form of a Maya plug-in is created to demonstrate the viability of the method.",
    "abstract_processed": "smooth skin still popular method anim deform human creatur charact becam almost industri standard intuit use effici comput howev suffer number problem collaps elbow candywrapp effect paper present new method abl solv defect littl extra stretch comput advantag method compat current anim workflow anim chang skin weight way like therefor favour creativ aim method tri retain realism comput effici time suitabl situat real time respons necessari like comput game practic implement form maya plug creat demonstr viabil method"
  },
  {
    "doc_id": "1667352",
    "abstract_original": "In recent years, computer scientists have recognized the office as a natural environment for the application of computing technology. At the same time, there has been a growing awareness of the need for automated tools to increase the productivity of white-collar workers. In an ideal office environment, machines would assume all the repetitive, mechanical tasks, thus freeing people to concentrate on problems that require creative thinking. The key to providing these office tools is the representation and utilization of information about the business of the office. This special issue of Computer focuses on recent office information systems research that is directed at improving the environment and productivity of office workers.",
    "abstract_processed": "recent year comput scientist recogn offic natur environ applic comput technolog time grow awar need autom tool increas product white collar worker ideal offic environ machin would assum repetit mechan task thu free peopl concentr problem requir creativ think key provid offic tool represent util inform busi offic special issu comput focus recent offic inform system research direct improv environ product offic worker"
  },
  {
    "doc_id": "1705426",
    "abstract_original": "Natural language's creative genres are traditionally considered to be outside the scope of computational modeling. Computational linguists have paid little attention to humor in particular because it is puzzling by nature. However, given the importance of humor in our daily lives and computers in our work and entertainment, studies related to computational humor will become increasingly significant in fields such as human-computer interaction, intelligent interactive entertainment, and computer-assisted education. In this article, we explore computational approaches' applicability to the recognition and use of verbally expressed humor. Particularly, we focus on three important research questions related to this problem: Can we automatically gather large collections of humorous texts? Can we automatically recognize humor in text? And can we automatically insert humorous add-ons into existing applications?",
    "abstract_processed": "natur languag creativ genr tradit consid outsid scope comput model comput linguist paid littl attent humor particular puzzl natur howev given import humor daili live comput work entertain studi relat comput humor becom increasingli signific field human comput interact intellig interact entertain comput assist educ articl explor comput approach applic recognit use verbal express humor particularli focu three import research question relat problem automat gather larg collect humor text automat recogn humor text automat insert humor add on exist applic"
  },
  {
    "doc_id": "1716070",
    "abstract_original": "A significant feature of brain intelligence is flexibility. This is generally lacking in current machine intelligence We think that learning that effectively uses the combination of multiple information representations is the key to constructing flexible machine intelligence. This hypothesis is demonstrated by means of a simple connectionist model of intrinsically motivated reinforcement learning. A linear approximation of reward functions that depends on multiple representations is engaged in our model. We show preliminary results for a model network that enables a flexible learning response to several different situations. Multiple representations in our model accelerate the learning not only in complex situations that need many kinds of information, but also in simple situations.",
    "abstract_processed": "signific featur brain intellig flexibl gener lack current machin intellig think learn effect use combin multipl inform represent key construct flexibl machin intellig hypothesi demonstr mean simpl connectionist model intrins motiv reinforc learn linear approxim reward function depend multipl represent engag model show preliminari result model network enabl flexibl learn respons sever differ situat multipl represent model acceler learn complex situat need mani kind inform also simpl situat"
  },
  {
    "doc_id": "1716123",
    "abstract_original": "A fast winners-take-all competition process, termed confabulation, is proposed as the fundamental mechanism of all aspects of cognition (vision, hearing, planning, language, initiation of thought and movement, etc.). Multiple, contemporaneous, mutually interacting confabulations -in which millions of items of relevant knowledge are applied in parallel -are typically employed in thinking. At the beginning of such a multiconfabulation, billions of distinct, potentially viable, conclusion sets are considered. At the end, only one remains. This fast, massively parallel application of relevant knowledge (an alien kind of information processing with no analogue in today's computational intelligence, computational neurobiology, or computer science) is hypothesized to be the core explanation for the information processing effectiveness of thought. This paper presents a synopsis of this confabulation theory of human cortical and thalamic function.",
    "abstract_processed": "fast winner take competit process term confabul propos fundament mechan aspect cognit vision hear plan languag initi thought movement etc multipl contemporan mutual interact confabul million item relev knowledg appli parallel typic employ think begin multiconfabul billion distinct potenti viabl conclus set consid end one remain fast massiv parallel applic relev knowledg alien kind inform process analogu today comput intellig comput neurobiolog comput scienc hypothes core explan inform process effect thought paper present synopsi confabul theori human cortic thalam function"
  },
  {
    "doc_id": "1716125",
    "abstract_original": "Creative thinking is one of the hallmarks of human-level competence. Although it is still a poorly understood subject speculative ideas about brain processes involved in creative thinking may be implemented in computational models. A review of different approaches to creativity, insight and intuition is presented. Two factors are essential for creativity: imagination and selection or filtering. Imagination should be constrained by experience, while filtering in the case of creative use of words may be based on semantic and phonological associations. Analysis of brain processes involved in invention of new words leads to practical algorithms that create many interesting and novel names associated with a set of keywords.",
    "abstract_processed": "creativ think one hallmark human level compet although still poorli understood subject specul idea brain process involv creativ think may implement comput model review differ approach creativ insight intuit present two factor essenti creativ imagin select filter imagin constrain experi filter case creativ use word may base semant phonolog associ analysi brain process involv invent new word lead practic algorithm creat mani interest novel name associ set keyword"
  },
  {
    "doc_id": "18056",
    "abstract_original": "A description is given of a systolic Cooley-Tukey fast Fourier transform algorithm for Boolean n-cubes with a substantial amount of storage per cube node. In mapping a Cooley-Tukey type FFT to such a network, the main concerns are effective use of the high connectivity/bandwidth of the Boolean n-cube, the computational resources, the storage bandwidth, if there is a storage hierarchy, and the pipelines should the arithmetic units have such a feature. Another important consideration in a multiprocessor, distributed storage architecture is the allocation and access to coefficients, if they are precomputed. FFT algorithms are described that use both the storage bandwidth and the communication system optimally and require storage of P+nN coefficients for a transform on P>or=N data elements. A complex-to-complex FFT on 16 million points is predicted to require about 1.5 s on a Connection Machine model CM-2.<>",
    "abstract_processed": "descript given systol cooley tukey fast fourier transform algorithm boolean n cube substanti amount storag per cube node map cooley tukey type fft network main concern effect use high connect bandwidth boolean n cube comput resourc storag bandwidth storag hierarchi pipelin arithmet unit featur anoth import consider multiprocessor distribut storag architectur alloc access coeffici precomput fft algorithm describ use storag bandwidth commun system optim requir storag p nn coeffici transform p n data element complex complex fft million point predict requir connect machin model cm"
  },
  {
    "doc_id": "182763",
    "abstract_original": "Identifies terms currently in use in the computer field. Standard definitions for thoseterms are established. Compilation of IEEE Stds IEEE Std 1084, IEEE Std 610.2, IEEE Std 610.3, IEEE Std 610.4, IEEE Std 610.5 and IEEE Std 610.12",
    "abstract_processed": "identifi term current use comput field standard definit thoseterm establish compil ieee std ieee std ieee std ieee std ieee std ieee std ieee std"
  },
  {
    "doc_id": "184155",
    "abstract_original": "Developing a user-friendly modeling environment has been a focus of recent research. One technique widely used in human modeling processes but virtually unexplored in existing model management literature is the application of analogical thinking to improve the productivity of model formulation. Modeling by analogy is a process by which model builders transform modeling knowledge obtained from previous experience to build models for new problems that share significant features with the previously formulated ones. It overcomes certain human cognitive limitations and reduces the need for repetitive trials. The author examines the process of modeling by analogy, explores how this approach can be applied to the formulation of linear programs, and discusses issues involved in supporting modeling by analogy.<>",
    "abstract_processed": "develop user friendli model environ focu recent research one techniqu wide use human model process virtual unexplor exist model manag literatur applic analog think improv product model formul model analog process model builder transform model knowledg obtain previou experi build model new problem share signific featur previous formul one overcom certain human cognit limit reduc need repetit trial author examin process model analog explor approach appli formul linear program discuss issu involv support model analog"
  },
  {
    "doc_id": "192924",
    "abstract_original": "Research results on the use of computers to solve simulation problems in a way closer to human thinking are reported. With the aid of techniques in artificial intelligence, database systems, and computer graphics, a set of general-purpose Lisp and Pascal based simulation tools have been developed. Each of these tools solves a specific problem in some stage of simulation. Rule-based and object oriented symbolic manipulations are extensively used. The tools provide more powerful and accurate modeling capability for complex objects, and permit simplicity and flexibility in implementation. They are used to study electrical transient problems, optimal load flow problems, linear control systems, and other simulation problems.<>",
    "abstract_processed": "research result use comput solv simul problem way closer human think report aid techniqu artifici intellig databas system comput graphic set gener purpos lisp pascal base simul tool develop tool solv specif problem stage simul rule base object orient symbol manipul extens use tool provid power accur model capabl complex object permit simplic flexibl implement use studi electr transient problem optim load flow problem linear control system simul problem"
  },
  {
    "doc_id": "194197",
    "abstract_original": "A new sliding controller is proposed. Second order linear system sliding curves eliminate the reaching phase and consequently and associated problems of load sensitivity and high demanded torque. Moreover, the chattering usually present in the sliding phase also disappears with the new control law. Simulation results show a negligible coupling between axes, thus enabling an easier and more efficient controller adjustment. It is also shown that the controller parameter set can be easily adjusted, and there is a large set of possible quasi-optimal values. This is of utmost importance, when one thinks of the industrial applications of this type of algorithms. Experiments were developed based on the position control problem. Nevertheless, generalization to the trajectory tracking problem is trivial. In either case the controller computational requirements are low, thus well adapted to today's microprocessor based digital control technology.<>",
    "abstract_processed": "new slide control propos second order linear system slide curv elimin reach phase consequ associ problem load sensit high demand torqu moreov chatter usual present slide phase also disappear new control law simul result show neglig coupl axe thu enabl easier effici control adjust also shown control paramet set easili adjust larg set possibl quasi optim valu utmost import one think industri applic type algorithm experi develop base posit control problem nevertheless gener trajectori track problem trivial either case control comput requir low thu well adapt today microprocessor base digit control technolog"
  },
  {
    "doc_id": "2007",
    "abstract_original": "The proceedings contain 137 papers. The special focus in this conference is on Education in Computer Aided Architectural Design in Europe. The topics include: Simulating dynamic forces in design with special effects tools; performative design in architecture employment of virtual prototyping as a simulation environment in design generation; safde-sadness, anger, fear, disgust, enjoyment; generative systems based on animation tools: Shaping alternatives to structure and form in architectural design; mediating between architectural design ideation and development through digital technology dynamic animation toys and mediation methods in designing; playing with game theory: Deviant strategies for digital design; new digital procedures through animation: Brief history and developments; gelassenheit: Dilemma of computational thinking in architecture; looking back to the future an updated case base of case-based design tools for architecture; conceptual design of high-rises with parametric methods; a generic data structure for an architectural design application; indexing and retrieval of visual design representations; enhancing the precision of design processes with localized time-based media; parsimonious models of urban space; novel approaches to city modeling: Generation and visualization of dynamic complex urban systems; procedural design of urban open spaces; second city a three-dimensional city model as interdisciplinary platform for research; precise uncertainty: Notes on historical modeling; cityzoom a visualization tool for the assessment of planning regulations; geometry in the caad curriculum; evolution of caad teaching methods; sharing and enriching metadata in architectural repositories; caad restarted some experiences in improvement of caad education; inserting new technologies in undergraduate architectural curricula a case study; an architectural learning environment.",
    "abstract_processed": "proceed contain paper special focu confer educ comput aid architectur design europ topic includ simul dynam forc design special effect tool perform design architectur employ virtual prototyp simul environ design gener safd sad anger fear disgust enjoy gener system base anim tool shape altern structur form architectur design mediat architectur design ideat develop digit technolog dynam anim toy mediat method design play game theori deviant strategi digit design new digit procedur anim brief histori develop gelassenheit dilemma comput think architectur look back futur updat case base case base design tool architectur conceptu design high rise parametr method gener data structur architectur design applic index retriev visual design represent enhanc precis design process local time base media parsimoni model urban space novel approach citi model gener visual dynam complex urban system procedur design urban open space second citi three dimension citi model interdisciplinari platform research precis uncertainti note histor model cityzoom visual tool assess plan regul geometri caad curriculum evolut caad teach method share enrich metadata architectur repositori caad restart experi improv caad educ insert new technolog undergradu architectur curricula case studi architectur learn environ"
  },
  {
    "doc_id": "2008",
    "abstract_original": "The proceedings contain 32 papers. The topics discussed include: the challenging face of informatics education in Poland; from top coders to top IT professionals; integrating mathematical analysis of sensors and motion in a mobile robotics course; development of an educational system to control robots for all students; proposal for teaching manufacturing and control programming using autonomous mobile robots with an arm; design disciplines and non-specific transfer; analysis of learning objectives in object oriented programming; understanding object oriented programming concepts in an advanced programming course; analysis of students' developed programs at the maturity exams in information technologies; informatics as a contribution to the modern constructivist education; computer science teacher training at the university of Groningen; and on the technological aspects of generative learning object development.",
    "abstract_processed": "proceed contain paper topic discuss includ challeng face informat educ poland top coder top profession integr mathemat analysi sensor motion mobil robot cours develop educ system control robot student propos teach manufactur control program use autonom mobil robot arm design disciplin non specif transfer analysi learn object object orient program understand object orient program concept advanc program cours analysi student develop program matur exam inform technolog informat contribut modern constructivist educ comput scienc teacher train univers groningen technolog aspect gener learn object develop"
  },
  {
    "doc_id": "2009",
    "abstract_original": "The proceedings contain 43 papers. The topics discussed include: the evolution of end user programming; implications for an exercise prescription authoring notation; visual explanations of probabilistic reasoning; modeling advanced concepts of interactive multimedia applications; modeling multicasting in communication spaces by reconfigurable high-level Petri nets; a graphical approach for modeling time-dependent behavior of domain specific languages; non-programmers identifying functionality in unfamiliar code: strategies and barriers; playing with information: how end users think about and integrate dynamic data; a visual system for analyzing user behavior in web tasks; template-based critic authoring for domain-specific visual language tools; language-based support for fostering computational thinking; changing Euler diagram properties by edge transformation of Euler dual graphs; and discovery-based edit assistance for spreadsheets.",
    "abstract_processed": "proceed contain paper topic discuss includ evolut end user program implic exercis prescript author notat visual explan probabilist reason model advanc concept interact multimedia applic model multicast commun space reconfigur high level petri net graphic approach model time depend behavior domain specif languag non programm identifi function unfamiliar code strategi barrier play inform end user think integr dynam data visual system analyz user behavior web task templat base critic author domain specif visual languag tool languag base support foster comput think chang euler diagram properti edg transform euler dual graph discoveri base edit assist spreadsheet"
  },
  {
    "doc_id": "2010",
    "abstract_original": "The proceedings contain 123 papers. The topics discussed include: MieruCompiler: integrated visualization tool with 'horizontal slicing' for educational compilers; Frances: a tool for understanding code generation; integrating evaluation into program development: benefits of baselining a NSF-BPC alliance; use of satellite imagery in multidisciplinary projects; MPCT: media propelled computational thinking; computational thinking for the sciences: a three day workshop for high school science teachers; expanding the frontiers of computer science: designing a curriculum to reflect a diverse field; connecting across campus; women in CS: An evaluation of three promising practices; relevant real-world undergraduate research problems: lessons from the NSF-REU trenches; variations on a theme: role of media in motivating computing education; and using the imagine cup SDI as the foundation for computer science capstone projects.",
    "abstract_processed": "proceed contain paper topic discuss includ mierucompil integr visual tool horizont slice educ compil franc tool understand code gener integr evalu program develop benefit baselin nsf bpc allianc use satellit imageri multidisciplinari project mpct media propel comput think comput think scienc three day workshop high school scienc teacher expand frontier comput scienc design curriculum reflect divers field connect across campu women cs evalu three promis practic relev real world undergradu research problem lesson nsf reu trench variat theme role media motiv comput educ use imagin cup sdi foundat comput scienc capston project"
  },
  {
    "doc_id": "2011",
    "abstract_original": "The proceedings contain 97 papers. The topics discussed include: object-oriented simulation: a modeling and programming perspective; making mathematical reasoning fun: tool-assisted, collaborative techniques; metaheuristic optimization with applications to computational vision for humanoid robots; game development with game maker, flash and unity; targeting FPGA-based processors for an implementation-driven compiler construction course; engaging non-majors in computer literacy courses; computational thinking: modeling applied to the teaching and learning of English; using the color image quantization problem as a course-long project in CS; EVMAT: an OVAL and NVD based enterprise vulnerability modeling and assessment tool; anomaly intrusion detection based upon an artificial immunology model; a platform-independent tool for modeling parallel programs; and a novel approach for automated music composition using memetic algorithms.",
    "abstract_processed": "proceed contain paper topic discuss includ object orient simul model program perspect make mathemat reason fun tool assist collabor techniqu metaheurist optim applic comput vision humanoid robot game develop game maker flash uniti target fpga base processor implement driven compil construct cours engag non major comput literaci cours comput think model appli teach learn english use color imag quantiz problem cours long project cs evmat oval nvd base enterpris vulner model assess tool anomali intrus detect base upon artifici immunolog model platform independ tool model parallel program novel approach autom music composit use memet algorithm"
  },
  {
    "doc_id": "2012",
    "abstract_original": "The proceedings contain 96 papers. The topics discussed include: infusing computational thinking into the middle- and high-school curriculum; pseudo abstract composition: the case of language concatenation; teaching graph algorithms to children of all ages; forming project groups while learning about matching and network flows in algorithms; refinement of an experimental approach to computer-based, active learning of greedy algorithms; digging for algorithmic nuggets in the land of polyominoes; the empirically refined competence structure model for embedded micro- and nanosystems; supporting operating systems projects using the μMPS2 hardware simulator; integrating data-intensive cloud computing with multicores and clusters in an HPC course; all syntax errors are not equal; and code comprehension problems as learning events.",
    "abstract_processed": "proceed contain paper topic discuss includ infus comput think middl high school curriculum pseudo abstract composit case languag concaten teach graph algorithm children age form project group learn match network flow algorithm refin experiment approach comput base activ learn greedi algorithm dig algorithm nugget land polyomino empir refin compet structur model embed micro nanosystem support oper system project use μmp hardwar simul integr data intens cloud comput multicor cluster hpc cours syntax error equal code comprehens problem learn event"
  },
  {
    "doc_id": "2013",
    "abstract_original": "The proceedings contain 110 papers. The topics discussed include: supporting and sustaining the holistic development of students into practicing physicists; using scientists' notebooks to foster authentic scientific practices; a framework for assessing learning assistants' reflective writing assignments; establishing reliability and validity: an ongoing process; understanding student computational thinking with computational modeling; instructional changes based on cogenerative physics reform; student predictions of functional but incomplete example programs in introductory calculus-based physics; critical classroom structures for empowering students to participate in science discourse; cultural toolkits in the urban physics learning community; building classroom and organizational structure around positive cultural values; initial replication results of learning assistants in university physics; research-based course materials and assessments for upper-division electrodynamics (E&M II); design guidelines for adapting scientific research articles: an example from an introductory level, interdisciplinary program on soft matter; introduction of studio physics teaching in Panama; Acer: a framework on the use of mathematics in upper-division physics; evidence of embodied cognition via speech and gesture complementarity; and student interactions leading to learning and transfer: a participationist perspective.",
    "abstract_processed": "proceed contain paper topic discuss includ support sustain holist develop student practic physicist use scientist notebook foster authent scientif practic framework assess learn assist reflect write assign establish reliabl valid ongo process understand student comput think comput model instruct chang base cogen physic reform student predict function incomplet exampl program introductori calculu base physic critic classroom structur empow student particip scienc discours cultur toolkit urban physic learn commun build classroom organiz structur around posit cultur valu initi replic result learn assist univers physic research base cours materi assess upper divis electrodynam e ii design guidelin adapt scientif research articl exampl introductori level interdisciplinari program soft matter introduct studio physic teach panama acer framework use mathemat upper divis physic evid embodi cognit via speech gestur complementar student interact lead learn transfer participationist perspect"
  },
  {
    "doc_id": "20131",
    "abstract_original": "The proceedings contain 17 papers. The special focus in this conference is on From Computer Usage to Computational Thinking, Algorithmic, Computational Thinking, Games and Retention of Competencies. The topics include: A first step towards a research framework for computer science education in schools; computer science in secondary schools in the UK; informatics in the French secondary curricula; informatics for all high school students; novice difficulties with interleaved pattern composition; blind pupils begin to solve algorithmic problems; location-based games in informatics education; using computer games as programming assignments for university students and secondary school pupils; the contribution of computer science to learning computational physics; constructionism and IBL in practice and motivation for studying stem; competence measurement and informatics standards in secondary education; on competence-based learning and neuroscience; categorization of pictures in tasks of the bebras contest and on using a Delphi process in informatics teacher education.",
    "abstract_processed": "proceed contain paper special focu confer comput usag comput think algorithm comput think game retent compet topic includ first step toward research framework comput scienc educ school comput scienc secondari school uk informat french secondari curricula informat high school student novic difficulti interleav pattern composit blind pupil begin solv algorithm problem locat base game informat educ use comput game program assign univers student secondari school pupil contribut comput scienc learn comput physic construction ibl practic motiv studi stem compet measur informat standard secondari educ compet base learn neurosci categor pictur task bebra contest use delphi process informat teacher educ"
  },
  {
    "doc_id": "2014",
    "abstract_original": "The proceedings contain 87 papers. The topics discussed include: SPOC-supported introduction to programming; teaching and learning with MOOCs: computing academics' perspectives and engagement; system for automatic generation of algorithm visualizations based on pseudocode interpretation; effect of a 2-week scratch intervention in CS1 on learners with varying prior knowledge; serious toys: three years of teaching computer science concepts in K-12 classrooms; the magic of algorithm design and analysis: teaching algorithmic skills using magic card tricks; MLSvisual: a visualization tool for teaching access control using multi-level security; student perceptions of the acceptability of various code-writing practices; cultural appropriation of computational thinking acquisition research: seeding fields of diversity; apps for social justice: motivating computer science learning with design and real-world problem solving; and understanding students' preferences of software engineering projects.",
    "abstract_processed": "proceed contain paper topic discuss includ spoc support introduct program teach learn mooc comput academ perspect engag system automat gener algorithm visual base pseudocod interpret effect week scratch intervent cs learner vari prior knowledg seriou toy three year teach comput scienc concept k classroom magic algorithm design analysi teach algorithm skill use magic card trick mlsvisual visual tool teach access control use multi level secur student percept accept variou code write practic cultur appropri comput think acquisit research seed field divers app social justic motiv comput scienc learn design real world problem solv understand student prefer softwar engin project"
  },
  {
    "doc_id": "2015",
    "abstract_original": "This proceedings contains 20 papers. The conference papers cover the varieties of theme topics, which includes: Gender, Curriculum, Employment; ICT Education I; ICT Education II; Programming Assessment; Introductory/Novice Programming, etc. The key terms of this proceedings include computational thinking, cognitive load theory, flipped learning, CSER digital technologies, programming educational tools, dynamic evaluation trees, mobile Apps development, automated marking, information analytics, ICT education. © 2015, Australian Computer Society, Inc.",
    "abstract_processed": "proceed contain paper confer paper cover varieti theme topic includ gender curriculum employ ict educ ict educ ii program assess introductori novic program etc key term proceed includ comput think cognit load theori flip learn cser digit technolog program educ tool dynam evalu tree mobil app develop autom mark inform analyt ict educ © australian comput societi inc"
  },
  {
    "doc_id": "2016",
    "abstract_original": "The proceedings contain 87 papers. The topics discussed include: the diffusion of inquiry based practices in the Singapore education system: navigating eddies of the 21st century; scaling studio-based learning through social innovation networks; multiple legitimate language games in family serendipitous science engagement; combining exploratory learning with structured practice to foster conceptual and procedural fractions knowledge; the effects of self-regulated learning on students' performance trajectory in the flipped math classroom; supporting inquiry learning as a practice: a practice perspective on the challenges of IBL design, implementation and research methodology; bringing computational thinking into high school mathematics and science classrooms; students' use of knowledge resources in environmental interaction on an outdoor learning trail; a qualitative exploration of self - and socially shared regulation in online collaborative learning; let your data tell a story: disciplinary expert feedback locates engaging in argumentation in a holistic system of practices; and teamwork in the balance: exploratory findings of teamwork competency patterns in effective learning teams.",
    "abstract_processed": "proceed contain paper topic discuss includ diffus inquiri base practic singapor educ system navig eddi st centuri scale studio base learn social innov network multipl legitim languag game famili serendipit scienc engag combin exploratori learn structur practic foster conceptu procedur fraction knowledg effect self regul learn student perform trajectori flip math classroom support inquiri learn practic practic perspect challeng ibl design implement research methodolog bring comput think high school mathemat scienc classroom student use knowledg resourc environment interact outdoor learn trail qualit explor self social share regul onlin collabor learn let data tell stori disciplinari expert feedback locat engag argument holist system practic teamwork balanc exploratori find teamwork compet pattern effect learn team"
  },
  {
    "doc_id": "20161",
    "abstract_original": "The proceedings contain 56 papers. The special focus in this conference is on Conceptual Modeling, Smart Education, Smart e-Learning, Software and Hardware Systems. The topics include: Smart universities, smart classrooms and students with disabilities; innovative approaches toward smart education at national institute of technology, GIFU college; smart university management based on process approach and it-standards; a formal algebraic approach to modeling smart university as an efficient and innovative system; conceptual framework for feedback automation in SLES; development of smart-system of distance learning of visually impaired people on the basis of the combined of owl model; data mining of students’ behaviors in programming exercises; social network sites as a good support for study purposes; a conceptual framework for knowledge creation based on constructed meanings within mentor-learner conversations; inductive teaching and problem-based learning as significant training tools in electrical engineering; a supporting service in teacher training; participation in state R&D projects jointly with industrial enterprises; pagerank algorithm to improve the peer-led team learning pedagogical approach; developing computational thinking abilities instead of digital literacy in primary and secondary school students; innovations in subjects knowledge technologies; an integrative approach of e-learning; using e-learning in teaching economics at universities of the Czech republic; the gamification model for e-learning participants engagement; RLCP-compatible virtual laboratories in computer science; tangible interfaces for cognitive assessment and training in children and sequencing educational contents using clustering and ant colony algorithms.",
    "abstract_processed": "proceed contain paper special focu confer conceptu model smart educ smart e learn softwar hardwar system topic includ smart univers smart classroom student disabl innov approach toward smart educ nation institut technolog gifu colleg smart univers manag base process approach standard formal algebra approach model smart univers effici innov system conceptu framework feedback autom sle develop smart system distanc learn visual impair peopl basi combin owl model data mine students’ behavior program exercis social network site good support studi purpos conceptu framework knowledg creation base construct mean within mentor learner convers induct teach problem base learn signific train tool electr engin support servic teacher train particip state r project jointli industri enterpris pagerank algorithm improv peer led team learn pedagog approach develop comput think abil instead digit literaci primari secondari school student innov subject knowledg technolog integr approach e learn use e learn teach econom univers czech republ gamif model e learn particip engag rlcp compat virtual laboratori comput scienc tangibl interfac cognit assess train children sequenc educ content use cluster ant coloni algorithm"
  },
  {
    "doc_id": "2017",
    "abstract_original": "The proceedings contain 48 papers. The special focus in this conference is on Computational Thinking Education. The topics include: Computational thinking in the science classroom; constructing models in physics: What computational thinking occurs?; domain specific modeling language design to support synergistic learning of stem and computational thinking; the role gender differences in computational thinking confidence levels plays in stem applications; k-12 computational thinking education in germany; gamified mathematics practice: designing with e-commerce and computational concepts; how computer scientists and computing teachers think differently in the concepts to be included in a secondary school computing curriculum; teaching computational thinking by gamification of k-12 mathematics: Mobile app math games in mathematics and computer science tournament; profile of a ct integration specialist; enhancing the link between parent-child in learning computational thinking; teaching computational thinking with electronic textiles: High school teachers’ contextualizing strategies in exploring computer science; application of the four phases of computational thinking and integration of blocky programming in a sixth-grade mathematics course; the design and evaluation of a teacher development programme in computational thinking education; connecting design thinking and computational thinking in the context of korean primary school teacher education; curriculum activities to foster primary school students’ computational practices in block-based programming environments; emergent roles, collaboration and computational thinking in the multi-dimensional problem space of robotics; a framework of computational thinking curriculum for k-12 with design thinking by app inverntor; development and validation of a programming self-efficacy scale for senior primary school learners; integrating computational thinking into discrete mathematics.",
    "abstract_processed": "proceed contain paper special focu confer comput think educ topic includ comput think scienc classroom construct model physic comput think occur domain specif model languag design support synergist learn stem comput think role gender differ comput think confid level play stem applic k comput think educ germani gamifi mathemat practic design e commerc comput concept comput scientist comput teacher think differ concept includ secondari school comput curriculum teach comput think gamif k mathemat mobil app math game mathemat comput scienc tournament profil ct integr specialist enhanc link parent child learn comput think teach comput think electron textil high school teachers’ contextu strategi explor comput scienc applic four phase comput think integr blocki program sixth grade mathemat cours design evalu teacher develop programm comput think educ connect design think comput think context korean primari school teacher educ curriculum activ foster primari school students’ comput practic block base program environ emerg role collabor comput think multi dimension problem space robot framework comput think curriculum k design think app inverntor develop valid program self efficaci scale senior primari school learner integr comput think discret mathemat"
  },
  {
    "doc_id": "20171",
    "abstract_original": "The proceedings contain 81 papers. The special focus in this conference is on Emerging Technologies Support for Game-Based, Joyful Learning, Emerging Technologies Supported Personalized, Adaptive Learning, Emerging Technologies of Pedagogical Issues, Emerging Technologies Enhanced Language Learning, Workshop on Active Ageing, Workshop on Social and Personal Computing for Web-Supported Learning Communities, Workshop on Peer Review, Peer Assessment, and Self-assessment in Education. The topics include: Exploring the factors that influence the intention to play a color mixing game; imitating a hot puzzle game for English vocabulary exercise in E-book System; a conceptual framework over contextual analysis of concept learning within human-machine interplays; construction of efficient cloud-based digital course learning platform for agricultural worker; using summarization technology for supporting problem-based learning; computer adaptive learning platform for calculus; a pathway into computational thinking in primary schools; an inquiry-based digital storytelling approach for increasing learner autonomy in English; towards personalization of peer review in learning programming; sentiment analysis for older people in cross-platform instant messaging service; photography-based intervention; when the aged meets digital age; an empirical study of corpora application in data-driven English lexical learning; text analysis of corpus linguistics in a post-concordancer era; obtaining assessment tests after double filtration; social network sites and their use in education; topic-level clustering on web resources and applying MOOCs to standard courses.",
    "abstract_processed": "proceed contain paper special focu confer emerg technolog support game base joy learn emerg technolog support person adapt learn emerg technolog pedagog issu emerg technolog enhanc languag learn workshop activ age workshop social person comput web support learn commun workshop peer review peer assess self assess educ topic includ explor factor influenc intent play color mix game imit hot puzzl game english vocabulari exercis e book system conceptu framework contextu analysi concept learn within human machin interplay construct effici cloud base digit cours learn platform agricultur worker use summar technolog support problem base learn comput adapt learn platform calculu pathway comput think primari school inquiri base digit storytel approach increas learner autonomi english toward person peer review learn program sentiment analysi older peopl cross platform instant messag servic photographi base intervent age meet digit age empir studi corpora applic data driven english lexic learn text analysi corpu linguist post concordanc era obtain assess test doubl filtrat social network site use educ topic level cluster web resourc appli mooc standard cours"
  },
  {
    "doc_id": "2017457",
    "abstract_original": "This chapter summarizes the main parts of the book. It then concludes the book by offering an outlook of how parallel programming will continue to contribute to the new innovations in science and technology. © 2017 David B. Kirk/NVIDIA Corporation and Wen-mei W. Hwu Published by Elsevier Inc. All rights reserved.",
    "abstract_processed": "chapter summar main part book conclud book offer outlook parallel program continu contribut new innov scienc technolog © david b kirk nvidia corpor wen mei w hwu publish elsevi inc right reserv"
  },
  {
    "doc_id": "2018",
    "abstract_original": "The proceedings contain 146 papers. The special focus in this conference is on Artificial Intelligence in Education. The topics include: Sequence based course recommender for personalized curriculum planning; Towards improving introductory computer programming with an ITS for conceptual learning; investigation of the influence of hint type on problem solving behavior in a logic proof tutor; modeling math success using cohesion network analysis; amplifying teachers intelligence in the design of gamified intelligent tutoring systems; where is the Nurse? Towards automatically visualising meaningful team movement in healthcare education; exploring gritty students’ behavior in an intelligent tutoring system; characterizing students based on their participation in the class; adaptive learning goes to China; ontology development for competence assessment in virtual communities of practice; how gamification impacts on vocational training students; ROBIN: Using a programmable robot to provide feedback and encouragement on programming tasks; classifying educational questions based on the expected characteristics of answers; on the learning curve attrition bias in additive factor modeling; the impact of affect-aware support on learning tasks that differ in their cognitive demands; mitigating knowledge decay from instruction with voluntary use of an adaptive learning system; Computational thinking through game creation in STEM classrooms; behavioral explanation versus structural explanation in learning by model-building; Temporal changes in affiliation and emotion in MOOC discussion forum discourse; investigating influence of demographic factors on study recommenders; A design-based approach to a classroom-centered OELE; on the value of answerers in early detection of response time to questions for peer recommender systems; conversational support for education.",
    "abstract_processed": "proceed contain paper special focu confer artifici intellig educ topic includ sequenc base cours recommend person curriculum plan toward improv introductori comput program conceptu learn investig influenc hint type problem solv behavior logic proof tutor model math success use cohes network analysi amplifi teacher intellig design gamifi intellig tutor system nurs toward automat visualis meaning team movement healthcar educ explor gritti students’ behavior intellig tutor system character student base particip class adapt learn goe china ontolog develop compet assess virtual commun practic gamif impact vocat train student robin use programm robot provid feedback encourag program task classifi educ question base expect characterist answer learn curv attrit bia addit factor model impact affect awar support learn task differ cognit demand mitig knowledg decay instruct voluntari use adapt learn system comput think game creation stem classroom behavior explan versu structur explan learn model build tempor chang affili emot mooc discuss forum discours investig influenc demograph factor studi recommend design base approach classroom center oel valu answer earli detect respons time question peer recommend system convers support educ"
  },
  {
    "doc_id": "20181",
    "abstract_original": "The proceedings contain 29 papers. The special focus in this conference is on Robotics in Education. The topics include: Comprehensive educational robotics activities TechColleges; robotics peer-to-peer teaching summer school project involving university students, summer interns and middle school students; methods for managing student-driven robotics research; robotics education in saint petersburg secondary school; LEGO WeDO curriculum for lower secondary school; teaching robotics concepts to elementary school children; the effect of the programming interfaces of robots in teaching computer languages; creativity and contextualization activities in educational robotics to improve engineering and computational thinking; educational robotics for communication, collaboration and digital fluency; using robotics to foster creativity in early gifted education; designing robotics student projects from concept inventories; teaching research methodologies with a robot in a CS lab course; teaching robotics for computer science students; open source robotics course at engineering: infrastructure and methodology; architectural overview and hedgehog in use; open-source robotic manipulator and sensory platform; an elementary science class with a robot teacher; teaching robotics with cloud tools; needs, opportunities and constraints on the way to the wide introduction of robotics to teaching at secondary vocational schools; an open robotics environment motivates students to learn the key concepts of artificial neural networks and reinforcement learning.",
    "abstract_processed": "proceed contain paper special focu confer robot educ topic includ comprehens educ robot activ techcolleg robot peer peer teach summer school project involv univers student summer intern middl school student method manag student driven robot research robot educ saint petersburg secondari school lego wedo curriculum lower secondari school teach robot concept elementari school children effect program interfac robot teach comput languag creativ contextu activ educ robot improv engin comput think educ robot commun collabor digit fluenci use robot foster creativ earli gift educ design robot student project concept inventori teach research methodolog robot cs lab cours teach robot comput scienc student open sourc robot cours engin infrastructur methodolog architectur overview hedgehog use open sourc robot manipul sensori platform elementari scienc class robot teacher teach robot cloud tool need opportun constraint way wide introduct robot teach secondari vocat school open robot environ motiv student learn key concept artifici neural network reinforc learn"
  },
  {
    "doc_id": "2019",
    "abstract_original": "The proceedings contain 13 papers. The topics discussed include: my lessons learned from 10 years of research and teaching as pillars of our company growth; agile is real – everyday life in a XP Office; UML in higher education: a critical reflection; formal methods in the software engineering lecture; stager: simplifying the manual assessment of programming exercises; learning software project management without a project; future skills: how to strengthen computational thinking in all software project roles; computer sciences is not only programming – but without programming is nothing computer sciences; using mini-projects to teach empirical software engineering; and experience report on an inquiry-based course on model checking.",
    "abstract_processed": "proceed contain paper topic discuss includ lesson learn year research teach pillar compani growth agil real – everyday life xp offic uml higher educ critic reflect formal method softwar engin lectur stager simplifi manual assess program exercis learn softwar project manag without project futur skill strengthen comput think softwar project role comput scienc program – without program noth comput scienc use mini project teach empir softwar engin experi report inquiri base cours model check"
  },
  {
    "doc_id": "2020",
    "abstract_original": "The proceedings contain 251 papers. The topics discussed include: applying computational thinking in Unsera students used online calculus training; development of kite number learning media help adobe flash cs6 on the concept of place number values in elementary school 2 Singaparna; Google forms utilization for student satisfaction survey towards quality of service at Universitas Muhammadiyah Tasikmalaya; sample identification approach by K-means clustering in thinner retail market segmentation; framework design of information retrieval system for official letter using extraction of geometry feature method; transjoin: an algorithm to implement division operator of relational algebra in structured query language; application of critical thinking on the social media (case study comments and statuses on facebook about miss tourism competition on West Nias); simplified equations and ansys simulation of head loss on nonlinear (sliced) bend for piping network; damage analysis of the electric generator diesel engine connecting rod; effect of stir-frying on calcium inside terrestrial water spinach (ipomoea reptans poir) with water spinach (ipomoea aquatica forks) with complexometric titration method; removal of methylene orange and procion blue with integrated adsorption-photocatalytic method; and building satisfaction and loyalty of student users ojek online through the use of it and quality of service in Tangerang city.",
    "abstract_processed": "proceed contain paper topic discuss includ appli comput think unsera student use onlin calculu train develop kite number learn media help adob flash cs concept place number valu elementari school singaparna googl form util student satisfact survey toward qualiti servic universita muhammadiyah tasikmalaya sampl identif approach k mean cluster thinner retail market segment framework design inform retriev system offici letter use extract geometri featur method transjoin algorithm implement divis oper relat algebra structur queri languag applic critic think social media case studi comment status facebook miss tourism competit west nia simplifi equat ansi simul head loss nonlinear slice bend pipe network damag analysi electr gener diesel engin connect rod effect stir fri calcium insid terrestri water spinach ipomoea reptan poir water spinach ipomoea aquatica fork complexometr titrat method remov methylen orang procion blue integr adsorpt photocatalyt method build satisfact loyalti student user ojek onlin use qualiti servic tangerang citi"
  },
  {
    "doc_id": "2021",
    "abstract_original": "The proceedings contain 45 papers. The special focus in this conference is on Web-Based Learning. The topics include: Attribute Reduction and Rule Acquisition of Formal Decision Context Based on Dual Concept Lattice; study on Sample Reduction Method Based on Neighborhood Granulation; research on Attribute Reduction Method Based on Local Dependency; research on Uncertain Prediction Method Based on Credibility Distribution; variable Precision Multi-granularity Rough Soft Sets Based on Multiple Thresholds; fuzzy N-soft Ordered Semigroups with Application; dominance-Based N-soft Rough Sets; trend Analysis of At-a-station Hydraulic Geometry Relations on the Loess Plateau of China; preparing Primary School Teachers for Teaching Computational Thinking: A Systematic Review; a Review on Visualization of Educational Data in Online Learning; A Classification Method of Inventory Spare Parts Based on Improved Super Efficient DEA-ABC Model; MSNet: A Multi-scale Segmentation Network for Documents Layout Analysis; research on Intelligent Transportation Platform Based on Big Data Technology; data Synthesis for Document Layout Analysis; An Experience of Teaching Advanced Control Engineering (ACE) for Postgraduate Students; modelling Change Towards Hybrid Learning; How Instructors Initially Viewed Teaching Online in Higher Education in the UK During the COVID-19 Pandemic; applying the Online Intelligent Grading System to College English Writing Teaching: An Empirical Study; The Construction and Measurement of an Online Learning Evaluation System Based on ACSI Mode; effective Cultivation of Cross-Border E-Commerce Talents via Virtual Communities of Practice with Multi-media, Multi-layered WeChat Groups; Technology Affordances in the Web-Based Learning Environment for SLA: A Case Study of a Chinese English Learner in the Time of COVID-19.",
    "abstract_processed": "proceed contain paper special focu confer web base learn topic includ attribut reduct rule acquisit formal decis context base dual concept lattic studi sampl reduct method base neighborhood granul research attribut reduct method base local depend research uncertain predict method base credibl distribut variabl precis multi granular rough soft set base multipl threshold fuzzi n soft order semigroup applic domin base n soft rough set trend analysi station hydraul geometri relat loess plateau china prepar primari school teacher teach comput think systemat review review visual educ data onlin learn classif method inventori spare part base improv super effici dea abc model msnet multi scale segment network document layout analysi research intellig transport platform base big data technolog data synthesi document layout analysi experi teach advanc control engin ace postgradu student model chang toward hybrid learn instructor initi view teach onlin higher educ uk covid pandem appli onlin intellig grade system colleg english write teach empir studi construct measur onlin learn evalu system base acsi mode effect cultiv cross border e commerc talent via virtual commun practic multi media multi layer wechat group technolog afford web base learn environ sla case studi chines english learner time covid"
  },
  {
    "doc_id": "2022",
    "abstract_original": "The proceedings contain 48 papers. The topics discussed include: research on heuristic teaching model based on case comparative experiment; ideological and political teaching reform: an introduction to artificial intelligence based on the OBE concept; research on the educational model of computational thinking cultivation in primary and middle schools oriented to production-based learning; design and research of a virtual computer network experimental teaching system; exploration on the application-oriented teaching mode of data mining course for undergraduates; research on hospital information system course design and evaluation based on project-driving method; teaching reform on compiler technology course based on ideological and political construction; current situation and development of outcome-based education in computer teaching; and an event-based framework for facilitating real-time sentiment analysis in educational contexts.",
    "abstract_processed": "proceed contain paper topic discuss includ research heurist teach model base case compar experi ideolog polit teach reform introduct artifici intellig base obe concept research educ model comput think cultiv primari middl school orient product base learn design research virtual comput network experiment teach system explor applic orient teach mode data mine cours undergradu research hospit inform system cours design evalu base project drive method teach reform compil technolog cours base ideolog polit construct current situat develop outcom base educ comput teach event base framework facilit real time sentiment analysi educ context"
  },
  {
    "doc_id": "20221",
    "abstract_original": "The education system is constantly growing and developing as more ways to teach and learn are implemented into the classroom. Recently, there has been a growing interest in teaching computational thinking with schools all over the world introducing it to the curriculum due to its ability to allow students to become proficient at problem solving using logic, an essential life skill. In order to provide the best education possible, it is imperative that computational thinking strategies, along with programming skills and the use of robotics in the classroom, be implemented in order for students to achieve maximum thought processing skills and computer competencies. © 2022 by IGI Global. All rights reserved.",
    "abstract_processed": "educ system constantli grow develop way teach learn implement classroom recent grow interest teach comput think school world introduc curriculum due abil allow student becom profici problem solv use logic essenti life skill order provid best educ possibl imper comput think strategi along program skill use robot classroom implement order student achiev maximum thought process skill comput compet © igi global right reserv"
  },
  {
    "doc_id": "202216",
    "abstract_original": "The theory and development of computer systems able to perform tasks normally requiring human intelligence, such as visual perception, speech recognition, decision-making, and translation between languages Artificial intelligence (AI), sometimes called machine intelligence, is intelligence demonstrated by machines, unlike the natural intelligence displayed by humans and animals. Many computer scientists agree that artificial intelligence is just mathematics. The purpose of the curriculum is to deliver a high-quality computing education which equips pupils to use computational thinking and creativity to understand and change the world. Computing has deep links with mathematics, science, and design and technology, and it provides insights into both natural and artificial systems. The binary numeral system is a way to write numbers using only two digits: 0 and 1. Bletchley Park is famous for the role it had during a war. Pupils should learn to generate, develop, model, and communicate their ideas through discussion, annotated sketches, cross-sectional and exploded diagrams, prototypes, pattern pieces, and computer-aided design. © 2023 Alison Shorer and Katie Quinn.",
    "abstract_processed": "theori develop comput system abl perform task normal requir human intellig visual percept speech recognit decis make translat languag artifici intellig ai sometim call machin intellig intellig demonstr machin unlik natur intellig display human anim mani comput scientist agre artifici intellig mathemat purpos curriculum deliv high qualiti comput educ equip pupil use comput think creativ understand chang world comput deep link mathemat scienc design technolog provid insight natur artifici system binari numer system way write number use two digit bletchley park famou role war pupil learn gener develop model commun idea discuss annot sketch cross section explod diagram prototyp pattern piec comput aid design © alison shorer kati quinn"
  },
  {
    "doc_id": "202264",
    "abstract_original": "Some people can breathe out and breathe in at the same time. This technique is called circular breathing, and it is used for playing the instruments such as the didgeridoo, which is an Aboriginal instrument, and the bagpipes. It is good to watch someone doing the technique. A high-quality music education should engage and inspire pupils to develop a love of music. If people can access a heart monitor on a smart watch or a computer, have a go a counting their heart beats with the monitor. A high-quality computing education equips pupils to use computational thinking and creativity to understand and change the world. Computing has deep links with mathematics, science, and design and technology, and it provides insights into both natural and artificial systems. Air quality varies around the world and in different parts of each country. © 2023 Alison Shorer and Katie Quinn.",
    "abstract_processed": "peopl breath breath time techniqu call circular breath use play instrument didgeridoo aborigin instrument bagpip good watch someon techniqu high qualiti music educ engag inspir pupil develop love music peopl access heart monitor smart watch comput go count heart beat monitor high qualiti comput educ equip pupil use comput think creativ understand chang world comput deep link mathemat scienc design technolog provid insight natur artifici system air qualiti vari around world differ part countri © alison shorer kati quinn"
  },
  {
    "doc_id": "2023",
    "abstract_original": "The proceedings contain 23 papers. The special focus in this conference is on Methodologies and Intelligent Systems for Technology Enhanced Learning. The topics include: Evaluation of the Bibliographical Importance of Digital Educational Disruption Related to Social Networks. The Case of LinkedIn Learning; may a Distance Learning Course in Statistics Satisfy Medical Students? The Experience with an Italian University Sample During the Covid Pandemic; combining Learner Model and Reinforcement Learning for Adaptive Sequencing of Learning Activities; Effects of VR on Learning Experience and Success; educational Code-Review Tool: A First Glimpse; Retrieving Key Topical Sentences with Topic-Aware BERT When Conducting Automated Essay Scoring; Automatic Educational Concept Extraction Using NLP; digital Environment for Literacy and Future Education. A Pilot Experience of Serious Game Co-design; how Learnweb Can Support Science Education Research on Climate Change in Social Media; is It Possible to Improve the Development of Executive Functions in Children by Teaching Computational Thinking?; open Government Data in Higher Education: A Multidisciplinary Innovation Teaching Experience; design and Computational Thinking with IoTgo: What Teachers Think; Brewing Umqombothi: Technicalities of a VR Prototype Merging STEM and South African Intangible Cultural Heritage; serious Games for Autism Based on Immersive Virtual Reality: A Lens on Methodological and Technological Challenges; supporting the Semi-automatic Feedback Provisioning on Programming Assignments; educational Chatbot to Support Question Answering on Slack; a Case Study on Students’ Opinions About Adaptive and Classical Tests; readability Assessment of Academic Texts at Different Degree Levels; materials Science and Engineering Education Based on Reality-Virtuality Technologies; kaleidoscope: A Multi-perspective Technology-Enhanced Observation Method to Support the Development of Negotiation Skills; a New Metric to Help Teachers Unveil Meaningful Learning in Concept Maps.",
    "abstract_processed": "proceed contain paper special focu confer methodolog intellig system technolog enhanc learn topic includ evalu bibliograph import digit educ disrupt relat social network case linkedin learn may distanc learn cours statist satisfi medic student experi italian univers sampl covid pandem combin learner model reinforc learn adapt sequenc learn activ effect vr learn experi success educ code review tool first glimps retriev key topic sentenc topic awar bert conduct autom essay score automat educ concept extract use nlp digit environ literaci futur educ pilot experi seriou game co design learnweb support scienc educ research climat chang social media possibl improv develop execut function children teach comput think open govern data higher educ multidisciplinari innov teach experi design comput think iotgo teacher think brew umqombothi technic vr prototyp merg stem south african intang cultur heritag seriou game autism base immers virtual realiti len methodolog technolog challeng support semi automat feedback provis program assign educ chatbot support question answer slack case studi students’ opinion adapt classic test readabl assess academ text differ degre level materi scienc engin educ base realiti virtual technolog kaleidoscop multi perspect technolog enhanc observ method support develop negoti skill new metric help teacher unveil meaning learn concept map"
  },
  {
    "doc_id": "2024",
    "abstract_original": "The proceedings contain 76 papers. The special focus in this conference is on Computer Science and Educational Informatization. The topics include: A Summary Research of the Current Status, Hot Spots and Trends in STEM Education: Visual Analysis Based on Relevant Literature Published in CNKI Database; research on the Current Situation and Enhancement Strategies of Information Technology Teaching Ability of Teachers in Rural Teaching Points; research on User Profile of Game Products Based on Self-determination Theory; knowledge Graph Embedding Based on Triple Multilayer Perceptron; research on Recognition of Official Script in Natural Environment; research on Information Literacy Evaluation Framework and Its Indicator Interaction Relationship; evolutionary Game Analysis to Promote the Improvement of Youth Digital Literacy from the Perspective of Multiple Collaboration; research on Construction of Student Academic Early Warning Model Based on Ensemble Learning; Generating One-Turn Dialogue from Given Keywords Based on GPT-2(Chinese) for Oral Chinese Teaching; research on the Cultivation of Media Literacy Among Adolescents from the Perspective of Smart Education; exploring the Establishment and Implementation of a Teaching Evaluation System Based on Value-Added Assessment; exploration and Practice of Operating System Curriculum Reform Based on the Integration of Science and Education; teaching Quality Evaluation of Online Courses Based on Cloud Model and Entropy Weight; curling Strategy Teaching Case Design Based on Deep Reinforcement Learning; improving Programming Education Based on Programming Contest Problems: The Algorithm Implementation for the Constructive Proof of Euler Graph; research on the Teaching Model of Interdisciplinary Computational Thinking Cultivating from the Perspective of Problem-Solving.",
    "abstract_processed": "proceed contain paper special focu confer comput scienc educ informat topic includ summari research current statu hot spot trend stem educ visual analysi base relev literatur publish cnki databas research current situat enhanc strategi inform technolog teach abil teacher rural teach point research user profil game product base self determin theori knowledg graph embed base tripl multilay perceptron research recognit offici script natur environ research inform literaci evalu framework indic interact relationship evolutionari game analysi promot improv youth digit literaci perspect multipl collabor research construct student academ earli warn model base ensembl learn gener one turn dialogu given keyword base gpt chines oral chines teach research cultiv media literaci among adolesc perspect smart educ explor establish implement teach evalu system base valu ad assess explor practic oper system curriculum reform base integr scienc educ teach qualiti evalu onlin cours base cloud model entropi weight curl strategi teach case design base deep reinforc learn improv program educ base program contest problem algorithm implement construct proof euler graph research teach model interdisciplinari comput think cultiv perspect problem solv"
  },
  {
    "doc_id": "204807",
    "abstract_original": "A teaching approach applied to the introductory circuit analysis course in electrical engineering is discussed. A primary feature is that all attempts to constrain student usage of simulators are rejected. The approach is implemented as a learning sequence: a presimulation thought process, then a simulation followed by a post-simulation thought process. The laboratory notebook illustrates the thought-to-paper conversion process inherent within the presimulation learning experience. Notebook scribblings, characterized by the student as a thinking schematic, are decoded by the instructor for the purpose of developing teaching materials, including new problems that cannot be immediately submitted to a simulator. The printed data produced by the simulation is processed during the post-simulation learning experience for the purpose of interpreting network behavior.<>",
    "abstract_processed": "teach approach appli introductori circuit analysi cours electr engin discuss primari featur attempt constrain student usag simul reject approach implement learn sequenc presimul thought process simul follow post simul thought process laboratori notebook illustr thought paper convers process inher within presimul learn experi notebook scribbl character student think schemat decod instructor purpos develop teach materi includ new problem cannot immedi submit simul print data produc simul process post simul learn experi purpos interpret network behavior"
  },
  {
    "doc_id": "215383",
    "abstract_original": "Circuit complexity theory has tried to understand which problems can be solved by 'small' circuits of constant depth. Normally 'small' has meant 'polynomial in the input size', but a number of recent results have dealt with circuits of size 2 to the log n/sup 0(1)/ power, or quasipolynomial size. The author summarizes the reasons for thinking about the complexity classes so introduced, surveys these results and gives an overview of these classes. He also shows that the Barrington-Immerman-Straubing uniformity definition for polynomial-size classes can easily be extended to quasipolynomial size as well, with most of the key results remaining true in the uniform setting.<>",
    "abstract_processed": "circuit complex theori tri understand problem solv small circuit constant depth normal small meant polynomi input size number recent result dealt circuit size log n sup power quasipolynomi size author summar reason think complex class introduc survey result give overview class also show barrington immerman straub uniform definit polynomi size class easili extend quasipolynomi size well key result remain true uniform set"
  },
  {
    "doc_id": "219854",
    "abstract_original": "The author presents his view on the future of distributed and parallel computing. He touches upon the topics of computational theory, computer languages, operating systems, databases, architecture, and applications.<>",
    "abstract_processed": "author present view futur distribut parallel comput touch upon topic comput theori comput languag oper system databas architectur applic"
  },
  {
    "doc_id": "219861",
    "abstract_original": "Benchmark results for the Numerical Aerodynamic Simulation (NAS) Program at NASA Ames Research Center, which is dedicated to advancing the science of computational aerodynamics are presented. The benchmark performance results are for the Y-MP, Y-MO EL, and C-90 systems from Cray Research; the TC2000 from Bolt Baranek and Newman; the Gamma iPSC/860 from Intel; the CM-2, CM-200, and CM-5 from Thinking Machines; the CS-1 from Meiko Scientific; the MP-1 and MP-2 from MasPar Computer; and the KSR-1 from Kendall Square Research. The results for the MP-1 and -2, the KSR-1, and the CM-5 have not been published before. Many of the other results are improved from previous listings, reflecting improvements both in compilers and in implementations.<>",
    "abstract_processed": "benchmark result numer aerodynam simul na program nasa ame research center dedic advanc scienc comput aerodynam present benchmark perform result mp mo el c system cray research tc bolt baranek newman gamma ipsc intel cm cm cm think machin cs meiko scientif mp mp maspar comput ksr kendal squar research result mp ksr cm publish mani result improv previou list reflect improv compil implement"
  },
  {
    "doc_id": "232636",
    "abstract_original": "Presents a scalable algorithm for short-range molecular dynamics which minimizes interprocessor communications at the expense of a modest computational redundancy. The method combines Verlet neighbor lists with coarse-grained cells. Each processing node is associated with a cubic volume of space and the particles it owns are those initially contained in the volume. Data structures for 'own' and 'visitor' particle coordinates are maintained in each node. Visitors are particles owned by one of the 26 neighboring cells but lying within an interaction range of a face. The Verlet neighbor list includes pointers to own-own and own-visitor interactions. To communicate, each of the 26 neighbor cells sends a corresponding block of particle coordinates using message-passing cells. The algorithms has the numerical properties of the standard serial Verlet method and is efficient for hundreds to thousands of particles per node allowing the simulation of large systems with millions of particles. Preliminary results on the new CM-5 supercomputer are described.<>",
    "abstract_processed": "present scalabl algorithm short rang molecular dynam minim interprocessor commun expens modest comput redund method combin verlet neighbor list coars grain cell process node associ cubic volum space particl own initi contain volum data structur visitor particl coordin maintain node visitor particl own one neighbor cell lie within interact rang face verlet neighbor list includ pointer visitor interact commun neighbor cell send correspond block particl coordin use messag pass cell algorithm numer properti standard serial verlet method effici hundr thousand particl per node allow simul larg system million particl preliminari result new cm supercomput describ"
  },
  {
    "doc_id": "234877",
    "abstract_original": "The Connection Machine model CM-5 provides high performance and ease of use for large data-intensive applications. The CM-5 architecture is designed to scale to teraflops performance on terabyte-sized problems. SPARC-based processing nodes, each with four vector pipes, are connected by two communications networks, the Data Network and the Control Network. The system combines the best features of SIMD (single-instruction multiple-data) and MIMD (multiple-instruction multiple-data) designs, integrating them into a single 'universal' parallel architecture. The processor nodes may be divided into independent computational partitions; each partition may be independently timeshared or devoted to batch processing. Programming languages include Fortran (with Fortran 90 array constructs) and C*, a parallel dialect of C. The PRISM programming environment supports source-level debugging, tracing, and profiling through a graphical interface based on X Windows.<>",
    "abstract_processed": "connect machin model cm provid high perform eas use larg data intens applic cm architectur design scale teraflop perform terabyt size problem sparc base process node four vector pipe connect two commun network data network control network system combin best featur simd singl instruct multipl data mimd multipl instruct multipl data design integr singl univers parallel architectur processor node may divid independ comput partit partit may independ timeshar devot batch process program languag includ fortran fortran array construct c parallel dialect c prism program environ support sourc level debug trace profil graphic interfac base x window"
  },
  {
    "doc_id": "236663",
    "abstract_original": "The authors present the results of an architectural comparison of SIMD (single-instruction multiple-data) massive parallelism, as implemented in the Thinking Machines Corp. CM-2, and vector or concurrent-vector processing, as implemented in the Cray Research Inc., Y-MP/8. The comparison is based primarily upon three application codes taken from the LANL (Los Alamos National Laboratory) CM-2 workload. Tests were run by porting CM Fortran codes to the Y-MP, so that nearly the same level of optimization was obtained on both machines. The results for fully configured systems, using measured data rather than scaled data from smaller configurations, show that the Y-MP/8 is faster than the 64 k CM-2 for all three codes. A simple model that accounts for the relative characteristic computational speeds of the two machines, and reduction in overall CM-2 performance due to communication or SIMD conditional execution, accurately predicts the performance of two of the three codes. The authors show the similarity of the CM-2 and Y-MP programming models and comment on selected future massively parallel processor designs.<>",
    "abstract_processed": "author present result architectur comparison simd singl instruct multipl data massiv parallel implement think machin corp cm vector concurr vector process implement cray research inc mp comparison base primarili upon three applic code taken lanl lo alamo nation laboratori cm workload test run port cm fortran code mp nearli level optim obtain machin result fulli configur system use measur data rather scale data smaller configur show mp faster k cm three code simpl model account rel characterist comput speed two machin reduct overal cm perform due commun simd condit execut accur predict perform two three code author show similar cm mp program model comment select futur massiv parallel processor design"
  },
  {
    "doc_id": "236673",
    "abstract_original": "Mixing of particles by chaotic flow fields was simulated on the Connection Machine. Each cell was assigned to the processor, and the coordinates of particles residing on the cell were kept in the local memory of the processor. This approach implies the exchange between the local memories, when a particle moves from one cell to another. Approximately 10/sup 5/ particles were injected into a time-dependent flow field obtained by solving the nonlinear system of partial differential equations describing turbulent thermal convection. The flow field was calculated on a CRAY, and data were transferred to a CM-200 through a high-speed HIPPI channel.<>",
    "abstract_processed": "mix particl chaotic flow field simul connect machin cell assign processor coordin particl resid cell kept local memori processor approach impli exchang local memori particl move one cell anoth approxim sup particl inject time depend flow field obtain solv nonlinear system partial differenti equat describ turbul thermal convect flow field calcul cray data transfer cm high speed hippi channel"
  },
  {
    "doc_id": "242440",
    "abstract_original": "Unlike conventional parallel languages, intentional languages let developers think of parallelism first and then use explicit constructs to express sequentialism, instead of the other way around.<>",
    "abstract_processed": "unlik convent parallel languag intent languag let develop think parallel first use explicit construct express sequenti instead way around"
  },
  {
    "doc_id": "246479",
    "abstract_original": "The authors describe the implementation and performance of a three dimensional particle simulation distributed between a Thinking Machines CM-2 and a Cray Y-MP. These are connected by a combination of two high-speed networks; a high performance parallel interface (HIPPI) and an optical network (Ultra Net). This is the first application to use this configuration at NASA Ames Research Center. The authors describe their experience implementing and using the application and report the results of several timing measurements. They show that the distribution of applications across disparate supercomputing platforms is feasible and has reasonable performance. In addition, several practical aspects of the computing environment are discussed.<>",
    "abstract_processed": "author describ implement perform three dimension particl simul distribut think machin cm cray mp connect combin two high speed network high perform parallel interfac hippi optic network ultra net first applic use configur nasa ame research center author describ experi implement use applic report result sever time measur show distribut applic across dispar supercomput platform feasibl reason perform addit sever practic aspect comput environ discuss"
  },
  {
    "doc_id": "269361",
    "abstract_original": "A finite-element solver for electrical defibrillation analysis has been developed on a massively parallel computer, Thinking Machines Corporation's Connection Machine 2 (CM-2), which allows a high degree of parallelism and the solution of large problems. The solver uses a nodal assembly technique where each node in the finite-element grid is mapped to a virtual processor in the computer. Using this solver, potential and current density distributions during transthoracic defibrillation have been calculated for different anatomic models, including a realistic 3-D finite-element model constructed from a series of cross-sectional magnetic resonance imaging (MRI) images of a mongrel dog. Numerical results obtained with this model are presented together with computational performance data for the algorithm.<>",
    "abstract_processed": "finit element solver electr defibril analysi develop massiv parallel comput think machin corpor connect machin cm allow high degre parallel solut larg problem solver use nodal assembl techniqu node finit element grid map virtual processor comput use solver potenti current densiti distribut transthorac defibril calcul differ anatom model includ realist finit element model construct seri cross section magnet reson imag mri imag mongrel dog numer result obtain model present togeth comput perform data algorithm"
  },
  {
    "doc_id": "28481",
    "abstract_original": "An expert system for pattern recognition based on features and knowledge is realized, and the theoretical and practical problems involved are discussed. The system, designed for analysis of geological patterns, has two novel characteristics. First, the system uses both features and knowledge for its analysis; there is some interaction between the two types of data. Secondly, the control strategy is based on an incomplete-reasoning and regression thinking model. The system is realized and proved to be effective.<>",
    "abstract_processed": "expert system pattern recognit base featur knowledg realiz theoret practic problem involv discuss system design analysi geolog pattern two novel characterist first system use featur knowledg analysi interact two type data secondli control strategi base incomplet reason regress think model system realiz prove effect"
  },
  {
    "doc_id": "296678",
    "abstract_original": "The Discrete Wavelet Transform (DWT) is becoming a widely used tool in image processing and other data analysis areas. A non-conventional variation of a spatiotemporal 3D DWT has been developed in order to analyze motion in time-sequential imagery. The computational complexity of this algorithm is /spl Theta/(n/sup 3/), where n is the number of samples in each dimension of the input image sequence. Methods are needed to increase the speed of these computations for large data sets. Fortunately, wavelet decomposition is very amenable to parallelization. Coarse-grained parallel versions of this process have been designed and implemented on three different architectures: a distributed network represented by a distributed network of Sun SPARCstation 2 workstations: two Intel hypercubes (an iPSC/2 and an iPSC/860); and a Thinking Machines Corporation CM-5, a massively parallel SPMD. This non-conventional 3D wavelet decomposition is very suitable for coarse-grain implementation on parallel computers with proper load balancing. Close to linear speedup over serial implementations has been achieved using a distributed network. Near-linear speedup was obtained on the hypercubes and the CM-5 for a variety of image-processing applications.<>",
    "abstract_processed": "discret wavelet transform dwt becom wide use tool imag process data analysi area non convent variat spatiotempor dwt develop order analyz motion time sequenti imageri comput complex algorithm spl theta n sup n number sampl dimens input imag sequenc method need increas speed comput larg data set fortun wavelet decomposit amen parallel coars grain parallel version process design implement three differ architectur distribut network repres distribut network sun sparcstat workstat two intel hypercub ipsc ipsc think machin corpor cm massiv parallel spmd non convent wavelet decomposit suitabl coars grain implement parallel comput proper load balanc close linear speedup serial implement achiev use distribut network near linear speedup obtain hypercub cm varieti imag process applic"
  },
  {
    "doc_id": "299539",
    "abstract_original": "Pioneered in Japan embraced in Europe and the United States, the engineering discipline of mechatronics seeks to design optimum performance into subsystems of electromechanical products. Mechatronics is the synergistic combination of precision mechanical engineering, electronic control and systems thinking in the design of products and manufacturing processes. The author examines the benefits of mechatronics by discussing the example of the design of an electronic braking system for automobiles.<>",
    "abstract_processed": "pioneer japan embrac europ unit state engin disciplin mechatron seek design optimum perform subsystem electromechan product mechatron synergist combin precis mechan engin electron control system think design product manufactur process author examin benefit mechatron discuss exampl design electron brake system automobil"
  },
  {
    "doc_id": "301956",
    "abstract_original": "Derby is a collection of independent computational entities that exchange money for work and information in the course of solving some problem. The key to building an agoric system is to design a monetary incentive structure that forces the individual entities to cooperate and work on the user's problem. While building Derby the authors discovered that it is very useful to think of the entities as being opportunistic and uncooperative. In Derby, information is traded in marketplaces, with sellers issuing predictions and placing bets on their correctness at predicting incoming data streams. Buyers submit bids of how much they are willing to pay for each dollar of bet placed. A sealed-bid second-price double auction determines which bidders are accepted. Later, the buyers report how happy they were with the information they bought, and this determines each seller's winnings in the parimutuel betting pool.<>",
    "abstract_processed": "derbi collect independ comput entiti exchang money work inform cours solv problem key build agor system design monetari incent structur forc individu entiti cooper work user problem build derbi author discov use think entiti opportunist uncoop derbi inform trade marketplac seller issu predict place bet correct predict incom data stream buyer submit bid much will pay dollar bet place seal bid second price doubl auction determin bidder accept later buyer report happi inform bought determin seller win parimutuel bet pool"
  },
  {
    "doc_id": "302309",
    "abstract_original": "After years of focussing almost exclusively on rather primitive symbolic forms of knowledge representation, AI has started a systematic attempt to design and implement a computational correlate to human diagrammatic representation and reasoning. However, a number of thinkers are on record as confidently claiming that such representation and reasoning is forever beyond a digital computer. Are such claims to be taken seriously? We think so/spl minus/when they are based on mental imagery more sophisticated than that which AI customarily concerns itself with. This \"recalcitrant\" imagery is the province of certain experts (e.g. authors and screenwriters).<>",
    "abstract_processed": "year focuss almost exclus rather primit symbol form knowledg represent ai start systemat attempt design implement comput correl human diagrammat represent reason howev number thinker record confid claim represent reason forev beyond digit comput claim taken serious think spl minu base mental imageri sophist ai customarili concern recalcitr imageri provinc certain expert e g author screenwrit"
  }
]