[
  {
    "doc_id": "10000326",
    "abstract_original": "The teaching of programming is a critical topic in our society. Given the Science and Technology initiatives, these topics are considered in different training cycles: primary, secondary and higher education. In the case of higher education, students must cultivate fundamental concepts for developing computer applications, which contribute to not only the knowledge of programming languages but also open guidelines for computational thinking. In previous research, we evaluated a set of platforms under a usability lens; on this occasion, we compare these results and their impact on the learning outcomes. We evaluated three experimental groups that used video game platforms to achieve their learning outcomes. Additionally, we will synthesize the literature regarding new paradigms of programming education under immersive environments.",
    "abstract_processed": "teach program critic topic societi given scienc technolog initi topic consid differ train cycl primari secondari higher educ case higher educ student must cultiv fundament concept develop comput applic contribut knowledg program languag also open guidelin comput think previou research evalu set platform usabl len occas compar result impact learn outcom evalu three experiment group use video game platform achiev learn outcom addit synthes literatur regard new paradigm program educ immers environ"
  },
  {
    "doc_id": "10003332",
    "abstract_original": "A pattern classifier named Hash-based Associative Memory-like Pattern Classifier (HAPC) based on hashing technique, associative memory, and human deep-thinking logic is proposed in this paper to solve pattern classification problems without complicated mathematical computation. In the hashing layer of the designed system, one of the similarity-preserve hashing is used to convert the input samples to hashed data which dramatically reduces the dimensionality of the data but keeps the similarity information. In the clustering layer, hashed samples are divided into different clusters, which can be considered a feature extraction process based on the similarity of the hash value. In the associate memory layer, each cluster will be trained as an associate memory to store the hashed data stably. In the logical layer, Bayesian inference is used to perform the decision-making process to classify the testing sample without complicated mathematical computation. In the simulation, we are able to achieve a good result, especially on small numbers of training data.",
    "abstract_processed": "pattern classifi name hash base associ memori like pattern classifi hapc base hash techniqu associ memori human deep think logic propos paper solv pattern classif problem without complic mathemat comput hash layer design system one similar preserv hash use convert input sampl hash data dramat reduc dimension data keep similar inform cluster layer hash sampl divid differ cluster consid featur extract process base similar hash valu associ memori layer cluster train associ memori store hash data stabli logic layer bayesian infer use perform decis make process classifi test sampl without complic mathemat comput simul abl achiev good result especi small number train data"
  },
  {
    "doc_id": "10003911",
    "abstract_original": "Brain-computer interface (BCI) is a promising technology that controls computers or machines using brain signals. With this technology, people with various disabilities, such as neural paralysis, and spinal cord injury can control electric devices or express their intention by thinking. However, previous BCI studies have a limitation that they can predict only one type of intention. To use the BCI system in daily life, the BCI user should be able to achieve various tasks such as moving, text typing, and arm movements. In this paper, we propose a multi-functional BCI method that can predict various intentions simultaneously. To classify multiple intentions, we proposed two prediction models using Neural Networks (NN) and Convolutional Neural Networks (CNN) models. To evaluate the proposed BCI system, the classification accuracy of the model was measured and compared using steady state visually evoked potential (SSVEP), sensory motor rhythm (SMR), and both of them (Multiple Intention). The average prediction accuracies were 22.46% in NN, 55.86% in CNN. These results indicate that the proposed multi-functional BCI can predict multiple intentions. It also means that users of the proposed BCI system can control various electric devices simultaneously.",
    "abstract_processed": "brain comput interfac bci promis technolog control comput machin use brain signal technolog peopl variou disabl neural paralysi spinal cord injuri control electr devic express intent think howev previou bci studi limit predict one type intent use bci system daili life bci user abl achiev variou task move text type arm movement paper propos multi function bci method predict variou intent simultan classifi multipl intent propos two predict model use neural network nn convolut neural network cnn model evalu propos bci system classif accuraci model measur compar use steadi state visual evok potenti ssvep sensori motor rhythm smr multipl intent averag predict accuraci nn cnn result indic propos multi function bci predict multipl intent also mean user propos bci system control variou electr devic simultan"
  },
  {
    "doc_id": "10004399",
    "abstract_original": "An increasing number of tools have been created to assist students in learning mathematics. Robots have been regarded as an especially powerful tool to help students master mathematics since students can simultaneously learn mathematics, programming, robotic control, and computational thinking. Although a number of educational robots and curricula have been developed, some of them do not comply with math standards, so they are primarily suitable for after-school programs, camps, or workshops. Students might not be able to focus on learning mathematics now that writing a program might be difficult for them due to debugging. In this paper, mathematics curricula that meet math standards are developed with a block-based programming platform, Roboblocky. Linkbots are utilized as robots in the curricula to teach and learn mathematics in school settings. Students learn mathematics by observing the motions of robots in simulations or on real mats. Most students improved greatly in mathematics after using the curricula. It is expected that the curricula based on Roboblocky will continue to be improved to enable more middle and high school students to be successful in learning mathematics.",
    "abstract_processed": "increas number tool creat assist student learn mathemat robot regard especi power tool help student master mathemat sinc student simultan learn mathemat program robot control comput think although number educ robot curricula develop compli math standard primarili suitabl school program camp workshop student might abl focu learn mathemat write program might difficult due debug paper mathemat curricula meet math standard develop block base program platform roboblocki linkbot util robot curricula teach learn mathemat school set student learn mathemat observ motion robot simul real mat student improv greatli mathemat use curricula expect curricula base roboblocki continu improv enabl middl high school student success learn mathemat"
  },
  {
    "doc_id": "10005170",
    "abstract_original": "As computing becomes more powerful and extends the reach of those who wield it, the imperative grows for computing professionals to make ethical decisions regarding the use of that power. We propose the concept of abstracted power to help computer science students understand how technology may distance them perceptually from consequences of their actions. Specifically, we identify technological intermediation and computational thinking as two factors in computer science that contribute to this distancing. To counter the abstraction of power, we argue for increased emotional engagement in computer science ethics education, to encourage students to feel as well as think regarding the potential impacts of their power on others. We suggest four concrete pedagogical approaches to enable this emotional engagement in computer science ethics curriculum, and we share highlights of student reactions to the material.",
    "abstract_processed": "comput becom power extend reach wield imper grow comput profession make ethic decis regard use power propos concept abstract power help comput scienc student understand technolog may distanc perceptu consequ action specif identifi technolog intermedi comput think two factor comput scienc contribut distanc counter abstract power argu increas emot engag comput scienc ethic educ encourag student feel well think regard potenti impact power other suggest four concret pedagog approach enabl emot engag comput scienc ethic curriculum share highlight student reaction materi"
  },
  {
    "doc_id": "10005436",
    "abstract_original": "The migration of traditional deployment to clouds has driven the need for a more robust security model, the Zero-Trust model. The application of zero-trust principles addresses known security issues such as lateral movement attacks but adds extra identity management complexity. In addition, to cover a broader range of attacks, one must think of strategies to protect data, code, and credentials in such applications. Confidential computing aims to fulfill this goal. Nevertheless, confidential computing is even more complex to implement than Zero-Trust. In this work, we combine the Zero-Trust model with confidential computing by leveraging the SPIFFE standard through its reference implementation (SPIRE), and Intel SGX through the SCONE framework, to seamlessly supply software identities to confidential microservices. Furthermore, we also protected the whole identity-provisioning stack with Intel SGX and assessed the performance overhead. We believe this combination not only improves the security of SPIFFE deployments but also leverages SPIFFE to facilitate the integration between confidential computing components and native applications.",
    "abstract_processed": "migrat tradit deploy cloud driven need robust secur model zero trust model applic zero trust principl address known secur issu later movement attack add extra ident manag complex addit cover broader rang attack one must think strategi protect data code credenti applic confidenti comput aim fulfil goal nevertheless confidenti comput even complex implement zero trust work combin zero trust model confidenti comput leverag spiff standard refer implement spire intel sgx scone framework seamlessli suppli softwar ident confidenti microservic furthermor also protect whole ident provis stack intel sgx assess perform overhead believ combin improv secur spiff deploy also leverag spiff facilit integr confidenti comput compon nativ applic"
  },
  {
    "doc_id": "10007773",
    "abstract_original": "Open-source research software plays a central role in accelerating advances in science and engineering. Its increasing significance, however, incentivizes malicious actors to attack that software and compromise the systems on which it runs, undermining the free and open exchange of trustworthy research codes. In the world of conventional software development, there has been a shift towards integrating security as early as possible in the development process to guard against malicious activity. Given the potential risks at hand, developers of research software must consider how to do the same across the research software lifecycle. This editorial argues for the need to unite diverse forms of expertise in scientific computing and software security to address these challenges and outlines a roadmap for future work in this space.",
    "abstract_processed": "open sourc research softwar play central role acceler advanc scienc engin increas signific howev incentiv malici actor attack softwar compromis system run undermin free open exchang trustworthi research code world convent softwar develop shift toward integr secur earli possibl develop process guard malici activ given potenti risk hand develop research softwar must consid across research softwar lifecycl editori argu need unit divers form expertis scientif comput softwar secur address challeng outlin roadmap futur work space"
  },
  {
    "doc_id": "10008928",
    "abstract_original": "Power, accountability, and responsibility for facial recognition technology require us to think carefully and methodically about the ethically significant interests of stakeholders. We suggest two simple models to help guide appropriate analysis when concerns arise.",
    "abstract_processed": "power account respons facial recognit technolog requir us think care method ethic signific interest stakehold suggest two simpl model help guid appropri analysi concern aris"
  },
  {
    "doc_id": "10009523",
    "abstract_original": "A lot of people are scared of cancer since it’s so deadly. However, if caught and treated early, cancer has a high chance of being cured. The ability of computer-assisted diagnosis to serve as a primary screening test for many illnesses, including cancer, has contributed to its rise in popularity in recent years. Deep learning is an artificial intelligence technology that gives computers intelligence by programming them to think like people. In this study, we explore the feasibility of training a deep neural network to provide such a prediction for breast cancer. Information is taken from a UCI-supplied dataset on breast cancer in Wisconsin. Over fitting is prevented by the early halting mechanism and the dropout layers in the neural network model, which together allow for an F1 score of more than 97.",
    "abstract_processed": "lot peopl scare cancer sinc it’ deadli howev caught treat earli cancer high chanc cure abil comput assist diagnosi serv primari screen test mani ill includ cancer contribut rise popular recent year deep learn artifici intellig technolog give comput intellig program think like peopl studi explor feasibl train deep neural network provid predict breast cancer inform taken uci suppli dataset breast cancer wisconsin fit prevent earli halt mechan dropout layer neural network model togeth allow f score"
  },
  {
    "doc_id": "10009551",
    "abstract_original": "Small, medium, and big organizations get several advantages from cloud computing, but it also presents obstacles. Whether a firm is in the financial, technology, or engineering sector, a cloud component might be beneficial. Though there are numerous obstacles associated with cloud computing, experts think that the benefits outweigh the drawbacks. The issues will be addressed when more research in the field of cloud computing is conducted. Cloud services are provided by a number of significant companies, including Amazon Web Services, Microsoft Azure, and Google Cloud Platform, among others. Among them, AWS (Amazon Web Services) is one of the fine cloud service providers that comprises several features, including the AWS EC2 (Elastic Compute Cloud) which is one of the widely used by many organizations. Amazon's Elastic Compute Cloud Web service delivers highly adjustable processing capacity throughout the cloud, allowing developers to construct applications with incredible scalability. Using EC2 (Elastic Compute Cloud) by using the proposed deployment method can be more effort saver for any IT development and deployment team for any organization. There should be an easy deployment method that auto-configures EC2 Instance. The aim of this research paper is to showcase the current deployment and service models provided by Amazon Web Services EC2 and present the proposed solution in order to the existing scenario. Furthermore, its advantages are also present so that it becomes easier to select the most appropriate one for deployment and research development.",
    "abstract_processed": "small medium big organ get sever advantag cloud comput also present obstacl whether firm financi technolog engin sector cloud compon might benefici though numer obstacl associ cloud comput expert think benefit outweigh drawback issu address research field cloud comput conduct cloud servic provid number signific compani includ amazon web servic microsoft azur googl cloud platform among other among aw amazon web servic one fine cloud servic provid compris sever featur includ aw ec elast comput cloud one wide use mani organ amazon elast comput cloud web servic deliv highli adjust process capac throughout cloud allow develop construct applic incred scalabl use ec elast comput cloud use propos deploy method effort saver develop deploy team organ easi deploy method auto configur ec instanc aim research paper showcas current deploy servic model provid amazon web servic ec present propos solut order exist scenario furthermor advantag also present becom easier select appropri one deploy research develop"
  },
  {
    "doc_id": "10010318",
    "abstract_original": "The development of social media in the form of websites and android applications should be appreciated. The background of this research is the stage to develop the software needed to know the age range. The objective thing to observe is through the visitor’s face on the web or application. The purpose is to avoid false information and get the proper process flow. The Technology used is deep learning for facial image recognition. The methods use Convolutional Neural Network with residuals because the advantage is using multi-branch layers but having a stable training process. The use of augmentation is needed to increase the variety of facial recognition image positions and to overcome unbalanced classes. The dataset used consists of seven categories, namely Children, Youth, Early Workers, Middle Ages, Pre-Retirement, Retirement, and Old People, which Bappenas regulate. Each folder contains about 1157 images with a total data of 8,105 images. The training process results can obtain a model with an average accuracy of 99.08% and a computational training time of about three hundred minutes. The model’s accuracy is 99.08%, with MSE 0.0037, RMSE 0.0610, and MAE 0.0037. Testing time is about 2 seconds.",
    "abstract_processed": "develop social media form websit android applic appreci background research stage develop softwar need know age rang object thing observ visitor’ face web applic purpos avoid fals inform get proper process flow technolog use deep learn facial imag recognit method use convolut neural network residu advantag use multi branch layer stabl train process use augment need increas varieti facial recognit imag posit overcom unbalanc class dataset use consist seven categori name children youth earli worker middl age pre retir retir old peopl bappena regul folder contain imag total data imag train process result obtain model averag accuraci comput train time three hundr minut model’ accuraci mse rmse mae test time second"
  },
  {
    "doc_id": "10013327",
    "abstract_original": "For current Internet is confronted with some defects such as structural rigidity, single function, and protocol-independent, the functions, performance and efficiency of the Internet were promoted from the perspective of the data plane, it proposes to support computing definable programmable data based on the full-dimensional defined polymorphic smart network. It uses in-network calculations to offload network functions to programmable network elements (programmable switches) to improve operational efficiency and flexibility. This article first uses the protocol-independent P4 language to realize the definable forwarding of the data plane; on this basis, a new forwarding model is designed, adding calculation functions that are not originally supported by P4, and the calculation is definable; finally, DES encryption is used as the calculation Function verification, and think and discuss the experimental process.",
    "abstract_processed": "current internet confront defect structur rigid singl function protocol independ function perform effici internet promot perspect data plane propos support comput defin programm data base full dimension defin polymorph smart network use network calcul offload network function programm network element programm switch improv oper effici flexibl articl first use protocol independ p languag realiz defin forward data plane basi new forward model design ad calcul function origin support p calcul defin final de encrypt use calcul function verif think discuss experiment process"
  },
  {
    "doc_id": "10013387",
    "abstract_original": "The educational challenges of society permeated by digital technologies are aimed at developing skills to identify and solve environment problems. In this context, computational thinking (CT) emerges as a set of skills to be developed from an early age, which requires the empowerment of programming and demands the use of technological tools. The purpose of this article is to present the design and implementation process of a computer tool for CT evaluation, as well as its validation with a sample of elementary school students from a public institution in Colombia. The methodology focuses on the phases of the SCRUM development process. The results show that women perceive less difficulty in understanding the activities to be solved. It is possible to obtain a web application type software taking into account the evaluated characteristics of the tools used for CT teaching, covering most of these, and with special emphasis on some such as the content in Spanish, instructional model, management of the course, learning activities, monitoring, feedback and gamification.",
    "abstract_processed": "educ challeng societi permeat digit technolog aim develop skill identifi solv environ problem context comput think ct emerg set skill develop earli age requir empower program demand use technolog tool purpos articl present design implement process comput tool ct evalu well valid sampl elementari school student public institut colombia methodolog focus phase scrum develop process result show women perceiv less difficulti understand activ solv possibl obtain web applic type softwar take account evalu characterist tool use ct teach cover special emphasi content spanish instruct model manag cours learn activ monitor feedback gamif"
  },
  {
    "doc_id": "10013445",
    "abstract_original": "In the article, the authors propose technological projects to develop computational thinking following the four problem-solving phases: understanding the problem, making the plan, executing the plan, and reviewing the solution. This study was based on a quantitative approach; the participants were 37 engineering students who had just entered university; also, the Pearson correlation statistical test was used to assess the relationship between computational thinking and problem- resolve. The activities of the technological projects have been developed using technological resources, such as the Arduino board, the mBlock software, and electronic sensors. It has been shown that following the problem-solving method based on the four phases contributes to the development of computational thinking skills in engineering students who have recently entered university.",
    "abstract_processed": "articl author propos technolog project develop comput think follow four problem solv phase understand problem make plan execut plan review solut studi base quantit approach particip engin student enter univers also pearson correl statist test use assess relationship comput think problem resolv activ technolog project develop use technolog resourc arduino board mblock softwar electron sensor shown follow problem solv method base four phase contribut develop comput think skill engin student recent enter univers"
  },
  {
    "doc_id": "10013462",
    "abstract_original": "Computational Thinking is one of the fundamental skills of the 21st century and will be a necessary part of all future work, so it is essential that children learn it in school. One way to work on Computational Thinking is through data visualization. This paper presents the motivation, design and implementation of a platform called AlfaDatizando, through which it is possible to work with data visualization activities to promote the skill of Computational Thinking in Digital Humanities. AlfaDatizando allows the creation, resolution, and feedback of data visualization activities without the need to use another platform. It also allows sharing didactic sequences and data sources with the educational community registered in the platform. AlfaDatizando is still in an early stage of development.",
    "abstract_processed": "comput think one fundament skill st centuri necessari part futur work essenti children learn school one way work comput think data visual paper present motiv design implement platform call alfadatizando possibl work data visual activ promot skill comput think digit human alfadatizando allow creation resolut feedback data visual activ without need use anoth platform also allow share didact sequenc data sourc educ commun regist platform alfadatizando still earli stage develop"
  },
  {
    "doc_id": "10013660",
    "abstract_original": "With the rapid development of autonomous driving technology, a variety of high-performance end-to-end driving models (E2EDMs) are being proposed. In order to understand the computational methods of E2EDMs, pixel-level explanations methods are used to obtain the explanations of the E2EDMs. However, little attention has been paid to the excellence of the explanations of E2EDMs. Therefore, in order to build trustworthy E2EDMs, we focus on improving the persuasibility of the explanations of E2EDMs. We propose an object-level explanation method (main approach) for E2EDMs, which masks the objects in the image and then treats the change in the prediction result as the importance of the objects, then we explain the E2EDM by the importance of each object. To further validate the effectiveness of object-level explanations, we propose another approach (validation approach), which trains E2EDMs with object information as input and generates the importance of objects using general explanation methods. Both approaches generate object-level explanations, in order to compare these object-level explanations with traditional pixel-level explanations, we propose experimental methods to measure the persuasibility of explanations of E2EDMs through a subjective and objective method. The subjective method evaluates persuasibility based on the extent to which participants think the importance of features indicated by the explanations is correct. The objective method evaluates the persuasibility based on the human annotation similarity between provided with only the important part of images and provided with the complete images. The experimental results show that the object-level explanations are more persuasive than the traditional pixel-level explanations.",
    "abstract_processed": "rapid develop autonom drive technolog varieti high perform end end drive model e edm propos order understand comput method e edm pixel level explan method use obtain explan e edm howev littl attent paid excel explan e edm therefor order build trustworthi e edm focu improv persuas explan e edm propos object level explan method main approach e edm mask object imag treat chang predict result import object explain e edm import object valid effect object level explan propos anoth approach valid approach train e edm object inform input gener import object use gener explan method approach gener object level explan order compar object level explan tradit pixel level explan propos experiment method measur persuas explan e edm subject object method subject method evalu persuas base extent particip think import featur indic explan correct object method evalu persuas base human annot similar provid import part imag provid complet imag experiment result show object level explan persuas tradit pixel level explan"
  },
  {
    "doc_id": "10014030",
    "abstract_original": "Many senior citizens stay in a hospital, or they are moved into sheltered accommodation. When they live apart from their family, there is a risk of them suffering from serious disturbance in mental ability including delirium due to stress [1] [2]. Their family can visit hospital or sheltered accomodation and meet senior citizens so as to reduce their stress and prevent them from suffering serious disturbance. However they might not be able to do so due to epidemics. They can communicate with their family as in the case of life when they live in same house by making constant video calls instead of visit. However, they may feel uncomfortable with constant shooting. We feel a need of the system that they can communicate without feeling uncomfortable even if senior citizens live apart from their family. When we came to think of the place where the families lived in comfortably, the living room came to our mind. Family live freely in the living room, spending much of their time without a strong connection each other. But a person can start a conversation at any time by talking to another person, and the conversation will end naturally without clear termination signal. For this reason, we have proposed “Virtual living room system” [3] that had these feature and reproduced a real living room. We made an experimental system in order to verify the validity of the system and conducted experiments that we had subjects live while using it. In the experiment, we confirm the usefulness of the system. However, we also confirm two problems through the opinions of participants. One is the lack of presence. The system displays an icon on the screen that represents the the information of whether person that lives away from the user is in a certain room or not. The icon is not related to the user, so it may not have made the users feel that they live in the same place. The other is the difficulty of setting up for using the system. Setting up this system is not easy for people who are not very familiar with computer operation. The system will actually be used in a hospital or nursing home. Therefore the staff work in would have to set up the system and help the user use it. They may be unfamiliar with computer operation and probably cannot set up the system and use it by theirselves. In this paper, we propose an improved system based on photos that is created in view of the problem and the actual users.",
    "abstract_processed": "mani senior citizen stay hospit move shelter accommod live apart famili risk suffer seriou disturb mental abil includ delirium due stress famili visit hospit shelter accomod meet senior citizen reduc stress prevent suffer seriou disturb howev might abl due epidem commun famili case life live hous make constant video call instead visit howev may feel uncomfort constant shoot feel need system commun without feel uncomfort even senior citizen live apart famili came think place famili live comfort live room came mind famili live freeli live room spend much time without strong connect person start convers time talk anoth person convers end natur without clear termin signal reason propos “virtual live room system” featur reproduc real live room made experiment system order verifi valid system conduct experi subject live use experi confirm use system howev also confirm two problem opinion particip one lack presenc system display icon screen repres inform whether person live away user certain room icon relat user may made user feel live place difficulti set use system set system easi peopl familiar comput oper system actual use hospit nurs home therefor staff work would set system help user use may unfamiliar comput oper probabl cannot set system use theirselv paper propos improv system base photo creat view problem actual user"
  },
  {
    "doc_id": "10016193",
    "abstract_original": "The number of network attacks is increasing at an unprecedented speed, and online phishing is the most common form of network attacks and the most close to our life. In order to enable users to better understand what kind of online phishing they have suffered, and enable scholars and researchers to more quickly customize detection for different types of online phishing detection. We need an in-depth summary of the existing types of online phishing and various detection methods. This paper classifies and summarizes all kinds of phishing, mainly introduces six kinds of phishing, including E-mail phishing and search engine phishing. For phishing detection methods, this paper also summarizes and classifies existing and widely used detection methods into seven categories such as list-based heuristic machine learning, and introduces them in detail. Then the paper analyzes the big data frontier technology and detection channel direction of assisted anomaly detection, and divides it into stream processing technology, Hadoop DPI parsing keyword recognition, web crawler recognition, etc. Finally the paper discusses and thinks deeply about the methods and techniques mentioned above as well as the current situation of phishing detection, and puts forward some forward-looking suggestions on the interpretation of data processing model selection and general detection architecture.",
    "abstract_processed": "number network attack increas unpreced speed onlin phish common form network attack close life order enabl user better understand kind onlin phish suffer enabl scholar research quickli custom detect differ type onlin phish detect need depth summari exist type onlin phish variou detect method paper classifi summar kind phish mainli introduc six kind phish includ e mail phish search engin phish phish detect method paper also summar classifi exist wide use detect method seven categori list base heurist machin learn introduc detail paper analyz big data frontier technolog detect channel direct assist anomali detect divid stream process technolog hadoop dpi pars keyword recognit web crawler recognit etc final paper discuss think deepli method techniqu mention well current situat phish detect put forward forward look suggest interpret data process model select gener detect architectur"
  },
  {
    "doc_id": "10018542",
    "abstract_original": "The three-way decision theory provides a three-way philosophical thinking to solve problems, and the regret theory quantifies the risk preferences of decision makers under different psychological behaviors. On the one hand, the combination of these two theories makes models more practical by considering the psychological behaviors of decision makers. On the other hand, we can effectively combine the advantages of the three-way decision theory with the regret theory to highlight the interpretability of decision-making processes. In this article, we propose a novel approximate estimation method for incomplete utility values via the regret theory and establish a wide sense of a three-way decision model on incomplete multiscale decision information systems. First, the degree of consistency for each scale is measured via using the dependence degree, then the optimal subsystem is selected by evaluating the scale selection cost. Furthermore, the incomplete multiscale evaluation information is transformed into triangular fuzzy numbers via linguistic term sets. Second, in light of fuzzy evaluation values and tradeoff factors, an estimation method for incomplete fuzzy subsystems is constructed, which can be used to calculate the utility difference and regret-rejoicing values for pairwise comparisons. Finally, from the perspective of human cognition, the tripartition and the corresponding decision rules are built by the tolerance degree, and the ranking of objects is calculated by the relative closeness degree. Additionally, multiaspect comparative and experimental analyses are performed by extensive experiments, and the feasibility, validity, and stability of the constructed model are shown by parametric analyses.",
    "abstract_processed": "three way decis theori provid three way philosoph think solv problem regret theori quantifi risk prefer decis maker differ psycholog behavior one hand combin two theori make model practic consid psycholog behavior decis maker hand effect combin advantag three way decis theori regret theori highlight interpret decis make process articl propos novel approxim estim method incomplet util valu via regret theori establish wide sens three way decis model incomplet multiscal decis inform system first degre consist scale measur via use depend degre optim subsystem select evalu scale select cost furthermor incomplet multiscal evalu inform transform triangular fuzzi number via linguist term set second light fuzzi evalu valu tradeoff factor estim method incomplet fuzzi subsystem construct use calcul util differ regret rejoic valu pairwis comparison final perspect human cognit tripartit correspond decis rule built toler degre rank object calcul rel close degre addit multiaspect compar experiment analys perform extens experi feasibl valid stabil construct model shown parametr analys"
  },
  {
    "doc_id": "10019495",
    "abstract_original": "The massively increasing data in computing world inspires the R&D of novel memory-centric computing architectures and devices. In this work, we propose a novel analog CIM technique for GEMM using 3D NOR Flash devices to support general-purpose matrix multiplication. Our analysis indicates that it’s very robust to use “billions” of memory cells with modest 4-level and large-spacing analog Icell to produce good accuracy and reliability, contrary to the past thinking to pursue many levels in each memory cell that inevitably suffers accuracy loss. We estimate that a 2.7Gb 3D NOR GEMM can provide a high-performance (frame/sec>300) image recognition inference of ResNet-50 on ImageNet dataset, using a simple flexible controller chip with 1MB SRAM without the need of massive ALU and external DRAM. The accuracy can maintain ~85% for Cifar-10 (by VGG7), and ~90% for ImageNet Top-5 (by ResNet-50) under good device control. This 3D NOR GEMM enjoys much lower system cost and flexibility than a complicated SOC. We also propose an operation and design method of “Cosine Similarity” computing using the 3D NOR. We can use a ternary similarity search algorithm with positive and negative inputs and weights to perform high-dimension feature vector (such as 512 for face recognition with FaceNet on VGGFace2 dataset) similarity computing in a high-parallelism CIM design (512 WL inputs, 1024 BL’s, at Tread=100ns). High-accuracy search (~97.8%, almost identical to 98% of software computing) and high internal search bandwidth (~5Tb/s per chip) are achieved. This in-Flash search accelerator is potential to enable new hardware-aware search algorithms in big data retrieval applications.",
    "abstract_processed": "massiv increas data comput world inspir r novel memori centric comput architectur devic work propos novel analog cim techniqu gemm use flash devic support gener purpos matrix multipl analysi indic it’ robust use “billions” memori cell modest level larg space analog icel produc good accuraci reliabl contrari past think pursu mani level memori cell inevit suffer accuraci loss estim gb gemm provid high perform frame sec imag recognit infer resnet imagenet dataset use simpl flexibl control chip mb sram without need massiv alu extern dram accuraci maintain cifar vgg imagenet top resnet good devic control gemm enjoy much lower system cost flexibl complic soc also propos oper design method “cosin similarity” comput use use ternari similar search algorithm posit neg input weight perform high dimens featur vector face recognit facenet vggface dataset similar comput high parallel cim design wl input bl’ tread ns high accuraci search almost ident softwar comput high intern search bandwidth tb per chip achiev flash search acceler potenti enabl new hardwar awar search algorithm big data retriev applic"
  },
  {
    "doc_id": "10020957",
    "abstract_original": "Reparative description of collections is a growing element of diversity, equity, and inclusion efforts at cultural heritage institutions. However, the scale and complexity of the work can be overwhelming in practice. I demonstrate that computational methodologies and data analytics can be used to kickstart the planning stage for reparative description of archival finding aids. I discuss auditing and analyzing finding aids at the University of Chicago Library’s Hanna Holborn Gray Special Collections Research Center for potentially problematic language utilizing Python, Trifacta, Tableau, and Neo4j. I describe insights gained by treating finding aids as data, and I share recommendations for structuring reparative description work in a logical and attainable way.",
    "abstract_processed": "repar descript collect grow element divers equiti inclus effort cultur heritag institut howev scale complex work overwhelm practic demonstr comput methodolog data analyt use kickstart plan stage repar descript archiv find aid discuss audit analyz find aid univers chicago library’ hanna holborn gray special collect research center potenti problemat languag util python trifacta tableau neo j describ insight gain treat find aid data share recommend structur repar descript work logic attain way"
  },
  {
    "doc_id": "10021019",
    "abstract_original": "This paper discusses the use of Computational Thinking (CT) in Archival Educators’ instruction towards enhancing the training and professional development of the library and archival workforce to meet the needs of their communities, and enhancing digital collection management and access to information and resources through retrospective and born-digital content. Four educators share their teaching strategies aimed at modernizing the way digital LIS and computational education are conducted. Their goal is to create an active and engaged community of future archival practitioners, ready to tackle the digital records and archives future.",
    "abstract_processed": "paper discuss use comput think ct archiv educators’ instruct toward enhanc train profession develop librari archiv workforc meet need commun enhanc digit collect manag access inform resourc retrospect born digit content four educ share teach strategi aim modern way digit li comput educ conduct goal creat activ engag commun futur archiv practition readi tackl digit record archiv futur"
  },
  {
    "doc_id": "10024282",
    "abstract_original": "Processing-in-memory (PIM) has attracted attention to overcome the memory bandwidth limitation, especially for computing memory-intensive DNN applications. Most PIM approaches use the CPU’s memory requests to deliver instructions and operands to the PIM engines, making a core busy and incurring unnecessary data transfer, thus, resulting in significant offloading overhead. DMA can resolve the issue by transferring a high volume of successive data without intervening CPU and polluting the memory hierarchy, thus perfectly fitting the PIM concept. However, the small computing resources of DRAM-based PIM devices allow us to transfer only small amounts of data at one DMA transaction and require a large number of descriptors, thus still incurring significant offloading overhead. This paper introduces PIM Instruction Set Architecture (ISA) using a DMA descriptor called PISA-DMA to express a PIM opcode and operand in a single descriptor. Our ISA makes PIM programming intuitive by thinking of committing one PIM instruction as completing one DMA transaction and representing a sequence of PIM instructions using the DMA descriptor list. Also, PISA-DMA minimizes the offloading overhead while guaranteeing compatibility with commercial platforms. Our PISA-DMA eliminates the opcode offloading overhead and achieves 1.25x, 1.31x, and 1.29x speedup over the baseline PIM at the sequence length of 128 with the BERT, RoBERTa, and GPT-2 models, respectively, in ONNX runtime with real machines. Also, we study how our proposed PISA affects performance in compiler optimization and show that the operator fusion of matrix-matrix multiplication and element-wise addition achieved 1.04x speedup, a similar performance gain using conventional ISAs.",
    "abstract_processed": "process memori pim attract attent overcom memori bandwidth limit especi comput memori intens dnn applic pim approach use cpu’ memori request deliv instruct operand pim engin make core busi incur unnecessari data transfer thu result signific offload overhead dma resolv issu transfer high volum success data without interven cpu pollut memori hierarchi thu perfectli fit pim concept howev small comput resourc dram base pim devic allow us transfer small amount data one dma transact requir larg number descriptor thu still incur signific offload overhead paper introduc pim instruct set architectur isa use dma descriptor call pisa dma express pim opcod operand singl descriptor isa make pim program intuit think commit one pim instruct complet one dma transact repres sequenc pim instruct use dma descriptor list also pisa dma minim offload overhead guarante compat commerci platform pisa dma elimin opcod offload overhead achiev x x x speedup baselin pim sequenc length bert roberta gpt model respect onnx runtim real machin also studi propos pisa affect perform compil optim show oper fusion matrix matrix multipl element wise addit achiev x speedup similar perform gain use convent isa"
  },
  {
    "doc_id": "10024444",
    "abstract_original": "Affective interaction with virtual humans can enhance the quality of user experience in virtual reality. It takes place through various considerations such as emotional representation in their behavioral patterns, facial expressions, head pose, body stance, and so on. Deciding on the emotional state of a virtual human at a moment, however, is still a challenge. Computational models of emotion, stemming from appraisal theories, are suggested for modeling emotion in virtual agents. Despite their competence in extracting emotion from appraisal values, they are poorly defined in describing how to assess appraisal values within a sense-think-act behavior model. Motivated by this lack of empirical knowledge on the appraisal stage, in this preliminary work, we propose a framework to bridge the gap between a computational model of emotion and a behavior model of virtual humans. To this end, we use a need-based, goal- oriented, autonomous behavior model to generate salient stimuli for eliciting emotions. Our simulation of a case study suggests that the proposed framework can produce sensible emotional states that conform to the essential principles of appraisal-based emotion theories.",
    "abstract_processed": "affect interact virtual human enhanc qualiti user experi virtual realiti take place variou consider emot represent behavior pattern facial express head pose bodi stanc decid emot state virtual human moment howev still challeng comput model emot stem apprais theori suggest model emot virtual agent despit compet extract emot apprais valu poorli defin describ assess apprais valu within sens think act behavior model motiv lack empir knowledg apprais stage preliminari work propos framework bridg gap comput model emot behavior model virtual human end use need base goal orient autonom behavior model gener salient stimuli elicit emot simul case studi suggest propos framework produc sensibl emot state conform essenti principl apprais base emot theori"
  },
  {
    "doc_id": "10024468",
    "abstract_original": "Many conflicts emanate from failure to understand others’ perspectives. Computationally supported roleplaying games have the potential to promote successful perspective taking. When implemented with the affordances of virtual reality, nuances of embodied communication in roleplaying can be more robustly modeled. In this paper, we describe the design and development of a roleplaying game aimed at simulating ingroup-outgroup biases with the goal of supporting positive perspective taking in virtual reality: On the Plane. The game presents players with a simulation of air travel experience, from airport security screening to in-flight events. On the Plane affords the ability to experience the simulation as different characters, supporting both ingroup and outgroup perspectives. We describe how the game is structured to simulate and challenge ingroupoutgroup biases within the context of xenophobia and lay out our plans for future research using On the Plane to promote positive perspective transformation (e.g., challenging one’s own ill-founded preconceptions).",
    "abstract_processed": "mani conflict eman failur understand others’ perspect comput support roleplay game potenti promot success perspect take implement afford virtual realiti nuanc embodi commun roleplay robustli model paper describ design develop roleplay game aim simul ingroup outgroup bias goal support posit perspect take virtual realiti plane game present player simul air travel experi airport secur screen flight event plane afford abil experi simul differ charact support ingroup outgroup perspect describ game structur simul challeng ingroupoutgroup bias within context xenophobia lay plan futur research use plane promot posit perspect transform e g challeng one’ ill found preconcept"
  },
  {
    "doc_id": "10025038",
    "abstract_original": "This study reports a pre-college initiative that aims to integrate computational thinking (CT) in an integrated STEM learning environment in community centers' after-school programs for upper-level elementary school students. The initiative takes a collaborative approach that engages a range of stakeholders including higher institution's STEM educational researchers and disciplinary experts, a school district, three community centers and their satellite campus that serve Title I schools, and both in-service and pre-service teachers to develop and implement an integrated “STEM + CT” curriculum. The design and development of the integrated STEM+CT curriculum was guided by project-based learning (PBL) that engages students in sustained project-based activities and requires students to apply multiple STEM content knowledge and skills to solve a problem, in after-school programs where they enjoy large blocks of dedicated time to learn and practice CT and STEM. The implementation of the curriculum was led by in-service teachers in community centers' after-school programs who serve as facilitators and learners, and bring a depth of pedagogical knowledge, and who also benefit from such sustained interactions. This collaborative initiative brings relevant stakeholders together and helps build a researcher-practitioner partnership that aims to design, study, improve, and scale innovations in teaching and learning, which facilities the solving of a shared challenge of educational practice - how to integrate CT in K-12 STEM learning? - in this study. Lessons learned from the collaborative process are also discussed.",
    "abstract_processed": "studi report pre colleg initi aim integr comput think ct integr stem learn environ commun center school program upper level elementari school student initi take collabor approach engag rang stakehold includ higher institut stem educ research disciplinari expert school district three commun center satellit campu serv titl school servic pre servic teacher develop implement integr “stem ct” curriculum design develop integr stem ct curriculum guid project base learn pbl engag student sustain project base activ requir student appli multipl stem content knowledg skill solv problem school program enjoy larg block dedic time learn practic ct stem implement curriculum led servic teacher commun center school program serv facilit learner bring depth pedagog knowledg also benefit sustain interact collabor initi bring relev stakehold togeth help build research practition partnership aim design studi improv scale innov teach learn facil solv share challeng educ practic integr ct k stem learn studi lesson learn collabor process also discuss"
  },
  {
    "doc_id": "10025068",
    "abstract_original": "K-12 computer science education has challenges related to content and to teacher expertise and comfort. This is further made difficult with inconsistent standards and teacher preparation from state-to-state. We describe a K-12 Computer Science Teaching certificate program, located at Montclair State University, aimed at providing current teachers in northern New Jersey with enhanced understanding of computer science concepts, capabilities, and skills, plus scaffolding of equitable and inclusive teacher practices for applied CS pedagogy. We discuss a brief history of the field, our curriculum and approach and then our first graduating cohort’s experiences and challenges. Finally, we discuss our future work.",
    "abstract_processed": "k comput scienc educ challeng relat content teacher expertis comfort made difficult inconsist standard teacher prepar state state describ k comput scienc teach certif program locat montclair state univers aim provid current teacher northern new jersey enhanc understand comput scienc concept capabl skill plu scaffold equit inclus teacher practic appli cs pedagogi discuss brief histori field curriculum approach first graduat cohort’ experi challeng final discuss futur work"
  },
  {
    "doc_id": "10025227",
    "abstract_original": "Computational thinking (CT) has been integrated into K-12 curricula globally, and coding has been the main vehicle in CT education. While great effort has been made in exploring cognitive effect of coding, limited has been done in attitudinal aspects. To bridge this gap, this study validated the existing Elementary Student Coding Attitudes Survey (ESCAS) in Chinese context and use the scale to explore how students perceived coding. Also, the association between coding attitude and CT performance was investigated. A total of 217 elementary students were involved. Psychometric qualities of ESCAS (Chinese) were examined, and the effect of coding attitudes on CT cognitive performance was analyzed with linear regression. Results showed that ESCAS (Chinese) was a valid and reliable attitudinal scale, and coding interest could predict CT performance. Future directions for the study were discussed.",
    "abstract_processed": "comput think ct integr k curricula global code main vehicl ct educ great effort made explor cognit effect code limit done attitudin aspect bridg gap studi valid exist elementari student code attitud survey esca chines context use scale explor student perceiv code also associ code attitud ct perform investig total elementari student involv psychometr qualiti esca chines examin effect code attitud ct cognit perform analyz linear regress result show esca chines valid reliabl attitudin scale code interest could predict ct perform futur direct studi discuss"
  },
  {
    "doc_id": "10027220",
    "abstract_original": "This article illustrates the online education platform technology of contemporary education and students' learning mode change and influence, and the technology to promote the development of derivatives of hybrid teaching concept, both at home and abroad present situation and existing problems, and through to the medical profession and carried on the thorough analysis of the characteristics of computer courses, through the strong support of the online education platform technology, In the teaching goal, curriculum resource development, to build hybrid curriculum implementation, formative assessment established medical college computer basic course reform model depth fusion, practice and summary and online education platform technology plays an indispensable role in hybrid teaching, online depth fusion teaching reform and innovation of teaching mode, It stimulates students' learning enthusiasm, steadily improves the degree of knowledge transfer, and promotes the improvement of talent training quality in medical higher education, which has important practical significance for the development of higher education.",
    "abstract_processed": "articl illustr onlin educ platform technolog contemporari educ student learn mode chang influenc technolog promot develop deriv hybrid teach concept home abroad present situat exist problem medic profess carri thorough analysi characterist comput cours strong support onlin educ platform technolog teach goal curriculum resourc develop build hybrid curriculum implement form assess establish medic colleg comput basic cours reform model depth fusion practic summari onlin educ platform technolog play indispens role hybrid teach onlin depth fusion teach reform innov teach mode stimul student learn enthusiasm steadili improv degre knowledg transfer promot improv talent train qualiti medic higher educ import practic signific develop higher educ"
  },
  {
    "doc_id": "10027252",
    "abstract_original": "In recent years, artificial intelligence technology is booming, and artificial intelligence technology has become a research hotspot in academic circles. The author uses CiteSpace to conduct citation analysis on the research literature of knowledge map in the field of artificial intelligence. Through LLR cluster analysis, it is known that most of the research topics focus on basic theoretical research, method research and application research. This paper analyzes the proportion of artificial intelligence in various industries by using SPSS technology, and forecasts the trend of the scale of China’s artificial intelligence market. On the basis of adhering to the principle of people-oriented and the unity of truth principle and value principle, we should overcome the problems caused by man-machine relationship and promote the harmonious coexistence of artificial intelligence and human intelligence.",
    "abstract_processed": "recent year artifici intellig technolog boom artifici intellig technolog becom research hotspot academ circl author use citespac conduct citat analysi research literatur knowledg map field artifici intellig llr cluster analysi known research topic focu basic theoret research method research applic research paper analyz proport artifici intellig variou industri use spss technolog forecast trend scale china’ artifici intellig market basi adher principl peopl orient uniti truth principl valu principl overcom problem caus man machin relationship promot harmoni coexist artifici intellig human intellig"
  },
  {
    "doc_id": "10027409",
    "abstract_original": "With the continuous development of big data and artificial intelligence, big data and intelligence in the traditional field will be inevitable. At present, the combination of artificial intelligence and the education industry is becoming a hot spot in artificial intelligence applications. This research explores the research hotspots of artificial intelligence in education, using Bloom’s educational goal classification method to divide learning effects into cognitive learning effects, emotional learning effects, and skill-behavior learning effects, and analyze the effects of artificial intelligence on student learning. Through the in-depth integration of artificial intelligence and education, cultivate students’ human-computer collaboration ability, promote education reform, strengthen the research of artificial intelligence education learning content, and strengthen artificial intelligence theoretical innovation and practical innovation to enhance the learning effect.",
    "abstract_processed": "continu develop big data artifici intellig big data intellig tradit field inevit present combin artifici intellig educ industri becom hot spot artifici intellig applic research explor research hotspot artifici intellig educ use bloom’ educ goal classif method divid learn effect cognit learn effect emot learn effect skill behavior learn effect analyz effect artifici intellig student learn depth integr artifici intellig educ cultiv students’ human comput collabor abil promot educ reform strengthen research artifici intellig educ learn content strengthen artifici intellig theoret innov practic innov enhanc learn effect"
  },
  {
    "doc_id": "10027412",
    "abstract_original": "Computational thinking is the process sequence of solving problems and behaves a method of systematic solving problems. Computational thinking is essentially a view of systematic information processing process. In essence, developing the computational thinking of middle school students is to improve their problem-solving ability and the corresponding practical accomplishment. The instructional activity design based on six links of problem solving can well meet the need of cultivating students’ computational thinking. The instructional mode of systematic problem solving in middle school can improve students’ learning effects and satisfaction, and promote students’ computational thinking ability significantly. The method of systematic information processing process can be trained.",
    "abstract_processed": "comput think process sequenc solv problem behav method systemat solv problem comput think essenti view systemat inform process process essenc develop comput think middl school student improv problem solv abil correspond practic accomplish instruct activ design base six link problem solv well meet need cultiv students’ comput think instruct mode systemat problem solv middl school improv students’ learn effect satisfact promot students’ comput think abil significantli method systemat inform process process train"
  },
  {
    "doc_id": "10029394",
    "abstract_original": "Design is a creative, complex, and iterative process. Although a variety of AI models for supporting design has been developed, there is little research on providing a seamless flow across multiple AI models, as well as the inspiration evolution within the process. We present an integrated AI-based Creativity Support Tool(AI-CST) that systematically integrates multiple AI models and contains a novel Inpiration Evolver to facilitate collaboration between designers and AI models. A between-subject sneaker-design experiment comparing our integrated AI-CST and non-integrated AI-CST shows that our AI-CST can significantly improve designers’ performance. Different using preferences and evolution styles have been discovered by the Inspiration Evolver, which inspires further study on the adaptation of the integrated AI-CST.",
    "abstract_processed": "design creativ complex iter process although varieti ai model support design develop littl research provid seamless flow across multipl ai model well inspir evolut within process present integr ai base creativ support tool ai cst systemat integr multipl ai model contain novel inpir evolv facilit collabor design ai model subject sneaker design experi compar integr ai cst non integr ai cst show ai cst significantli improv designers’ perform differ use prefer evolut style discov inspir evolv inspir studi adapt integr ai cst"
  },
  {
    "doc_id": "10031762",
    "abstract_original": "With the development of corpus linguistics and the improvement of computer performance, the effect of machine translation is getting better and better, and has been widely used. However, the existing automatic machine translation technology is far from being completely practical. As a feasible alternative to automatic machine translation technology, computer-aided translation technology has been greatly developed, and a feasible mode of computer-aided translation is interactive machine translation technology. Therefore, this paper proposes a Human-Computer Interaction Algorithm(HCIA) and designs an English machine translation system(MTS). Based on the research and analysis of the existing interactive machine translation technology, a human-computer interactive English machine translation algorithm model is proposed; The experimental test and analysis of the English MTS proposed in this paper show that the translation system designed in this paper reduces the translator’s thinking time and cognitive burden, does not need to spend too much time and energy on the correct translation recognition, and improves the translation efficiency.",
    "abstract_processed": "develop corpu linguist improv comput perform effect machin translat get better better wide use howev exist automat machin translat technolog far complet practic feasibl altern automat machin translat technolog comput aid translat technolog greatli develop feasibl mode comput aid translat interact machin translat technolog therefor paper propos human comput interact algorithm hcia design english machin translat system mt base research analysi exist interact machin translat technolog human comput interact english machin translat algorithm model propos experiment test analysi english mt propos paper show translat system design paper reduc translator’ think time cognit burden need spend much time energi correct translat recognit improv translat effici"
  },
  {
    "doc_id": "10033178",
    "abstract_original": "This paper presents a comprehensive model of smart and collaborative last mile supply networks. Facing a multitude of challenges such as economic pressure, demographic change, and environmental demands, urban last mile supply networks are increasingly strained. Various solutions and strategies such as the integration of novel technologies and collaborative approaches are discussed in the literature and tested in case studies. The application of artificial intelligence for supply networks holds potential for future urban logistics optimization and is thus considered a relevant research avenue. A design science approach comprising system dynamics-based modeling is chosen due to last mile networks' inherent complexity. Systems thinking has proven to be useful in urban logistics and smart city research contexts as it enables researchers and practitioners to achieve a more holistic perspective. The proposed model contributes to a better understanding of last mile network complexity as well as the underlying interdependencies.",
    "abstract_processed": "paper present comprehens model smart collabor last mile suppli network face multitud challeng econom pressur demograph chang environment demand urban last mile suppli network increasingli strain variou solut strategi integr novel technolog collabor approach discuss literatur test case studi applic artifici intellig suppli network hold potenti futur urban logist optim thu consid relev research avenu design scienc approach compris system dynam base model chosen due last mile network inher complex system think proven use urban logist smart citi research context enabl research practition achiev holist perspect propos model contribut better understand last mile network complex well underli interdepend"
  },
  {
    "doc_id": "10033266",
    "abstract_original": "The design and development of smart products and services with data science enabled solutions forms a core topic of the current trend of digitalisation in industry. Enabling skilled staff, employees, and students to use data science in their daily work routine of designing such products and services is a key concern of higher education institutions, including universities, company workshop providers and in further education. The scope and usage scenario of this paper is to assess software modules ('tools') for integrated data and analytics as service (DAaaS). The tools are usually driven by machine learning, may be deployed in cloud infrastructures, and are specifically targeted at particular needs of the industrial manufacturing, production, or supply chain sector. The paper describes existing theories and previous work, namely methods used in didactics, work done for visually designing and using machine learning algorithms (no-code /low-code tools), as well as combinations of these two topics. For tools available on the market, an extended assessment of their suitability for a set of learning scenarios and personas is discussed.",
    "abstract_processed": "design develop smart product servic data scienc enabl solut form core topic current trend digitalis industri enabl skill staff employe student use data scienc daili work routin design product servic key concern higher educ institut includ univers compani workshop provid educ scope usag scenario paper assess softwar modul tool integr data analyt servic daaa tool usual driven machin learn may deploy cloud infrastructur specif target particular need industri manufactur product suppli chain sector paper describ exist theori previou work name method use didact work done visual design use machin learn algorithm code low code tool well combin two topic tool avail market extend assess suitabl set learn scenario persona discuss"
  },
  {
    "doc_id": "10036693",
    "abstract_original": "Information technology changes people's way of working, learning and thinking at an amazing speed, which will inevitably lead to comprehensive reform and development in the education field. The epidemic situation of COVID-19 makes online teaching the main teaching mode of “teaching without stopping and learning without stopping”. The application of modern education technology based on “Chaoxing Platform+Tencent Meeting” in teaching process is explored. Based on teaching environment, interactive teaching mode construction, teaching management and evaluation, the teaching design is carried out in combination with the actual characteristics of each teaching link. The application of virtual simulation modern educational technology in the course Circuit Analysis is studied, and the convenience and the intuitiveness brought by virtual simulation technical resources and interactive platform are given full play, and the virtual simulation technology can effectively solve the obscure circuit analysis problem in theoretical teaching. The aim of teaching model reform has been achieved.",
    "abstract_processed": "inform technolog chang peopl way work learn think amaz speed inevit lead comprehens reform develop educ field epidem situat covid make onlin teach main teach mode “teach without stop learn without stopping” applic modern educ technolog base “chaox platform tencent meeting” teach process explor base teach environ interact teach mode construct teach manag evalu teach design carri combin actual characterist teach link applic virtual simul modern educ technolog cours circuit analysi studi conveni intuit brought virtual simul technic resourc interact platform given full play virtual simul technolog effect solv obscur circuit analysi problem theoret teach aim teach model reform achiev"
  },
  {
    "doc_id": "10036735",
    "abstract_original": "The impact of new technology on higher vocational education(HVE) has attracted the attention of many domestic scholars. The current direction of education informatization research is mostly smart classrooms. Therefore, schools will inevitably promote education informatization through the use of smart classrooms, and smart classrooms with classroom teaching(CT), teacher-student activities, and Internet + education will also become the core. This article uses experimental analysis and questionnaire survey methods to experiment on the design and application of the intelligent CT model of deep learning in HVE, compare and analyze the learning effects of the experimental and control classes of computer professional courses, and investigate and analyze their attitudes to the application of the intelligent classroom model. The experimental survey results show that the outstanding students in the experimental class has more students than that in the control class, and the learning effect is better than the traditional mode in the smart CT mode of deep learning, and most students in the experimental class prefer the use of the smart classroom mode. It can be concluded that it is necessary to study the design and application of the intelligent CT model of deep learning in HVE. In the intelligent classroom teaching system, data mining, K-means algorithm and MapReduce framework are comprehensively applied. By analyzing various behavioral data of students in school, the potential value behind these data is mined, so as to improve the construction of intelligent classroom and promote the improvement of higher vocational education.",
    "abstract_processed": "impact new technolog higher vocat educ hve attract attent mani domest scholar current direct educ informat research mostli smart classroom therefor school inevit promot educ informat use smart classroom smart classroom classroom teach ct teacher student activ internet educ also becom core articl use experiment analysi questionnair survey method experi design applic intellig ct model deep learn hve compar analyz learn effect experiment control class comput profession cours investig analyz attitud applic intellig classroom model experiment survey result show outstand student experiment class student control class learn effect better tradit mode smart ct mode deep learn student experiment class prefer use smart classroom mode conclud necessari studi design applic intellig ct model deep learn hve intellig classroom teach system data mine k mean algorithm mapreduc framework comprehens appli analyz variou behavior data student school potenti valu behind data mine improv construct intellig classroom promot improv higher vocat educ"
  },
  {
    "doc_id": "10036800",
    "abstract_original": "Big data is relative to data in the general sense. It refers to such a data collection: the amount of data is growing so fast that it is impossible to collect, process, store and store data within a certain period of time with conventional data tools. Calculated data set. The era of big data has changed people's social life and way of thinking. In the field of education, it has also promoted the reform of teaching mode, especially the teaching of foreign languages. At the same time, it also brings challenges and new ideas to Japanese grammar teaching.",
    "abstract_processed": "big data rel data gener sens refer data collect amount data grow fast imposs collect process store store data within certain period time convent data tool calcul data set era big data chang peopl social life way think field educ also promot reform teach mode especi teach foreign languag time also bring challeng new idea japanes grammar teach"
  },
  {
    "doc_id": "10038656",
    "abstract_original": "John Clark was inventor of the Eureka machine to generate hexameter Latin verse. He labored for 13 years from 1832 to implement the device that could compose at random over 26 million different lines of well-formed verse. This article proposes that Clark should be regarded as an early cognitive scientist. Clark described his machine as an illustration of a theory of “kaleidoscopic evolution” whereby the Latin verse is “conceived in the mind of the machine” then mechanically produced and displayed. We describe the background to automated generation of verse, the design and mechanics of Eureka, its reception in London in 1845 and its place in the history of language generation by machine. The article interprets Clark's theory of kaleidoscopic evolution in terms of modern cognitive science. It suggests that Clark has not been given the recognition he deserves as a pioneer of computational creativity.",
    "abstract_processed": "john clark inventor eureka machin gener hexamet latin vers labor year implement devic could compos random million differ line well form vers articl propos clark regard earli cognit scientist clark describ machin illustr theori “kaleidoscop evolution” wherebi latin vers “conceiv mind machine” mechan produc display describ background autom gener vers design mechan eureka recept london place histori languag gener machin articl interpret clark theori kaleidoscop evolut term modern cognit scienc suggest clark given recognit deserv pioneer comput creativ"
  },
  {
    "doc_id": "10039663",
    "abstract_original": "The application of “programming education” has become one of the future technological trends, and students with design backgrounds should also grasp this important development. In this study, the “AgilePoint NX” program course was established, and computational thinking was introduced into the course to guide students, through the image flow and low-code learning process, to carry out structured thinking and question speculation, and complete task exercises. This aims to teach design students to learn programming and computational thinking through a cloud-based low-code development platform with image processes and interdisciplinary learning processes. We conduct a comprehensive analysis and evaluate the learning effect through classroom learning observation, simple questionnaire survey, imagination scale, and other methods. Finally, the study found that in interdisciplinary programming learning, different factors lead to low learning effects of programming courses for design background students, resulting in different degrees of learning pain points and learning experiences. The power of imagination test is a tentative exploration of this research, but for the low-code development platform with fewer measurement data and biased towards procedural thinking, only predictive exploration has no significant data to show the specific impact on the programming learning process, only As a reference for interdisciplinary study.",
    "abstract_processed": "applic “program education” becom one futur technolog trend student design background also grasp import develop studi “agilepoint nx” program cours establish comput think introduc cours guid student imag flow low code learn process carri structur think question specul complet task exercis aim teach design student learn program comput think cloud base low code develop platform imag process interdisciplinari learn process conduct comprehens analysi evalu learn effect classroom learn observ simpl questionnair survey imagin scale method final studi found interdisciplinari program learn differ factor lead low learn effect program cours design background student result differ degre learn pain point learn experi power imagin test tent explor research low code develop platform fewer measur data bias toward procedur think predict explor signific data show specif impact program learn process refer interdisciplinari studi"
  },
  {
    "doc_id": "10040274",
    "abstract_original": "Alzheimer's disease is one of the commonly occurring disease in which the common cause of dementia called as memory loss will happen resiliently and damage the brain activity. It also produces cognitive abilities and serious impact of interference with the day today life. Disease contains 60% to 80% of dementia cases in the early stages are predicted and further actions are initiated to alert the patient behaviour from abnormal activity. The direct impact of Alzheimer's disease (AD) interfere with the regular activity and make complexity in making decisions, thinking capability, problem solving and speaking. The evaluation of artificial intelligence (AI) created numerous ways of analysing strategies, helpful for making the early prediction. In spite of image processing technology, Machine learning models are created to analyse the disease features, symptoms, Chronic records to perform AD detection. The role of deep learning algorithm incorporated with image processing, deep feature extraction, and deep feature fusion enhances the scope of research in AD analysis. Further the benefit of deep learning algorithm to provide search detection mechanism. The presented study discusses various criteria of AD detection and tabulated the findings.",
    "abstract_processed": "alzheim diseas one commonli occur diseas common caus dementia call memori loss happen resili damag brain activ also produc cognit abil seriou impact interfer day today life diseas contain dementia case earli stage predict action initi alert patient behaviour abnorm activ direct impact alzheim diseas ad interfer regular activ make complex make decis think capabl problem solv speak evalu artifici intellig ai creat numer way analys strategi help make earli predict spite imag process technolog machin learn model creat analys diseas featur symptom chronic record perform ad detect role deep learn algorithm incorpor imag process deep featur extract deep featur fusion enhanc scope research ad analysi benefit deep learn algorithm provid search detect mechan present studi discuss variou criteria ad detect tabul find"
  },
  {
    "doc_id": "10040291",
    "abstract_original": "“India's agriculture is its lifeline.” The production of agriculture depends on fertilisers. One of the main issues that farmers face is a lack of information regarding the necessary fertiliser amounts. Farmers think that when fertiliser use rises, production rises as well. This, however, is untrue since the soil just uses what it need and leaves the remainder behind. Overuse results in leaching, a decrease in the natural fertility of the soil, and other problems. A solution is to make it possible for farmers to test their soil and use fertilisers in accordance with the needs of the soil at a reasonable cost. This study describes the development of a low-cost soil nutrient detection method using pre-made capsules. Here, it is possible to do three different nutritional tests for sodium, potassium, and phosphorus. In this experiment, three test tubes are used, and after adding varied amounts of dirt and water to each, the mixture is stirred for 15 minutes. After then, the tube starts to change colour. A colour sensor is used in this instance, and it recognises the colour shift in the test tubes and compares it to the information previously known about the colour deficit. The farmer is advised of the shortage and how much fertiliser is necessary to make up for it once the sensor data is analysed using Arduino.",
    "abstract_processed": "“india agricultur lifelin ” product agricultur depend fertilis one main issu farmer face lack inform regard necessari fertilis amount farmer think fertilis use rise product rise well howev untru sinc soil use need leav remaind behind overus result leach decreas natur fertil soil problem solut make possibl farmer test soil use fertilis accord need soil reason cost studi describ develop low cost soil nutrient detect method use pre made capsul possibl three differ nutrit test sodium potassium phosphoru experi three test tube use ad vari amount dirt water mixtur stir minut tube start chang colour colour sensor use instanc recognis colour shift test tube compar inform previous known colour deficit farmer advis shortag much fertilis necessari make sensor data analys use arduino"
  },
  {
    "doc_id": "10040358",
    "abstract_original": "Alzheimer's disease progress over several years, it slowly ruins memories and thinking ability, and eventually the capacity to carry out daily tasks, leading to full-time care. The brain shrinks and loses brain cells as a result of Alzheimer's disease. While the condition can strike at any age, most patients with Alzheimer's disease are over 65.. Alzheimer patients mostly have Symptoms like memory loss, disorientation and problems with thinking ability but vary from person to person. Although genetics, environment, and lifestyle are the most likely causes of this illness, other experts think there may be multiple causes. The term “dementia” refers to brain illnesses that impair thinking, memory, and behaviour. The most typical cause of dementia is Alzheimer's disease. Patients with Alzheimer's disease typically struggle to speak clearly, identify relatives and friends, and recognise items. They can also become angry, restless, and frustrated. As Alzheimer's disease progresses, physical issues like weakness, loss of balance, and impaired bladder and bowel control appear. In this study paper, we will introduce a convolutional neural network (CNN), which is a machine learning technique, to recognise Alzheimer's disease. On the input image, image segmentation is carried out. CNN is a group of artificial neural networks that provides a more scalable approach to image classification and identification of patterns in images. Convolution is a mathematical procedure that CNN employs in place of matrix multiplication at one layer. CNN are different from other neural networks by their exceptional performance with audio, image or speech signal inputs. CNN algorithm take an input image, assign priority to different aspects for an image to find difference between images. CNN Captures Spatial and Temporal dependencies of an image using application of relevant filters.",
    "abstract_processed": "alzheim diseas progress sever year slowli ruin memori think abil eventu capac carri daili task lead full time care brain shrink lose brain cell result alzheim diseas condit strike age patient alzheim diseas alzheim patient mostli symptom like memori loss disorient problem think abil vari person person although genet environ lifestyl like caus ill expert think may multipl caus term “dementia” refer brain ill impair think memori behaviour typic caus dementia alzheim diseas patient alzheim diseas typic struggl speak clearli identifi rel friend recognis item also becom angri restless frustrat alzheim diseas progress physic issu like weak loss balanc impair bladder bowel control appear studi paper introduc convolut neural network cnn machin learn techniqu recognis alzheim diseas input imag imag segment carri cnn group artifici neural network provid scalabl approach imag classif identif pattern imag convolut mathemat procedur cnn employ place matrix multipl one layer cnn differ neural network except perform audio imag speech signal input cnn algorithm take input imag assign prioriti differ aspect imag find differ imag cnn captur spatial tempor depend imag use applic relev filter"
  },
  {
    "doc_id": "10040412",
    "abstract_original": "Twitter, a social networking platform allows users to convey their ideas. on a wide range of topics, including politics, sports, the stock market, and entertainment. It has a big influence on how people think. A bot on Twitter sends spam messages. As a result, detecting bots aids in spam detection. In this paper, the detection of twitter bots using Deep Learning methods is addressed. At present, the used models aren't updated with latest datasets and have reduced accuracy and some aren't multilingual. A final classifier, Bot-DenseNet, is built on a dense neural network on combining additional metadata with text encodings. Existing methods consider metadata information or along with some semantic features of text in encoding the user account. It will be trained and then verified using extensive data sets collected from Kaggle and twitter API. Subsequently, comparison between the performance of the Bot-DenseNet and Bag-of-Words model is also analyzed.",
    "abstract_processed": "twitter social network platform allow user convey idea wide rang topic includ polit sport stock market entertain big influenc peopl think bot twitter send spam messag result detect bot aid spam detect paper detect twitter bot use deep learn method address present use model updat latest dataset reduc accuraci multilingu final classifi bot densenet built dens neural network combin addit metadata text encod exist method consid metadata inform along semant featur text encod user account train verifi use extens data set collect kaggl twitter api subsequ comparison perform bot densenet bag word model also analyz"
  },
  {
    "doc_id": "10040422",
    "abstract_original": "Alzheimer's disease (AD) is a kind of Dementia. It affects the brain functions, thinking ability and creates memory loss. Each stage of AD is worsening the symptoms and also affects the patient's daily activities. The current diagnosis AD detection process is not providing an accurate report for the early stages of AD. Therefore, accurate Alzheimer detection is an open challenge for the researchers. In this research, a deep learning model is introduced to improve Alzheimer's stage diagnosis. The Hybrid deep model is designed to detect abnormal changes in brain (Magnetic Resonance Imaging) MRI scans. It utilizes the multi-class log loss (MCLL) function as the objective function to reduce the error rate in detecting AD stages. The MCLL approach computes the variations in actual and detected AD stages of each biomarkers features of input MRI images to identify loss rate. It helps to reduce the loss rate in AD stages detection. Moreover, the Hybrid deep learning model for Alzheimer stages detection (HDLMASD)system analysis the images deeply to provide accurate biomarkers detection with the help of all essential biomarkers processing steps. The efficiency of the Alzheimer stages diagnosis system is evaluated with various evaluation metrics. Finally, a comparative analysis is made with multiple present diagnosis systems to verify the performance of the AD detection system. The performance analysis proves that the AD stages diagnosis approach accuracy rate is improved up to 0.47% and the prediction error rate reduced up to 0.49% than comparison approaches.",
    "abstract_processed": "alzheim diseas ad kind dementia affect brain function think abil creat memori loss stage ad worsen symptom also affect patient daili activ current diagnosi ad detect process provid accur report earli stage ad therefor accur alzheim detect open challeng research research deep learn model introduc improv alzheim stage diagnosi hybrid deep model design detect abnorm chang brain magnet reson imag mri scan util multi class log loss mcll function object function reduc error rate detect ad stage mcll approach comput variat actual detect ad stage biomark featur input mri imag identifi loss rate help reduc loss rate ad stage detect moreov hybrid deep learn model alzheim stage detect hdlmasd system analysi imag deepli provid accur biomark detect help essenti biomark process step effici alzheim stage diagnosi system evalu variou evalu metric final compar analysi made multipl present diagnosi system verifi perform ad detect system perform analysi prove ad stage diagnosi approach accuraci rate improv predict error rate reduc comparison approach"
  },
  {
    "doc_id": "10040862",
    "abstract_original": "This document presents the results of the development of a learning program on computational thinking through programming challenges with robots oriented to early childhood. The methodological approach used was quantitative, using a quasi-experimental design, taking pretest/posttest measures, with experimental and control groups. The sample of participating students was 46. They belonged to a group of first grade of primary education, aged between 6 and 7 years, in a Spanish educational center. The learning of computational thinking was measured through the following dimensions: algorithmic thinking-sequences, abstraction-patterns and debugging. The learning activities used were an adaptation of the activities proposed in the “TangibleK” robotics curriculum. The results generated show positive effects in relation to the level of achievement reached by the students in the proposed challenges; in other words, there is a significant effect on the mastery of skills related to computational thinking. Differences were found between the pretest and posttest measures of the experimental group. Those of the latter group were statistically significant and higher than those of the control group. Therefore, we can statistically attribute the mastery of computational thinking skills to the participation in the training activities.",
    "abstract_processed": "document present result develop learn program comput think program challeng robot orient earli childhood methodolog approach use quantit use quasi experiment design take pretest posttest measur experiment control group sampl particip student belong group first grade primari educ age year spanish educ center learn comput think measur follow dimens algorithm think sequenc abstract pattern debug learn activ use adapt activ propos “tangiblek” robot curriculum result gener show posit effect relat level achiev reach student propos challeng word signific effect masteri skill relat comput think differ found pretest posttest measur experiment group latter group statist signific higher control group therefor statist attribut masteri comput think skill particip train activ"
  },
  {
    "doc_id": "10041572",
    "abstract_original": "This paper presents an interactive software tool developed to be used in an entry level course of control system. This software tool is open-source and it was programmed using Python3 language. It was created with the purpose of offering students an alternative software tool with a low computational cost. It was made thinking in providing a great user experience to the students when they are learning about process dynamics and closed-loop system behavior based on proportional-integral and derivative controllers. In particular, the real-time simulation mode, provides to the user an interactive way to understand the meaning of each parameter in classical second order process models or in PID controllers and, hence it could become in a useful tool in careers as electrical engineering.",
    "abstract_processed": "paper present interact softwar tool develop use entri level cours control system softwar tool open sourc program use python languag creat purpos offer student altern softwar tool low comput cost made think provid great user experi student learn process dynam close loop system behavior base proport integr deriv control particular real time simul mode provid user interact way understand mean paramet classic second order process model pid control henc could becom use tool career electr engin"
  },
  {
    "doc_id": "10042116",
    "abstract_original": "The expansion of artificial intelligence (AI) into our lives and livelihoods makes it clear that we must develop AI to be ethical and trustworthy. We propose Wasabi, a novel conceptual model for trustworthy AI based on an adaptation of the well-known ability–benevolence–integrity model of trust to trustworthiness.",
    "abstract_processed": "expans artifici intellig ai live livelihood make clear must develop ai ethic trustworthi propos wasabi novel conceptu model trustworthi ai base adapt well known ability–benevolence–integr model trust trustworthi"
  },
  {
    "doc_id": "10043302",
    "abstract_original": "Compared with combat in other fields, ground combat has the characteristics of complex environment, fierce confrontation and difficult coordination. The inherent shortcomings of artificial intelligence in understanding, interpretability and controllability restrict the development speed of unmanned ground combat. In order to give full play to the advantages of artificial intelligence, overcome deficiencies and promote the development of ground unmanned combat, this paper starts from the advantages of man-machine hybrid intelligence, Combined with OODA(Observatio, Orientation, Decision, Action) ring theory, this paper analyzes the application and prospect of man-machine hybrid intelligence in ground unmanned combat, and finally briefly analyzes the key technologies that should be grasped in the development of man-machine hybrid intelligence, hoping to provide inspiration and reference for the research of ground unmanned combat.",
    "abstract_processed": "compar combat field ground combat characterist complex environ fierc confront difficult coordin inher shortcom artifici intellig understand interpret control restrict develop speed unman ground combat order give full play advantag artifici intellig overcom defici promot develop ground unman combat paper start advantag man machin hybrid intellig combin ooda observatio orient decis action ring theori paper analyz applic prospect man machin hybrid intellig ground unman combat final briefli analyz key technolog grasp develop man machin hybrid intellig hope provid inspir refer research ground unman combat"
  },
  {
    "doc_id": "10046490",
    "abstract_original": "Cloud computing has arisen as a correlative response to deal with the troubles stood up to in figuring. While dispensed computing lets in us to greater deal extra with time/delay-delicate IoT functions (e.g., wise frameworks and ill-disposed climate), there is a scope of practical difficulties. For instance, the asset-compelled nature of mist hubs and heterogeneity of IoT occupations entangle endeavors to proficiently timetable errands. In this manner, to greater clean out time/delay-delicate unique IoE demands, the creators contribute by using imparting a sharp layer between IoE devices and haze hubs to contain a speedy and versatile learning-based mission planning strategy. We cautiously think about the exhibition of the proposed procedure the utilization of reproduction, as pleasantly as its accuracy the use of formal confirmation. The difference discoveries are promising, each in expressions of solidarity utilization and Quality of Service (QoS).",
    "abstract_processed": "cloud comput arisen correl respons deal troubl stood figur dispens comput let us greater deal extra time delay delic iot function e g wise framework ill dispos climat scope practic difficulti instanc asset compel natur mist hub heterogen iot occup entangl endeavor profici timet errand manner greater clean time delay delic uniqu ioe demand creator contribut use impart sharp layer ioe devic haze hub contain speedi versatil learn base mission plan strategi cautious think exhibit propos procedur util reproduct pleasantli accuraci use formal confirm differ discoveri promis express solidar util qualiti servic qo"
  },
  {
    "doc_id": "10046557",
    "abstract_original": "Now with the current state of power engineering, the idea of a microgrid (MG) is widely accepted because of how quickly energy electronics are being made. People are also becoming more interested in direct current (DC) MGs because DC delivery schemes have benefits like less damage and quick alignment of energy loading resources. With the rise of distributed output, a DCMG with many fonts is an important area to investigate. In this DCMG with many sources, the goal is to offer voltage help and strong value division. The control technique includes a thorough analysis of the \"state-of-the-art\" control procedures in DCMGs. This is important because it makes sure that MG's power and performance are always the same. In this section, the main and secondary control mechanisms in the DCMG hierarchy are explained. In particular, the main ways to control internal loop and droop control are looked at. The secondary regulation is a solution that is centralized, spread out, and independent.",
    "abstract_processed": "current state power engin idea microgrid mg wide accept quickli energi electron made peopl also becom interest direct current dc mg dc deliveri scheme benefit like less damag quick align energi load resourc rise distribut output dcmg mani font import area investig dcmg mani sourc goal offer voltag help strong valu divis control techniqu includ thorough analysi state art control procedur dcmg import make sure mg power perform alway section main secondari control mechan dcmg hierarchi explain particular main way control intern loop droop control look secondari regul solut central spread independ"
  },
  {
    "doc_id": "10046729",
    "abstract_original": "Credit card fraud, although not directly impacting banks, does have repercussions for the financial sector as a whole. Criminals pose a significant threat to safety since they are continually thinking up new methods to commit these types of fraud. Early detection of fraudulent behavior is therefore vital to retain customer trust and defend the firm. Since lawful transactions far outnumber fraudulent transactions, which typically make up less than 1% of all transactions, addressing the class imbalance issue in the data presents a significant challenge for developing fraud detection algorithms. It is challenging to identify a positive example (fraudulent case), and this challenge increases as more data is gathered, leading to a lower proportion of positive examples. Because of this, research is very important. Models for making predictions were trained in this study utilizing a variety of sampling strategies, including the ANN, GBM, and the RF. Models used SMOTE, RUS, DBSMOTE, and SMOTE plus ENS were all examples of Synthetic Minority Over-Sampling Technique (SMOTEENN). This research suggests that SMOTE-based sampling techniques will provide positive results. The highest recall (0.81) was achieved by the SMOTE sampling method when a DRF classifier was used. It was determined that this classifier has an accuracy score of 0.87. The Stacked Ensembling algorithm was accomplished using altogether of collected data, and its average performance was 0.78, making it the clear winner. As a fraud detection model, the Stacked Ensemble has performed well in most sampling operations.",
    "abstract_processed": "credit card fraud although directli impact bank repercuss financi sector whole crimin pose signific threat safeti sinc continu think new method commit type fraud earli detect fraudul behavior therefor vital retain custom trust defend firm sinc law transact far outnumb fraudul transact typic make less transact address class imbal issu data present signific challeng develop fraud detect algorithm challeng identifi posit exampl fraudul case challeng increas data gather lead lower proport posit exampl research import model make predict train studi util varieti sampl strategi includ ann gbm rf model use smote ru dbsmote smote plu en exampl synthet minor sampl techniqu smoteenn research suggest smote base sampl techniqu provid posit result highest recal achiev smote sampl method drf classifi use determin classifi accuraci score stack ensembl algorithm accomplish use altogeth collect data averag perform make clear winner fraud detect model stack ensembl perform well sampl oper"
  },
  {
    "doc_id": "10050074",
    "abstract_original": "This study uses a physical programming course to explore the development of children’s multiple intelligences. The process includes the design of teaching objectives, course design, course implementation and evaluation of effectiveness. A graphic multiple intelligences test scale was designed to measure children’s multiple intelligences. The study was conducted as a controlled experiment and the implementation of the courses showed that the physical programming coursess had a significant effect on the development of children’s natural observation, visual-spatial and mathematical-logical intelligences compared to the traditional courses.",
    "abstract_processed": "studi use physic program cours explor develop children’ multipl intellig process includ design teach object cours design cours implement evalu effect graphic multipl intellig test scale design measur children’ multipl intellig studi conduct control experi implement cours show physic program coursess signific effect develop children’ natur observ visual spatial mathemat logic intellig compar tradit cours"
  },
  {
    "doc_id": "10050860",
    "abstract_original": "Growing electricity demand, the deployment of renewable energy sources and the widespread use of smart home appliances provide new opportunities for home energy management systems (HEMSs), which can be defined as systems that improve the overall energy production and consumption of residential buildings by controlling and scheduling the use of household equipment. By saving energy, reducing residential electricity costs, optimizing the utilization rate and reliability of utility companies’ power systems, and reducing air pollution for society, HEMSs lead to an enhancement in the socioeconomic development of low-carbon economies. This review aims to systematically analyze and summarize the development trends and challenges of HEMSs in recent years. This paper reviews the development history of the HEMS architecture and discusses the characteristics of several major communication technologies in the current HEMS infrastructure. In addition, the common objectives and constraints related to scheduling optimization are classified, and several optimization methods in the literature, including various intelligent algorithms, have been introduced, compared, and critically analyzed. Furthermore, experimental studies and challenges in the real world are also summarized and recommendations are given. This paper reveals the trend from simple to complex in the architecture and functionality of HEMSs, discusses the challenges for future improvements in modeling and scheduling, and shows the development of various modeling and scheduling methods. Based on this review, researchers can gain a comprehensive understanding of current research trends in HEMSs and open up ideas for developing new modeling and scheduling approaches by gaining insight into the trade-offs between optimum solutions and computational complexity.",
    "abstract_processed": "grow electr demand deploy renew energi sourc widespread use smart home applianc provid new opportun home energi manag system hemss defin system improv overal energi product consumpt residenti build control schedul use household equip save energi reduc residenti electr cost optim util rate reliabl util companies’ power system reduc air pollut societi hemss lead enhanc socioeconom develop low carbon economi review aim systemat analyz summar develop trend challeng hemss recent year paper review develop histori hem architectur discuss characterist sever major commun technolog current hem infrastructur addit common object constraint relat schedul optim classifi sever optim method literatur includ variou intellig algorithm introduc compar critic analyz furthermor experiment studi challeng real world also summar recommend given paper reveal trend simpl complex architectur function hemss discuss challeng futur improv model schedul show develop variou model schedul method base review research gain comprehens understand current research trend hemss open idea develop new model schedul approach gain insight trade off optimum solut comput complex"
  },
  {
    "doc_id": "10053182",
    "abstract_original": "Epilepsy is considered as one of the most dangerous and fatal neurological disorder for the patient suffering from it. It affects the particular areas of the brain, due to which patient has seizures. Epilepsy is often referred to as ‘mirgi’ in the Hindi language. The purpose of the paper is to identify and understand the prediction of the seizures that occur due to neurological disorder called Epilepsy. Epilepsy can be explained as the disorder of central nervous system, which results in abnormal activities inside the brain. The impacts of this disorder come out as seizures, and patient behaves in a weird manner. Sometimes the patient can even lose the track of consciousness and sensations, the power of thinking and reacting is also affected. When seen during Electroencephalogram, the brain wave patterns which are observed appear to be different and abnormal. It is one of the difficult diseases to be diagnosed. In this project, we have tried to find out the result as whether the patient is having an epileptic seizure or not, using machine learning models, like KNN, logistic regression and naïve bayes. The Output label column of the dataset has the value whether patient is having (1) or not having (0) a seizure. In this paper, we have preprocessed the dataset and calculated the accuracies of the models on both training and testing datasets. Dataset is extracted from GitHub and the coding is performed in python programming language. Python libraries like seaborn, matplotlib, pandas, numpyetc are used in the pre-processing of the model. We have later on come to the result as out of the three models that we have used which one gives the best results, with the help of AUC value.",
    "abstract_processed": "epilepsi consid one danger fatal neurolog disord patient suffer affect particular area brain due patient seizur epilepsi often refer ‘mirgi’ hindi languag purpos paper identifi understand predict seizur occur due neurolog disord call epilepsi epilepsi explain disord central nervou system result abnorm activ insid brain impact disord come seizur patient behav weird manner sometim patient even lose track conscious sensat power think react also affect seen electroencephalogram brain wave pattern observ appear differ abnorm one difficult diseas diagnos project tri find result whether patient epilept seizur use machin learn model like knn logist regress naïv bay output label column dataset valu whether patient seizur paper preprocess dataset calcul accuraci model train test dataset dataset extract github code perform python program languag python librari like seaborn matplotlib panda numpyetc use pre process model later come result three model use one give best result help auc valu"
  },
  {
    "doc_id": "10053425",
    "abstract_original": "Suicide is a very critical and important issue in modern society. Suicide is the third-leading cause of death for college and high school students. Social media allows students in the digital environment to share their suicidal ideas and thoughts with others. Accurate and early detection and prevention of suicidal ideation in students can save the students' lives. To identify the risk factor for suicidal attempts, a suitable method of analysing the suicidal behaviour of students using their sentiment text posted on social media can be used. This paper presents an optimized Dragonfly algorithm (DFA) using a Deep Belief Network (DBN) for the automatic detection of suicidal ideation in students. In our CyberHelp Solution, the proposed DFA-based DBN model analyses student social media data, predicts suicidal behavior, and treats students appropriately. The sentiment analysis performs automated categorization of online messages and makes accurate predictions of the student’s suicidal behaviors. The dragonfly heuristic optimization algorithm is used for tuning the hyperparameter in the deep belief network. The proposed DFA-DBN technique has been implemented to predict suicidal ideation in students with a higher accuracy of 95.5% compared with other classification models.",
    "abstract_processed": "suicid critic import issu modern societi suicid third lead caus death colleg high school student social media allow student digit environ share suicid idea thought other accur earli detect prevent suicid ideat student save student live identifi risk factor suicid attempt suitabl method analys suicid behaviour student use sentiment text post social media use paper present optim dragonfli algorithm dfa use deep belief network dbn automat detect suicid ideat student cyberhelp solut propos dfa base dbn model analys student social media data predict suicid behavior treat student appropri sentiment analysi perform autom categor onlin messag make accur predict student’ suicid behavior dragonfli heurist optim algorithm use tune hyperparamet deep belief network propos dfa dbn techniqu implement predict suicid ideat student higher accuraci compar classif model"
  },
  {
    "doc_id": "10054028",
    "abstract_original": "Data mining approaches have proven to be successful in improving learners’ interaction with educational computer games. Despite the potential of predictive modelling in providing timely adaptive learning and gameplay experience, there is a lack of research on the early prediction of learners’ performance in educational games. In this research, we propose an early predictive modelling approach, called GameEPM, to estimate learners’ final scores in an educational game for promoting computational thinking. Specifically, the GameEPM approach models the sequence of learners’ actions and then uses a limited sequence of the actions to predict the final score of the game for each learner. The findings from our initial trials show that our approach can accurately and robustly estimate the learners’ performance at the early stages of the game. Using less than 50% of learners’ action sequences, the cross-validated deep learning model achieves a squared correlation higher than 0.8 with a relative error of less than 8%, outperforming a range of regression models like linear regression, random forest, neural networks, and support vector machines. An additional experiment showed that the validated deep learning model can also achieve high performance while tested on an independent game dataset, showing its applicability and robustness in real-world cases. Comparing the results with traditional machine learning methods revealed that, in the validation and application phases, up to 0.30 and 0.35 R2 gain is achieved in favor of the deep learning model, respectively. Finally, we found that while the lengths of action sequences influence the predictive power of the traditional machine learning methods, this effect is not substantial in the deep learning model.",
    "abstract_processed": "data mine approach proven success improv learners’ interact educ comput game despit potenti predict model provid time adapt learn gameplay experi lack research earli predict learners’ perform educ game research propos earli predict model approach call gameepm estim learners’ final score educ game promot comput think specif gameepm approach model sequenc learners’ action use limit sequenc action predict final score game learner find initi trial show approach accur robustli estim learners’ perform earli stage game use less learners’ action sequenc cross valid deep learn model achiev squar correl higher rel error less outperform rang regress model like linear regress random forest neural network support vector machin addit experi show valid deep learn model also achiev high perform test independ game dataset show applic robust real world case compar result tradit machin learn method reveal valid applic phase r gain achiev favor deep learn model respect final found length action sequenc influenc predict power tradit machin learn method effect substanti deep learn model"
  },
  {
    "doc_id": "10054368",
    "abstract_original": "The rise of the Industrial Revolution 4.0 and the increasing reliance on the digital economy drive the need for a new set of skills, especially in robotics learning, that includes computational thinking (CT) and adversarial thinking (AT) for the young generation. The need for CT-related skills includes various fields, such as robotics, engineering, computer science, mathematics, music, arts, and humanities. Therefore, adopting robotic learning with CT and AT can enhance learning skills over the conventional learning model. This paper presents a systematic literature review on CT and AT practices in robotics learning to improve educational methods. This study conducts a systematic literature review from four databases: ACM, Scopus, IEEE Xplore, and ScienceDirect. Sixty-five studies in robotics learning to increase CT and AT skills were analyzed by applying the inclusion and exclusion criteria. The study’s findings show that CT and AT are significant in training students to engage in robotics learning activities. These considerations will lead to strengthening their skill and critical thinking. The study also suggests that integrating these skills can prepare teachers for critical thinking and boost student learning. The findings suggest that CT and AT can directly adopt digital adversarial learning skills to improve overall robotics learning activities. For future studies, the difference in learning ages related to robotics activities with CT and AT applications can be studied to deeply comprehend the effectiveness of CT and AT applications.",
    "abstract_processed": "rise industri revolut increas relianc digit economi drive need new set skill especi robot learn includ comput think ct adversari think young gener need ct relat skill includ variou field robot engin comput scienc mathemat music art human therefor adopt robot learn ct enhanc learn skill convent learn model paper present systemat literatur review ct practic robot learn improv educ method studi conduct systemat literatur review four databas acm scopu ieee xplore sciencedirect sixti five studi robot learn increas ct skill analyz appli inclus exclus criteria study’ find show ct signific train student engag robot learn activ consider lead strengthen skill critic think studi also suggest integr skill prepar teacher critic think boost student learn find suggest ct directli adopt digit adversari learn skill improv overal robot learn activ futur studi differ learn age relat robot activ ct applic studi deepli comprehend effect ct applic"
  },
  {
    "doc_id": "1005573",
    "abstract_original": "Kohonen's self organizing maps (SOM) is a kind of neural network that the algorithm learns the feature of input data thorough unsupervised and competitive neighborhood learning. SOM is mapped from a high dimensional space onto a two dimensional space, so it can visualize the high-dimensional information to the map. In the SOM's learning algorithm, there are many factors to aggravate the computational load and a competition to be declared the winner. We think it is a major factor at the beginning of learning process that SOM's map is changing dynamically and widely and the learning dynamics depends on the distance of each input data. Thus we suppose that, by adjusting the data order, the competition must be reduced and the learning convergence must become faster. In this paper, we discuss the \"efficient learning by data order adjustment\", and compare it with the conventional method. We achieved a maximum 9% improvement.",
    "abstract_processed": "kohonen self organ map som kind neural network algorithm learn featur input data thorough unsupervis competit neighborhood learn som map high dimension space onto two dimension space visual high dimension inform map som learn algorithm mani factor aggrav comput load competit declar winner think major factor begin learn process som map chang dynam wide learn dynam depend distanc input data thu suppos adjust data order competit must reduc learn converg must becom faster paper discuss effici learn data order adjust compar convent method achiev maximum improv"
  },
  {
    "doc_id": "10057228",
    "abstract_original": "Digital human in cyberspace can help provide humanized services in specific applications, such as question & answer systems, recommender systems, chatter robots, and intelligent assistants. While most researches focus on behavior analytics, few of them integrate the personality that is also a closely related factor. As a classic indicator for personality representation, Myers–Briggs type indicator (MBTI) categorizes an individual into mutually exclusive types from four dichotomous axes (extraversion versus introversion, sensing versus intuition, thinking versus feeling, judging versus perceiving). Traditional recognition method using MBTI simply measures the user’s preference frequency in each axis through questionnaires, treating the dominant value as the identified result. Such a paradigm, however, represents all the people with only 16 types and cannot distinguish heterogeneous users clearly. This article proposes a novel personality recognition method using fuzzy logic. Different from previous classifications, our new method categorizes the individual in a continuous space and represents one’s personality in a more fine-grained level. We have designed comparative psychological tests for 77 people. The validation experiments on such tests indicate that the fuzzy-logic-based method is not only consistent with the classic MBTI tests (in the sense of defuzzification) but also provides the uncertainty for each personality type. Therefore, it can be viewed as a generalization of the classic MBTI tests and promotes the representation of individual’s heterogeneity for fine-grained analytics of digital human.",
    "abstract_processed": "digit human cyberspac help provid human servic specif applic question answer system recommend system chatter robot intellig assist research focu behavior analyt integr person also close relat factor classic indic person represent myers–brigg type indic mbti categor individu mutual exclus type four dichotom axe extravers versu introvers sens versu intuit think versu feel judg versu perceiv tradit recognit method use mbti simpli measur user’ prefer frequenc axi questionnair treat domin valu identifi result paradigm howev repres peopl type cannot distinguish heterogen user clearli articl propos novel person recognit method use fuzzi logic differ previou classif new method categor individu continu space repres one’ person fine grain level design compar psycholog test peopl valid experi test indic fuzzi logic base method consist classic mbti test sens defuzzif also provid uncertainti person type therefor view gener classic mbti test promot represent individual’ heterogen fine grain analyt digit human"
  },
  {
    "doc_id": "10058022",
    "abstract_original": "The study explores the effects of an interdisciplinary learning approach on developing students’ English learning (EL) and computational thinking (CT) through two different game-based learning approaches. A quasi-experiment is conducted to evaluate the effectiveness of this approach in terms of enhancing students’ CT knowledge and their EL achievement in an elementary school English as a foreign language (EFL) learning context. A total of 52 Grade 3 students take part in the experiment, of whom 28 are assigned to the experimental group learned with a machine educational robot (machine-ER) board game and 24 are assigned to the control group learned with a character educational robot (character-ER) board game. Results indicate that both groups made significant improvements in learning achievement: 1) in English-language achievement of learning vocabulary and sentence patterns; and 2) in CT concepts, although the machine-ER board game produces a greater increase than the character-ER board game in both language learning achievement and CT knowledge, their learning anxieties are also lower than those of the control group. The analysis of behavioral patterns also reveals that students playing the machine-ER board game demonstrate better language-learning interaction, whereas the students playing character-ER board game present greater CT development in finding solutions.",
    "abstract_processed": "studi explor effect interdisciplinari learn approach develop students’ english learn el comput think ct two differ game base learn approach quasi experi conduct evalu effect approach term enhanc students’ ct knowledg el achiev elementari school english foreign languag efl learn context total grade student take part experi assign experiment group learn machin educ robot machin er board game assign control group learn charact educ robot charact er board game result indic group made signific improv learn achiev english languag achiev learn vocabulari sentenc pattern ct concept although machin er board game produc greater increas charact er board game languag learn achiev ct knowledg learn anxieti also lower control group analysi behavior pattern also reveal student play machin er board game demonstr better languag learn interact wherea student play charact er board game present greater ct develop find solut"
  },
  {
    "doc_id": "10059942",
    "abstract_original": "The emergence of cloud computing(CC), the three service levels of IaaS, PaaS and SaaS, and the cloud service delivery model of “cloud” + “end” have changed the development thinking of the entire IT industry. The education industry has also been influenced by new technologies and concepts, especially the core technologies of CC - “virtualization” and “distribution”, which make the education industry face the challenges in teaching and learning resources management and laboratory management. In particular, the core technologies of CC - “virtualization” and “distributed” - have given the education industry a revolutionary solution to the challenges faced in the management of teaching resources and laboratory management. In this paper, we design a simulation model of physical education(PE) teaching in CC based on Java. The results show that the Java-based CC PE teaching is more conducive to improving students' performance and thus physical and motor skills; stimulating students' learning needs and thus forming expectations for course learning; and being able to continuously improve students' performance. The results show that the Java-based cloud-based PE teaching is more conducive to improving students' performance and thus physical and motor skills; stimulating students' learning needs and thus forming expectations for the learning of the course; and continuously stimulating students' learning initiatives to achieve the purpose of improving academic interest indicators.",
    "abstract_processed": "emerg cloud comput cc three servic level iaa paa saa cloud servic deliveri model “cloud” “end” chang develop think entir industri educ industri also influenc new technolog concept especi core technolog cc “virtualization” “distribution” make educ industri face challeng teach learn resourc manag laboratori manag particular core technolog cc “virtualization” “distributed” given educ industri revolutionari solut challeng face manag teach resourc laboratori manag paper design simul model physic educ pe teach cc base java result show java base cc pe teach conduc improv student perform thu physic motor skill stimul student learn need thu form expect cours learn abl continu improv student perform result show java base cloud base pe teach conduc improv student perform thu physic motor skill stimul student learn need thu form expect learn cours continu stimul student learn initi achiev purpos improv academ interest indic"
  },
  {
    "doc_id": "10060059",
    "abstract_original": "Both Artificial Intelligence (otherwise called recreated intelligence) and Robotics are instances of cutting edge improvements that will affect the development of mankind as fast as doable. The idea of “artificial intelligence” may be characterized as “any sort of artificial computational framework that exhibits shrewd lead, i.e., confounded direct that is successful for appearing at focuses on.” This definition envelops the conceivable outcomes of “artificial intelligence.” Minsky said that we ought to abstain from restricting “intelligence” to exercises that explicitly require data, whether or not they are performed by people. This proposes that we ought to join various machines, including those that illustrate “specific PC based intelligence that show just bound limits in learning or thinking anyway outperform presumptions at the robotization of explicit errands, likewise as machines general artificial intelligence that expect to make a by and large canny overseer.” Robots are the fake experts filling the role of real people. The fields of electrical engineering, mechanical engineering, and computer programming are the ones that meet up to frame robotics, which is a “part of recreated intelligence” that arrangements with the association, improvement, and use of robots. A theory on artificial intelligence can be viewed as here. The improvement of PC systems has made it conceivable to achieve undertakings that previously required the intelligence of a human. A few instances of these errands incorporate visual segregation, the affirmation of discussion, the arrangement of bearing, and the investigation of tongue contrasts. The subject matter expert, who is the “performer” in this reference, brings forth the item and polishes itself off in the body of the hardware. This is the key piece of the reference. The association between these two is that the control of the robot is an item expert that looks at input from the sensors, comes to a choice on what to do right away, and afterward guides the effectors to act in reality. The reason for this study is to give essential, basic measurements on two arising progressions: artificial intelligence (recreated intelligence), and robotics, as well as how much they are available in India. Consequently, the range of the things being examined is the primary significant part of these two disciplines. Moreover, it is feasible to portray them as being testing, engaging, and between disciplinary in nature. A flexible robot that was intended to complete various undertakings simultaneously to decide the ideal gathering that has the most noteworthy effectiveness extent of CAS model.",
    "abstract_processed": "artifici intellig otherwis call recreat intellig robot instanc cut edg improv affect develop mankind fast doabl idea “artifici intelligence” may character “ani sort artifici comput framework exhibit shrewd lead e confound direct success appear focus ” definit envelop conceiv outcom “artifici intellig ” minski said ought abstain restrict “intelligence” exercis explicitli requir data whether perform peopl propos ought join variou machin includ illustr “specif pc base intellig show bound limit learn think anyway outperform presumpt robot explicit errand likewis machin gener artifici intellig expect make larg canni overs ” robot fake expert fill role real peopl field electr engin mechan engin comput program one meet frame robot “part recreat intelligence” arrang associ improv use robot theori artifici intellig view improv pc system made conceiv achiev undertak previous requir intellig human instanc errand incorpor visual segreg affirm discuss arrang bear investig tongu contrast subject matter expert “performer” refer bring forth item polish bodi hardwar key piec refer associ two control robot item expert look input sensor come choic right away afterward guid effector act realiti reason studi give essenti basic measur two aris progress artifici intellig recreat intellig robot well much avail india consequ rang thing examin primari signific part two disciplin moreov feasibl portray test engag disciplinari natur flexibl robot intend complet variou undertak simultan decid ideal gather noteworthi effect extent ca model"
  },
  {
    "doc_id": "10061264",
    "abstract_original": "In 2022, the image governs daily life. The Image guides navigation, the sharing of affections, political geography, and the evolution of knowledge in the most varied scientific areas. In this article, we will try to reflect on the positioning of the subject before digital technology and on how we can think about the real at this moment in history. In practical terms, the real has imposed itself in the last three years in which the pandemic by COVID-19 made us rethink the bases of our existence. Its relationship with image expressions, like indexicality, mimicry or visibility, seems obvious. However, the complexity of the image brought by digital technologies that capture, edit and/or construct in a participative way in realtime, implies that expressions like illusion, participation, simulation or creativity; become much more pertinent to the discussion of the image and the positioning of the subject. By dislocating/displacing reality, /replacing it, through the manipulative capacity offered by the technology that is essentially plasma through computer graphics and exponentiated in portable devices, the image lost one of the fundamental characteristics of its essence as testimony, gaining an interactive synaesthetic dimension and enhancing the creativity of the users/fruiters.",
    "abstract_processed": "imag govern daili life imag guid navig share affect polit geographi evolut knowledg vari scientif area articl tri reflect posit subject digit technolog think real moment histori practic term real impos last three year pandem covid made us rethink base exist relationship imag express like index mimicri visibl seem obviou howev complex imag brought digit technolog captur edit construct particip way realtim impli express like illus particip simul creativ becom much pertin discuss imag posit subject disloc displac realiti replac manipul capac offer technolog essenti plasma comput graphic exponenti portabl devic imag lost one fundament characterist essenc testimoni gain interact synaesthet dimens enhanc creativ user fruiter"
  },
  {
    "doc_id": "10061374",
    "abstract_original": "The foreign object doped in the conveying belt is the most important factor to cause the tearing of the conveying belt. In order to solve the problem of low accuracy and poor real-time performance of foreign object detection, a new method based on improved Nanodet is proposed in this paper. The hardware of conveyor belt foreign object detection system is designed with ARM processor, and the system software is designed based on Android. It uses a conveyor belt foreign object detection system to detect foreign object. In order to detect foreign object images, a better Nanodet model is suggested. In order to increase detection accuracy while preserving processing speed, the model uses SIoU in place of the original position loss function. When the enhanced Nanodet model is applied to the conveyor belt foreign object detection system, the image of the foreign object appearing on the conveyor belt can be identified. The experimental findings indicate that a conveyor belt foreign object detection system based on an ARM processor and an Android operating system is capable of detecting foreign objects on conveyor belts with an average detection accuracy of 94.3%, a detection speed of 30 frames per second. The application of this method in the detection of foreign objects in conveyor belt can solve the shortcomings of existing methods. At the same time meet the requirements of the conveyor belt foreign object detection site environment.",
    "abstract_processed": "foreign object dope convey belt import factor caus tear convey belt order solv problem low accuraci poor real time perform foreign object detect new method base improv nanodet propos paper hardwar conveyor belt foreign object detect system design arm processor system softwar design base android use conveyor belt foreign object detect system detect foreign object order detect foreign object imag better nanodet model suggest order increas detect accuraci preserv process speed model use siou place origin posit loss function enhanc nanodet model appli conveyor belt foreign object detect system imag foreign object appear conveyor belt identifi experiment find indic conveyor belt foreign object detect system base arm processor android oper system capabl detect foreign object conveyor belt averag detect accuraci detect speed frame per second applic method detect foreign object conveyor belt solv shortcom exist method time meet requir conveyor belt foreign object detect site environ"
  },
  {
    "doc_id": "10063777",
    "abstract_original": "This research purpose is to figure out whether educational robotics is a strategy to develop young children's computational thinking. The method used in this research was quantitative with a descriptive exploratory scope, with an inductive-deductive approach. The sample consisted of 28 students taken from the population of the tenth-grade students of “Santa Mariana de Jesús” high school. The technique used was the survey and the data collection instrument was a questionnaire at the beginning (Pre-Test) and at the end of the process (Post Test). A \"Rubric to evaluate computational thinking\" using the Likert scale was used for its tabulation, with the use of the STEAM instructional framework learning methodology, and a \"Checklist\" was used to monitor the progress of the project. The result of the data analysis showed positive increase in computational thinking skills, due to in the Post Test the students reached the scale Very well with 64%, taking into account that in the beginning (PreTest) it was 14%, concluding that educational robotics is a didactic strategy that promotes computational thinking.",
    "abstract_processed": "research purpos figur whether educ robot strategi develop young children comput think method use research quantit descript exploratori scope induct deduct approach sampl consist student taken popul tenth grade student “santa mariana de jesús” high school techniqu use survey data collect instrument questionnair begin pre test end process post test rubric evalu comput think use likert scale use tabul use steam instruct framework learn methodolog checklist use monitor progress project result data analysi show posit increas comput think skill due post test student reach scale well take account begin pretest conclud educ robot didact strategi promot comput think"
  },
  {
    "doc_id": "10066039",
    "abstract_original": "The deep multi-view stereo (MVS) approaches generally construct a cost volume pyramid in a coarse- to- fine manner to regularize and regress the depth or disparity, which is often built upon a feature pyramid encoding geometry or an image pyramid. A pyramid is an excellent approach to reducing memory, and many papers said even low-resolution images or features contain enough information for estimating low-resolution depth maps. However, recent papers show that the higher the image resolution, the better the output depth map, which means the resolution of depth maps in each stage cause effect on the final outputs. Therefore, we think the low-resolution depth map may not be enough for the high-resolution depth map. In this paper, we propose a sub-pixel upsampling module for post-processing the cost volume to generate a big resolution depth map at each stage. Besides, we also proposed an edge-weighted loss function for optimizing those inaccurate depth values in the edge regions of objects. Finally, we implement them on CasMVSNet, showing the effectiveness of our proposed method. The content of abstract.",
    "abstract_processed": "deep multi view stereo mv approach gener construct cost volum pyramid coars fine manner regular regress depth dispar often built upon featur pyramid encod geometri imag pyramid pyramid excel approach reduc memori mani paper said even low resolut imag featur contain enough inform estim low resolut depth map howev recent paper show higher imag resolut better output depth map mean resolut depth map stage caus effect final output therefor think low resolut depth map may enough high resolut depth map paper propos sub pixel upsampl modul post process cost volum gener big resolut depth map stage besid also propos edg weight loss function optim inaccur depth valu edg region object final implement casmvsnet show effect propos method content abstract"
  },
  {
    "doc_id": "1006638",
    "abstract_original": "Nowadays, it is easy to find a number of different hybrid approaches for fuzzy modeling. All these approaches were built in a very ad-hoc manner, and did not follow a systematic approach. However, we think that some kind of information system which helps in the study of how algorithms can combine to model systems in a fuzzy fashion should be very helpful. In this article, we propose METALA (META-Learning Architecture), an architecture to study the typical processes of machine learning, to study the particular issue of fuzzy modeling.",
    "abstract_processed": "nowaday easi find number differ hybrid approach fuzzi model approach built ad hoc manner follow systemat approach howev think kind inform system help studi algorithm combin model system fuzzi fashion help articl propos metala meta learn architectur architectur studi typic process machin learn studi particular issu fuzzi model"
  },
  {
    "doc_id": "10066827",
    "abstract_original": "As 5G is deployed and applied, a large number of mobile devices have been increasingly deployed on the network. Scenarios such as smartphones, smart car, smart transportation, smart wearable devices, and smart industry are increasingly demanding for networks. And the Internet of Things (IoT), as a new and high technology, will play an important role and generate huge economic benefits. However, IoT security also faces many challenges due to the inherent security vulnerabilities in multiple device interactions and the data also needs more accurate processing. Big data and deep learning have been gradually applied in various industries. Therefore, we have summarized and analyzed the use of big data and deep learning technology to solve the hidden dangers of the IoT security under the consideration of some suggestions and thinking for industry applications.",
    "abstract_processed": "g deploy appli larg number mobil devic increasingli deploy network scenario smartphon smart car smart transport smart wearabl devic smart industri increasingli demand network internet thing iot new high technolog play import role gener huge econom benefit howev iot secur also face mani challeng due inher secur vulner multipl devic interact data also need accur process big data deep learn gradual appli variou industri therefor summar analyz use big data deep learn technolog solv hidden danger iot secur consider suggest think industri applic"
  },
  {
    "doc_id": "10067330",
    "abstract_original": "The artificial intelligence algorithm Generative Adversarial Networks (GAN) is excellent in creating works that simulate human output. As a result, many researchers have created impressive and satisfying art pieces such as images of non-existent people or expressive paintings. The Hijazi heritage is full of unique art forms, including the Rawashin that adorn Hijazi buildings. With the remarkable technical progress of recent years, it has become necessary to highlight this identity in a contemporary way. This work aims to exploit and explore the capabilities of artificial intelligence techniques and GAN networks in creating and producing innovative new shapes with regard to Rawashin (wooden windows). The aim is to integrate such shapes with Arabic lettering in order to produce unprecedented designs in terms of Hijazi buildings. This is done by training the machine using a dataset consisting of images of different building shapes containing Rawashin and some Arabic calligraphy using two types of GAN models. As a result, the model was able to learn and produce a new style of Rawashin.",
    "abstract_processed": "artifici intellig algorithm gener adversari network gan excel creat work simul human output result mani research creat impress satisfi art piec imag non exist peopl express paint hijazi heritag full uniqu art form includ rawashin adorn hijazi build remark technic progress recent year becom necessari highlight ident contemporari way work aim exploit explor capabl artifici intellig techniqu gan network creat produc innov new shape regard rawashin wooden window aim integr shape arab letter order produc unpreced design term hijazi build done train machin use dataset consist imag differ build shape contain rawashin arab calligraphi use two type gan model result model abl learn produc new style rawashin"
  },
  {
    "doc_id": "10069714",
    "abstract_original": "Robotic technologies have opened up hundreds of new limitless perspectives for educational reform. We have conducted research to study the impact and outcomes of Robotic teaching in systematic studies, experimental studies, and surveys. The conclusions of this study reveal that educational robots have an impact on children, teachers, and students. We looked into how robots affect children’s behavior, learning outcomes, perceptions, and human interactions. The learning efficacy of educational Robot teachers is determined by a variety of factors, including learning outcome, student behavior and mood during class sessions, student reaction, and student involvement during workshops/class participation/quizzes/Q&A sessions. The majority of the research articles we chose were experimental studies, and they all met their objectives, which included teaching mathematical problems, unit conversion problems, teaching English/secondary language, developing analytical, and computational skills, behavior, and attitude development, critical thinking, and improving communication skills.",
    "abstract_processed": "robot technolog open hundr new limitless perspect educ reform conduct research studi impact outcom robot teach systemat studi experiment studi survey conclus studi reveal educ robot impact children teacher student look robot affect children’ behavior learn outcom percept human interact learn efficaci educ robot teacher determin varieti factor includ learn outcom student behavior mood class session student reaction student involv workshop class particip quizz q session major research articl chose experiment studi met object includ teach mathemat problem unit convers problem teach english secondari languag develop analyt comput skill behavior attitud develop critic think improv commun skill"
  },
  {
    "doc_id": "10070941",
    "abstract_original": "Facing the growing complexity of Deep Neural Networks (DNNs), high-performance and power-efficient AI accelerators are desired to provide effective and affordable cloud inference services. We introduce our flagship product, i.e., the Cloudblazer i20 accelerator, which integrates the innovated Deep Thinking Unit (DTU 2.0). The design is driven by requests drawn from various AI inference applications and insights learned from our previous products. With careful tradeoffs in hardware-software co-design, Cloudblazer i20 delivers impressive performance and energy efficiency while maintaining acceptable hardware costs and software complexity/flexibility. To tackle computation- and data-intensive workloads, DTU 2.0 integrates powerful vector/matrix engines and a large-capacity multi-level memory hierarchy with high bandwidth. It supports comprehensive data flow and synchronization patterns to fully exploit parallelism in computation/memory access within or among concurrent tasks. Moreover, it enables sparse data compression/decompression, data broadcasting, repeated data transfer, and kernel code prefetching to optimize bandwidth utilization and reduce data access overheads. To utilize the underlying hardware and simplify the development of customized DNNs/operators, the software stack enables automatic optimizations (such as operator fusion and data flow tuning) and provides diverse programming interfaces for developers. Lastly, the energy consumption is optimized through dynamic power integrity and efficiency management, eliminating integrity risks and energy wastes. Based on the performance requirement, developers also can assign their workloads with the entire or partial hardware resources accordingly. Evaluated with 10 representative DNN models widely adopted in various domains, Cloudblazer i20 outperforms Nvidia T4 and A10 GPUs with a geometric mean of 2.22x and 1.16x in performance and 1.04x and 1.17x in energy efficiency, respectively. The improvements demonstrate the effectiveness of Cloudblazer i20’s design that emphasizes performance, efficiency, and flexibility.",
    "abstract_processed": "face grow complex deep neural network dnn high perform power effici ai acceler desir provid effect afford cloud infer servic introduc flagship product e cloudblaz acceler integr innov deep think unit dtu design driven request drawn variou ai infer applic insight learn previou product care tradeoff hardwar softwar co design cloudblaz deliv impress perform energi effici maintain accept hardwar cost softwar complex flexibl tackl comput data intens workload dtu integr power vector matrix engin larg capac multi level memori hierarchi high bandwidth support comprehens data flow synchron pattern fulli exploit parallel comput memori access within among concurr task moreov enabl spars data compress decompress data broadcast repeat data transfer kernel code prefetch optim bandwidth util reduc data access overhead util underli hardwar simplifi develop custom dnn oper softwar stack enabl automat optim oper fusion data flow tune provid divers program interfac develop lastli energi consumpt optim dynam power integr effici manag elimin integr risk energi wast base perform requir develop also assign workload entir partial hardwar resourc accordingli evalu repres dnn model wide adopt variou domain cloudblaz outperform nvidia gpu geometr mean x x perform x x energi effici respect improv demonstr effect cloudblaz ’s design emphas perform effici flexibl"
  },
  {
    "doc_id": "10070992",
    "abstract_original": "This paper first presents an input-stationary (IS) implemented crossbar accelerator (INCA), supporting inference and training for deep neural networks (DNNs). Processing-in-memory (PIM) accelerators for DNNs have been actively researched, specifically, with resistive random-access memory (RRAM), due to RRAM’s computing and memorizing capabilities and device merits. To the best of our knowledge, all previous PIM accelerators have saved weights into RRAMs and inputs (activations) into conventional memories—it naturally forms weight-stationary (WS) dataflow. WS has generally been considered the most optimized choice for high parallelism and data reuse. How-ever, WS-based PIM accelerators show fundamental limitations: first, remaining high dependency on DRAM and buffers for fetching and saving inputs (activations); second, a remarkable number of extra RRAMs for transposed weights and additional computational intermediates in training; third, coarse-grained arrays demanding high-bit analog-to-digital converters (ADCs) and introducing poor utilization in depthwise and pointwise convolution; last, degraded accuracy due to its sensitivity to weights which are affected by RRAM’s nonideality. On the other hand, we observe that IS dataflow, where RRAMs retain inputs (activations), can effectively address the limitations of WS, because of low dependency by only loading weights, no need for extra RRAMs, feasibility of fine-grained accelerator design, and less impact of input (activation) variance on accuracy. But IS dataflow is hardly achievable by the existing crossbar structure because it is difficult to implement kernel sliding and preserve the high parallelism. To support kernel movement, we constitute a cell structure with two-transistor-one-RRAM (2T1R). Based on the 2T1R cell, we design a novel three-dimensional (3D) architecture for high parallelism in batch training. Our experiment results prove the potential of INCA. Compared to the WS accelerator, INCA achieves up to 20.6× and 260× energy efficiency improvement in inference and training, respectively; 4.8× (inference) and 18.6× (training) speedup as well. While accuracy in WS drops to 15% in our high-noise simulation, INCA presents an even more robust result as 86% accuracy.",
    "abstract_processed": "paper first present input stationari implement crossbar acceler inca support infer train deep neural network dnn process memori pim acceler dnn activ research specif resist random access memori rram due rram’ comput memor capabl devic merit best knowledg previou pim acceler save weight rram input activ convent memories—it natur form weight stationari ws dataflow ws gener consid optim choic high parallel data reus ever ws base pim acceler show fundament limit first remain high depend dram buffer fetch save input activ second remark number extra rram transpos weight addit comput intermedi train third coars grain array demand high bit analog digit convert adc introduc poor util depthwis pointwis convolut last degrad accuraci due sensit weight affect rram’ nonid hand observ dataflow rram retain input activ effect address limit ws low depend load weight need extra rram feasibl fine grain acceler design less impact input activ varianc accuraci dataflow hardli achiev exist crossbar structur difficult implement kernel slide preserv high parallel support kernel movement constitut cell structur two transistor one rram r base r cell design novel three dimension architectur high parallel batch train experi result prove potenti inca compar ws acceler inca achiev × × energi effici improv infer train respect × infer × train speedup well accuraci ws drop high nois simul inca present even robust result accuraci"
  },
  {
    "doc_id": "10071224",
    "abstract_original": "With the increasing number of Internet applications and frequent network interactions, the resources in the Internet show explosive growth. Under the impact of this wave, methods based on large-scale data, such as deep learning, have been put forward, and scholars have begun to think about many classical tasks from a new perspective. The LDA model is used to mine the topic information in the texts in parallel corpora, and the polynomial distribution of thesaurus is used to represent the topic, so as to judge the proportion of each document topic in the document collection. The specific words are obtained according to the polynomial distribution of the corresponding thesaurus of the topic by probability sampling. The monolingual corpus of the target language is processed by maximum likelihood estimation method, and the parallel corpus is taken as the training target. The monolingual corpus of the target language is estimated by importance sampling and full probability formula, and a machine English translation model is established. The estimated expected value is obtained by beam search method, so that English sentence translation can be realized. When disambiguating 2000 groups of random phrases, the correct rate of word sense disambiguation was 79.9%, and the correct rate of structure disambiguation was 85.7%, which was 8.6% and 3.9% higher than the original system respectively.",
    "abstract_processed": "increas number internet applic frequent network interact resourc internet show explos growth impact wave method base larg scale data deep learn put forward scholar begun think mani classic task new perspect lda model use mine topic inform text parallel corpora polynomi distribut thesauru use repres topic judg proport document topic document collect specif word obtain accord polynomi distribut correspond thesauru topic probabl sampl monolingu corpu target languag process maximum likelihood estim method parallel corpu taken train target monolingu corpu target languag estim import sampl full probabl formula machin english translat model establish estim expect valu obtain beam search method english sentenc translat realiz disambigu group random phrase correct rate word sens disambigu correct rate structur disambigu higher origin system respect"
  },
  {
    "doc_id": "10074154",
    "abstract_original": "Software development techniques has been understood and give systematical model used to plan, design, test, implement, verification, validation and control the designing processes for developing an information-based system and satisfied the end-user’s requirements and needs. Human-centred software development, is a design methodology that provides a solution-based approach to solving user’s-oriented problems and fulfill the human-centredneeds and provides framework to provides results according to end-user’s requirements. In this paper we analyze the systematic literature reviews (Ss) and mapping studies and covering numerous primary research studies on different aspects of human centred software development(HCSD) exists. Software development has been turned focus from developed the application phase to user’s-oriented application and switched all the development scenario toward the human centred development. In this paper we review the different literature views papers on software development approaches in past and provide the comparative studies between those approaches and in final we provide the objective and proposed research overview.",
    "abstract_processed": "softwar develop techniqu understood give systemat model use plan design test implement verif valid control design process develop inform base system satisfi end user’ requir need human centr softwar develop design methodolog provid solut base approach solv user’ orient problem fulfil human centredne provid framework provid result accord end user’ requir paper analyz systemat literatur review ss map studi cover numer primari research studi differ aspect human centr softwar develop hcsd exist softwar develop turn focu develop applic phase user’ orient applic switch develop scenario toward human centr develop paper review differ literatur view paper softwar develop approach past provid compar studi approach final provid object propos research overview"
  },
  {
    "doc_id": "10074398",
    "abstract_original": "A form of artificial intelligence (AI) that is advanced and involves rules that are applied to data to simulate a person's thought process in a particular area, knowledge engineering can be described as an advanced form of artificial intelligence (AI). Knowledge engineering had evolved from its original form when it focused on transferring and analyzing knowledge from human problem-solvers into computer programs that could do the same. .It is essential to realize that transfer processing has limitations because humans make decisions differently than machines do. Non-linear thinking and analogous reasoning, often not logical, have not been considered in this case.It is becoming increasingly common today to use a modeling process for knowledge engineering, which creates a system that can reach the same conclusions as experts without following the same path or acquiring the same information from the same sources. In this paper, we aim to represent Knowledge engineering to transform knowledge into software that makes decisions similar to those made by human experts, such as financial advisors, whose decisions are based on their learning.Eventually, it is expected that human experts will be replaced by knowledge engineering in decision support software",
    "abstract_processed": "form artifici intellig ai advanc involv rule appli data simul person thought process particular area knowledg engin describ advanc form artifici intellig ai knowledg engin evolv origin form focus transfer analyz knowledg human problem solver comput program could essenti realiz transfer process limit human make decis differ machin non linear think analog reason often logic consid case becom increasingli common today use model process knowledg engin creat system reach conclus expert without follow path acquir inform sourc paper aim repres knowledg engin transform knowledg softwar make decis similar made human expert financi advisor whose decis base learn eventu expect human expert replac knowledg engin decis support softwar"
  },
  {
    "doc_id": "10074596",
    "abstract_original": "The purpose of this paper is to analyze the integration of information and communication technologies in the education sector and identify the most promising barriers that affect the efficient implementation of these technologies in the education sector.For this study, various research papers were analysed and a survey was conducted to identify the barriers that affect the integration of information and communication technologies in the education sector. Interpretive Structured Modeling (ISM) methodology has been used in this work to level up the barriers to identify which among the identified barriers is the most and the least significant.The findings reveal that Limited Awareness is the most significant barrier to the implementation of ICTs in the education sector along with other barriers which include Poor Infrastructure, Budget, Lack of Experience, Privacy, Lack of Communication, Resistance to Change, Restricted Training on New Software, Management Issues and Complex to Implement.",
    "abstract_processed": "purpos paper analyz integr inform commun technolog educ sector identifi promis barrier affect effici implement technolog educ sector studi variou research paper analys survey conduct identifi barrier affect integr inform commun technolog educ sector interpret structur model ism methodolog use work level barrier identifi among identifi barrier least signific find reveal limit awar signific barrier implement ict educ sector along barrier includ poor infrastructur budget lack experi privaci lack commun resist chang restrict train new softwar manag issu complex implement"
  },
  {
    "doc_id": "10075649",
    "abstract_original": "User interactions with visualization systems have been shown to encode a great deal of information about the the users’ thinking processes, and analyzing their interaction trails can teach us more about the users, their approach, and how they arrived at insights. This deeper understanding is critical to improving their experience and outcomes, and there are tools available to visualize logs of interactions. It can be difficult to determine the structurally interesting parts of interaction data, though, like what set of button clicks constitutes an action that matters. In the case of visual analytics systems that use machine learning models, there is a convenient marker of when the user has significantly altered the state of the system via interaction: when the model is updated based on new information. We present a method for numerical analytic provenance using high-dimensional visualization to show and compare the trails of these sequences of model states of the system. We evaluate this approach with a prototype tool, ModelSpace, applied to two case studies on experimental data from model-steering visual analytics tools. ModelSpace reveals individual user’s progress, the relationships between their paths, and the characteristics of certain regions of the space of possible models.",
    "abstract_processed": "user interact visual system shown encod great deal inform users’ think process analyz interact trail teach us user approach arriv insight deeper understand critic improv experi outcom tool avail visual log interact difficult determin structur interest part interact data though like set button click constitut action matter case visual analyt system use machin learn model conveni marker user significantli alter state system via interact model updat base new inform present method numer analyt proven use high dimension visual show compar trail sequenc model state system evalu approach prototyp tool modelspac appli two case studi experiment data model steer visual analyt tool modelspac reveal individu user’ progress relationship path characterist certain region space possibl model"
  },
  {
    "doc_id": "10075775",
    "abstract_original": "Current pandemic situation has a significant impact affecting human life not only socially and economically, but emotionally and psychologically as well. This impact can be easily observed on social media platforms. Along with the knowledge exchange related to Covid-19 pandemic on social media, there is an emotional trauma wave that can be felt by carefully analyzing the activities of this social media. Keeping this view in thought, we analyze around 12000 tweets of Indian people to find out whether there is a trend shift of thinking pattern and mindset of Indian people as the pandemic progresses. The study is bifurcated into stages to clearly see the paradigm shift. We use tweets since twitter is a rich medium that can be leveraged to its optimum to have a good amount of understanding of the sentiments of the people. Analyzing the twitter dataset, we derive results and find out whether the amount of negative tweets v/s positive (or motivational) tweets have increased or not as the pandemic progresses. The study is supported by graphical visualizations of the polarity of the tweets month wise. Further, Wordmap approach is used to perform qualitative mining analysis in addition to the sentiment score based calculation. This work helps us to understand how the public opinions are changing with the changes in the spread dynamics of the virus. This kind of mood mining helps in identifying the Covid-19 situation from the psychological perspective that whether there is a sense of fear among people or they are quite optimistic of the situation. It can help in a great extend to the strategic and decision making bodies to plan out for future decisions. Further, such kind of studies can be used as reference to provide insights about mental health of people for any future incident or event of such nature.",
    "abstract_processed": "current pandem situat signific impact affect human life social econom emot psycholog well impact easili observ social media platform along knowledg exchang relat covid pandem social media emot trauma wave felt care analyz activ social media keep view thought analyz around tweet indian peopl find whether trend shift think pattern mindset indian peopl pandem progress studi bifurc stage clearli see paradigm shift use tweet sinc twitter rich medium leverag optimum good amount understand sentiment peopl analyz twitter dataset deriv result find whether amount neg tweet v posit motiv tweet increas pandem progress studi support graphic visual polar tweet month wise wordmap approach use perform qualit mine analysi addit sentiment score base calcul work help us understand public opinion chang chang spread dynam viru kind mood mine help identifi covid situat psycholog perspect whether sens fear among peopl quit optimist situat help great extend strateg decis make bodi plan futur decis kind studi use refer provid insight mental health peopl futur incid event natur"
  },
  {
    "doc_id": "10076418",
    "abstract_original": "Disease detection/recognition with limited data sets and labels in the medical image domain is a very costly and greatest challenge. Although open image data sets have increased recently, researches on this problem still need to be developed. Researches to diversify data sets are both costly and face the problem of subjectivity. Unseen classes can be trained with the Zero-Shot Learning (ZSL) in order to overcome this problem. In this paper, we aimed to strengthen ZSL by using ontology as an auxiliary information for class embeddings. In our approach, ZSL is supported by the image embeddings and class embeddings of the multi-labelled ChestX-ray14 data set, as well as the semantic data from DBpedia. In this paper, which we believe will be pioneering in the medical image domain, the Cosine, Hamming and Euclidean distances were taken into account in order to maximize the similarities. We trained ResNet50 neural network with different parameters on the multi-labelled ChestX-ray14 data set. 23.25% precision value in one-to-one matching and 29.59% precision value in at least one matching were obtained. We think that this paper will make a significant contribution to the medical image domain by detecting/recognizing unseen disease images.",
    "abstract_processed": "diseas detect recognit limit data set label medic imag domain costli greatest challeng although open imag data set increas recent research problem still need develop research diversifi data set costli face problem subject unseen class train zero shot learn zsl order overcom problem paper aim strengthen zsl use ontolog auxiliari inform class embed approach zsl support imag embed class embed multi label chestx ray data set well semant data dbpedia paper believ pioneer medic imag domain cosin ham euclidean distanc taken account order maxim similar train resnet neural network differ paramet multi label chestx ray data set precis valu one one match precis valu least one match obtain think paper make signific contribut medic imag domain detect recogn unseen diseas imag"
  },
  {
    "doc_id": "10077006",
    "abstract_original": "This paper is inspired by the beauty of the mathematical optimisations, such as Euler's theory, and Rosenbrock's banana function. By seasoning with the idea of economic marginal theory, this research reveals the detailed characteristic of experiment data, makes a creative fusion as the luminance stimulation controlling colour model in creative computing, which has the potential usage for the future digital colour software, such as the connotation based human computer interaction and potentially able to adjust filmcolour automatically.",
    "abstract_processed": "paper inspir beauti mathemat optimis euler theori rosenbrock banana function season idea econom margin theori research reveal detail characterist experi data make creativ fusion lumin stimul control colour model creativ comput potenti usag futur digit colour softwar connot base human comput interact potenti abl adjust filmcolour automat"
  },
  {
    "doc_id": "10078050",
    "abstract_original": "The proclivity of today&#x2019;s technology to think like humans may be seen in new developing disciplines such as neural computing, fuzzy logic, evolutionary computation, machine learning, and probabilistic reasoning. These strategies are grouped together into one main technique known as &#x201C;soft computing.&#x201D; This book discusses the most recent soft computing and fuzzy logic-based applications and innovations in industrial advancements, supply chain and logistics, system optimization, decision-making, artificial intelligence, smart systems, and other rapidly evolving technologies. In today's competitive world, the book provides soft computing solutions to help companies overcome the obstacles posed by sophisticated decision-making systems.",
    "abstract_processed": "procliv today x technolog think like human may seen new develop disciplin neural comput fuzzi logic evolutionari comput machin learn probabilist reason strategi group togeth one main techniqu known x c soft comput x book discuss recent soft comput fuzzi logic base applic innov industri advanc suppli chain logist system optim decis make artifici intellig smart system rapidli evolv technolog today competit world book provid soft comput solut help compani overcom obstacl pose sophist decis make system"
  },
  {
    "doc_id": "10079806",
    "abstract_original": "Artificial Wisdom is advancement of Artificial Intelligence where wisdom should be recognized with the intelligence. It means the constructive behavior and values of humanity need to be the part of Artificial intelligence by incorporating wisdom. These can be demonstrates by simulating thought process and hence thinking ability of human beings is recognized as the consciousness. Currently researchers are working on thoughts and consciousness. These thoughts are coexisted with the particular mental factor. Abhidhamma model of ancient Indian literature are claimed 52 mental factors which are categorized in basic three classes such as Ethically Variable Factor, Unwholesome Factor and Beautiful Factor. Proposed model demonstrates the classification of the mental states. Dataset consists of 445 samples collected from various respondents by asking three questions. Preprocessing is performed by using the techniques of Natural language processing and Non-axiomatic logic. Convolutional Neural Network Machine learning technique applied to classify the mental factors. Performance of the proposed system is measured by applying statistical measures such as Accuracy, Precision, Specificity, Recall and F1-Score. Accuracy for small and large database is obtained as 86.92 percent and 93.02 percent respectively.",
    "abstract_processed": "artifici wisdom advanc artifici intellig wisdom recogn intellig mean construct behavior valu human need part artifici intellig incorpor wisdom demonstr simul thought process henc think abil human be recogn conscious current research work thought conscious thought coexist particular mental factor abhidhamma model ancient indian literatur claim mental factor categor basic three class ethic variabl factor unwholesom factor beauti factor propos model demonstr classif mental state dataset consist sampl collect variou respond ask three question preprocess perform use techniqu natur languag process non axiomat logic convolut neural network machin learn techniqu appli classifi mental factor perform propos system measur appli statist measur accuraci precis specif recal f score accuraci small larg databas obtain percent percent respect"
  },
  {
    "doc_id": "10079832",
    "abstract_original": "Sentiment analysis, otherwise called emotion AI, is the computational analysis of raw data that uses text to detect a person's sentiment. Opinions and feelings are communicated more frequently and extensively than ever before in the age of social media. The number of likes for social media opinions reveals which subjects are receiving the most attention, allowing companies and artists to better understand what their customers think of their products. As a result, the problem of picture or text sentiment categorization is of tremendous interest. Document level, phrase level, and aspect level sentiment analysis are the three ways for doing sentiment analysis. There are three major jobs at the aspect level. The most important and first objective is to recognise and extract question parts. The second goal is to identify the extremes of diverse points of view on various characteristics: positive, negative, and neutral. Next task is determined by compiling a list of terms that are similar to features. The goal of aspect-level sentiment analysis is to predict the sentiment polarity of each individual aspect term in a sentence, which is a notable challenge in natural language processing. Fine-grained sentiment analysis at the aspect level is a research hotspot.",
    "abstract_processed": "sentiment analysi otherwis call emot ai comput analysi raw data use text detect person sentiment opinion feel commun frequent extens ever age social media number like social media opinion reveal subject receiv attent allow compani artist better understand custom think product result problem pictur text sentiment categor tremend interest document level phrase level aspect level sentiment analysi three way sentiment analysi three major job aspect level import first object recognis extract question part second goal identifi extrem divers point view variou characterist posit neg neutral next task determin compil list term similar featur goal aspect level sentiment analysi predict sentiment polar individu aspect term sentenc notabl challeng natur languag process fine grain sentiment analysi aspect level research hotspot"
  },
  {
    "doc_id": "10083435",
    "abstract_original": "In this paper we summarize results of our internet survey which took place in Spring 2021 having over 3400 respondents and focused on adolescent sexting presence on the Instagram social network. We were interested in the frequency of this phenomena, awareness and general experience of adolescents with sexting and in general in Instagram social network security regarding adolescents. Results in terms of the danger of this phenomena are clear and demonstrable: a significant amount of the teenagers came across with it. The linkage and necessity of awareness in terms of secure behaviour on the internet and relevance with computational thinking is obvious but out of scope of this work.",
    "abstract_processed": "paper summar result internet survey took place spring respond focus adolesc sext presenc instagram social network interest frequenc phenomena awar gener experi adolesc sext gener instagram social network secur regard adolesc result term danger phenomena clear demonstr signific amount teenag came across linkag necess awar term secur behaviour internet relev comput think obviou scope work"
  },
  {
    "doc_id": "10083709",
    "abstract_original": "In this Hybrid K-Means Clustering for Grouping research work, the k-means methodology is a well-known process for grouping things together. Most of the time, this algorithm sorts the objects into a set number of clusters, but in this case, the user gives the number k. At first, it picks cluster centres at random and measures how far apart k points are. This kind of cluster centre is called k centroids, and it will keep changing until there are no more changes. When making applications that use machine intelligence, a machine should be able to think like a person and make the right choices. In this case, it's not possible to get k-points from the user. So, the Genetic Algorithm (GA) is used to search with heuristics to find the initial cluster centres. The goal of this research work is to look at how k-means clustering with GA can be used to optimise. The performance evaluation of hybrid k means method illustrates the precision and accuracy of the selected clustering methods. The result states that precision was 78.35% and its accuracy was 72.67% found while using the approach. The ROC curve analysis is performed with sensitivity and specificity data. The result states that the area under curve of the approach is 84.0%.",
    "abstract_processed": "hybrid k mean cluster group research work k mean methodolog well known process group thing togeth time algorithm sort object set number cluster case user give number k first pick cluster centr random measur far apart k point kind cluster centr call k centroid keep chang chang make applic use machin intellig machin abl think like person make right choic case possibl get k point user genet algorithm ga use search heurist find initi cluster centr goal research work look k mean cluster ga use optimis perform evalu hybrid k mean method illustr precis accuraci select cluster method result state precis accuraci found use approach roc curv analysi perform sensit specif data result state area curv approach"
  },
  {
    "doc_id": "10084967",
    "abstract_original": "In this era, Machine Learning is transforming human lives in a very different way. The need to give machines the power to make decisions or giving the moral compass is a big dilemma when humanity is more divided than it has ever been. There are two main ways in which law and AI interact. AI may be subject to legal restrictions and be employed in courtroom procedures. The world around us is being significantly and swiftly changed by AI in all of its manifestations. Public law includes important facets such as nondiscrimination law and labor law. In a manner similar to this when artificial intelligence (AI) is applied to tangible technology like robots. In certain cases, artificial intelligence (AI) might be hardly noticeable to customers but evident to those who built and are using it. The behavior research offers suggestions for how to build enduring and beneficial interactions between intelligent robots and people. The human improvement is main obstacles in the development and implementation of artificial intelligence. Best practices in this area are not governed by any one strategy that is generally acknowledged. Machine learning is about to revolutionize society as it is know it. It is crucial to give intelligent computers a moral compass now more than ever before because of how divided mankind is. Although machine learning has limitless potential, inappropriate usage might have detrimental long-term implications. It will think about how, for instance, earlier cultures built trust and improved social interactions via creative answers to many of the ethical issues that machine learning is posing now.",
    "abstract_processed": "era machin learn transform human live differ way need give machin power make decis give moral compass big dilemma human divid ever two main way law ai interact ai may subject legal restrict employ courtroom procedur world around us significantli swiftli chang ai manifest public law includ import facet nondiscrimin law labor law manner similar artifici intellig ai appli tangibl technolog like robot certain case artifici intellig ai might hardli notic custom evid built use behavior research offer suggest build endur benefici interact intellig robot peopl human improv main obstacl develop implement artifici intellig best practic area govern one strategi gener acknowledg machin learn revolution societi know crucial give intellig comput moral compass ever divid mankind although machin learn limitless potenti inappropri usag might detriment long term implic think instanc earlier cultur built trust improv social interact via creativ answer mani ethic issu machin learn pose"
  },
  {
    "doc_id": "10085124",
    "abstract_original": "With the world becoming more and more reliant on technology, we are transitioning from a society that values rational evaluation over intuitive thinking to one in which both of those methods coexist. AI devices rely solely on rational evaluation and machine learning allows us to focus on intuition. The task of intelligence is to deduce which method should be relied upon when solving various problems via the establishment of realistic judgments, according to what kind it identifies as being best for that particular problem. However, human judgments cannot simply be quantitatively compared and ranked by a computer according to conditions set by algorithms because certain difficult-to-measure criteria are not easily passable through algorithm systems such as ethics and common sense. In this research, the authors focus on developing judgment classification models using random forest and support vector machine. The authors attempt to test the effectiveness of sentiment proportions as features in judgment classification models.",
    "abstract_processed": "world becom reliant technolog transit societi valu ration evalu intuit think one method coexist ai devic reli sole ration evalu machin learn allow us focu intuit task intellig deduc method reli upon solv variou problem via establish realist judgment accord kind identifi best particular problem howev human judgment cannot simpli quantit compar rank comput accord condit set algorithm certain difficult measur criteria easili passabl algorithm system ethic common sens research author focu develop judgment classif model use random forest support vector machin author attempt test effect sentiment proport featur judgment classif model"
  },
  {
    "doc_id": "10086259",
    "abstract_original": "The outbreak of COVID-19 has impacted traditional teaching methods in schools, and blended teaching in the post-pandemic has gradually become a hot topic of research in higher education. Computational thinking, as one of the core literacies to be acquired in the 21st century, can help students realize the importance of computers as well as enable them to solve specific problems more effectively when facing real-life situations. The article takes the C language programming course as an example, analyzes the problems faced in teaching in the post-pandemic, introduces the concept of computational thinking and integrates it into all aspects of blended teaching design, pays attention to students' individual differences, and proposes a blended teaching model based on computational thinking and puts it into practice. The results show that this teaching model can improve students' learning performance, exercise students' computational thinking skills, and promote blended teaching reform and students' personalized development.",
    "abstract_processed": "outbreak covid impact tradit teach method school blend teach post pandem gradual becom hot topic research higher educ comput think one core literaci acquir st centuri help student realiz import comput well enabl solv specif problem effect face real life situat articl take c languag program cours exampl analyz problem face teach post pandem introduc concept comput think integr aspect blend teach design pay attent student individu differ propos blend teach model base comput think put practic result show teach model improv student learn perform exercis student comput think skill promot blend teach reform student person develop"
  },
  {
    "doc_id": "10089249",
    "abstract_original": "We live in a complex world where uncertainty is the only certainty. Today's compelling business problem is replaced tomorrow with a problem which was not even imagined yesterday. Data driven decision systems are used by managers in support of their strategic decisions and should be agile and flexibility to survive in our ever change world of complex decisions. The argument presented in this conceptual paper is that data vault modeling is inherently better equipped than dimensional modelling to handle the turbulations of our complex world. The paper investigates the underlying assumptions of dimensional modelling and data vault modelling in terms of requirements collection and the resulting data modelling techniques. It uses critical systems thinking as guiding philosophy to reflect on the benefits of understanding and modelling a variety of perspectives in a problem situation. Critical systems thinking also promotes equal opportunity and accountability. It is argued that both these aspirations can better be achieved by using dimensional modeling as alternative to dimensional modelling. We hope to promote the development of sustainable data driven decision systems which can stand the test of our turbulent times.",
    "abstract_processed": "live complex world uncertainti certainti today compel busi problem replac tomorrow problem even imagin yesterday data driven decis system use manag support strateg decis agil flexibl surviv ever chang world complex decis argument present conceptu paper data vault model inher better equip dimension model handl turbul complex world paper investig underli assumpt dimension model data vault model term requir collect result data model techniqu use critic system think guid philosophi reflect benefit understand model varieti perspect problem situat critic system think also promot equal opportun account argu aspir better achiev use dimension model altern dimension model hope promot develop sustain data driven decis system stand test turbul time"
  },
  {
    "doc_id": "10090213",
    "abstract_original": "Literature of studying algal growth has started to take advantages of data mining and machine learning methods, such as classification, clustering, regression, correlation analysis and principal component analysis. However, the performance of such methods might heavily rely on the data collectable for the studies sites. Moreover, some factors directly relate to algal growth, including hydrodynamics, weather and ecology, are notoriously difficult to model and predict. In this paper we present a study to model algal bloom using deep learning methods. It is assumed that algal bloom is the consequence of all factors that are more or less associated with the growth of algal. This offers a new way of thinking that even unknown factors or those factors far too complicated to model can still be inexplicitly represented by the deep learning models. We evaluate this new approach through our studies of algal bloom in the JinJi Lake, Suzhou, China. The experimental results are compared with the popular machine learning methods used in literature. It has been found that the deep learning method can achieve a better accuracy in comparison with other well applied machine learning methods.",
    "abstract_processed": "literatur studi algal growth start take advantag data mine machin learn method classif cluster regress correl analysi princip compon analysi howev perform method might heavili reli data collect studi site moreov factor directli relat algal growth includ hydrodynam weather ecolog notori difficult model predict paper present studi model algal bloom use deep learn method assum algal bloom consequ factor less associ growth algal offer new way think even unknown factor factor far complic model still inexplicitli repres deep learn model evalu new approach studi algal bloom jinji lake suzhou china experiment result compar popular machin learn method use literatur found deep learn method achiev better accuraci comparison well appli machin learn method"
  },
  {
    "doc_id": "10092318",
    "abstract_original": "This study presents the introduction of Arduino to undergraduate architecture students through a series of project-based exercises in two different universities. The main motivation of study is based on supporting students’ motivation, engagement, and creativity under remote education conditions in the context of digital fabrication. This research consolidates the digital fabrication pedagogy efficiency in the time of post COVID-19 using both distant and hybrid learning modes. Students have exerted a dedication effort and enjoyed digital craft especially while using Arduino despite the virtual teaching classes. Kinetic applications have received students' total endorsement and hands-on involvement supported with theoretical lectures focusing on fabrication techniques, materials and tools along with parametric algorithmic design. Assignments are both structured and semi-structured to promote their skills and grant them a free-flexible pedagogical approach.",
    "abstract_processed": "studi present introduct arduino undergradu architectur student seri project base exercis two differ univers main motiv studi base support students’ motiv engag creativ remot educ condit context digit fabric research consolid digit fabric pedagogi effici time post covid use distant hybrid learn mode student exert dedic effort enjoy digit craft especi use arduino despit virtual teach class kinet applic receiv student total endors hand involv support theoret lectur focus fabric techniqu materi tool along parametr algorithm design assign structur semi structur promot skill grant free flexibl pedagog approach"
  },
  {
    "doc_id": "10097489",
    "abstract_original": "Humans have rich experience applying linear models and logical thinking, but only experts understand the behaviour of non-linear systems. However, the deep neural network (DNN) implementation of text non-linear systems outperforms optimal linear models. Therefore, the forward DNN (the pattern recognition system in this paper) attracts attention to the necessity of interpreting the results obtained by DNN. To preserve the high performance of DNN, we focus on a post-hoc explanation; this approach means building an explainable model for the decision obtained by the black box. To avoid the interpretation of a set of millions of non-linear functions, we divide DNN into two parts: the feature extractor and the classifier. Following that, we argue for a specific interpretation of each of them. While for classifiers, we have several suitable explainable models (and we decided on the fuzzy logical function), we believe that feature interpretation is a creative scientific activity corresponding to the usual research. The paper presents a tool to help researchers and users understand extracted features not necessarily known in the specific application domain. Explaining the new features offers a way to learn from computers.",
    "abstract_processed": "human rich experi appli linear model logic think expert understand behaviour non linear system howev deep neural network dnn implement text non linear system outperform optim linear model therefor forward dnn pattern recognit system paper attract attent necess interpret result obtain dnn preserv high perform dnn focu post hoc explan approach mean build explain model decis obtain black box avoid interpret set million non linear function divid dnn two part featur extractor classifi follow argu specif interpret classifi sever suitabl explain model decid fuzzi logic function believ featur interpret creativ scientif activ correspond usual research paper present tool help research user understand extract featur necessarili known specif applic domain explain new featur offer way learn comput"
  },
  {
    "doc_id": "10097957",
    "abstract_original": "The requirement of explainability is gaining more and more importance in Artificial Intelligence applications based on Machine Learning techniques, especially in those contexts where critical decisions are entrusted to software systems (think, for example, of financial and medical consultancy). In this paper, we propose an Argumentation-based methodology for explaining the results predicted by Machine Learning models. Argumentation provides frameworks that can be used to represent and analyse logical relations between pieces of information, serving as a basis for constructing human tailored rational explanations to a given problem. In particular, we use extension-based semantics to find the rationale behind a class prediction.",
    "abstract_processed": "requir explain gain import artifici intellig applic base machin learn techniqu especi context critic decis entrust softwar system think exampl financi medic consult paper propos argument base methodolog explain result predict machin learn model argument provid framework use repres analys logic relat piec inform serv basi construct human tailor ration explan given problem particular use extens base semant find rational behind class predict"
  },
  {
    "doc_id": "10097999",
    "abstract_original": "Ethics should be a practice, not a checkbox. Data scientists want to answer questions about individuals and society using the vast torrent of data that flows around us. Machine learning practitioners want to develop and connect complex models of the world and use them safely in critical situations. Ethical issues can be seen as getting in the way of the core idea and form pain points around managing, using and learning from data, as well as designing human-centric and ethical systems. This is because there is a design gap around ethics in data science and machine learning: the tools that we use do not support ethical data use, which means that data scientists and machine learning practitioners, already engaged in technically complex, multidisciplinary work, must add another dimension to their thinking. This work proposes and outlines an infrastructure and framework that can support in-the-moment ethical decision making and recording, as well as post-hoc audits and ethical model deployment.",
    "abstract_processed": "ethic practic checkbox data scientist want answer question individu societi use vast torrent data flow around us machin learn practition want develop connect complex model world use safe critic situat ethic issu seen get way core idea form pain point around manag use learn data well design human centric ethic system design gap around ethic data scienc machin learn tool use support ethic data use mean data scientist machin learn practition alreadi engag technic complex multidisciplinari work must add anoth dimens think work propos outlin infrastructur framework support moment ethic decis make record well post hoc audit ethic model deploy"
  },
  {
    "doc_id": "10099179",
    "abstract_original": "This paper presents a systematic approach to using the Socratic method in developing prompt templates that effectively interact with large language models, including GPT-3. Various methods are examined, and those that yield precise answers and justifications while fostering creativity and imagination to enhance creative writing are identified. Techniques such as definition, elenchus, dialectic, maieutics, generalization, and counterfactual reasoning are discussed for their application in engineering prompt templates and their connections to inductive, deductive, and abductive reasoning. Through examples, the effectiveness of these dialogue and reasoning methods is demonstrated. An interesting observation is made that when the task's goal and user intent are conveyed to GPT-3 via ChatGPT before the start of a dialogue, the large language model seems to connect to the external context expressed in the intent and perform more effectively.",
    "abstract_processed": "paper present systemat approach use socrat method develop prompt templat effect interact larg languag model includ gpt variou method examin yield precis answer justif foster creativ imagin enhanc creativ write identifi techniqu definit elenchu dialect maieutic gener counterfactu reason discuss applic engin prompt templat connect induct deduct abduct reason exampl effect dialogu reason method demonstr interest observ made task goal user intent convey gpt via chatgpt start dialogu larg languag model seem connect extern context express intent perform effect"
  },
  {
    "doc_id": "10099445",
    "abstract_original": "Artificial general intelligence revived in recent years after people achieved significant advances in machine learning and deep learning. This leads to the thinking of how real intelligence could be created. Consciousness theories believe that general intelligence is essentially conscious, yet no universal definition is agreed upon. In this work, global workspace (GW) theory is implemented and integrated with crucial cognitive components. With the focus on episodic memory and inspiration from the nature of episodic memory in psychology and neuroscience, the episodic memory component is implemented within the GW framework. In our experiment, the robotic agent operates in a real-world interactive context, forming episodic memory and demonstrating static, temporal, and context memory capabilities during interactions. Consciousness in this work engages in all formation, maintenance, and retrieval processes of episodic memory. The novelty and contributions of this work are: 1) this work is implementing episodic memory within the consciousness framework, suggesting the sustainable potential of such an integrated approach to cognitive agents with artificial general intelligence (AGI); 2) regarding the limited examples in consciousness-based cognitive architectures, this work attempts to contribute to the diversity of perspectives and approaches; 3) extant episodic memory implementations are suffering from various limitations, while this work summarises some key features for modeling episodic memory within a cognitive architecture; and 4) authors discuss the relationship between episodic memory, consciousness, and general intelligence, proposing the compatibility and relationship between machine consciousness and other AGI research. It is believed that a better alignment between them would further boost the fusion of diverse research for achieving desired cognitive machines.",
    "abstract_processed": "artifici gener intellig reviv recent year peopl achiev signific advanc machin learn deep learn lead think real intellig could creat conscious theori believ gener intellig essenti consciou yet univers definit agre upon work global workspac gw theori implement integr crucial cognit compon focu episod memori inspir natur episod memori psycholog neurosci episod memori compon implement within gw framework experi robot agent oper real world interact context form episod memori demonstr static tempor context memori capabl interact conscious work engag format mainten retriev process episod memori novelti contribut work work implement episod memori within conscious framework suggest sustain potenti integr approach cognit agent artifici gener intellig agi regard limit exampl conscious base cognit architectur work attempt contribut divers perspect approach extant episod memori implement suffer variou limit work summaris key featur model episod memori within cognit architectur author discuss relationship episod memori conscious gener intellig propos compat relationship machin conscious agi research believ better align would boost fusion divers research achiev desir cognit machin"
  },
  {
    "doc_id": "10101670",
    "abstract_original": "The emergence of abstract sciences as a counterpart of classic concrete sciences is presented in this work. The framework of abstract sciences encompasses data, information, knowledge, and intelligence sciences from the bottom up. It is found that intelligence is the ultimate level of cognitive objects generated in human brains aggregated from data (sensory), information (cognition), and knowledge (comprehension). However, there is a lack of rigorous studies and coherent theories towards the theoretical framework of abstract sciences as the counterpart of classical concrete sciences. This paper explores the cognitive and mathematical models of abstract mental objects in the brain. The taxonomy and cognitive foundations of them are explored. A set of mathematical models of data, information, knowledge, and intelligence is formally created in intelligent mathematics. Based on the cognitive and mathematical models of the cognitive objects, formal properties and relationship of contemporary data, information, knowledge, and intelligence sciences are rigorously explained.",
    "abstract_processed": "emerg abstract scienc counterpart classic concret scienc present work framework abstract scienc encompass data inform knowledg intellig scienc bottom found intellig ultim level cognit object gener human brain aggreg data sensori inform cognit knowledg comprehens howev lack rigor studi coher theori toward theoret framework abstract scienc counterpart classic concret scienc paper explor cognit mathemat model abstract mental object brain taxonomi cognit foundat explor set mathemat model data inform knowledg intellig formal creat intellig mathemat base cognit mathemat model cognit object formal properti relationship contemporari data inform knowledg intellig scienc rigor explain"
  },
  {
    "doc_id": "10102868",
    "abstract_original": "This article presents a course that relates environmental education and the development of STEAM skills through the valorization of WEEE (Waste of Electrical and Electronic Equipment). As a didactic tool, the BEAM Robots are used, which are simple robots that can be built with elements extracted from WEEE. For the execution of the course, a four-phase curriculum design is developed: propaedeutics, assembly, Computational Thinking (CT), and WEEE. The course is built in a modular way and implemented virtually. The students were evaluated with pre and post-surveys, to investigate the impact of the course. In addition, evaluation activities were created that made it possible to follow the development of the students. In general, it can be concluded that the course had a positive impact on students' STEAM skills and knowledge, as well as an improvement in environmental awareness related to the creative reuse of WEEE.",
    "abstract_processed": "articl present cours relat environment educ develop steam skill valor weee wast electr electron equip didact tool beam robot use simpl robot built element extract weee execut cours four phase curriculum design develop propaedeut assembl comput think ct weee cours built modular way implement virtual student evalu pre post survey investig impact cours addit evalu activ creat made possibl follow develop student gener conclud cours posit impact student steam skill knowledg well improv environment awar relat creativ reus weee"
  },
  {
    "doc_id": "10104848",
    "abstract_original": "Artificial Intelligence is a booming technology and is applied in almost every domain of application. To design an intelligent system, a thorough understanding of complex AI Algorithm is required. The idea behind the AI Algorithm Simulator was born from the recognition that algorithms are a critical component of a person’s computational thinking and programming abilities. Despite their complexity, our AI Algorithm simulator seeks to make the subject more accessible and engaging for learners. The AI Algorithm Simulator is designed to be both interactive and visually appealing, providing learners with hands-on experience in implementing algorithms.",
    "abstract_processed": "artifici intellig boom technolog appli almost everi domain applic design intellig system thorough understand complex ai algorithm requir idea behind ai algorithm simul born recognit algorithm critic compon person’ comput think program abil despit complex ai algorithm simul seek make subject access engag learner ai algorithm simul design interact visual appeal provid learner hand experi implement algorithm"
  },
  {
    "doc_id": "10105236",
    "abstract_original": "ChatGPT has sparked both excitement and skepticism in education. To analyze its impact on teaching and learning it is crucial to understand how students perceive ChatGPT and assess its potential and challenges. Toward this, we conducted a two-stage study with senior students in a computer engineering program ( $n=56$ ). In the first stage, we asked the students to evaluate ChatGPT using their own words after they used it to complete one learning activity. The returned responses (3136 words) were analyzed by coding and theme building (36 codes and 15 themes). In the second stage, we used the derived codes and themes to create a 27-item questionnaire. The students responded to this questionnaire three weeks later after completing other activities with the help of ChatGPT. The results show that the students admire the capabilities of ChatGPT and find it interesting, motivating, and helpful for study and work. They find it easy to use and appreciate its human-like interface that provides well-structured responses and good explanations. However, many students feel that ChatGPT’s answers are not always accurate and most of them believe that it requires good background knowledge to work with since it does not replace human intelligence. So, most students think that ChatGPT needs to be improved but are optimistic that this will happen soon. When it comes to the negative impact of ChatGPT on learning, academic integrity, jobs, and life, the students are divided. We conclude that ChatGPT can and should be used for learning. However, students should be aware of its limitations. Educators should try using ChatGPT and guide students on effective prompting techniques and how to assess generated responses. The developers should improve their models to enhance the accuracy of given answers. The study provides insights into the capabilities and limitations of ChatGPT in education and informs future research and development.",
    "abstract_processed": "chatgpt spark excit skeptic educ analyz impact teach learn crucial understand student perceiv chatgpt assess potenti challeng toward conduct two stage studi senior student comput engin program n first stage ask student evalu chatgpt use word use complet one learn activ return respons word analyz code theme build code theme second stage use deriv code theme creat item questionnair student respond questionnair three week later complet activ help chatgpt result show student admir capabl chatgpt find interest motiv help studi work find easi use appreci human like interfac provid well structur respons good explan howev mani student feel chatgpt’ answer alway accur believ requir good background knowledg work sinc replac human intellig student think chatgpt need improv optimist happen soon come neg impact chatgpt learn academ integr job life student divid conclud chatgpt use learn howev student awar limit educ tri use chatgpt guid student effect prompt techniqu assess gener respons develop improv model enhanc accuraci given answer studi provid insight capabl limit chatgpt educ inform futur research develop"
  },
  {
    "doc_id": "10105336",
    "abstract_original": "The manual assessment of creativity by human raters is coupled with unavoidable subjectivity and often costs much time and human resources. To address these issues, this paper explores how to apply natural language processing (NLP) methods to the assessment of creativity. Using the Alternative Use Task (AUT), participants were encouraged to generate ideas as fast as possible for a fixed time. It was hypothesized that the similarity of ideas would decrease over time in the AUT, considering the design fixation and the limitation of working memory. In the first study, 12 university students completed the AUT in paper-pencil form and generated a total of 376 responses. We applied two NLP models, namely BERT (Bidirectional Encoder Representations from Transformers) and USE (Universal Sentence Encoder), to assess the similarity of responses between individuals. The results did not confirm our hypothesis. One prominent reason might be that the applied models represent millions of sentence structures that are over-ecological and too dissimilar to the sentence structures participants had used while finishing the AUT. Nevertheless, the results did show that BERT and USE could more accurately express the semantic information of responses pace with the Latent Semantic Analysis, a popular computer-aided model for AUT response assessment. In study 2, we proposed an algorithm to reanalyze the 376 responses in study 1 based on word embedding with crowdsourced responses. There were 1690 crowdsourced responses collected from 550 participants who completed an online version of the AUT. The results supported our hypothesis and showed that the similarity of responses increases as time passes. This indicates the proposed algorithm would alleviate the influence of sentence structure in AUT tasks. The differences between BERT, USE, and proposed algorithms are discussed in relation to the assessment of creativity, and the implications for future work are explored in-depth.",
    "abstract_processed": "manual assess creativ human rater coupl unavoid subject often cost much time human resourc address issu paper explor appli natur languag process nlp method assess creativ use altern use task aut particip encourag gener idea fast possibl fix time hypothes similar idea would decreas time aut consid design fixat limit work memori first studi univers student complet aut paper pencil form gener total respons appli two nlp model name bert bidirect encod represent transform use univers sentenc encod assess similar respons individu result confirm hypothesi one promin reason might appli model repres million sentenc structur ecolog dissimilar sentenc structur particip use finish aut nevertheless result show bert use could accur express semant inform respons pace latent semant analysi popular comput aid model aut respons assess studi propos algorithm reanalyz respons studi base word embed crowdsourc respons crowdsourc respons collect particip complet onlin version aut result support hypothesi show similar respons increas time pass indic propos algorithm would allevi influenc sentenc structur aut task differ bert use propos algorithm discuss relat assess creativ implic futur work explor depth"
  },
  {
    "doc_id": "10106116",
    "abstract_original": "The purpose of this article is to historize the definition of computer science, particularly the characteristic ambiguity of the discipline toward the computer. This ambiguity is foundational to computer science and has its roots in the response of university computer centers to the commercialization of computing in the mid-1950s. University computing experts developed an understanding of the activity of computing disentangled from the computer itself, a conceptual shift that went together with a parallel process of dematerialization of the notion of computer. These transformations were facilitated by the ascendance of a high modernist agenda in the sciences in the United States. University computing experts embraced the high modernist agenda and developed analogies across programs, notations, and a notion of the computer now understood as a model of computation. This immaterial conflation of notations, programs, and representations of the machine, would become one of the core tenets of computer science.",
    "abstract_processed": "purpos articl histor definit comput scienc particularli characterist ambigu disciplin toward comput ambigu foundat comput scienc root respons univers comput center commerci comput mid univers comput expert develop understand activ comput disentangl comput conceptu shift went togeth parallel process demateri notion comput transform facilit ascend high modernist agenda scienc unit state univers comput expert embrac high modernist agenda develop analog across program notat notion comput understood model comput immateri conflat notat program represent machin would becom one core tenet comput scienc"
  },
  {
    "doc_id": "10107843",
    "abstract_original": "Computational thinking, as one of the core literacies of the Chinese IT courses, is an important area of IT education in primary and secondary schools. This research aims to improve the level of computational thinking of high school students by using Minecraft as a tool for Python gamified programming teaching design and analyzing the effectiveness of 60 high school students’ improvement in algorithmic thinking, problem solving, creativity, critical thinking, and collaboration after the teaching practice. The research results show that gamified programming teaching can significantly improve high school students’ computational thinking, providing a new teaching approach and ideas for high school IT education and computational thinking development.",
    "abstract_processed": "comput think one core literaci chines cours import area educ primari secondari school research aim improv level comput think high school student use minecraft tool python gamifi program teach design analyz effect high school students’ improv algorithm think problem solv creativ critic think collabor teach practic research result show gamifi program teach significantli improv high school students’ comput think provid new teach approach idea high school educ comput think develop"
  },
  {
    "doc_id": "10107885",
    "abstract_original": "The assessment of computational thinking (CT) skills based on text-based programming is a necessary part of the implementation of CT education in higher education. However, the current research on CT assessment is mostly single-approach, which is not effective in accurately measuring numerous competencies of CT skills and has the disadvantage of assessment limitation. In order to solve the problem of assessment limitations, this paper defines the content of CT evaluation from the perspective of text-based programming and constructs a multidimensional test method. Different test schemes are selected according to the characteristics of CT skills, and assessment tools are developed by combining the question test, programming test and scale survey, and the assessment tools are used to evaluate and analyze learners' CT skills from qualitative and quantitative perspectives. The results show that the evaluation indicators and test questions designed on text-based programming are more consistent with the evaluation objectives. And the approach of evaluating CT skills from both qualitative and quantitative perspectives can reflect learners' CT skills more comprehensively and accurately.",
    "abstract_processed": "assess comput think ct skill base text base program necessari part implement ct educ higher educ howev current research ct assess mostli singl approach effect accur measur numer compet ct skill disadvantag assess limit order solv problem assess limit paper defin content ct evalu perspect text base program construct multidimension test method differ test scheme select accord characterist ct skill assess tool develop combin question test program test scale survey assess tool use evalu analyz learner ct skill qualit quantit perspect result show evalu indic test question design text base program consist evalu object approach evalu ct skill qualit quantit perspect reflect learner ct skill comprehens accur"
  },
  {
    "doc_id": "10109435",
    "abstract_original": "This unprecedented time of the COVID-19 outbreak challenged the status-quo whether it is on business operation, political leadership, scientific capability, engineering implementation, data analysis, and strategic thinking, in terms of resiliency, agility, and innovativeness. Due to some identified constraints, while addressing the issue of global health, human ingenuity has proven again that in times of crisis, it is our best asset. Constraints like limited testing capacity and lack of real-time information regarding the spread of the virus, are the highest priority in the mitigation process, aside from the development of vaccines and the pushing through of vaccination programs. Using the available Chest X-Ray Images dataset and an AI-Computer Vision Technique called Convolutional Neural Network, features of the images were extracted and classified as COVID-19 positive or not. This paper proposes the usage of the 18-layer Residual Neural Network (ResNet-18) as an architecture instead of other ResNet with a higher number of layers. The researcher achieves the highest validation accuracy of 99.26%. Moving forward, using this lower number of layers in training a model classifier, resolves the issue of device constraints such as storage capacity and computing resources while still assuring highly accurate outputs.",
    "abstract_processed": "unpreced time covid outbreak challeng statu quo whether busi oper polit leadership scientif capabl engin implement data analysi strateg think term resili agil innov due identifi constraint address issu global health human ingenu proven time crisi best asset constraint like limit test capac lack real time inform regard spread viru highest prioriti mitig process asid develop vaccin push vaccin program use avail chest x ray imag dataset ai comput vision techniqu call convolut neural network featur imag extract classifi covid posit paper propos usag layer residu neural network resnet architectur instead resnet higher number layer research achiev highest valid accuraci move forward use lower number layer train model classifi resolv issu devic constraint storag capac comput resourc still assur highli accur output"
  },
  {
    "doc_id": "10110199",
    "abstract_original": "Proper Pronunciation is essential for a successful career. In the present era, recruiters do not want mug pots or rote learners i.e one that scores well in the technical or the core area. The need of the hour demands a holistic personality which must include good communication skills, critical thinking, managerial skills & logical reasoning. In the present study, the researchers have studied the mother tongue influence (MTI) in the English language spoken by the regional speakers of the Kumaun region. In the present study, the researchers have observed that the students of Uttarakhand have high MTI (Mother Tongue Influence) which is noticeable in their communication. They face difficulty in articulation of certain consonant sounds like sh (ꭍ), v, w, etc. Words like sheep /ꭍi:p/ are mispronounced as seep /si:p/, career/kₔriₔ/ as carrier /kᵆriₔ/ (Kay-rier). Due to poor pronunciation, they face challenges not only in the recruitment process but also in survival in Multi-National Companies where the American / British accent is widely used. The researchers conducted a diagnostic test to identify the extent and frequency of flaws in the articulation of words. It was observed that the performance of the regional learners was poor and required improvement. They implemented a Pre-Defined Algorithm model for improving the performance of the regional students. It was followed by a post-implementation test which was conducted through the proposed model. The proposed model has a better outcome concerning reducing the MTI in general pronunciation of the English Language among Kumauoni speakers of Uttarakhand.",
    "abstract_processed": "proper pronunci essenti success career present era recruit want mug pot rote learner e one score well technic core area need hour demand holist person must includ good commun skill critic think manageri skill logic reason present studi research studi mother tongu influenc mti english languag spoken region speaker kumaun region present studi research observ student uttarakhand high mti mother tongu influenc notic commun face difficulti articul certain conson sound like sh ꭍ v w etc word like sheep ꭍi p mispronounc seep si p career kₔriₔ carrier kᵆriₔ kay rier due poor pronunci face challeng recruit process also surviv multi nation compani american british accent wide use research conduct diagnost test identifi extent frequenc flaw articul word observ perform region learner poor requir improv implement pre defin algorithm model improv perform region student follow post implement test conduct propos model propos model better outcom concern reduc mti gener pronunci english languag among kumauoni speaker uttarakhand"
  },
  {
    "doc_id": "10111198",
    "abstract_original": "In this paper, we create a learning path and curate projects that let students learn certain computational concepts in a consistent way that bridges story, conversation, visual programming, and text-based programming. Our approach is to provide young children with both visual and text-based programming materials that are directly associated with the computational logic in some selected children’s daily dialogues and stories. We demonstrate this combo-design idea with examples of roleplaying, Snap! program, and Python code. Our design pattern and examples could be adapted to other suitable children’s activities in different school settings on a variety of technology platforms.",
    "abstract_processed": "paper creat learn path curat project let student learn certain comput concept consist way bridg stori convers visual program text base program approach provid young children visual text base program materi directli associ comput logic select children’ daili dialogu stori demonstr combo design idea exampl roleplay snap program python code design pattern exampl could adapt suitabl children’ activ differ school set varieti technolog platform"
  },
  {
    "doc_id": "10111237",
    "abstract_original": "With the rapid development of science and technology over the world, programming education has shown as a trend in decades. Programming courses have been offered in primary education to promote students’ computational thinking skills. However, teaching and learning programming in primary schools involve different knowledge including complex mathematical concepts and programming syntax. Also, traditional teaching methods may not effectively cater for students’ individual needs and learning trajectories. Thus, learning difficulties are common among students. Teachers keep examining innovation on programming education to improve their teaching. This study investigated used a pretest-posttest method with two groups of grade five students in Macao, to compare the influence of two pedagogical strategies, flipped classroom and traditional teaching, in students’ learning achievements. The major findings of the study showed that the experimental group in flipped classroom had significantly higher learning achievements than the control group in the programming course. Moreover, the students in the flipped classroom showed a significant effective mastery of more complex programming concepts, such as conditions and loops.",
    "abstract_processed": "rapid develop scienc technolog world program educ shown trend decad program cours offer primari educ promot students’ comput think skill howev teach learn program primari school involv differ knowledg includ complex mathemat concept program syntax also tradit teach method may effect cater students’ individu need learn trajectori thu learn difficulti common among student teacher keep examin innov program educ improv teach studi investig use pretest posttest method two group grade five student macao compar influenc two pedagog strategi flip classroom tradit teach students’ learn achiev major find studi show experiment group flip classroom significantli higher learn achiev control group program cours moreov student flip classroom show signific effect masteri complex program concept condit loop"
  },
  {
    "doc_id": "1011207",
    "abstract_original": "In previous papers, the Fourier transform (FT) has been generalized into the fractional Fourier transform (FRFT), the linear canonical transform (LCT), and the simplified fractional Fourier transform (SFRFT). Because the cosine, sine, and Hartley transforms are very similar to the FT, it is reasonable to think they can also be generalized by the similar way. We introduce several new transforms. They are all the generalization of the cosine, sine, or Hartley transform. We first derive the fractional cosine, sine, and Hartley transforms (FRCT/FRST/FRHT). They are analogous to the FRFT. Then, we derive the canonical cosine and sine transforms (CCT/CST). They are analogous to the LCT. We also derive the simplified fractional cosine, sine, and Hartley transforms (SFRCT/SFRST/SFRHT). They are analogous to the SFRFT and have the advantage of real-input-real-output. We also discuss the properties, digital implementation, and applications (e.g., the applications for filter design and space-variant pattern recognition) of these transforms. The transforms introduced in this paper are very efficient for digital implementation. We can just use one half or one fourth of the real multiplications required for the FRFT and LCT to implement them. When we want to process even, odd, or pure real/imaginary functions, we can use these transforms instead of the FRFT and LCT. Besides, we also show that the FRCT/FRST, CCT/CST, and SFRCT/SFRST are also useful for the one-sided (t /spl isin/ [0, /spl infin/]) signal processing.",
    "abstract_processed": "previou paper fourier transform ft gener fraction fourier transform frft linear canon transform lct simplifi fraction fourier transform sfrft cosin sine hartley transform similar ft reason think also gener similar way introduc sever new transform gener cosin sine hartley transform first deriv fraction cosin sine hartley transform frct frst frht analog frft deriv canon cosin sine transform cct cst analog lct also deriv simplifi fraction cosin sine hartley transform sfrct sfrst sfrht analog sfrft advantag real input real output also discuss properti digit implement applic e g applic filter design space variant pattern recognit transform transform introduc paper effici digit implement use one half one fourth real multipl requir frft lct implement want process even odd pure real imaginari function use transform instead frft lct besid also show frct frst cct cst sfrct sfrst also use one side spl isin spl infin signal process"
  },
  {
    "doc_id": "10112083",
    "abstract_original": "The healthcare industry generates vast amounts of data that are crucial for improving patient outcomes and advancing medical research. However, traditional on premise solutions for data storage and analysis can become inadequate to handle the increasing volume, variety and velocity of healthcare data. The study aims to investigate the potential benefits and challenges of using cloud-based solutions for data analytics in healthcare. This paper reports about latest development and detailed role of using Artificial intelligence and capabilities of cloud Computing in health care sector/industry to foster innovative thinking, optimum wellbeing of the patient, focused medicinal support. This paper discusses various applications, algorithms and future of big data analytics with a focus on architecture, application and applicability of big data analytics using Hadoop and Cloud Computing in healthcare industry such as monitoring, prediction, performance, management etc including intensive care unit. many cloud platforms, like MMAP, are working in this field to provide a fast, reliable cost effective, efficient, and patient centric and solution to community health issues with capability of forecasting the health impact of various diseases on community for a given region or nation. Cloud computing framework, along with Artificial intelligence and Hadoop, aids healthcare management in completing analytical computations to identify logical, pertinent, and factual trends essential to strategize and enhanced readiness in event of catastrophes by facilitating data exchange among all stake holders.",
    "abstract_processed": "healthcar industri gener vast amount data crucial improv patient outcom advanc medic research howev tradit premis solut data storag analysi becom inadequ handl increas volum varieti veloc healthcar data studi aim investig potenti benefit challeng use cloud base solut data analyt healthcar paper report latest develop detail role use artifici intellig capabl cloud comput health care sector industri foster innov think optimum wellb patient focus medicin support paper discuss variou applic algorithm futur big data analyt focu architectur applic applic big data analyt use hadoop cloud comput healthcar industri monitor predict perform manag etc includ intens care unit mani cloud platform like mmap work field provid fast reliabl cost effect effici patient centric solut commun health issu capabl forecast health impact variou diseas commun given region nation cloud comput framework along artifici intellig hadoop aid healthcar manag complet analyt comput identifi logic pertin factual trend essenti strateg enhanc readi event catastroph facilit data exchang among stake holder"
  },
  {
    "doc_id": "10112848",
    "abstract_original": "A daily commitment to our health and exercise routines helps us to become more energized and effective in our lives. But merely having the intention won't ever be sufficient to get to point of the aim. Health and fitness routine is always a mandatory segment of life, which helps us to become more productive and energetic in our day to day life. But that intention alone can never be enough to achieve the destination. In our project, we're creating a novel tool that can assist people in ensuring their general health, simply by collecting their food data and making dietary recommendations for doing the exercises to reach their objectives. By consulting a nutritionist, anybody could possibly get the guidance to reach their objective of getting healthier and stronger. Our model which has the aim to solve the daily life style problems caused by the unselective foods. Every sports person and the people in health and fitness area are aware of their foods by the consultation of nutritionist. But in the rapid moving times, normal people in day to day life, don't have the needed time and space to meet the nutritionist every time. Our model which tries to replace the space of the nutritionist by giving consultation and addressing the nutritional values of foods to the end users",
    "abstract_processed": "daili commit health exercis routin help us becom energ effect live mere intent ever suffici get point aim health fit routin alway mandatori segment life help us becom product energet day day life intent alon never enough achiev destin project creat novel tool assist peopl ensur gener health simpli collect food data make dietari recommend exercis reach object consult nutritionist anybodi could possibl get guidanc reach object get healthier stronger model aim solv daili life style problem caus unselect food everi sport person peopl health fit area awar food consult nutritionist rapid move time normal peopl day day life need time space meet nutritionist everi time model tri replac space nutritionist give consult address nutrit valu food end user"
  },
  {
    "doc_id": "10113096",
    "abstract_original": "Augmented Reality (AR), a unique method of integrating the virtual world into the real world, has the potential to increase academic attainment in the classroom. This research work focuses on developing and evaluating a strategy for enhancing student education with AR in the classroom. AR enables unique human-computer interactions in real time between the physical and digital worlds. The effectiveness of AR in the classroom will depend on its development, deployment, and integration into both standard and nontraditional teaching environments. Throughout the creation and implementation of an AR classroom, collaborative learning practices and other methodologies were taken into account. Collaboration occurs when two or more individuals work together, share information, and gain insights from one another. This research offers a succinct summary of the promise and challenges of adopting AR to transform the classroom.",
    "abstract_processed": "augment realiti ar uniqu method integr virtual world real world potenti increas academ attain classroom research work focus develop evalu strategi enhanc student educ ar classroom ar enabl uniqu human comput interact real time physic digit world effect ar classroom depend develop deploy integr standard nontradit teach environ throughout creation implement ar classroom collabor learn practic methodolog taken account collabor occur two individu work togeth share inform gain insight one anoth research offer succinct summari promis challeng adopt ar transform classroom"
  },
  {
    "doc_id": "10118041",
    "abstract_original": "The accessibility of fawning and observational information over the NASA database has made a wide extend of exercises conceivable, counting the distinguishing proof of planets and the forecast of their directions for the elucidation and improvement of machine learning models. We require photographs with higher picture quality for ideal representation. Pictures of a geological range so grant the watcher a establishment for understanding how characteristics can alter both spatially and transiently. The required data almost the target regularly impacts the imaging innovation determination. Conventional imaging strategies regularly make utilize of well characterized signals, such as enthusiastic impartial molecules or photons with a restricted range run. In any case, a number of viable imaging strategies have been made for analyzing different planetary and space situations utilizing long-wavelength electromagnetic radio waves. The categorization and show of planets employing a consecutive demonstrate are hence finished in this think about exertion with the help of the dataset, which is vital for investigate purposes. Profound learning and machine learning methods are utilized to achieve this. The proposed sequential model offers the highest degree of precision for further investigations.",
    "abstract_processed": "access fawn observ inform nasa databas made wide extend exercis conceiv count distinguish proof planet forecast direct elucid improv machin learn model requir photograph higher pictur qualiti ideal represent pictur geolog rang grant watcher establish understand characterist alter spatial transient requir data almost target regularli impact imag innov determin convent imag strategi regularli make util well character signal enthusiast imparti molecul photon restrict rang run case number viabl imag strategi made analyz differ planetari space situat util long wavelength electromagnet radio wave categor show planet employ consecut demonstr henc finish think exert help dataset vital investig purpos profound learn machin learn method util achiev propos sequenti model offer highest degre precis investig"
  },
  {
    "doc_id": "10118630",
    "abstract_original": "The role of computers is indispensable in various aspects of life, especially in the Production Monitoring information system which increases work productivity. PT Citra Banjar Abadi is a company that produces iron and steel electric towers for the needs of making High Voltage Power Line Towers, where this research takes place. The problem that occurs at this time is that the steel production monitoring information system is not optimal because it still uses a manual system so that there are often problems, one of which is the problem of production progress that cannot be monitored properly so that the completion of production is not on time. The purpose of this study is to provide solutions to problems that occur using the FAST (Framework Analytical System Thinking) method. The result of this research is to produce a steel production monitoring information system for the Tower Extra High Voltage Power Line for PT Citra Banjar Abadi, Indonesia.",
    "abstract_processed": "role comput indispens variou aspect life especi product monitor inform system increas work product pt citra banjar abadi compani produc iron steel electr tower need make high voltag power line tower research take place problem occur time steel product monitor inform system optim still use manual system often problem one problem product progress cannot monitor properli complet product time purpos studi provid solut problem occur use fast framework analyt system think method result research produc steel product monitor inform system tower extra high voltag power line pt citra banjar abadi indonesia"
  },
  {
    "doc_id": "10121868",
    "abstract_original": "Recent years have seen rapid gaming development. As development speeds up, game complexity rises. Software engineers are using agile methodologies to enhance output. In this paper, a meta-model-based computer gaming model is shown. The meta-model was created for design reusability, with the purpose of building codes that automatically make implementations in a well-defined manner by constructing the sections individually and independently for implementation. Early game makers had little industry or resources. Space-time game modeling aids in computer game creation describes related topics and provides a game metamodel. Hand-coded parts and regulations make it harder to adapt to different game areas. MDD is an innovative software development method. Some people think drawing is enough to build a model. Diagrams are also needed. Models must have a well-defined, abstract syntax-illustrative structure consistent with met models. Building a space-time model for games allows for model language research. Meta models and OCL can close the design-implementation gap. The code structure facilitates sorting and querying models.",
    "abstract_processed": "recent year seen rapid game develop develop speed game complex rise softwar engin use agil methodolog enhanc output paper meta model base comput game model shown meta model creat design reusabl purpos build code automat make implement well defin manner construct section individu independ implement earli game maker littl industri resourc space time game model aid comput game creation describ relat topic provid game metamodel hand code part regul make harder adapt differ game area mdd innov softwar develop method peopl think draw enough build model diagram also need model must well defin abstract syntax illustr structur consist met model build space time model game allow model languag research meta model ocl close design implement gap code structur facilit sort queri model"
  },
  {
    "doc_id": "10124008",
    "abstract_original": "This study analyzes 15,453 math topic-based Scratch projects of the online Scratch community to find the relations among K–12 math topics, usage of 13 programming elements, and project popularity. Among the six math topics, only statistics and calculus significantly contribute to projecting popularity. In addition, noncore programming elements, including sound and look, are widely adapted across various math topics and contribute significantly to project popularity. Although some studies discussed the integration of computation thinking (CT) and math in the classrooms, scant research focuses on the effect of math topics on CT element adoption for achieving better integration in the creative learning context. Moreover, few studies involve a large sample size for generalizable findings.",
    "abstract_processed": "studi analyz math topic base scratch project onlin scratch commun find relat among k– math topic usag program element project popular among six math topic statist calculu significantli contribut project popular addit noncor program element includ sound look wide adapt across variou math topic contribut significantli project popular although studi discuss integr comput think ct math classroom scant research focus effect math topic ct element adopt achiev better integr creativ learn context moreov studi involv larg sampl size generaliz find"
  },
  {
    "doc_id": "10125117",
    "abstract_original": "Recent trends in Science, Technology, Engineering, and Mathematics (STEM) education are focused on developing problem-solving skills and computational thinking and empowering students with the STEM discipline's knowledge to solve real-world problems. STEM incorporates an interdisciplinary approach that includes inquiry, analysis, critical thinking, practical experimentation, and cooperative problem-solving. Technological advancements are offering new ways to integrate new tools such as drones, robotics and gaming in teaching and learning practices and modify the pedagogical approaches that are more appealing and engaging. This paper presents an innovative pedagogical approach and practice that integrate drone technology and block-based programming to foster students' computation thinking in a STEM context. The block-based visual programming languages provide an interactive environment to connect the blocks and write programs. The study was conducted in six Australian schools. Students were assigned projects to automate drones using the DroneBlocks app and make programs to fly the drone in different geometrical patterns; straight line, arch, rectangle, triangles and zig-zag and integrate the various manoeuvres; bounce, 8D flips, and throw & go along flight paths. Students' computational thinking development was examined with an emphasis on their performance in formulating and problem-solving. Results have shown that integrated drone and programming pedagogy contributed significantly to students' learning of developing computational thinking for problem-solving and decomposing a problem into smaller parts in a sequence that includes mathematical algorithms to write programs.",
    "abstract_processed": "recent trend scienc technolog engin mathemat stem educ focus develop problem solv skill comput think empow student stem disciplin knowledg solv real world problem stem incorpor interdisciplinari approach includ inquiri analysi critic think practic experiment cooper problem solv technolog advanc offer new way integr new tool drone robot game teach learn practic modifi pedagog approach appeal engag paper present innov pedagog approach practic integr drone technolog block base program foster student comput think stem context block base visual program languag provid interact environ connect block write program studi conduct six australian school student assign project autom drone use droneblock app make program fli drone differ geometr pattern straight line arch rectangl triangl zig zag integr variou manoeuvr bounc flip throw go along flight path student comput think develop examin emphasi perform formul problem solv result shown integr drone program pedagogi contribut significantli student learn develop comput think problem solv decompos problem smaller part sequenc includ mathemat algorithm write program"
  },
  {
    "doc_id": "10125266",
    "abstract_original": "Quantum mechanics is a revolutionary scientific field, which lies at the crossroad section of Physics, Mathematics, Computer and Computational Science. In essence, it is considered a cross-disciplinary STEM field, advancing the philosophy of Quantum Literacy (QL), which addresses the transdisciplinary nature of real world complex problems. QL addresses the challenges of learning and skills acquisition, through specific computing activities, within a highly bounded discipline and of access to the kind of powerful knowledge that should be more accessible to a wide group of learners. It is therefore important that quantum computing and quantum technologies knowledge is accessible to students and teachers who work with real problems, in a more inclusive and interactive way. In this paper, we argue for the necessity of exposing students to new and powerful quantum tools, as provided by cutting edge quantum computing technologies. We do that by proposing contemporary and STEM related activities and gamification scenarios, in which they acquire stronger mathematical and computational - problem decomposition and modelling skills, working as real researchers. By engaging students in games and activities related to quantum computing and quantum information processing, they acquire all necessary knowledge related to: superposition, teleportation, entanglement, quantum gates and quantum information. The serious games proposed in this paper relates to quantum strategic games, necessary for STEM activities to train students within the computational thinking 2.0 framework. All scenarios were implemented using the didactic model of inquiry-based learning using Python libraries.",
    "abstract_processed": "quantum mechan revolutionari scientif field lie crossroad section physic mathemat comput comput scienc essenc consid cross disciplinari stem field advanc philosophi quantum literaci ql address transdisciplinari natur real world complex problem ql address challeng learn skill acquisit specif comput activ within highli bound disciplin access kind power knowledg access wide group learner therefor import quantum comput quantum technolog knowledg access student teacher work real problem inclus interact way paper argu necess expos student new power quantum tool provid cut edg quantum comput technolog propos contemporari stem relat activ gamif scenario acquir stronger mathemat comput problem decomposit model skill work real research engag student game activ relat quantum comput quantum inform process acquir necessari knowledg relat superposit teleport entangl quantum gate quantum inform seriou game propos paper relat quantum strateg game necessari stem activ train student within comput think framework scenario implement use didact model inquiri base learn use python librari"
  },
  {
    "doc_id": "10127288",
    "abstract_original": "Problem based learning has been adapted by various universities and inscribed with perspectives based on the demographic challenges. The method known to be effective for producing lifelong learners and improve cognitive skills, has been experimented on several facades. Problems, being major drivers in the process, have been researched to design and the deliberate the most effective ways. Through this paper we propose a game based learning model which can be used as problems in a problem based learning framework. In contrast to learning activities supplied using more old-fashioned didactic methodologies, this strategy can be used to engage a student through meaningful activities. This paper presents a model to use game in problem based learning followed by a case study and its analysis. Giglane game was used in the process to analyze the effectiveness with respect to number of stakeholders and incidents reported. The method is validated for effectiveness and promises to be an effective strategy for reflections and self-directed learning attributes. The method directly supports the decomposition structure from the computational thinking methodology which can be combined with the problem based learning process.",
    "abstract_processed": "problem base learn adapt variou univers inscrib perspect base demograph challeng method known effect produc lifelong learner improv cognit skill experi sever facad problem major driver process research design deliber effect way paper propos game base learn model use problem problem base learn framework contrast learn activ suppli use old fashion didact methodolog strategi use engag student meaning activ paper present model use game problem base learn follow case studi analysi giglan game use process analyz effect respect number stakehold incid report method valid effect promis effect strategi reflect self direct learn attribut method directli support decomposit structur comput think methodolog combin problem base learn process"
  },
  {
    "doc_id": "10127310",
    "abstract_original": "The paradigm of education has undergone a significant transition from traditional teacher-directed instruction to student-centered problem-based learning. In various contexts, problem-based learning, computational thinking, and metaphor-based learning approaches have been used to deliver an efficacious learning of the concept. This paper puts forward a model and its usage to build metaphor based case studies directing towards cognitive thinking, self-directed learning and lifelong learning. The model directly influences on the problem solving thought process. The paper further presents a case study on application of this model and its effectiveness validated through the embedded design method. The method appears to be effective in from model analysis and feedback collected. This directly connects to the pattern recognition paradigm of the computational thinking process.",
    "abstract_processed": "paradigm educ undergon signific transit tradit teacher direct instruct student center problem base learn variou context problem base learn comput think metaphor base learn approach use deliv efficaci learn concept paper put forward model usag build metaphor base case studi direct toward cognit think self direct learn lifelong learn model directli influenc problem solv thought process paper present case studi applic model effect valid embed design method method appear effect model analysi feedback collect directli connect pattern recognit paradigm comput think process"
  },
  {
    "doc_id": "10127438",
    "abstract_original": "A problem based learning pedagogy has paved its pathway into teaching and learning standing as one of the effective contributors in the teaching and learning process. With the varying institutional philosophies, the methodology has ample scope for improvements when it comes to its design and delivery. This paper proposes a method of using abstraction from computational thinking to construct knowledge in problem based learning process. Arriving at principles is one of the major objectives of learning process and also contributes towards the self-directed learning. A paper piece activity with shapes and sizes is designed to create free and themed scenarios and further analyzed with various attributes and its contribution towards the knowledge construction process. The paper presents a model and discusses the various perspectives of the activity. The method is found to be an effective approach to design problems that contribute to holistic learning. Knowledge construction process can aid into an effective learning method.",
    "abstract_processed": "problem base learn pedagogi pave pathway teach learn stand one effect contributor teach learn process vari institut philosophi methodolog ampl scope improv come design deliveri paper propos method use abstract comput think construct knowledg problem base learn process arriv principl one major object learn process also contribut toward self direct learn paper piec activ shape size design creat free theme scenario analyz variou attribut contribut toward knowledg construct process paper present model discuss variou perspect activ method found effect approach design problem contribut holist learn knowledg construct process aid effect learn method"
  },
  {
    "doc_id": "10127710",
    "abstract_original": "Technology has an important role in predicting a person's possible risk of chronic disease with the emergence of various kinds of research in the field of medical informatics, especially those related to the four chronic diseases that cause death in Indonesia, such as heart disease, stroke, cancer, and diabetes. Delays in medical treatment due to not predicting the disease can lead to other serious complications in the future. Therefore, doctors must think and work harder to assess patients early with factors influencing chronic disease risk. Many studies have carried out disease prediction focused only on one to two disease predictions. Still, research related to risk prediction for four diseases simultaneously has not been carried out in health and medical services. This study makes a risk prediction model for patients suffering from one or four chronic diseases, which goes through several stages in data mining from medical record data and assessments. We used 29 variables from two combination data sources, calculated using the C4.5 algorithm to predict the patient's risk for the disease. Based on the accuracy test results, the chronic disease prediction model has an accuracy value of 84%.This shows that the resulting model has good decision-making and high accuracy. For further research, other parameters can be used to predict disease, such as dietary habits in a certain period.",
    "abstract_processed": "technolog import role predict person possibl risk chronic diseas emerg variou kind research field medic informat especi relat four chronic diseas caus death indonesia heart diseas stroke cancer diabet delay medic treatment due predict diseas lead seriou complic futur therefor doctor must think work harder assess patient earli factor influenc chronic diseas risk mani studi carri diseas predict focus one two diseas predict still research relat risk predict four diseas simultan carri health medic servic studi make risk predict model patient suffer one four chronic diseas goe sever stage data mine medic record data assess use variabl two combin data sourc calcul use c algorithm predict patient risk diseas base accuraci test result chronic diseas predict model accuraci valu show result model good decis make high accuraci research paramet use predict diseas dietari habit certain period"
  },
  {
    "doc_id": "10130181",
    "abstract_original": "This work reports an innovative product-based pedagogy that was developed by incorporating entrepreneurial education into the upper-level undergraduate and graduate courses in the Electrical Engineering department at the University of Texas (UT) at Tyler. Several aspects make this work different from existing research. We adopted an iterative challenge-based STAR cycle and investigated the effectiveness of computational thinking in our course projects. In addition, entrepreneurial components were incorporated into a series of senior and graduate-level courses with the goal of creating student entrepreneurs. The entrepreneurship-focused curriculum encouraged students to participate in regional pitch competitions and conference presentations. The findings from this work suggest a positive impact of entrepreneurial learning on student learning outcomes.",
    "abstract_processed": "work report innov product base pedagogi develop incorpor entrepreneuri educ upper level undergradu graduat cours electr engin depart univers texa ut tyler sever aspect make work differ exist research adopt iter challeng base star cycl investig effect comput think cours project addit entrepreneuri compon incorpor seri senior graduat level cours goal creat student entrepreneur entrepreneurship focus curriculum encourag student particip region pitch competit confer present find work suggest posit impact entrepreneuri learn student learn outcom"
  },
  {
    "doc_id": "10131683",
    "abstract_original": "This research paper critically analyzes whether current business curriculum and teaching methods address the integration of emerging technologies. It examines the challenges and opportunities educational institutions face in incorporating technology into the business curriculum. The paper identifies the new skill sets required by industries due to rapid technological changes and highlights the existing gap. It concludes by outlining the challenges and opportunities for bridging the gap between industry needs and educational offerings. The paper is based on secondary data and establishes a conceptual foundation for future primary research.",
    "abstract_processed": "research paper critic analyz whether current busi curriculum teach method address integr emerg technolog examin challeng opportun educ institut face incorpor technolog busi curriculum paper identifi new skill set requir industri due rapid technolog chang highlight exist gap conclud outlin challeng opportun bridg gap industri need educ offer paper base secondari data establish conceptu foundat futur primari research"
  },
  {
    "doc_id": "10131704",
    "abstract_original": "An effective prediction of orthodontics treatment outcome is highly essential for further scheme of clinical treatment for the patient with the simplified cost. An appropriate utilization of information technology simplifies the treatment for teeth irregularities and misaligned jaws in an effective manner. Lot of research works carried out in the area of dentistry to come out with an optimistic result. With the advent of artificial intelligence and machine learning methodologies in recent years, lot of clinical problems and difficulties can be efficiently managed and overcome by orthodontists. This research article provides the complete insight about the impact of intelligent technologies in the field of orthodontics. It provides a complete overview of futuristic applications in the field of orthodontic clinical diagnosis, planning of treatment for various cases and the correct prediction of outcome of clinical treatment which regularly faced by an orthodontist in the health care sector.",
    "abstract_processed": "effect predict orthodont treatment outcom highli essenti scheme clinic treatment patient simplifi cost appropri util inform technolog simplifi treatment teeth irregular misalign jaw effect manner lot research work carri area dentistri come optimist result advent artifici intellig machin learn methodolog recent year lot clinic problem difficulti effici manag overcom orthodontist research articl provid complet insight impact intellig technolog field orthodont provid complet overview futurist applic field orthodont clinic diagnosi plan treatment variou case correct predict outcom clinic treatment regularli face orthodontist health care sector"
  },
  {
    "doc_id": "10131752",
    "abstract_original": "Global business environment in the modern times is being impacted by various forces such as advancement in technology, borderless trade, economic tremors and disruptions of business which have resulted in organizations adopting and using business excellence practices in order to achieve success in all domains of their business. There are several business excellence models available which are very famous amongst businesses, government and private accreditation agencies, regulators and policy makers. ISO has remained an all-time favorite quality standard for businesses. In the journey of excellence, most of the companies start with getting them in line with ISO standards and get certification. EFQM has also become very popular amongst modern day businesses as it sets more comprehensive view of business excellence and quality assurance. The aim of this paper is to understand the significance of business excellence and its internationally recognized models such as EFQM and ISO which assist in improving business performance. The paper also intends to highlight the similarities and dissimilarities between the two models and their implementation. Also, this is an effort to compare the two models (ISO and EFQM) to see their relevance and impact in the area of quality assurance and business excellence.",
    "abstract_processed": "global busi environ modern time impact variou forc advanc technolog borderless trade econom tremor disrupt busi result organ adopt use busi excel practic order achiev success domain busi sever busi excel model avail famou amongst busi govern privat accredit agenc regul polici maker iso remain time favorit qualiti standard busi journey excel compani start get line iso standard get certif efqm also becom popular amongst modern day busi set comprehens view busi excel qualiti assur aim paper understand signific busi excel intern recogn model efqm iso assist improv busi perform paper also intend highlight similar dissimilar two model implement also effort compar two model iso efqm see relev impact area qualiti assur busi excel"
  },
  {
    "doc_id": "10131894",
    "abstract_original": "Traditionally, many people still wish to write on pen and paper. However, it has some drawbacks, like accessing and storing physical documents efficiently, searching through them, and sharing them efficiently. Handwriting to Text Conversion (HTC) classifies and converts an individual’s handwriting into digital form. However, HTC removes all the mentioned problems as storing, retrieving, and using the text as and when required is easier. Emotions are a basic and particularly important aspect of one’s life. To understand this important aspect of an individual’s life, we must detect emotions using affect data like text, voice, and image. We have used text as the effect data for this work. We can find a person’s emotions behind his text by sentiment analysis. Sentiment recognition and analysis is a topic with wide research as many brands, companies, and even famous personalities are very much interested in getting feedback and thus do the evaluation of their performance and knowing what people think about them around the world. Authors have proposed a model where they collected data from social media reviews and classified it into three broad categories, which are positive, negative, and neutral. Find the emotions category viz. happiness, sadness, shame, anger, disgust, fear, surprise, or neutral from three types of classified sentiments. The proposed model combined machine learning, deep learning, and natural language processing techniques to achieve the best outcome.",
    "abstract_processed": "tradit mani peopl still wish write pen paper howev drawback like access store physic document effici search share effici handwrit text convers htc classifi convert individual’ handwrit digit form howev htc remov mention problem store retriev use text requir easier emot basic particularli import aspect one’ life understand import aspect individual’ life must detect emot use affect data like text voic imag use text effect data work find person’ emot behind text sentiment analysi sentiment recognit analysi topic wide research mani brand compani even famou person much interest get feedback thu evalu perform know peopl think around world author propos model collect data social media review classifi three broad categori posit neg neutral find emot categori viz happi sad shame anger disgust fear surpris neutral three type classifi sentiment propos model combin machin learn deep learn natur languag process techniqu achiev best outcom"
  },
  {
    "doc_id": "10132652",
    "abstract_original": "If I were to point to a group of professionals who are constantly updating their mental models and technological frameworks to correspond to new social and scientific knowledge, I would choose doctors. As a layperson, I think about the tangle of race in medicine a lot because my own experience with it doesn&#x0027;t fit neatly into computational categories. I am a Black woman with light skin, and people often don&#x0027;t know what racial or ethnic category to put me in. I&#x0027;ve been asked if I am Black, white, Puerto Rican, Egyptian, Israeli&#x2014;the whole spectrum. For the purposes of medical forms, I usually write that I am multiracial. My mother was white, my father was Black, and I want my doctors to be aware of any genetic or epigenetic factors that might be inherited along either family line. As the cultural conversation about race has evolved over the years, I&#x0027;ve noticed my doctors adapting their practices.",
    "abstract_processed": "point group profession constantli updat mental model technolog framework correspond new social scientif knowledg would choos doctor layperson think tangl race medicin lot experi x fit neatli comput categori black woman light skin peopl often x know racial ethnic categori put x ask black white puerto rican egyptian isra x whole spectrum purpos medic form usual write multiraci mother white father black want doctor awar genet epigenet factor might inherit along either famili line cultur convers race evolv year x notic doctor adapt practic"
  },
  {
    "doc_id": "10132718",
    "abstract_original": "Humans cannot easily manage large stacks of unsorted items&#x2014; think of millions of different items randomly dumped and heaped in a warehouse.<superscript>1</superscript> The usual way for us to deal with a mess is to give it some order; for example, to find a name among one million we typically invest a lot of upfront work to sort all those names alphabetically; that investment pays back each time we look for a name, because then we know in advance where it is, and we don&#x0027;t have to read one million names to find the one we are looking for. The same in mathematics: to handle one million mathematical points we typically inscribe them in an equation, so we deal with just a few lines of algebraic script instead of having to deal with one million coordinates. In applied sciences, as in design, we do not handle dimensionless mathematical points, but physical particles, pixels, or voxels&#x2014;chunks of images and of three-dimensional objects; yet the logic is the same. No human can notate and calculate one billion parts (chunks, pixels, voxels) one by one. Life is too short for that. When dealing with data, simplification is the humans&#x0027; inescapable lot. That&#x0027;s the way our mind works.",
    "abstract_processed": "human cannot easili manag larg stack unsort item x think million differ item randomli dump heap warehous superscript superscript usual way us deal mess give order exampl find name among one million typic invest lot upfront work sort name alphabet invest pay back time look name know advanc x read one million name find one look mathemat handl one million mathemat point typic inscrib equat deal line algebra script instead deal one million coordin appli scienc design handl dimensionless mathemat point physic particl pixel voxel x chunk imag three dimension object yet logic human notat calcul one billion part chunk pixel voxel one one life short deal data simplif human x inescap lot x way mind work"
  },
  {
    "doc_id": "10134081",
    "abstract_original": "As methodology has created and sensors have been scaled down, there have been endeavors to utilize contemporary innovation in different fields to work on the nature of human existence. One of the significant areas of examination that has been distinguished is the consideration of innovation in the medical services business. Individuals who require medical care administrations think that they are preposterously costly, particularly in creating nations. The main part involves utilizing sensors like ECG signal, Temperature, Glucose and heart beat sensors to distinguish a patient's vitals, the second sending information to cloud capacity, and the third conveying the noticed information for ML model like SVM and KNN to anticipate regardless of whether the individual having heart illness or not and then the performance of both the models are compared. The information might be seen from a distance, permitting a specialist or gatekeeper to screen a patient's wellbeing state even while they are not in the emergency clinic. The Web of Things (IoT) has been generally used to interface promptly accessible clinical assets and give patients with insightful, trustworthy, and viable medical care administrations.",
    "abstract_processed": "methodolog creat sensor scale endeavor util contemporari innov differ field work natur human exist one signific area examin distinguish consider innov medic servic busi individu requir medic care administr think preposter costli particularli creat nation main part involv util sensor like ecg signal temperatur glucos heart beat sensor distinguish patient vital second send inform cloud capac third convey notic inform ml model like svm knn anticip regardless whether individu heart ill perform model compar inform might seen distanc permit specialist gatekeep screen patient wellb state even emerg clinic web thing iot gener use interfac promptli access clinic asset give patient insight trustworthi viabl medic care administr"
  },
  {
    "doc_id": "10134169",
    "abstract_original": "Social media has become an essential means for communicating the review/opinions of people around the world due to the rapid expansion and availability of the internet. Reviews and opinions are expressed both as text and audio. But text communication via networking media is overwhelming. Each and every second, a vast amount of information is produced online because of social media sites. However, online reviews on social media provides an excellent and trustworthy channel for examining the areas that require improvement and for understanding the needs of customers. This paper tries to understand the various topics that are discussed by customers about food with the aim of providing an insight to improve the area where there are negative comments. By doing this, customer retention will increase and gradually the business also. Topic modeling is done to find the hidden topic in a set of comments or customer reviews to find out on which topic customers are talking, thinking, or discussing more about restaurant services. It helps to read customers' mindsets, and accordingly, improvements can be made to increase consumer demand for a restaurant. So, a system is proposed to detect topics of textual reviews of different restaurants using the latent Dirichlet allocation (LDA) modelling approach. A probabilistic, statistical strategy for document designing called latent document analysis (LDA) identifies latent semantic topics in sizable corpora. The dataset used for this study was taken from Kaggle, which had 111,105 reviews. First, topics from reviews were extracted using the LDA model, then data was visualised using the LDAvis tool. The experiment's findings show that the analysis obtained a successful topic division outcome especially in long-to-short text level topic classification.",
    "abstract_processed": "social media becom essenti mean commun review opinion peopl around world due rapid expans avail internet review opinion express text audio text commun via network media overwhelm everi second vast amount inform produc onlin social media site howev onlin review social media provid excel trustworthi channel examin area requir improv understand need custom paper tri understand variou topic discuss custom food aim provid insight improv area neg comment custom retent increas gradual busi also topic model done find hidden topic set comment custom review find topic custom talk think discuss restaur servic help read custom mindset accordingli improv made increas consum demand restaur system propos detect topic textual review differ restaur use latent dirichlet alloc lda model approach probabilist statist strategi document design call latent document analysi lda identifi latent semant topic sizabl corpora dataset use studi taken kaggl review first topic review extract use lda model data visualis use ldavi tool experi find show analysi obtain success topic divis outcom especi long short text level topic classif"
  },
  {
    "doc_id": "10134585",
    "abstract_original": "In recent years, with the continuous development of digitalization, all kinds of data on the Internet have increased rapidly, and knowledge graphs have emerged. Knowledge graphs have become one of the important means for us to manage and utilize knowledge. Knowledge reasoning is part of building a knowledge graph. There are many different methods of knowledge reasoning, which are mainly divided into traditional knowledge reasoning and knowledge reasoning over knowledge graph. The knowledge reasoning manner based on neural network has stronger thinking ability and generalization ability. The inference effect is better. The utilization rate of the relation, entity, attribute and text information in the knowledge base is higher. In this paper, the basic ideas of knowledge graph are introduced in detail. The basic principle of knowledge reasoning is expounded. In addition, from the three dimensions of semantics, structure and auxiliary storage. Three inference methods are introduced. Furthermore, the problems of neural network are summarized, and the challenges of knowledge reasoning are described. Finally, The development prospect of neural network and knowledge reasoning are prospected.",
    "abstract_processed": "recent year continu develop digit kind data internet increas rapidli knowledg graph emerg knowledg graph becom one import mean us manag util knowledg knowledg reason part build knowledg graph mani differ method knowledg reason mainli divid tradit knowledg reason knowledg reason knowledg graph knowledg reason manner base neural network stronger think abil gener abil infer effect better util rate relat entiti attribut text inform knowledg base higher paper basic idea knowledg graph introduc detail basic principl knowledg reason expound addit three dimens semant structur auxiliari storag three infer method introduc furthermor problem neural network summar challeng knowledg reason describ final develop prospect neural network knowledg reason prospect"
  },
  {
    "doc_id": "10134633",
    "abstract_original": "The study aims to learn deep features from EEG signals corresponding to the imagery of words to design a BCI(Brain computer interface) system based on human thoughts. Topological plots of time-averaged EEG signals across all the trials corresponding to the imagery of a particular word are fed as input to the designed deep neural network algorithm. Designed deep learning architecture has an amalgamation of the Two-dimensional convolutional neural network and LSTM that takes the assistance of the capabilities and assets of both neural network architectures. The proposed neural network architecture achieves admirable accuracy in identifying imagined words from the EEG-based Kara one dataset. The accuracy of the designed CNN-LSTM model with topological plots as input features was 20-25% more than chance level accuracy and comparable to the state of arts.",
    "abstract_processed": "studi aim learn deep featur eeg signal correspond imageri word design bci brain comput interfac system base human thought topolog plot time averag eeg signal across trial correspond imageri particular word fed input design deep neural network algorithm design deep learn architectur amalgam two dimension convolut neural network lstm take assist capabl asset neural network architectur propos neural network architectur achiev admir accuraci identifi imagin word eeg base kara one dataset accuraci design cnn lstm model topolog plot input featur chanc level accuraci compar state art"
  },
  {
    "doc_id": "10137840",
    "abstract_original": "Three-way decisions model adopts the idea of’’rule by three divisions’’ and “simplify complexity which provides a multi-level and multi granularity thinking framework and implementation method for solving complex uncertain problems. Within this framework, how to extend the application of the generalized model from decision system to interval-valued decision system is an important issue. In this paper, we propose multigranulation sequential three-way decision models in inter-valvalued information system. Firstly, three types of similarity relations from the view of optimistic, pessimistic and weighted are defined. Based on these similarity relations, the lower and upper approximations under multiple granular structures are computed. Then optimistic, pessimistic and weighted arithmetic strategies are adopted to compute three disjoint regions in each level of multigranulation sequential three-way decisions. Furthermore, nine types of multigranulation sequential threeway decision models were analysed. Finally, the experimental results show that the size of the probabilistic regions varies with the similarity relations and aggregation strategies.",
    "abstract_processed": "three way decis model adopt idea of’’rul three divisions’’ “simplifi complex provid multi level multi granular think framework implement method solv complex uncertain problem within framework extend applic gener model decis system interv valu decis system import issu paper propos multigranul sequenti three way decis model inter valvalu inform system firstli three type similar relat view optimist pessimist weight defin base similar relat lower upper approxim multipl granular structur comput optimist pessimist weight arithmet strategi adopt comput three disjoint region level multigranul sequenti three way decis furthermor nine type multigranul sequenti threeway decis model analys final experiment result show size probabilist region vari similar relat aggreg strategi"
  },
  {
    "doc_id": "10138187",
    "abstract_original": "This work proposes a transformer-based model capable of generating music in its symbolic domain, in a controllable fashion. The ultimate goal of this is to build a system with which people can compose music collaboratively with a computer. Using an NLP model as a base (GPT-2), we take advantage of the similarities across symbolic music representation and written language to build a model capable of conditionally predicting musical sequences. Controllability is achieved without explicit programming for it, and does not require extensive retraining of the model. A study with 939 participants was performed to evaluate this controllability. The results of this suggest the proposed method is indeed effective and can be used to control the generation of music in its symbolic domain. The method itself is flexible to any desired “control”, but this work focuses specifically on the emotion conveyed when one listens to a piece of music.",
    "abstract_processed": "work propos transform base model capabl gener music symbol domain control fashion ultim goal build system peopl compos music collabor comput use nlp model base gpt take advantag similar across symbol music represent written languag build model capabl condit predict music sequenc control achiev without explicit program requir extens retrain model studi particip perform evalu control result suggest propos method inde effect use control gener music symbol domain method flexibl desir “control” work focus specif emot convey one listen piec music"
  },
  {
    "doc_id": "10138574",
    "abstract_original": "This manuscript presents a ring-core Bragg Fiber (RC-BF) for orbital angular momentum (OAM) modes propagation and supercontinuum generation. The proposed RC-BF is composed of alternating layers of soft glasses SF57 and LLF1 to render high nonlinearity to the fiber. Mode analysis using full-vectorial finite element method resulted in obtaining HE/EH modes to support vector modes as well as orbital angular momentum modes. The optimized fiber supports 22 OAM modes and exhibits a zero-dispersion wavelength (ZDW). The small effective area of Fiber 3 aided in achieving the highest nonlinearity,  $\\gamma $  = 91.51  $\\text{W}^{-1}$ km $^{-1}$ . A near-infrared supercontinuum is generated with a 35 dB flatness over a bandwidth of  $\\sim $ 1087 - 2024 nm in a 20 cm long RC-BF using a chirp-free hyperbolic secant pulse of width 200 fs and peak power of 5 kW.",
    "abstract_processed": "manuscript present ring core bragg fiber rc bf orbit angular momentum oam mode propag supercontinuum gener propos rc bf compos altern layer soft glass sf llf render high nonlinear fiber mode analysi use full vectori finit element method result obtain eh mode support vector mode well orbit angular momentum mode optim fiber support oam mode exhibit zero dispers wavelength zdw small effect area fiber aid achiev highest nonlinear \\gamma \\text w km near infrar supercontinuum gener db flat bandwidth \\sim nm cm long rc bf use chirp free hyperbol secant puls width fs peak power kw"
  },
  {
    "doc_id": "10139678",
    "abstract_original": "The last decade has seen a surge in expanding access to Computer Science (CS) education, especially for K-12, with many states even stipulating student learning standards in CS and Computational Thinking (CT). Our 21st century K-12 students are no longer just computer users, but are now required to be computationally literate creators with proficient skills both in the concepts and practices of CS and CT. At the same time, technology continues to pervade our lives and expand at a relentless pace and all aspects of our lives are now embedded in technology surrounded by Artificial Intelligence (AI). AI in the form of Machine Learning (ML) is a key technology in a diversity of applications, where we use sensors to meaningfully perceive the world around us, analyze and organize the perceived data, and autonomously use that data to make predictions and decisions. In higher education, AI/ML courses proliferate, with many institutions now conferring degrees and certifications in these. To an extent, some high schools (grades 9–12) have started introducing these concepts in a technology class, or a robotics club, or as an after-school activity. As for middle (grades 6–8) and elementary school (grades K-5), there are very few examples of such instruction. In this paper, we present a complete framework for elementary and middle school teachers to help them prepare and incorporate AI/ML lessons in their classrooms using hands-on active learning strategies. We want to empower these teachers to impart improved learning to their students, which in turn will prepare their students to become effective thinkers, problem solvers, communicators, and gain necessary skills for high-skilled and high-demand jobs. We describe a detailed AI/ML lesson plan based on standards and framework, AI4K12 big ideas, art and science of curriculum design, active learning, and culturally responsive and inclusive pedagogy. Then we discuss our experiences in teaching the same to $\\boldsymbol{4}^{\\mathbf{th}}$ grade students in an elementary school.",
    "abstract_processed": "last decad seen surg expand access comput scienc cs educ especi k mani state even stipul student learn standard cs comput think ct st centuri k student longer comput user requir comput liter creator profici skill concept practic cs ct time technolog continu pervad live expand relentless pace aspect live embed technolog surround artifici intellig ai ai form machin learn ml key technolog divers applic use sensor meaning perceiv world around us analyz organ perceiv data autonom use data make predict decis higher educ ai ml cours prolifer mani institut confer degre certif extent high school grade – start introduc concept technolog class robot club school activ middl grade – elementari school grade k exampl instruct paper present complet framework elementari middl school teacher help prepar incorpor ai ml lesson classroom use hand activ learn strategi want empow teacher impart improv learn student turn prepar student becom effect thinker problem solver commun gain necessari skill high skill high demand job describ detail ai ml lesson plan base standard framework ai k big idea art scienc curriculum design activ learn cultur respons inclus pedagogi discuss experi teach \\boldsymbol \\mathbf th grade student elementari school"
  },
  {
    "doc_id": "10140549",
    "abstract_original": "The fermentation process refers to the reaction process in which specialized metabolites are produced and accumulated in large quantities through the growth, culture and chemical changes of microorganisms (or animal and plant cells). The biomass parameters play a key role, and they cannot be detected online. Measurement technology offers a solution. Expert system technology can solve the problems of complicated fermentation process classification and numerous mechanism models in the process of biomass soft sensing modeling. This paper presents the structure of an expert system for biomass detection in fermentation process. This expert system provides a new technical method for the division of soft-sensing hybrid models.",
    "abstract_processed": "ferment process refer reaction process special metabolit produc accumul larg quantiti growth cultur chemic chang microorgan anim plant cell biomass paramet play key role cannot detect onlin measur technolog offer solut expert system technolog solv problem complic ferment process classif numer mechan model process biomass soft sens model paper present structur expert system biomass detect ferment process expert system provid new technic method divis soft sens hybrid model"
  },
  {
    "doc_id": "10140623",
    "abstract_original": "In mechanical design, this paper uses CAD interface for 3D modeling to generate 3D solids. This paper clarifies the intelligent standard view generation technology in 3D CAD software and its intelligent technologies such as axonometric drawing, internal structure, auxiliary view, intelligent annotation, parametric design and assembly design, showing its powerful application function. According to the principle of shape design in 3D conception, this paper discusses the teaching mode of combining composition theory with 3D CAD application, and using 3D CAD system to cultivate students' abstract thinking, image thinking and innovative thinking.",
    "abstract_processed": "mechan design paper use cad interfac model gener solid paper clarifi intellig standard view gener technolog cad softwar intellig technolog axonometr draw intern structur auxiliari view intellig annot parametr design assembl design show power applic function accord principl shape design concept paper discuss teach mode combin composit theori cad applic use cad system cultiv student abstract think imag think innov think"
  },
  {
    "doc_id": "10140696",
    "abstract_original": "This paper highlighted the key challenges impacting Management Education in India (MEI) in the current digitalized scenario, especially after COVID-19. Initially, an exploratory research design was utilized and then it was descriptive to analyze the collected data. The sample size was 100(valid responses) being the management educator of Meerut city as a sample unit. Table & Descriptive Statistics were used to define the data and ‘Correlation and Multiple Regression Analysis’ were used for calculating the outcomes. Major respondents were young-aged educators that truly believe in a challenging and dynamic MEI as of now. The crisis management ability was the most crucial challenge of MEI. \"Industry orientation\" and \"international perspective\" were not significant challenges. The study was highly practical because \"MEI\" has been undergoing a roundabout transformation in the current digitalized scenario, and there has been a paradigm shift in overall higher education following COVID-19. It was highly important because budding managers and forthcoming business leaders have to perform in a highly dynamic environment, and the paper was original as 100 primary responses of management educators in Meerut City were taken into account for study.",
    "abstract_processed": "paper highlight key challeng impact manag educ india mei current digit scenario especi covid initi exploratori research design util descript analyz collect data sampl size valid respons manag educ meerut citi sampl unit tabl descript statist use defin data ‘correl multipl regress analysis’ use calcul outcom major respond young age educ truli believ challeng dynam mei crisi manag abil crucial challeng mei industri orient intern perspect signific challeng studi highli practic mei undergo roundabout transform current digit scenario paradigm shift overal higher educ follow covid highli import bud manag forthcom busi leader perform highli dynam environ paper origin primari respons manag educ meerut citi taken account studi"
  },
  {
    "doc_id": "10141836",
    "abstract_original": "In present study the fractal theory has been reviewed in the context of bio-functional and biomedical complex systems. The chaotic approach is a critical component of the theoretical framework and can be used in analyzing complex biological structures such as chromatin structures. Fractality is a metric of complexity in biological functions; it is an indicator of the complication level of the self-similar structure, while chaos is a sort of dynamic behavior that usually produces totally arbitrary patterns. Fractal measurements in vivo could be used to predict the efficiency of painful therapy. The fractal technique can be used to assess carcinogenesis, tumor progression, chemoprophylaxis, and treatment with the convergence of modern sensing techniques in nano-scale spectroscopic techniques, which is a prospective biomarker. The mathematical principles of fractals and chaos in biological systems are presented in the context of the condition of health treatment and their significance. Fractality in different biological functions including the heart has now been investigated and measured the dosing quantity with chaos and fractal level. As excessive amounts of chaos and fractal complexity are harmful to biological predictions. For biological applications, chaos analysis may be advantageous. This paper is a review which highlights the fractal and chaos theories for biological functions and biomedical systems. The focus will be to explore biological functions, due to its computational machine learning-based demands and capability in mathematical complexity.",
    "abstract_processed": "present studi fractal theori review context bio function biomed complex system chaotic approach critic compon theoret framework use analyz complex biolog structur chromatin structur fractal metric complex biolog function indic complic level self similar structur chao sort dynam behavior usual produc total arbitrari pattern fractal measur vivo could use predict effici pain therapi fractal techniqu use assess carcinogenesi tumor progress chemoprophylaxi treatment converg modern sens techniqu nano scale spectroscop techniqu prospect biomark mathemat principl fractal chao biolog system present context condit health treatment signific fractal differ biolog function includ heart investig measur dose quantiti chao fractal level excess amount chao fractal complex harm biolog predict biolog applic chao analysi may advantag paper review highlight fractal chao theori biolog function biomed system focu explor biolog function due comput machin learn base demand capabl mathemat complex"
  },
  {
    "doc_id": "10142352",
    "abstract_original": "The ascent of a few insightful labor and products throughout the course of recent years, as well as their business feasibility and financial impacts, have driven some to contemplate whether the ongoing coming of computer based intelligence is just marketing publicity or really can possibly change society. The review investigates the few impacts of artificial intelligence (artificial intelligence), and digs further into both good and troublesome consequences for legislatures, networks, organizations, and individuals. The entire impacts of simulated intelligence, from exploration and advancement to execution, are analyzed in this paper. With the advancement of computer based intelligence innovations, the marketing business is developing rapidly. Artificial intelligence offers numerous open doors, including the capacity to acquire data, hyper-customize administrations, further develop consumer loyalty, save working expenses, support efficiency, and so forth. For both monetary administrations organizations and advertisers, artificial intelligence has changed the game.",
    "abstract_processed": "ascent insight labor product throughout cours recent year well busi feasibl financi impact driven contempl whether ongo come comput base intellig market public realli possibl chang societi review investig impact artifici intellig artifici intellig dig good troublesom consequ legislatur network organ individu entir impact simul intellig explor advanc execut analyz paper advanc comput base intellig innov market busi develop rapidli artifici intellig offer numer open door includ capac acquir data hyper custom administr develop consum loyalti save work expens support effici forth monetari administr organ advertis artifici intellig chang game"
  },
  {
    "doc_id": "10143123",
    "abstract_original": "Chat Generative Pretrained Transformer (Chat-GPT) and related Generative AI models are leading a paradigm shift in the acceptance and application of Artificial Intelligence (AI) across all disciplines and industry sectors. Despite the criticisms of an ‘intelligence without knowledge or reasoning or the notions of truth’, ChatGPT is highly effective at human-like conversation with seemingly sophisticated and useful responses to questions, summarization, classification, extraction and generation tasks. Unlike similar large AI models in the modalities of image, audio and video, text-based conversation is straightforward and familiar to a large audience of regular users of the Internet and smartphone applications. This is further accentuated by the large-scale adoption of ‘standard’ chatbot technologies for trivial conversations in task-specific automation, across every industry sector. This rare combination of highly effective human-like conversation, familiarity of foundational technology and versatility of intelligent application, has led to several challenges and opportunities in leveraging generative AI. A primary challenge is its impact on the academic integrity of scholarly work, where AI-generated content can be useful and detrimental in both teaching and research. On the other hand, ChatGPT presents a unique opportunity in augmenting preexisting (‘standard’) chatbots with human-like conversation for advanced intelligent automation, across all application domains. Although diametrically opposed, the challenge of addressing academic integrity and the opportunity of augmenting pre-existing chatbots are grounded in the conversational AI capabilities of ChatGPT and similar generative AI models. In this paper, we investigate these formative capabilities and present guidelines for leveraging ChatGPT and similar generative AI models.",
    "abstract_processed": "chat gener pretrain transform chat gpt relat gener ai model lead paradigm shift accept applic artifici intellig ai across disciplin industri sector despit critic ‘intellig without knowledg reason notion truth’ chatgpt highli effect human like convers seemingli sophist use respons question summar classif extract gener task unlik similar larg ai model modal imag audio video text base convers straightforward familiar larg audienc regular user internet smartphon applic accentu larg scale adopt ‘standard’ chatbot technolog trivial convers task specif autom across everi industri sector rare combin highli effect human like convers familiar foundat technolog versatil intellig applic led sever challeng opportun leverag gener ai primari challeng impact academ integr scholarli work ai gener content use detriment teach research hand chatgpt present uniqu opportun augment preexist ‘standard’ chatbot human like convers advanc intellig autom across applic domain although diametr oppos challeng address academ integr opportun augment pre exist chatbot ground convers ai capabl chatgpt similar gener ai model paper investig form capabl present guidelin leverag chatgpt similar gener ai model"
  },
  {
    "doc_id": "10143578",
    "abstract_original": "With the rapid development of DNA microarray technology, the application of informatics research methods in oncology is becoming more and more popular. Because the gene expression data extraction experiment has the characteristics of a large number of genes and complex and changeable experimental conditions, clustering technology has been introduced into the field of molecular biology to assist research and analyze gene expression data. Currently, many clustering algorithms are applied in gene expression analysis. Nevertheless, owing to the high dimensionality of gene expression data, many algorithms face the problem of low computational efficiency. The method based on the graph theory thinks of the sample of gene expression data as the point in high-dimensional space. Its low sample performance determines that the constructed matrix is small in size. Therefore, it has lower computational complexity. Therefore, the graph regularized non-negative matrices factorization (GNMF) proposed by Cai et al. has been widely used for gene clustering. However, the deficiency of the GNMF algorithm is unstable with data variation for gene clustering. In this paper, we propose post-processing of Graph Regularized Nonnegative Matrix Factorization Algorithm for Gene Clustering, called pGNMF. In the pGNMF method, we first normalize the solution of GNMF, thereby reducing the sensitivity of the traditional GNMF method to the prior selection of genes or initial conditions, and effectively improving the robustness of the algorithm. Experimental results show that the proposed algorithms outperform existing GNMF algorithms for gene clustering.",
    "abstract_processed": "rapid develop dna microarray technolog applic informat research method oncolog becom popular gene express data extract experi characterist larg number gene complex changeabl experiment condit cluster technolog introduc field molecular biolog assist research analyz gene express data current mani cluster algorithm appli gene express analysi nevertheless owe high dimension gene express data mani algorithm face problem low comput effici method base graph theori think sampl gene express data point high dimension space low sampl perform determin construct matrix small size therefor lower comput complex therefor graph regular non neg matric factor gnmf propos cai et al wide use gene cluster howev defici gnmf algorithm unstabl data variat gene cluster paper propos post process graph regular nonneg matrix factor algorithm gene cluster call pgnmf pgnmf method first normal solut gnmf therebi reduc sensit tradit gnmf method prior select gene initi condit effect improv robust algorithm experiment result show propos algorithm outperform exist gnmf algorithm gene cluster"
  },
  {
    "doc_id": "10143650",
    "abstract_original": "Social media has revolutionized the way individuals connect and share information globally. However, the rise of these platforms has led to the proliferation of cyber-hate, which is a significant concern that has garnered attention from researchers. To combat this issue, various solutions have been proposed, utilizing Machine learning and Deep learning techniques such as Naive Bayes, Logistic Regression, Convolutional Neural Networks, and Recurrent Neural Networks. These methods rely on a mathematical approach to distinguish one class from another. However, when dealing with sentiment-oriented data, a more “critical thinking” perspective is needed for accurate classification, as it provides a more realistic representation of how people interpret online messages. Based on a literature review conducted to explore efficient classification techniques, this study applied two machine learning classifiers, Multinomial Naive Bayes and Logistic Regression, to four online hate datasets. The results of the classifiers were optimized using bio-inspired optimization techniques such as Particle Swarm Optimization and Genetic Algorithms, in conjunction with Fuzzy Logic, to gain a deeper understanding of the text in the datasets.",
    "abstract_processed": "social media revolution way individu connect share inform global howev rise platform led prolifer cyber hate signific concern garner attent research combat issu variou solut propos util machin learn deep learn techniqu naiv bay logist regress convolut neural network recurr neural network method reli mathemat approach distinguish one class anoth howev deal sentiment orient data “critic thinking” perspect need accur classif provid realist represent peopl interpret onlin messag base literatur review conduct explor effici classif techniqu studi appli two machin learn classifi multinomi naiv bay logist regress four onlin hate dataset result classifi optim use bio inspir optim techniqu particl swarm optim genet algorithm conjunct fuzzi logic gain deeper understand text dataset"
  },
  {
    "doc_id": "10143930",
    "abstract_original": "This research explored the degree of learning self-efficacy of machine learning experience (MLSE) and artificial intelligence learning anxiety (AILA) of elementary and junior high school teachers. The participants were in-service teachers in the technology domain. This research applied the AI2 Robot City, which is a computational thinking board game, to in-service teacher education. The learning content was image classification for AI application. Elementary and junior high school teachers operated the MIT App Inventor(MAI) and Personal Image Classifier(PIC) platform, and trained the model for practicing AI to implement supervised machine learning on the PIC platform. The learners then inserted the model they had trained into the block-based programming environment of MAI. They completed the smart phone app and used the app to recognize the board game cards so as to control the movement of the smart cars on the table map to meet the requirements of the task in the AI2 Robot City board game. In order to understand affective factors such as the self-efficacy and learning anxiety of the elementary and middle school teachers participating in the AI teacher training workshop, the MLSE and AILA scales were administered before and after the classes. A total of 28 samples were collected. The results showed that there was no significant difference between the MLSE of the elementary and junior high school teachers. However, the average AILA degree of the junior high school teachers was significantly higher than that of the elementary school teachers. It was found that AILA was significantly negatively correlated with MLSE. The elementary and junior high school teachers were confident that they could study AI-related courses. However, the AILA of the junior high school teachers was higher than that of the elementary school teachers. Therefore, more teacher training workshops on AI application can be conducted for junior high school teachers to generally improve their familiarity with AI application. Future research can further explore whether teachers will gradually improve their AILA and MLSE with time and as training courses increase.",
    "abstract_processed": "research explor degre learn self efficaci machin learn experi mlse artifici intellig learn anxieti aila elementari junior high school teacher particip servic teacher technolog domain research appli ai robot citi comput think board game servic teacher educ learn content imag classif ai applic elementari junior high school teacher oper mit app inventor mai person imag classifi pic platform train model practic ai implement supervis machin learn pic platform learner insert model train block base program environ mai complet smart phone app use app recogn board game card control movement smart car tabl map meet requir task ai robot citi board game order understand affect factor self efficaci learn anxieti elementari middl school teacher particip ai teacher train workshop mlse aila scale administ class total sampl collect result show signific differ mlse elementari junior high school teacher howev averag aila degre junior high school teacher significantli higher elementari school teacher found aila significantli neg correl mlse elementari junior high school teacher confid could studi ai relat cours howev aila junior high school teacher higher elementari school teacher therefor teacher train workshop ai applic conduct junior high school teacher gener improv familiar ai applic futur research explor whether teacher gradual improv aila mlse time train cours increas"
  },
  {
    "doc_id": "10143932",
    "abstract_original": "Computational thinking (CT), one of the 21st-century essential competencies, has been broadly accepted by artificial intelligence (AI) and STEM. However, little was conducted to explore its potential in foreign language (FL) learning and teaching. To examine its possibilities, the relevant challenges, computer-language input and output process, and literature shreds of evidence were offered and analyzed. English grammar learning and teaching practice based on CT principal skills steps-focused mode further confirmed its social mediation tool in English learning and teaching.",
    "abstract_processed": "comput think ct one st centuri essenti compet broadli accept artifici intellig ai stem howev littl conduct explor potenti foreign languag fl learn teach examin possibl relev challeng comput languag input output process literatur shred evid offer analyz english grammar learn teach practic base ct princip skill step focus mode confirm social mediat tool english learn teach"
  },
  {
    "doc_id": "10145792",
    "abstract_original": "Even without hearing or seeing individuals, humans are able to determine subtle emotions from a range of indicators and surroundings. However, existing research on emotion recognition is mostly focused on recognizing the emotions of speakers across complete modalities. In real-world situations, emotion reasoning is an interesting field for inferring human emotions from a person’s surroundings when neither the face nor voice can be observed. Therefore, in this paper, we propose a novel multimodal approach for predicting emotion from missing one or more modalities based on attention mechanisms. Specifically, we employ self-attention for each unimodal representation to extract the dominant features and utilize the compounded paired-modality attention (CPMA) among sets of modalities to identify the context of the considered individual, such as the interplay of modalities, and capture people’s interactions in the video. The proposed model is trained on the Multimodal Emotion Reasoning (MEmoR) dataset, which includes multimedia inputs such as visual, audio, text, and personality. The proposed model achieves a weighted F1-score of 50.63% for the primary emotion group and 42.7% for the fine-grained one. According to the results, our proposed model outperforms the conventional approaches in terms of emotion reasoning.",
    "abstract_processed": "even without hear see individu human abl determin subtl emot rang indic surround howev exist research emot recognit mostli focus recogn emot speaker across complet modal real world situat emot reason interest field infer human emot person’ surround neither face voic observ therefor paper propos novel multimod approach predict emot miss one modal base attent mechan specif employ self attent unimod represent extract domin featur util compound pair modal attent cpma among set modal identifi context consid individu interplay modal captur people’ interact video propos model train multimod emot reason memor dataset includ multimedia input visual audio text person propos model achiev weight f score primari emot group fine grain one accord result propos model outperform convent approach term emot reason"
  },
  {
    "doc_id": "10148299",
    "abstract_original": "Recent years have seen a high volume of computational thinking (CT) review studies. However, there have been no existing studies that map these reviews with the goal of achieving comprehensive understanding of the field of CT. This paper utilizes Tikva & Tambouris’ (2021) K-12 CT research domain conceptual model as the basis for identifying and defining CT reviews, then maps the identified 38 CT reviews onto the identified domains. We pinpoint eight potential future review topics, including \"communities\" of tools, \"modeling simulations,\" \"problem-solving\" and \"scaffolding\" of learning strategies, \"demographic attributes\" of factors, \"practices\" and \"perspectives\" of the knowledge-based areas, and the \"teacher training\" of capacity building. We also examine the topical keywords of the reviews and identify that the scope of the term \"unplugged\" is vaguely defined among the existing research, suggesting a need to refine the definition of this frequently discussed topic so as to be able to more effectively conduct supplementary reviews. Our results help to better understand the CT review field and formulate future directions.",
    "abstract_processed": "recent year seen high volum comput think ct review studi howev exist studi map review goal achiev comprehens understand field ct paper util tikva tambouris’ k ct research domain conceptu model basi identifi defin ct review map identifi ct review onto identifi domain pinpoint eight potenti futur review topic includ commun tool model simul problem solv scaffold learn strategi demograph attribut factor practic perspect knowledg base area teacher train capac build also examin topic keyword review identifi scope term unplug vagu defin among exist research suggest need refin definit frequent discuss topic abl effect conduct supplementari review result help better understand ct review field formul futur direct"
  },
  {
    "doc_id": "10148382",
    "abstract_original": "In this work, we aim to improve code writing skill in Python-based introductory programming courses for first-year university students. In such courses, students as novice programmers would benefit from personalised and formative feedback to: 1) quickly identify issues in their computational thinking process or coding techniques, and 2) know how to proceed when facing a certain problem. Due to the large number of students, it is impractical for instructors to manually assess all the work of each student to provide tailored feedback. We design and implement Automatic Programming Coach (AP-Coach), a web-based tool for automatically generating formative feedback for exercises on basic programming concepts. AP-Coach combines software engineering techniques (code similarity measures based on abstract syntax trees, and unit testing), and AI techniques (machine translation) in a novel manner to provide relevant feedback. We report promising results for AP-Coach in the following aspects: 1) quantitative evaluation of code similarity computation and machine translation, 2) qualitative evaluation of the perceived quality and usability of auto-generated feedback, and 3) experience of a selected group of computing students using the system.",
    "abstract_processed": "work aim improv code write skill python base introductori program cours first year univers student cours student novic programm would benefit personalis form feedback quickli identifi issu comput think process code techniqu know proceed face certain problem due larg number student impract instructor manual assess work student provid tailor feedback design implement automat program coach ap coach web base tool automat gener form feedback exercis basic program concept ap coach combin softwar engin techniqu code similar measur base abstract syntax tree unit test ai techniqu machin translat novel manner provid relev feedback report promis result ap coach follow aspect quantit evalu code similar comput machin translat qualit evalu perceiv qualiti usabl auto gener feedback experi select group comput student use system"
  },
  {
    "doc_id": "10148435",
    "abstract_original": "The computer science industry suffers from a significant gender gap. This situation likely hinders the creation of inclusive and user-friendly systems due to a bias in perspectives. To narrow this gender gap, this study investigates how females program to increase interest in computer sciences. Specifically, 60 open Scratch projects on the web are analyzed to clarify differences in the Computational Thinking scores with respect to gender. The difference in the Computational Thinking score by gender suggests that the gap may be due to the lack of the Synchronization element in female users’ projects. A deeper understanding of how people program based on gender should support creating an effective and inclusive learning environment and allow educators to create programming materials that attract both genders equally into the field.",
    "abstract_processed": "comput scienc industri suffer signific gender gap situat like hinder creation inclus user friendli system due bia perspect narrow gender gap studi investig femal program increas interest comput scienc specif open scratch project web analyz clarifi differ comput think score respect gender differ comput think score gender suggest gap may due lack synchron element femal users’ project deeper understand peopl program base gender support creat effect inclus learn environ allow educ creat program materi attract gender equal field"
  },
  {
    "doc_id": "10148486",
    "abstract_original": "Large extant studies highlighted the importance of motivation in promoting students’ CT skills. However, few of them focused on basic psychological needs satisfaction (BPNS) and behavioral engagement. Since needs satisfaction could influence intrinsic motivation and lead to better performance. It is critical to understand whether, and to what extent, the learners’ CT skills are influenced by the level of BPNS. In light of this, the work-in-progress study employed a semester-long intervention to explore the role of BPNS in students’ CT skill development. A total of 600 primary students participated in this study. The findings of this study will contribute to a better understanding of primary students’ motivation in programming learning.",
    "abstract_processed": "larg extant studi highlight import motiv promot students’ ct skill howev focus basic psycholog need satisfact bpn behavior engag sinc need satisfact could influenc intrins motiv lead better perform critic understand whether extent learners’ ct skill influenc level bpn light work progress studi employ semest long intervent explor role bpn students’ ct skill develop total primari student particip studi find studi contribut better understand primari students’ motiv program learn"
  },
  {
    "doc_id": "10148487",
    "abstract_original": "We conducted a systematic review of studies aimed at exploring the state of parental involvement in computational thinking (CT) education to facilitate students’ efficiency in learning computational thinking. In this review, we started with reviewing theories of parental involvement. Then we investigated and categorized types of parental involvement, parent roles, and parents’ psychological factors in the parenting process. We also supplemented a new involvement form in Level 2 of Hoover-Dempsey and Sandler’s Model of Parental Involvement in CT Education, namely parents’ support with concerns about using technology and CT tools. We proposed the Model of Parental Involvement in Computational Thinking Education. We conducted comprehensive research of related studies on parental involvement in CT education and identified the research gap in involving parents in children’s CT learning.",
    "abstract_processed": "conduct systemat review studi aim explor state parent involv comput think ct educ facilit students’ effici learn comput think review start review theori parent involv investig categor type parent involv parent role parents’ psycholog factor parent process also supplement new involv form level hoover dempsey sandler’ model parent involv ct educ name parents’ support concern use technolog ct tool propos model parent involv comput think educ conduct comprehens research relat studi parent involv ct educ identifi research gap involv parent children’ ct learn"
  },
  {
    "doc_id": "10148553",
    "abstract_original": "With the worldwide momentum of promoting computational thinking (CT) education, greater attention has been received on assessing learning effects in both cognitive and attitudinal aspects. However, the cross-lagged relations between the two were unknown. This study investigated the cross-lagged association between CT cognitive performance and attitudinal beliefs of primary students through a three-wave longitudinal design. The paper reported the first two waves of data collection, with an 8-month time interval, involving a sample of 392 students (age 9-11). At each wave, students were asked to complete a CT cognitive test and a self-reported attitude survey. Through cross-lagged analyses, the results showed that prior CT cognitive performance significantly predicted later learning attitudes, and the paths remained significant after controlling for students’ demographics and learning experiences. The study contributes to the literature by pioneering documenting the cross-lagged relations between students’ cognitive and attitudinal attainments in the context of CT education.",
    "abstract_processed": "worldwid momentum promot comput think ct educ greater attent receiv assess learn effect cognit attitudin aspect howev cross lag relat two unknown studi investig cross lag associ ct cognit perform attitudin belief primari student three wave longitudin design paper report first two wave data collect month time interv involv sampl student age wave student ask complet ct cognit test self report attitud survey cross lag analys result show prior ct cognit perform significantli predict later learn attitud path remain signific control students’ demograph learn experi studi contribut literatur pioneer document cross lag relat students’ cognit attitudin attain context ct educ"
  },
  {
    "doc_id": "10148557",
    "abstract_original": "As Computational Thinking (CT) becomes an increasingly necessary skill, it is crucial to examine how CT can be taught in the classroom. Pedagogical Content Knowledge (PCK) is a practical concept to examine how CT education can be developed. This systematic literature review presents the discussion of K-8 teachers’ PCK in the implementation of CT- related activities in the classroom. Studies were extracted from Google Scholar’s database. Among these studies, 14 articles were deemed to be relevant for a more in-depth examination. Findings from this preliminary literature review suggest that teachers have clear purposes and goals for teaching CT and various instructional strategies for teaching CT. However, the existing studies lacked information about teachers’ knowledge and beliefs regarding the methods for assessing students’ CT. Practical implications and future directions to enhance K-8 teachers’ PCK on CT are discussed in this study.",
    "abstract_processed": "comput think ct becom increasingli necessari skill crucial examin ct taught classroom pedagog content knowledg pck practic concept examin ct educ develop systemat literatur review present discuss k teachers’ pck implement ct relat activ classroom studi extract googl scholar’ databas among studi articl deem relev depth examin find preliminari literatur review suggest teacher clear purpos goal teach ct variou instruct strategi teach ct howev exist studi lack inform teachers’ knowledg belief regard method assess students’ ct practic implic futur direct enhanc k teachers’ pck ct discuss studi"
  },
  {
    "doc_id": "10151565",
    "abstract_original": "Depigmentation of the skin is a primary symptom of the vitiligo disorder. By reducing their self-esteem and causing them psychological distress, it lowers patients’ quality of life. The study made use of a number of computational tools, including Cyto Hubba, BioVia Discovery Studio through, Open babel, Drug bank, Avogadro, Auto dock, and Protein-Interaction Ligand profiler. The interaction between 6AAH and (Myristic acid, Heptadecanoic acid, Riboflavin, Propanol, 2,6-Dimethyl-7-octene-2,3,6-trio1) has been examined in this study using Cyto Hubba and PILP clustering interactions, followed by Molecular Docking of Protein and Ligand. Due to its polygenic nature, vitiligo is frequently associated with a number of autoimmune or autoinflammatory disorders, including thyroid disease, psoriasis, atopic dermatitis, diabetes mellitus, and pernicious anaemia. Hence, it is conceivable to think about riboflavin as a possible drug for Vitiligo treatment. The findings imply that riboflavin laboratory tests reveal its inhibitory potential on skin depigmentation",
    "abstract_processed": "depigment skin primari symptom vitiligo disord reduc self esteem caus psycholog distress lower patients’ qualiti life studi made use number comput tool includ cyto hubba biovia discoveri studio open babel drug bank avogadro auto dock protein interact ligand profil interact aah myrist acid heptadecano acid riboflavin propanol dimethyl octen trio examin studi use cyto hubba pilp cluster interact follow molecular dock protein ligand due polygen natur vitiligo frequent associ number autoimmun autoinflammatori disord includ thyroid diseas psoriasi atop dermat diabet mellitu pernici anaemia henc conceiv think riboflavin possibl drug vitiligo treatment find impli riboflavin laboratori test reveal inhibitori potenti skin depigment"
  },
  {
    "doc_id": "10152154",
    "abstract_original": "Supported by a state grant, our team of researchers (consisting of both Computer Science faculty and Teacher Education faculty) is offering a series of Professional Development sessions to K-8 teachers. These Professional Development (or PD) sessions are meant to help K-8 teachers develop their understanding of core computing concepts (such as algorithms, programming, data analysis, and networks) and thereby develop strong computer science programs for their students. In order to offer effective and meaningful Professional Development (PD) sessions, our research team first intended to understand the perceptions and experiences of K-8 teachers about Computer Science (CS) and Computational Thinking (CT) education. This paper presents the results of a K-8 teacher survey that we conducted as a pre-cursor to our PD series. The results of this survey provided valuable insights about elementary and middle-school teachers' perceptions of computer science education, self-perception of their ability to teach and learn CS, and understanding of CS discipline and those who typically engage in CS activities. The impact of teachers' perceptions impact how leaders in education and the CS industry can meet the needs of teachers, who in turn can meet the growing demand of CS education in K-8 schools.",
    "abstract_processed": "support state grant team research consist comput scienc faculti teacher educ faculti offer seri profession develop session k teacher profession develop pd session meant help k teacher develop understand core comput concept algorithm program data analysi network therebi develop strong comput scienc program student order offer effect meaning profession develop pd session research team first intend understand percept experi k teacher comput scienc cs comput think ct educ paper present result k teacher survey conduct pre cursor pd seri result survey provid valuabl insight elementari middl school teacher percept comput scienc educ self percept abil teach learn cs understand cs disciplin typic engag cs activ impact teacher percept impact leader educ cs industri meet need teacher turn meet grow demand cs educ k school"
  },
  {
    "doc_id": "10156061",
    "abstract_original": "Reinforcement learning (RL) is effective in optimizing cumulative rewards, and it provides policies that account for how the system will interact over the future with the agent. However, when more than one learning agents are present, developing efficient collaborations/interactions is a challenging issue; not every agent may have access to the same amount of information and computational resources; not every agent may make the same assumptions about the decision-making mechanisms of one another; and many agents may not even be aware of the existence of other agents. These cognitive and physical limitations can be seen as a form of bounded rationality. Several recent experimental and empirical studies have found that the initial responses of decision-makers in multi-player games are often far from the equilibrium, which is very often out-predicted by structural non-equilibrium (e.g., cognitive hierarchy) models. This is because non-equilibrium play models allow for players who are boundedly rational and have limited information, so that their policy is not necessarily a best response to the actual adjustment laws of other agents. This tutorial talk will present computationally and communicationally efficient approaches for decision-making in boundedly rational stochastic games. Motivated by the inherent complexity of computing Nash equilibria, as well as the innate tendency of agents to choose non-equilibrium strategies, two models of bounded rationality based on recursive reasoning will be described. In the first model, named level-k thinking, each agent assumes that everyone else has a cognitive level immediately lower than theirs, and—given such an assumption—chooses their policy to be a best response to them. In the second model, named cognitive hierarchy, each agent conjectures that the rest of the agents have a cognitive level that is lower than theirs, but follows a distribution instead of being deterministic. To explicitly compute the boundedly rational policies, this tutorial talk will present both a level-recursive as well as a level-paralleled algorithm, where the latter can have an overall reduced computational complexity. For more information please see the main tutorial paper [1].",
    "abstract_processed": "reinforc learn rl effect optim cumul reward provid polici account system interact futur agent howev one learn agent present develop effici collabor interact challeng issu everi agent may access amount inform comput resourc everi agent may make assumpt decis make mechan one anoth mani agent may even awar exist agent cognit physic limit seen form bound ration sever recent experiment empir studi found initi respons decis maker multi player game often far equilibrium often predict structur non equilibrium e g cognit hierarchi model non equilibrium play model allow player boundedli ration limit inform polici necessarili best respons actual adjust law agent tutori talk present comput commun effici approach decis make boundedli ration stochast game motiv inher complex comput nash equilibria well innat tendenc agent choos non equilibrium strategi two model bound ration base recurs reason describ first model name level k think agent assum everyon els cognit level immedi lower and—given assumption—choos polici best respons second model name cognit hierarchi agent conjectur rest agent cognit level lower follow distribut instead determinist explicitli comput boundedli ration polici tutori talk present level recurs well level parallel algorithm latter overal reduc comput complex inform pleas see main tutori paper"
  },
  {
    "doc_id": "10156712",
    "abstract_original": "We live in the age of Artificial Intelligence (AI) which permeates all aspects of our lives, from spam filtering to image classification on social media. While it is already well-established in industries ranging from heavy manufacturing to the IT field, its impact on the design professions remains relatively unexplored. This essay explores the use of neural networks in architecture, which is arguably the first genuinely 21st-century design technique and discusses experiments with Generative Adversarial Networks (GANs) to generate unexplored futuristic possible noble forms in architecture. In this way this paper also raises the question if machine can generate noble forms through its creative data optimization process. In this process one of the most famous heritages building of Bangladesh 60 dome mosque (Shat Gombuj Moshjid) has been examined to get expected result. Furthermore, this paper discusses how AI can be used as a personalized tool for architects to generate and express design ideas. It evaluates popular datasets for architectural purposes and considers the potential outcomes of experiments. The input of AI in the design process could usher in a new era of architectural design. As data continues to grow, it is shaping our collective future. Therefore, this paper concludes that it is essential to prepare our trained datasets to accept the future which might open up an extraordinary new chapter in the architectural realm.",
    "abstract_processed": "live age artifici intellig ai permeat aspect live spam filter imag classif social media alreadi well establish industri rang heavi manufactur field impact design profess remain rel unexplor essay explor use neural network architectur arguabl first genuin st centuri design techniqu discuss experi gener adversari network gan gener unexplor futurist possibl nobl form architectur way paper also rais question machin gener nobl form creativ data optim process process one famou heritag build bangladesh dome mosqu shat gombuj moshjid examin get expect result furthermor paper discuss ai use person tool architect gener express design idea evalu popular dataset architectur purpos consid potenti outcom experi input ai design process could usher new era architectur design data continu grow shape collect futur therefor paper conclud essenti prepar train dataset accept futur might open extraordinari new chapter architectur realm"
  },
  {
    "doc_id": "10158192",
    "abstract_original": "The application of virtual reality technology for landscape planning and design, designers will have a more intuitive and interactive space experience, but also better reflect the authenticity of the landscape scene, so as to help designers constantly improve the design scheme. In addition, through the virtual reality system, the audience can watch the scheme design from multiple angles, which not only deepens the understanding of the designer’s design intention, but also makes them feel as if they are on the scene. This paper takes virtual reality technology as the research object and focuses on its specific application in assisting landscape planning and design. Firstly, the literature on computer aided technology and its application at home and abroad is analyzed and studied. It also introduces modern landscape planning and design, including the thinking of landscape planning and design, advantages of computer-aided landscape planning and design and related design software. Secondly, the concept and theory of virtual reality technology are simply analyzed, and the application of virtual reality technology in each stage of landscape architecture is analyzed, and the key technologies of virtual reality technology assisted landscape architecture design are introduced emphatically. Thirdly, it introduces the software of landscape planning and design assisted by virtual reality technology, and analyzes its practical application, such as SketchUp modeling technology, Lumion3D technology and baking technology. Finally, from the actual case, the specific operation of landscape architecture design assisted by virtual reality technology is analyzed and studied.",
    "abstract_processed": "applic virtual realiti technolog landscap plan design design intuit interact space experi also better reflect authent landscap scene help design constantli improv design scheme addit virtual realiti system audienc watch scheme design multipl angl deepen understand designer’ design intent also make feel scene paper take virtual realiti technolog research object focus specif applic assist landscap plan design firstli literatur comput aid technolog applic home abroad analyz studi also introduc modern landscap plan design includ think landscap plan design advantag comput aid landscap plan design relat design softwar secondli concept theori virtual realiti technolog simpli analyz applic virtual realiti technolog stage landscap architectur analyz key technolog virtual realiti technolog assist landscap architectur design introduc emphat thirdli introduc softwar landscap plan design assist virtual realiti technolog analyz practic applic sketchup model technolog lumion technolog bake technolog final actual case specif oper landscap architectur design assist virtual realiti technolog analyz studi"
  },
  {
    "doc_id": "10158548",
    "abstract_original": "In the competitive economy of the 21st century, innovation and the attitude to innovation are key factors. The depletion of traditional natural resources in today’s fast-changing world has virtually eliminated the former engine of economic growth, and a new approach is needed to enable economic actors to cope with the new environment. New solutions are the only way to overcome the anomaly of natural resources. It is essential that all economic actors, from micro to large enterprises, can play their part in this process. It is therefore of the utmost importance that the conditions are created in the near future to promote and stimulate innovation. The aim of this study is to present the Hungarian SME sector’s view on the factors that stimulate innovation, assessing the potential characteristics that can contribute to these processes and behaviours.",
    "abstract_processed": "competit economi st centuri innov attitud innov key factor deplet tradit natur resourc today’ fast chang world virtual elimin former engin econom growth new approach need enabl econom actor cope new environ new solut way overcom anomali natur resourc essenti econom actor micro larg enterpris play part process therefor utmost import condit creat near futur promot stimul innov aim studi present hungarian sme sector’ view factor stimul innov assess potenti characterist contribut process behaviour"
  },
  {
    "doc_id": "10158552",
    "abstract_original": "The events of recent years have shed new light on the crisis and change management practices of economic actors. It has been a truism that actors who are more receptive to change can be more successful and efficient than their peers in business markets. Perhaps the most significant changes in recent years have confirmed this even more. One only has to think of the impact of pandemic COVID-19, the energy crisis or the Russian-Ukrainian conflict. In a very short period of time, these events have brought about very significant changes and their impact has been largely negative for most economic actors. If it has not been sufficiently understood so far why it can be important to adapt to changes in a timely and appropriate way, or why good crisis management practices can be important, perhaps everyone will now. Meanwhile, other trends are shaping the global economy and will have an impact on the future state of the economy and society. Examples include sustainability (or the green transition) and digitalisation. Two global changes that will certainly have a long-term impact on society and business processes. No one can afford the luxury of ignoring these changes. What is more, the most competitive economic players are seeking to turn them to their advantage and to reap the benefits of sustainability or digitalisation. It is clear that our world has become faster and more complex than ever before. More and more things are changing around us, with ever more intense consequences. We need to recognise in time how we can respond to changing environmental conditions or circumstances. This is the subject of the present paper, which, after a brief literature review, draws on research findings to illustrate the importance and relevance of digitalisation.",
    "abstract_processed": "event recent year shed new light crisi chang manag practic econom actor truism actor recept chang success effici peer busi market perhap signific chang recent year confirm even one think impact pandem covid energi crisi russian ukrainian conflict short period time event brought signific chang impact larg neg econom actor suffici understood far import adapt chang time appropri way good crisi manag practic import perhap everyon meanwhil trend shape global economi impact futur state economi societi exampl includ sustain green transit digitalis two global chang certainli long term impact societi busi process one afford luxuri ignor chang competit econom player seek turn advantag reap benefit sustain digitalis clear world becom faster complex ever thing chang around us ever intens consequ need recognis time respond chang environment condit circumst subject present paper brief literatur review draw research find illustr import relev digitalis"
  },
  {
    "doc_id": "10158582",
    "abstract_original": "Aim of the study is to show the importance and necessity of the course “Philosophy” in a medical university. This study elaborates on the philosophy role in the educational, humanizing aspect in the formation of a holistic personality of the future doctors. Questions about “crisis” of philosophy in medicine, a new scientific cognitive system creation necessity, ethical aspects in medicine, Mathematical modeling of moral structures represented. The ideological atmosphere in which the formation of the personality of a doctor is carried out today is influenced by the latest trends associated with the latest achievements in the field of biotechnology, which can even generate threats and risks to the biological nature of man.",
    "abstract_processed": "aim studi show import necess cours “philosophy” medic univers studi elabor philosophi role educ human aspect format holist person futur doctor question “crisis” philosophi medicin new scientif cognit system creation necess ethic aspect medicin mathemat model moral structur repres ideolog atmospher format person doctor carri today influenc latest trend associ latest achiev field biotechnolog even gener threat risk biolog natur man"
  },
  {
    "doc_id": "10158648",
    "abstract_original": "Our qualitative research was inspired by the 75-year long Harvard University Happiness Survey.In October-November 2022, 65 young marketing undergraduates from Generation Z were asked what value and happiness meant to them. Today’s 20-year-olds were forced to live one tenth of their lives, i.e., 2 years, locked in their homes, isolated from friends and university peers, during the COVID -19 pandemic. Hardly had they recovered from the threat of the pandemic, from their grief, when they were hit by another trauma, as were other members of society. War in neighbouring Ukraine, serious energy crisis, climate crisis, skyrocketing inflation, uncertain future…The focus of the research was therefore on the question of what kind of life they would be satisfied with, and what they would do to achieve the quality of life they want. What goals do they have, what do they want to achieve in their lives? Are human relationships important to them? As our interviewees were marketing students, we asked them if they were happy buying a product or using a service, how important is the experience of buying a product or service to them? How do they think about this topic, what strategy do they want to follow as marketing employees based on their life experiences? Their way of thinking is also decisive at a societal level.",
    "abstract_processed": "qualit research inspir year long harvard univers happi survey octob novemb young market undergradu gener z ask valu happi meant today’ year old forc live one tenth live e year lock home isol friend univers peer covid pandem hardli recov threat pandem grief hit anoth trauma member societi war neighbour ukrain seriou energi crisi climat crisi skyrocket inflat uncertain future…th focu research therefor question kind life would satisfi would achiev qualiti life want goal want achiev live human relationship import interviewe market student ask happi buy product use servic import experi buy product servic think topic strategi want follow market employe base life experi way think also decis societ level"
  },
  {
    "doc_id": "10158658",
    "abstract_original": "With the appearance of 2D graphical user interfaces in the 1980s, users began to carry out most operations on 2D icon-based interfaces instead of using line-based terminals. With the emergence of smartphones in the 2010s, the notion of portable 2D graphical user interfaces was born, and by today, users accessing digital services are no longer tethered to a single location. All of these advances have led to immense changes in our conceptualization of digital information systems, the effects of which are difficult to overestimate. Recent developments in virtual and augmented reality (VR/AR), as well as in Internet of Things (IoT) and artificial intelligence (AI) are poised to lead to the next major breakthrough in this series of cognitive expansions, bringing to the forefront portable, context-aware spatial interfaces. A consequence of these developments is that users are expecting to be able to access a growing multitude and variety of digital content in ways that are increasingly contextualized and personalized, i.e., relevant to the time, location and topic from the perspective of the users’ personal history. In this paper, we propose an adaptive content labeling and storage model that is suitable to these challenges. Our model, called the Graph-Indexed Tensor Store (GITS) has the benefits of being adaptive and personalized, while also allowing for content retrieval to be carried out based on associative search operations. In a preliminary analysis of the model, we address the challenges of what we refer to as syntactic, semantic and pragmatic saturation, and provide ways to quantity and further explore their effects.",
    "abstract_processed": "appear graphic user interfac user began carri oper icon base interfac instead use line base termin emerg smartphon notion portabl graphic user interfac born today user access digit servic longer tether singl locat advanc led immens chang conceptu digit inform system effect difficult overestim recent develop virtual augment realiti vr ar well internet thing iot artifici intellig ai pois lead next major breakthrough seri cognit expans bring forefront portabl context awar spatial interfac consequ develop user expect abl access grow multitud varieti digit content way increasingli contextu person e relev time locat topic perspect users’ person histori paper propos adapt content label storag model suitabl challeng model call graph index tensor store git benefit adapt person also allow content retriev carri base associ search oper preliminari analysi model address challeng refer syntact semant pragmat satur provid way quantiti explor effect"
  },
  {
    "doc_id": "10158668",
    "abstract_original": "Today’s technological developments are also having an impact on education. In higher education, there are more and more innovations in content and methodology, such as educational robots, which can be used not only for teaching programming, but also as teaching assistants and pedagogical assistants. Tutor robots offer new opportunities for curriculum development, motivating students, stimulating interest and developing soft skills, while preparing young people to use the latest technological tools. In our online survey, conducted in summer 2022, we explored the views of educators in 14 countries on the characteristics of robot-supported innovation in higher education. The results of the survey show that educators are open to educational innovations. Educational robots are mainly used for teaching programming. They believe that the use of social robots significantly improves students’ creativity and self-expression. The results of this research have shown that the use of educational social robots is an excellent opportunity for methodological innovation and provides scope for experimental teaching.",
    "abstract_processed": "today’ technolog develop also impact educ higher educ innov content methodolog educ robot use teach program also teach assist pedagog assist tutor robot offer new opportun curriculum develop motiv student stimul interest develop soft skill prepar young peopl use latest technolog tool onlin survey conduct summer explor view educ countri characterist robot support innov higher educ result survey show educ open educ innov educ robot mainli use teach program believ use social robot significantli improv students’ creativ self express result research shown use educ social robot excel opportun methodolog innov provid scope experiment teach"
  },
  {
    "doc_id": "10159750",
    "abstract_original": "Critical and computational thinking in primary and secondary education in recent years shows growing importance in methodical approaches used in the classroom. Although many examples exist for using critical and computational thinking in STEM educational area, the social sciences i.e., non-STEM areas were somehow left out due to the relatively more difficult design of such content, especially in the part of the development of computational thinking. In that context, in this paper we present one way of using critical and computational thinking in non-STEM education, more specifically on the example of historical data sources, through the use of programming in Python. As an example, we use historical data for Trans-Atlantic Slave Trade routes, that were the largest long-distance coerced movement of people in history up to the mid-nineteenth century, for connecting concepts of databases, Data Science and programming for development of critical and computational thinking in context of history science. This way of using modern approaches in classroom should give teachers and pupils a broader picture of importance of interdisciplinary education for critical and computational thinking development through STEM and non-STEM classes that give pupils novel skills needed for future labor market.",
    "abstract_processed": "critic comput think primari secondari educ recent year show grow import method approach use classroom although mani exampl exist use critic comput think stem educ area social scienc e non stem area somehow left due rel difficult design content especi part develop comput think context paper present one way use critic comput think non stem educ specif exampl histor data sourc use program python exampl use histor data tran atlant slave trade rout largest long distanc coerc movement peopl histori mid nineteenth centuri connect concept databas data scienc program develop critic comput think context histori scienc way use modern approach classroom give teacher pupil broader pictur import interdisciplinari educ critic comput think develop stem non stem class give pupil novel skill need futur labor market"
  },
  {
    "doc_id": "10165540",
    "abstract_original": "ChatGPT is a pre-trained model in the field of natural language processing. As a generative model, the technical foundation of ChatGPT is a deep learning model called the \"Generative Adversarial Network\". The pre-trained large model architecture of ChatGPT can be summarized as \"corpus system+pre-training+fine-tuning\". Under the combined force of massive data, super large models, and enormous computing power, chatGPT has ushered in the era of universal artificial intelligence and formed a new paradigm of generative AI development. Generative AI products represented by ChatGPT will promote the development and implementation of Artificial Intelligence Generated Content (AIGC), and trigger significant changes in areas such as information acquisition methods and economic and social cost structures",
    "abstract_processed": "chatgpt pre train model field natur languag process gener model technic foundat chatgpt deep learn model call gener adversari network pre train larg model architectur chatgpt summar corpu system pre train fine tune combin forc massiv data super larg model enorm comput power chatgpt usher era univers artifici intellig form new paradigm gener ai develop gener ai product repres chatgpt promot develop implement artifici intellig gener content aigc trigger signific chang area inform acquisit method econom social cost structur"
  },
  {
    "doc_id": "10168286",
    "abstract_original": "The main aspect powering GNNs is the multi-layer network architecture to learn the nonlinear representation for graph learning task. The core operation in GNNs is the message propagation in which each node updates its information by aggregating the information from its neighbors. Existing GNNs usually adopt either linear neighborhood aggregation (e.g. mean, sum) or max aggregator in their message propagation. 1) For linear aggregators, the whole nonlinearity and network's capacity of GNNs are generally limited because deeper GNNs usually suffer from the over-smoothing issue due to their inherent information propagation mechanism. Also, linear aggregators are usually vulnerable to the spatial perturbations. 2) For max aggregator, it usually fails to be aware of the detailed information of node representations within neighborhood. To overcome these issues, we re-think the message propagation mechanism in GNNs and develop the new general nonlinear aggregators for neighborhood information aggregation in GNNs. One main aspect of our nonlinear aggregators is that they all provide the optimally balanced aggregator between max and mean/sum aggregators. Thus, they can inherit both i) high nonlinearity that enhances network's capacity, robustness and ii) detail-sensitivity that is aware of the detailed information of node representations in GNNs’ message propagation. Promising experiments show the effectiveness, high capacity and robustness of the proposed methods.",
    "abstract_processed": "main aspect power gnn multi layer network architectur learn nonlinear represent graph learn task core oper gnn messag propag node updat inform aggreg inform neighbor exist gnn usual adopt either linear neighborhood aggreg e g mean sum max aggreg messag propag linear aggreg whole nonlinear network capac gnn gener limit deeper gnn usual suffer smooth issu due inher inform propag mechan also linear aggreg usual vulner spatial perturb max aggreg usual fail awar detail inform node represent within neighborhood overcom issu think messag propag mechan gnn develop new gener nonlinear aggreg neighborhood inform aggreg gnn one main aspect nonlinear aggreg provid optim balanc aggreg max mean sum aggreg thu inherit high nonlinear enhanc network capac robust ii detail sensit awar detail inform node represent gnns’ messag propag promis experi show effect high capac robust propos method"
  },
  {
    "doc_id": "10169436",
    "abstract_original": "Suppose that you are the boss of a company and you want to accomplish a specific task through two groups of employees. Where, one group involves old and expert employees and the other consists of young and inexperienced ones. In this case, we think that your best choice is to establish a teamwork from both groups to ensure this mission will be done rapidly with high quality, of course, if the team members could work in consistence with each other. In this research, we are interested in investigating the benefit of applying this concept in search with two groups, one consists of a set of informed algorithms with different complexity based on their search mechanism, and the other group includes a collection of heuristic functions has varying degree of simplicity based on their informedness. The main goal of our study is the distinguishing of work teams that should be used to improve the efficiency of exploring the search space of a sliding-tile puzzle. The actual computational time of our experiments proved that choosing a proper teamwork can rapidly find optimal solutions by professionally exploiting the heuristic informedness and reducing the algorithm complexity.",
    "abstract_processed": "suppos boss compani want accomplish specif task two group employe one group involv old expert employe consist young inexperienc one case think best choic establish teamwork group ensur mission done rapidli high qualiti cours team member could work consist research interest investig benefit appli concept search two group one consist set inform algorithm differ complex base search mechan group includ collect heurist function vari degre simplic base informed main goal studi distinguish work team use improv effici explor search space slide tile puzzl actual comput time experi prove choos proper teamwork rapidli find optim solut profession exploit heurist informed reduc algorithm complex"
  },
  {
    "doc_id": "10169561",
    "abstract_original": "The revolution of the Internet of Things (IoT) is increasing dramatically, where everything has become smart, and this new technology has helped facilitate plenty of things for humanity and made life easier in terms of applications and machines that think like humans using artificial intelligence. Currently, many applications of the Internet of Things affect our daily lives. Although the Internet of Things has brought us ease of life, it has brought many challenges related to security. However, solving these issues and challenges requires a high degree of skills. The approach that addresses the increment of cybercrimes is IoT Forensics. IoT forensics is a call for investigating and mitigating these cybercrimes. In this study, we overview the basics of IoT and present an illustrative study of digital forensics and IoT Forensics, then discussing that with some differences between IoT Forensics, Digital Forensics, and IoT Security, and an overview of the Process of IoT Forensics have been discussed. In addition, this work focuses on recent research work from 2018 onwards in terms of IoT Forensics models, frameworks, analysis, and use cases; finally, IoT and Digital Forensics Challenges and open issues have been discussed.",
    "abstract_processed": "revolut internet thing iot increas dramat everyth becom smart new technolog help facilit plenti thing human made life easier term applic machin think like human use artifici intellig current mani applic internet thing affect daili live although internet thing brought us eas life brought mani challeng relat secur howev solv issu challeng requir high degre skill approach address increment cybercrim iot forens iot forens call investig mitig cybercrim studi overview basic iot present illustr studi digit forens iot forens discuss differ iot forens digit forens iot secur overview process iot forens discuss addit work focus recent research work onward term iot forens model framework analysi use case final iot digit forens challeng open issu discuss"
  },
  {
    "doc_id": "10170028",
    "abstract_original": "Learning how to program has become a trend in Taiwan even for younger students. IoT is a topic to interest new learners in programming. Given the fact that there are already plenty of tools e.g. Micro:bit and Arduino designed to make IoT programming simple and full of fun, it is usually believed that adopting IoT topics is beneficial for younger students learning how to program. However, younger students’ learning performance in programming courses varies dramatically depending on the tools mentioned above. There are many metrics to predict the academic achievements of young students. Among them, the operation span is an objective one. Operation span mainly assesses one’s working memory capacity. According to the research results, one’s working memory capacity predicts individual high-level cognitive performance. Furthermore, students’ cognitive performance was highly related to their learning performance in programming courses. Nevertheless, the relationship between operation span and the learning performance of programming courses for junior high school students has not been researched yet. In Taiwan, computer programming has already been included as a mandatory subject in the junior high school curriculum for developing students' computational thinking and problem-solving skills. As such, understanding the relationship between OSPAN and programming performance is crucial for effective teaching and learning in this subject. We designed an experiment for an IoT-related after-school club in a junior high school to evaluate the relationship between students’ operation span and learning performance.",
    "abstract_processed": "learn program becom trend taiwan even younger student iot topic interest new learner program given fact alreadi plenti tool e g micro bit arduino design make iot program simpl full fun usual believ adopt iot topic benefici younger student learn program howev younger students’ learn perform program cours vari dramat depend tool mention mani metric predict academ achiev young student among oper span object one oper span mainli assess one’ work memori capac accord research result one’ work memori capac predict individu high level cognit perform furthermor students’ cognit perform highli relat learn perform program cours nevertheless relationship oper span learn perform program cours junior high school student research yet taiwan comput program alreadi includ mandatori subject junior high school curriculum develop student comput think problem solv skill understand relationship ospan program perform crucial effect teach learn subject design experi iot relat school club junior high school evalu relationship students’ oper span learn perform"
  },
  {
    "doc_id": "10170138",
    "abstract_original": "The field of machine learning and artificial intelligence is growing rapidly. The deep neural network is a field of ML which is showing greater possibility. The deep neural network has been widely acknowledged as being in a golden age and advancing with the advent of new technologies. It is slowly becoming the leader of the technological world in artificial intelligence. The models which are built by machine learning algorithms with great accuracy help in every sector of human evolution. Image and audio processing is done through many algorithms to intensify its behavioral pattern. The development of modern art is largely dependent on the painters who are developing the style. The Deep Dream algorithm can also do the artistic creation of the image and audio. The deep dream algorithm which googles engineer Alexander Mordvintsevin built in the year 2015. It enhances the patterns in the multimedia through algorithmic pareidolia. It creates a dream-like effect. It gives a new vision of hallucinations to images. This could be used in the health sector for the purpose of detecting diseases and defects through scans of the patients. It is redefining lower-definition multimedia to higher-definition multimedia. Previous model were able to only generate one of the multimedia format. Proposed system will be able to create multimedia based on DeepDream and link different formats together so that they appear to be generated together.",
    "abstract_processed": "field machin learn artifici intellig grow rapidli deep neural network field ml show greater possibl deep neural network wide acknowledg golden age advanc advent new technolog slowli becom leader technolog world artifici intellig model built machin learn algorithm great accuraci help everi sector human evolut imag audio process done mani algorithm intensifi behavior pattern develop modern art larg depend painter develop style deep dream algorithm also artist creation imag audio deep dream algorithm googl engin alexand mordvintsevin built year enhanc pattern multimedia algorithm pareidolia creat dream like effect give new vision hallucin imag could use health sector purpos detect diseas defect scan patient redefin lower definit multimedia higher definit multimedia previou model abl gener one multimedia format propos system abl creat multimedia base deepdream link differ format togeth appear gener togeth"
  },
  {
    "doc_id": "10171767",
    "abstract_original": "Operational risk analysis of the Protections and Automations used in Power Systems is analyzed with the help of a composite model using Fuzzy Sets-Event Tree Stochastic model. On this purpose we built a complex algorithm and computer application, and we made the configuration of the analyzed system. We exemplified the analysis algorithm for the study case of the power electric protection system-SP for the example of the very used radial distribution and curled distribution. The paper exemplifies the critical analysis of the faults including abnormal workings. The most important power elements need the risk analysis, and its random events adopt with success the Fuzzy logic which is added to the Event Tree method. This allows us to build the realistic model performance-dependability, so important technical operational Risk results are computed.",
    "abstract_processed": "oper risk analysi protect autom use power system analyz help composit model use fuzzi set event tree stochast model purpos built complex algorithm comput applic made configur analyz system exemplifi analysi algorithm studi case power electr protect system sp exampl use radial distribut curl distribut paper exemplifi critic analysi fault includ abnorm work import power element need risk analysi random event adopt success fuzzi logic ad event tree method allow us build realist model perform depend import technic oper risk result comput"
  },
  {
    "doc_id": "10172317",
    "abstract_original": "Multihop reasoning is essential in knowledge graph (KG) research and applications. Current methods rely on specific KG entities, while human cognition operates at a more abstract level. This article proposes a category-aware rule-based (CRule) approach for symbolic multihop reasoning. Specifically, given a KG, CRule first categorizes entities and constructs a category-aware KG; it then uses rules retrieved from the categorized KG to perform multihop reasoning on the original KG. Experiments on five datasets show that CRule is simple, is effective, and combines the advantages of symbolic and neural network methods. It overcomes symbolic reasoning’s complexity limitations, can perform reasoning on KGs of more than 300,000 edges, and can be three times more efficient than neural network models.",
    "abstract_processed": "multihop reason essenti knowledg graph kg research applic current method reli specif kg entiti human cognit oper abstract level articl propos categori awar rule base crule approach symbol multihop reason specif given kg crule first categor entiti construct categori awar kg use rule retriev categor kg perform multihop reason origin kg experi five dataset show crule simpl effect combin advantag symbol neural network method overcom symbol reasoning’ complex limit perform reason kg edg three time effici neural network model"
  },
  {
    "doc_id": "10173917",
    "abstract_original": "Software engineering for mobile applications has its own challenges, different from when we engineer software just for desktop environments. With the emergence of smart things (including smart everyday objects embedded with connectivity, computational ability, sensors, and sometimes actuators, urban robots such as delivery and cleaning robots, smart street lighting, smart vehicles, and smart park benches, and so on) not just within the home but in public spaces, there is a need to consider software engineering challenges for software on such things. Human-centred software engineering and work on ethical behaviours in smart things will need to come together, even as we continue to understand what it takes to effectively develop software (and systems) for such emerging devices. In order to demonstrate how software (and systems) for intelligent devices in public places might be developed, findings from a quantitative survey we performed are discussed in this study. The survey was designed such that the questions focused on the socio-ethical behaviours of smart devices when interacting with people in public places. The survey was based on a supermarket scenario where the participants had to answer the different questions in the questionnaire. There were 250 participants who only completed part of the survey; of them, 60 participants finished it in full. The complete replies have been examined and analysed in this paper. To determine how people feel about employing smart technology in public places, a variety of smart devices, including robots, smart cameras, smart speakers, and smart trolleys, are utilised in the survey questions. According to the findings, more than 80 percent of respondents think it important for smart gadgets to be socially-aware and ethical in public places.General Abstract This paper examines the survey results conducted to explore if smart devices such as robots or smart cameras can be deployed in public areas. The respondents reply to survey questions asking them whether they believe it is crucial to keep smart robots, smart carts, or any other smart devices in the supermarket. The survey’s questions are constructed in such a manner that participants are asked to imagine themselves as either a customer shopping for groceries at a store or a manager running the business and dealing with the friendly robot. This survey was created with the intention of thinking carefully about how intelligent software systems may be designed from the standpoint of software engineering for public settings. Later in this article, the survey findings and insights are discussed.",
    "abstract_processed": "softwar engin mobil applic challeng differ engin softwar desktop environ emerg smart thing includ smart everyday object embed connect comput abil sensor sometim actuat urban robot deliveri clean robot smart street light smart vehicl smart park bench within home public space need consid softwar engin challeng softwar thing human centr softwar engin work ethic behaviour smart thing need come togeth even continu understand take effect develop softwar system emerg devic order demonstr softwar system intellig devic public place might develop find quantit survey perform discuss studi survey design question focus socio ethic behaviour smart devic interact peopl public place survey base supermarket scenario particip answer differ question questionnair particip complet part survey particip finish full complet repli examin analys paper determin peopl feel employ smart technolog public place varieti smart devic includ robot smart camera smart speaker smart trolley utilis survey question accord find percent respond think import smart gadget social awar ethic public place gener abstract paper examin survey result conduct explor smart devic robot smart camera deploy public area respond repli survey question ask whether believ crucial keep smart robot smart cart smart devic supermarket survey’ question construct manner particip ask imagin either custom shop groceri store manag run busi deal friendli robot survey creat intent think care intellig softwar system may design standpoint softwar engin public set later articl survey find insight discuss"
  },
  {
    "doc_id": "10179136",
    "abstract_original": "Recent advances in text-conditioned generative models have provided us with neural networks capable of creating images of astonishing quality, be they realistic, abstract, or even creative. These models have in common that (more or less explicitly) they all aim to produce a high-quality one-off output given certain conditions, and in that they are not well suited for a creative collaboration framework. Drawing on theories from cognitive science that model how professional designers and artists think, we argue how this setting differs from the former and introduce CICADA: a Collaborative, Interactive Context-Aware Drawing Agent. CICADA uses a vector-based synthesis-by-optimisation method to take a partial sketch (such as might be provided by a user) and develop it towards a goal by adding and/or sensibly modifying traces. Given that this topic has been scarcely explored, we also introduce a way to evaluate desired characteristics of a model in this context by means of proposing a diversity measure. CICADA is shown to produce sketches of quality comparable to a human user’s, enhanced diversity and most importantly to be able to cope with change by continuing the sketch minding the user's contributions in a flexible manner.",
    "abstract_processed": "recent advanc text condit gener model provid us neural network capabl creat imag astonish qualiti realist abstract even creativ model common less explicitli aim produc high qualiti one output given certain condit well suit creativ collabor framework draw theori cognit scienc model profession design artist think argu set differ former introduc cicada collabor interact context awar draw agent cicada use vector base synthesi optimis method take partial sketch might provid user develop toward goal ad sensibl modifi trace given topic scarc explor also introduc way evalu desir characterist model context mean propos divers measur cicada shown produc sketch qualiti compar human user’ enhanc divers importantli abl cope chang continu sketch mind user contribut flexibl manner"
  },
  {
    "doc_id": "10179639",
    "abstract_original": "Thinking about life without using the internet is impossible. Internet and network have become a part of our daily life. Sharing confidential information through internet and doing lots of important and confidential official work is done easily by using internet. One side internet has made life easy and another side is it cheap and fast compare to other methods such as letter or fax. With the growing technology some third party cybercriminals and hackers are trying to use the internet for their personal gain and harm the users or organizations. Malware is one of those malicious software whose sole purpose is to harm the user, system or organization and steal information and sent it to third party for harmful use. It is necessary to find this malicious software and prevent them from harming through the internet. The proposed model detects the harmful malware lurking on the internet and prevent the user and system from any potential harmful effect. The model is very simple and cost effective yet very efficient. the accuracy of the model is 99.72%.",
    "abstract_processed": "think life without use internet imposs internet network becom part daili life share confidenti inform internet lot import confidenti offici work done easili use internet one side internet made life easi anoth side cheap fast compar method letter fax grow technolog third parti cybercrimin hacker tri use internet person gain harm user organ malwar one malici softwar whose sole purpos harm user system organ steal inform sent third parti harm use necessari find malici softwar prevent harm internet propos model detect harm malwar lurk internet prevent user system potenti harm effect model simpl cost effect yet effici accuraci model"
  },
  {
    "doc_id": "10179854",
    "abstract_original": "Due to the advancement of technology network has become a part of our daily life. Thinking about life without network has become impossible. Sharing important and confidential information through network has become common. It is important to maintain the data integrity and confidentiality to maintain the trust on the network. Thus, network need to have strong and strict security. There are lots of criminal and unwanted ways to destroy the data integrity and confidentiality. It is import to prevent and block those illigal ways. This paper focus on Beth dataset. This analysis will give an insight of the Beth dataset. This gives researcher scientist an idea to if they can use this dataset to build strong and efficient anomaly detection model for the network.",
    "abstract_processed": "due advanc technolog network becom part daili life think life without network becom imposs share import confidenti inform network becom common import maintain data integr confidenti maintain trust network thu network need strong strict secur lot crimin unwant way destroy data integr confidenti import prevent block illig way paper focu beth dataset analysi give insight beth dataset give research scientist idea use dataset build strong effici anomali detect model network"
  },
  {
    "doc_id": "10181148",
    "abstract_original": "Graph Neural Networks (GNNs) train neural networks that combine the topological properties of a graph with the vertex and edge features to perform tasks such as node classification and link prediction. We propose a novel middleware that approaches GNN training from the perspective of a vertex-centric model (VCM) of distributed graph processing and overlays neural network training over it. Giraph Graph Neural Network (G2N2) uses a three-phase execution pattern by construction a distributed computation graph per mini-batch, and maps the forward and backward passes of the GNN training to VCM. We implement a prototype of G2N2 in Apache Giraph and report results from a preliminary evaluation using two real-world graphs on a commodity cluster.",
    "abstract_processed": "graph neural network gnn train neural network combin topolog properti graph vertex edg featur perform task node classif link predict propos novel middlewar approach gnn train perspect vertex centric model vcm distribut graph process overlay neural network train giraph graph neural network g n use three phase execut pattern construct distribut comput graph per mini batch map forward backward pass gnn train vcm implement prototyp g n apach giraph report result preliminari evalu use two real world graph commod cluster"
  },
  {
    "doc_id": "10181711",
    "abstract_original": "Currently we see globalization and technological advances accelerating worldwide, transforming the world of work and human coexistence. We still notice that the educational systems, in their majority, are disconnected from these global realities. In this sense, it is necessary to have an educational formation more aligned to the contemporary world, preparing young people for the challenges of the 21st century, how to deal with technological resources and processes, developing soft and hard skills. In this way, it can be observed that in recent years computational thinking has gained relevance in this scenario, being a field of research in the most varied areas of knowledge, developing communication skills, creativity, leadership, problem solving, familiarity with technologies, management, transforming young people into autonomous individuals who are prepared for the technological changes that the world requires. Taking these transformations as a reference, this paper describes/presents the development of an online tool to stimulate computational thinking in elementary school, through online games. he use of the ThinkinGame makes it possible to identify the pillars to be worked on with young people, after its use, thus improving the approaches to be given in the formation of these young people, being able to turn attention to the challenge of teaching additional skills, such as sophisticated thinking and flexible problem solving.",
    "abstract_processed": "current see global technolog advanc acceler worldwid transform world work human coexist still notic educ system major disconnect global realiti sens necessari educ format align contemporari world prepar young peopl challeng st centuri deal technolog resourc process develop soft hard skill way observ recent year comput think gain relev scenario field research vari area knowledg develop commun skill creativ leadership problem solv familiar technolog manag transform young peopl autonom individu prepar technolog chang world requir take transform refer paper describ present develop onlin tool stimul comput think elementari school onlin game use thinkingam make possibl identifi pillar work young peopl use thu improv approach given format young peopl abl turn attent challeng teach addit skill sophist think flexibl problem solv"
  },
  {
    "doc_id": "10182189",
    "abstract_original": "Computational thinking is a fundamental competence for the 21st century. It refers to a set of capacities and skills that can be stimulated to facilitate the teaching-learning process in a wide range of fields, including Science, Technology, Engineering and Mathematics (STEM). Experts in information technology argue that the earlier children are exposed to programming through digital platforms appropriate for their age, the easier it will be for them to assimilate their concepts in the future. This effort should be continued throughout the educational stages of children and youth to increase students' interest in pursuing STEM studies and careers.This paper describes the Scratch4All project promoted by the consortium CASPAE (a Private Social Solidarity Institution) and Inova-Ria, with technical assistance from professors at the public higher education institution Coimbra Institute of Engineering. Scratch4All Project includes the activities Scratch on Road, Programming and Robotics Lab, and the Scratch4All Digital Platform. According to the impact assessment for the school year 2020-2021, the Scratch4All project promotes school success and true equality in access to new technologies for students in the 1st, 2nd, and 3rd cycles of elementary school, developing essential skills for their academic and professional future such as computational thinking, STEM competencies and social skills. By encouraging young girls to participate in technological projects, this project also aims to combat gender stereotypes.",
    "abstract_processed": "comput think fundament compet st centuri refer set capac skill stimul facilit teach learn process wide rang field includ scienc technolog engin mathemat stem expert inform technolog argu earlier children expos program digit platform appropri age easier assimil concept futur effort continu throughout educ stage children youth increas student interest pursu stem studi career paper describ scratch project promot consortium caspa privat social solidar institut inova ria technic assist professor public higher educ institut coimbra institut engin scratch project includ activ scratch road program robot lab scratch digit platform accord impact assess school year scratch project promot school success true equal access new technolog student st nd rd cycl elementari school develop essenti skill academ profession futur comput think stem compet social skill encourag young girl particip technolog project project also aim combat gender stereotyp"
  },
  {
    "doc_id": "10182534",
    "abstract_original": "A person with mild cognitive disability (MCD), a kind of memory loss that affects both memory and thinking skills, may be at an increased risk of acquiring dementia brought on by Alzheimer's disease or other neurological diseases. MCD affects between 13 and 19% of those who are 60 years of age or older. People who suffer from cognitive abnormalities should seek therapy and diagnosis as soon as they can. The major effect of MCD on the target is its effect on memory. Accurate MCD diagnosis is quite challenging with the current approaches. A hybrid approach is put forward in this study to identify MCD at an early stage. EEG data from MCD individuals and healthy controls was collected for this purpose. With the use of machine learning models including Support Vector Machines (SVM), Decision Trees (DT), k-Nearest Neighbour (KNN), and the hybrid approach ACO KNN, Renyi entropy (RE) and Discrete Wavelet Transform (DWT) characteristics were retrieved (combined Ant Colony Optimisation with k-Nearest Neighbour). The performance of the system is assessed based on an accuracy comparison with machine learning models. When compared to other models, RE and ACO KNN had an accuracy of 85.0%.",
    "abstract_processed": "person mild cognit disabl mcd kind memori loss affect memori think skill may increas risk acquir dementia brought alzheim diseas neurolog diseas mcd affect year age older peopl suffer cognit abnorm seek therapi diagnosi soon major effect mcd target effect memori accur mcd diagnosi quit challeng current approach hybrid approach put forward studi identifi mcd earli stage eeg data mcd individu healthi control collect purpos use machin learn model includ support vector machin svm decis tree dt k nearest neighbour knn hybrid approach aco knn renyi entropi discret wavelet transform dwt characterist retriev combin ant coloni optimis k nearest neighbour perform system assess base accuraci comparison machin learn model compar model aco knn accuraci"
  },
  {
    "doc_id": "10182654",
    "abstract_original": "Internet of Medical Things (IoMT) is gaining interest as an emerging paradigm for healthcare improvement. Cyber-security is one of the major issues breaking down its expansion. Indeed, IoMT ecosystem complexities and cyber-attacks development require thinking about smart and efficient security solutions. Machine Learning (ML) techniques are widely used to help detecting abnormalities and intrusions in such environments in order to improve trustworthiness in Connected Medical Devices (CMD). Towards this direction, risk assessment is also proposed to proactively evaluate the security of such platforms. Regarding the complexity and heterogeneity of IoMT, dealing with the inherent security risks is a challenging task. In this context, we aim to evaluate the cumulative risk of CMD based on anomaly detection in IoMT traffic via ML algorithms. Our model relies on anomalies detection coupled with intrinsic risk assessment of medical devices trying to have a holistic risk evaluation for the platform.",
    "abstract_processed": "internet medic thing iomt gain interest emerg paradigm healthcar improv cyber secur one major issu break expans inde iomt ecosystem complex cyber attack develop requir think smart effici secur solut machin learn ml techniqu wide use help detect abnorm intrus environ order improv trustworthi connect medic devic cmd toward direct risk assess also propos proactiv evalu secur platform regard complex heterogen iomt deal inher secur risk challeng task context aim evalu cumul risk cmd base anomali detect iomt traffic via ml algorithm model reli anomali detect coupl intrins risk assess medic devic tri holist risk evalu platform"
  },
  {
    "doc_id": "10182738",
    "abstract_original": "The successful distribution of computer services, including software, storage needs, analytics, intelligence, and many others, is reflected in cloud computing. Additionally, it provides quicker innovation while simultaneously providing flexible resources.Deep learning (DL), a subset of artificial intelligence (AI) and machine learning, is widely seen as a key technology of the Fourth Industrial Revolution (4IR or Industry 4.0). The artificial neural network (ANN)-based technique known as deep learning (DL) has gained popularity in the computing world due to its capacity for learning from data. frequently used in a variety of application fields, including cybersecurity, healthcare, visual recognition, and many more. However, because of the dynamic nature and differences in real-world environments, creating an acceptable DL model is a difficult process. issues and information Additionally, because of a lack of fundamental knowledge, DL techniques become black-box devices that hinder standard level progress.A cloud computing system in an organization offers high data security at a cheap maintenance cost. Business cooperation has increased significantly as a result of cloud technology. Use of AI has enhanced each of those procedures. The use of artificial intelligence in certain industries has a considerable impact on how successful cloud services techniques are, resulting in a consequence, the two innovations' cumulative effect boosts the prosperity of such businesses. The use of smart - device and computer vision models improve the effectiveness of public clouds. It has also demonstrated implementing AI into public cloud strategies may benefit enterprises in a variety of ways.This essay includes a thorough introduction and an insightful literature review. Three objectives are outlined in a methodological approach that has also been given.",
    "abstract_processed": "success distribut comput servic includ softwar storag need analyt intellig mani other reflect cloud comput addit provid quicker innov simultan provid flexibl resourc deep learn dl subset artifici intellig ai machin learn wide seen key technolog fourth industri revolut ir industri artifici neural network ann base techniqu known deep learn dl gain popular comput world due capac learn data frequent use varieti applic field includ cybersecur healthcar visual recognit mani howev dynam natur differ real world environ creat accept dl model difficult process issu inform addit lack fundament knowledg dl techniqu becom black box devic hinder standard level progress cloud comput system organ offer high data secur cheap mainten cost busi cooper increas significantli result cloud technolog use ai enhanc procedur use artifici intellig certain industri consider impact success cloud servic techniqu result consequ two innov cumul effect boost prosper busi use smart devic comput vision model improv effect public cloud also demonstr implement ai public cloud strategi may benefit enterpris varieti way essay includ thorough introduct insight literatur review three object outlin methodolog approach also given"
  },
  {
    "doc_id": "10183057",
    "abstract_original": "With the introduction of low-cost and widely accessible sensors such as cellphones, drones, satellites, voice recorders, and bio-logging equipment, the amount of information collected about animals has expanded. Meanwhile, modern data processing systems prohibit them from collecting, digesting, and condensing data into usable information. We think that machine learning, especially deep learning algorithms, will be able to tackle this analytical difficulty by enhancing our understanding, monitoring capacities, and animal welfare. By merging machine learning with ecological processes, it may be feasible to expand the inputs to population and behavior models, resulting in integrated hybrid modeling tools where machine learning models give data-supported insights and ecological models act as constraints. Animal ecologists may basically profit from the quantity of data created by contemporary sensor technologies by integrating cutting-edge machine learning methods with ecological domain expertise. This will enable them to assess population abundances more precisely, research animal behavior, and reduce human-wildlife conflicts.",
    "abstract_processed": "introduct low cost wide access sensor cellphon drone satellit voic record bio log equip amount inform collect anim expand meanwhil modern data process system prohibit collect digest condens data usabl inform think machin learn especi deep learn algorithm abl tackl analyt difficulti enhanc understand monitor capac anim welfar merg machin learn ecolog process may feasibl expand input popul behavior model result integr hybrid model tool machin learn model give data support insight ecolog model act constraint anim ecologist may basic profit quantiti data creat contemporari sensor technolog integr cut edg machin learn method ecolog domain expertis enabl assess popul abund precis research anim behavior reduc human wildlif conflict"
  },
  {
    "doc_id": "10183290",
    "abstract_original": "In a number of tasks for assessing natural and medical prints, deep neural networks have bettered humans. These achievements, however, are solely reliant on properly labelled training data. When presented with a few samples of noisy-labelled images, the network training strategy might encounter difficulties, resulting in a suboptimal classification models. The quality of medical picture annotations strongly depends on the knowledge and experience of the annotators, which makes this difficulty more acute in the context of medical image analysis. Such problem arises due to a number of reasons ranging from human error, inexperience or even misreading of the images. But at the same time, proper labels are exceptionally useful in training models, while improperly labelled data actually hampers the efficiency of the model. Label for a lot of the image dataset out there is actually already generated, but when we think about the noisy labelled data and go for an unsupervised learning model instead of a supervised model the labels that are correct are also going to waste. To solve this problem without wasting labels, a sparsely supervised learning strategy based on transfer learning is constructed with the aid of the keras Xception model. This paper compares the efficiency of a sparsely supervised learning model employing transfer learning to that of other traditional CNN models based on their performance metrics.",
    "abstract_processed": "number task assess natur medic print deep neural network better human achiev howev sole reliant properli label train data present sampl noisi label imag network train strategi might encount difficulti result suboptim classif model qualiti medic pictur annot strongli depend knowledg experi annot make difficulti acut context medic imag analysi problem aris due number reason rang human error inexperi even misread imag time proper label except use train model improperli label data actual hamper effici model label lot imag dataset actual alreadi gener think noisi label data go unsupervis learn model instead supervis model label correct also go wast solv problem without wast label spars supervis learn strategi base transfer learn construct aid kera xception model paper compar effici spars supervis learn model employ transfer learn tradit cnn model base perform metric"
  },
  {
    "doc_id": "10183482",
    "abstract_original": "Story Generation through Deep Learning is a fascinating area of research in Artificial Intelligence that aims to create computer systems that can produce original and compelling narratives and is an interesting concept that has flourished in the domain of Machine Learning applications starting from 2018. Most of the research carried out in this specific area has shown advances in Modelling and efficiency of story generation. However, some of the setbacks in Artificial Story Generation include little to no coherency with human generating pattern, tokens/words limitation, missing plot twists and direction of story. In this paper, we have performed a comparative study on Automatic Story Generation as well as the proposed scheme of this paper has main focus on generating a meaningful story with the help of conditional text generation using keywords upto five hundred words by optimizing hugging face generative pre trained model Version Two catering towards the problem of coherency in the text generated. As a result each sentence is semantically coherent and the first three sentences are indeed related to the title itself. The experimental results show a BLEU score of 0.704 averaging over ten genres.",
    "abstract_processed": "stori gener deep learn fascin area research artifici intellig aim creat comput system produc origin compel narr interest concept flourish domain machin learn applic start research carri specif area shown advanc model effici stori gener howev setback artifici stori gener includ littl coher human gener pattern token word limit miss plot twist direct stori paper perform compar studi automat stori gener well propos scheme paper main focu gener meaning stori help condit text gener use keyword upto five hundr word optim hug face gener pre train model version two cater toward problem coher text gener result sentenc semant coher first three sentenc inde relat titl experiment result show bleu score averag ten genr"
  },
  {
    "doc_id": "10183895",
    "abstract_original": "6G is currently under definition, often being addressed from a plain telecommunications perspective as an evolutionary paradigm that represents an extension of 5G. Having as its horizon 2030, 6G initiatives are being deployed across the globe, to further ignite the development of 6G services. In its philosophy core, 6G embodies the &#x201C;human in the loop&#x201D; principle. The research effort aimed at 6G requires an interdisciplinary approach that ignites discussion across different key technological sectors, ranging from communications to services and business cases. The contribution of this book to research in the field concerns an evolutionary and interdisciplinary design of 6G as a paradigm that can be addressed by working together the four different computational areas of CONASENSE: communications; satellites and navigation; sensing; services. This book starts with a perspective on 6G challenges towards sustainability and addressing new business models, moving on to key topics concerning communications. It ends with chapters focusing on 6G service design. This book is, therefore, envisioned to assist in developing critical thinking to back up novel networking, applications, and services towards 6G.",
    "abstract_processed": "g current definit often address plain telecommun perspect evolutionari paradigm repres extens g horizon g initi deploy across globe ignit develop g servic philosophi core g embodi x c human loop x principl research effort aim g requir interdisciplinari approach ignit discuss across differ key technolog sector rang commun servic busi case contribut book research field concern evolutionari interdisciplinari design g paradigm address work togeth four differ comput area conasens commun satellit navig sens servic book start perspect g challeng toward sustain address new busi model move key topic concern commun end chapter focus g servic design book therefor envis assist develop critic think back novel network applic servic toward g"
  },
  {
    "doc_id": "10183901",
    "abstract_original": "6G is currently under definition, often being addressed from a plain telecommunications perspective as an evolutionary paradigm that represents an extension of 5G. Having as its horizon 2030, 6G initiatives are being deployed across the globe, to further ignite the development of 6G services. In its philosophy core, 6G embodies the &#x201C;human in the loop&#x201D; principle. The research effort aimed at 6G requires an interdisciplinary approach that ignites discussion across different key technological sectors, ranging from communications to services and business cases. The contribution of this book to research in the field concerns an evolutionary and interdisciplinary design of 6G as a paradigm that can be addressed by working together the four different computational areas of CONASENSE: communications; satellites and navigation; sensing; services. This book starts with a perspective on 6G challenges towards sustainability and addressing new business models, moving on to key topics concerning communications. It ends with chapters focusing on 6G service design. This book is, therefore, envisioned to assist in developing critical thinking to back up novel networking, applications, and services towards 6G.",
    "abstract_processed": "g current definit often address plain telecommun perspect evolutionari paradigm repres extens g horizon g initi deploy across globe ignit develop g servic philosophi core g embodi x c human loop x principl research effort aim g requir interdisciplinari approach ignit discuss across differ key technolog sector rang commun servic busi case contribut book research field concern evolutionari interdisciplinari design g paradigm address work togeth four differ comput area conasens commun satellit navig sens servic book start perspect g challeng toward sustain address new busi model move key topic concern commun end chapter focus g servic design book therefor envis assist develop critic think back novel network applic servic toward g"
  },
  {
    "doc_id": "10183902",
    "abstract_original": "6G is currently under definition, often being addressed from a plain telecommunications perspective as an evolutionary paradigm that represents an extension of 5G. Having as its horizon 2030, 6G initiatives are being deployed across the globe, to further ignite the development of 6G services. In its philosophy core, 6G embodies the &#x201C;human in the loop&#x201D; principle. The research effort aimed at 6G requires an interdisciplinary approach that ignites discussion across different key technological sectors, ranging from communications to services and business cases. The contribution of this book to research in the field concerns an evolutionary and interdisciplinary design of 6G as a paradigm that can be addressed by working together the four different computational areas of CONASENSE: communications; satellites and navigation; sensing; services. This book starts with a perspective on 6G challenges towards sustainability and addressing new business models, moving on to key topics concerning communications. It ends with chapters focusing on 6G service design. This book is, therefore, envisioned to assist in developing critical thinking to back up novel networking, applications, and services towards 6G.",
    "abstract_processed": "g current definit often address plain telecommun perspect evolutionari paradigm repres extens g horizon g initi deploy across globe ignit develop g servic philosophi core g embodi x c human loop x principl research effort aim g requir interdisciplinari approach ignit discuss across differ key technolog sector rang commun servic busi case contribut book research field concern evolutionari interdisciplinari design g paradigm address work togeth four differ comput area conasens commun satellit navig sens servic book start perspect g challeng toward sustain address new busi model move key topic concern commun end chapter focus g servic design book therefor envis assist develop critic think back novel network applic servic toward g"
  },
  {
    "doc_id": "10183904",
    "abstract_original": "6G is currently under definition, often being addressed from a plain telecommunications perspective as an evolutionary paradigm that represents an extension of 5G. Having as its horizon 2030, 6G initiatives are being deployed across the globe, to further ignite the development of 6G services. In its philosophy core, 6G embodies the &#x201C;human in the loop&#x201D; principle. The research effort aimed at 6G requires an interdisciplinary approach that ignites discussion across different key technological sectors, ranging from communications to services and business cases. The contribution of this book to research in the field concerns an evolutionary and interdisciplinary design of 6G as a paradigm that can be addressed by working together the four different computational areas of CONASENSE: communications; satellites and navigation; sensing; services. This book starts with a perspective on 6G challenges towards sustainability and addressing new business models, moving on to key topics concerning communications. It ends with chapters focusing on 6G service design. This book is, therefore, envisioned to assist in developing critical thinking to back up novel networking, applications, and services towards 6G.",
    "abstract_processed": "g current definit often address plain telecommun perspect evolutionari paradigm repres extens g horizon g initi deploy across globe ignit develop g servic philosophi core g embodi x c human loop x principl research effort aim g requir interdisciplinari approach ignit discuss across differ key technolog sector rang commun servic busi case contribut book research field concern evolutionari interdisciplinari design g paradigm address work togeth four differ comput area conasens commun satellit navig sens servic book start perspect g challeng toward sustain address new busi model move key topic concern commun end chapter focus g servic design book therefor envis assist develop critic think back novel network applic servic toward g"
  },
  {
    "doc_id": "10183906",
    "abstract_original": "6G is currently under definition, often being addressed from a plain telecommunications perspective as an evolutionary paradigm that represents an extension of 5G. Having as its horizon 2030, 6G initiatives are being deployed across the globe, to further ignite the development of 6G services. In its philosophy core, 6G embodies the &#x201C;human in the loop&#x201D; principle. The research effort aimed at 6G requires an interdisciplinary approach that ignites discussion across different key technological sectors, ranging from communications to services and business cases. The contribution of this book to research in the field concerns an evolutionary and interdisciplinary design of 6G as a paradigm that can be addressed by working together the four different computational areas of CONASENSE: communications; satellites and navigation; sensing; services. This book starts with a perspective on 6G challenges towards sustainability and addressing new business models, moving on to key topics concerning communications. It ends with chapters focusing on 6G service design. This book is, therefore, envisioned to assist in developing critical thinking to back up novel networking, applications, and services towards 6G.",
    "abstract_processed": "g current definit often address plain telecommun perspect evolutionari paradigm repres extens g horizon g initi deploy across globe ignit develop g servic philosophi core g embodi x c human loop x principl research effort aim g requir interdisciplinari approach ignit discuss across differ key technolog sector rang commun servic busi case contribut book research field concern evolutionari interdisciplinari design g paradigm address work togeth four differ comput area conasens commun satellit navig sens servic book start perspect g challeng toward sustain address new busi model move key topic concern commun end chapter focus g servic design book therefor envis assist develop critic think back novel network applic servic toward g"
  },
  {
    "doc_id": "10183907",
    "abstract_original": "6G is currently under definition, often being addressed from a plain telecommunications perspective as an evolutionary paradigm that represents an extension of 5G. Having as its horizon 2030, 6G initiatives are being deployed across the globe, to further ignite the development of 6G services. In its philosophy core, 6G embodies the &#x201C;human in the loop&#x201D; principle. The research effort aimed at 6G requires an interdisciplinary approach that ignites discussion across different key technological sectors, ranging from communications to services and business cases. The contribution of this book to research in the field concerns an evolutionary and interdisciplinary design of 6G as a paradigm that can be addressed by working together the four different computational areas of CONASENSE: communications; satellites and navigation; sensing; services. This book starts with a perspective on 6G challenges towards sustainability and addressing new business models, moving on to key topics concerning communications. It ends with chapters focusing on 6G service design. This book is, therefore, envisioned to assist in developing critical thinking to back up novel networking, applications, and services towards 6G.",
    "abstract_processed": "g current definit often address plain telecommun perspect evolutionari paradigm repres extens g horizon g initi deploy across globe ignit develop g servic philosophi core g embodi x c human loop x principl research effort aim g requir interdisciplinari approach ignit discuss across differ key technolog sector rang commun servic busi case contribut book research field concern evolutionari interdisciplinari design g paradigm address work togeth four differ comput area conasens commun satellit navig sens servic book start perspect g challeng toward sustain address new busi model move key topic concern commun end chapter focus g servic design book therefor envis assist develop critic think back novel network applic servic toward g"
  },
  {
    "doc_id": "10183910",
    "abstract_original": "6G is currently under definition, often being addressed from a plain telecommunications perspective as an evolutionary paradigm that represents an extension of 5G. Having as its horizon 2030, 6G initiatives are being deployed across the globe, to further ignite the development of 6G services. In its philosophy core, 6G embodies the &#x201C;human in the loop&#x201D; principle. The research effort aimed at 6G requires an interdisciplinary approach that ignites discussion across different key technological sectors, ranging from communications to services and business cases. The contribution of this book to research in the field concerns an evolutionary and interdisciplinary design of 6G as a paradigm that can be addressed by working together the four different computational areas of CONASENSE: communications; satellites and navigation; sensing; services. This book starts with a perspective on 6G challenges towards sustainability and addressing new business models, moving on to key topics concerning communications. It ends with chapters focusing on 6G service design. This book is, therefore, envisioned to assist in developing critical thinking to back up novel networking, applications, and services towards 6G.",
    "abstract_processed": "g current definit often address plain telecommun perspect evolutionari paradigm repres extens g horizon g initi deploy across globe ignit develop g servic philosophi core g embodi x c human loop x principl research effort aim g requir interdisciplinari approach ignit discuss across differ key technolog sector rang commun servic busi case contribut book research field concern evolutionari interdisciplinari design g paradigm address work togeth four differ comput area conasens commun satellit navig sens servic book start perspect g challeng toward sustain address new busi model move key topic concern commun end chapter focus g servic design book therefor envis assist develop critic think back novel network applic servic toward g"
  },
  {
    "doc_id": "10183912",
    "abstract_original": "6G is currently under definition, often being addressed from a plain telecommunications perspective as an evolutionary paradigm that represents an extension of 5G. Having as its horizon 2030, 6G initiatives are being deployed across the globe, to further ignite the development of 6G services. In its philosophy core, 6G embodies the &#x201C;human in the loop&#x201D; principle. The research effort aimed at 6G requires an interdisciplinary approach that ignites discussion across different key technological sectors, ranging from communications to services and business cases. The contribution of this book to research in the field concerns an evolutionary and interdisciplinary design of 6G as a paradigm that can be addressed by working together the four different computational areas of CONASENSE: communications; satellites and navigation; sensing; services. This book starts with a perspective on 6G challenges towards sustainability and addressing new business models, moving on to key topics concerning communications. It ends with chapters focusing on 6G service design. This book is, therefore, envisioned to assist in developing critical thinking to back up novel networking, applications, and services towards 6G.",
    "abstract_processed": "g current definit often address plain telecommun perspect evolutionari paradigm repres extens g horizon g initi deploy across globe ignit develop g servic philosophi core g embodi x c human loop x principl research effort aim g requir interdisciplinari approach ignit discuss across differ key technolog sector rang commun servic busi case contribut book research field concern evolutionari interdisciplinari design g paradigm address work togeth four differ comput area conasens commun satellit navig sens servic book start perspect g challeng toward sustain address new busi model move key topic concern commun end chapter focus g servic design book therefor envis assist develop critic think back novel network applic servic toward g"
  },
  {
    "doc_id": "10183914",
    "abstract_original": "6G is currently under definition, often being addressed from a plain telecommunications perspective as an evolutionary paradigm that represents an extension of 5G. Having as its horizon 2030, 6G initiatives are being deployed across the globe, to further ignite the development of 6G services. In its philosophy core, 6G embodies the &#x201C;human in the loop&#x201D; principle. The research effort aimed at 6G requires an interdisciplinary approach that ignites discussion across different key technological sectors, ranging from communications to services and business cases. The contribution of this book to research in the field concerns an evolutionary and interdisciplinary design of 6G as a paradigm that can be addressed by working together the four different computational areas of CONASENSE: communications; satellites and navigation; sensing; services. This book starts with a perspective on 6G challenges towards sustainability and addressing new business models, moving on to key topics concerning communications. It ends with chapters focusing on 6G service design. This book is, therefore, envisioned to assist in developing critical thinking to back up novel networking, applications, and services towards 6G.",
    "abstract_processed": "g current definit often address plain telecommun perspect evolutionari paradigm repres extens g horizon g initi deploy across globe ignit develop g servic philosophi core g embodi x c human loop x principl research effort aim g requir interdisciplinari approach ignit discuss across differ key technolog sector rang commun servic busi case contribut book research field concern evolutionari interdisciplinari design g paradigm address work togeth four differ comput area conasens commun satellit navig sens servic book start perspect g challeng toward sustain address new busi model move key topic concern commun end chapter focus g servic design book therefor envis assist develop critic think back novel network applic servic toward g"
  },
  {
    "doc_id": "10184343",
    "abstract_original": "The article considers the possibilities of integrating computer modeling into the process of the formation of probabilistic thinking in teaching mathematics students. We give an example of studying the features of heavy-tailed distributions in comparison with the properties of a normal distribution.",
    "abstract_processed": "articl consid possibl integr comput model process format probabilist think teach mathemat student give exampl studi featur heavi tail distribut comparison properti normal distribut"
  }
]